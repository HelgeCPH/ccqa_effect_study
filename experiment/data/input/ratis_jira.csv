issue_type,issue_component,creator_name,creator_display_name,reporter_name,reporter_display_name,priority,description,labels,created,resolution,updated,status,id,key
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,Just a version bump after the 0.7.0 release of ratis-thirdparty,[],2021-06-14 07:02:33+00:00,,2021-06-14 07:56:57+00:00,Open,13383669,RATIS-1382
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"MetricsRegistriesImpl throws a warning when creating RatisMetricsRegistry without registering any reporters beforehand.
{code:java}
@Override
public RatisMetricRegistry create(MetricRegistryInfo info) {
  return registries.put(info, () -> {
    if (reporterRegistrations.isEmpty()) {
      LOG.warn(
          ""First MetricRegistry has been created without registering reporters. You may need to call"" +
              "" MetricRegistries.global().addReporterRegistration(...) before."");
      StackTraceElement[] stackTrace = Thread.currentThread().getStackTrace();
      for(StackTraceElement element : stackTrace) {
        LOG.warn(""     "" + element.getClassName() + "" - "" + element.getMethodName() + "" - "" +
            element.getLineNumber());
      }
    }
    RatisMetricRegistry registry = factory.create(info);
    reporterRegistrations.forEach(reg -> reg.accept(registry));
    return registry;
  });
}
{code}
This leads to a lot of noise in the logs as every ratis client logs this message. 
{code:java}
21/06/02 12:37:35 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-CBAF50A69A13->24ecdbe1-e8c3-4211-94fc-31429681f184
21/06/02 12:37:35 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:37:40 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1A65382B9313->082aff6d-b8b6-435b-993e-1b3b37b9770b
21/06/02 12:37:40 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:37:44 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-530530878B2F->06c72e97-a5ea-4474-b73c-5642d30ee3cf
21/06/02 12:37:44 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:37:52 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B39FB0CD2151->24ecdbe1-e8c3-4211-94fc-31429681f184
21/06/02 12:37:52 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:37:57 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-12092E53EF9C->082aff6d-b8b6-435b-993e-1b3b37b9770b
21/06/02 12:37:57 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:38:00 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-89C870BA12C6->d5196d6f-753d-4113-87ef-2bfbba66c2af
21/06/02 12:38:00 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:38:03 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A9412DBA8690->06c72e97-a5ea-4474-b73c-5642d30ee3cf
21/06/02 12:38:03 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
21/06/02 12:38:25 INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-49743027A7AD->d5196d6f-753d-4113-87ef-2bfbba66c2af
21/06/02 12:38:25 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
{code}
We can remove the warning message or at the least change it to debug level.

cc. [~elek]",[],2021-06-10 16:27:14+00:00,,2021-06-14 08:09:25+00:00,Open,13383238,RATIS-1381
Improvement,[],iamazy,iamazy,iamazy,iamazy,Minor,Fix typo in org.apache.ratis.protocol.RaftRpcMessage#getRequesterId,[],2021-06-10 02:06:38+00:00,,2021-06-10 02:14:39+00:00,Open,13383071,RATIS-1380
New Feature,[],txdong-sz,donglei,txdong-sz,donglei,Major,"!image-2021-06-09-16-37-41-716.png!

 

!image-2021-06-09-16-38-00-460.png! some data have execute with state machine with restart  that will re execute from last snapshot index

 ",[],2021-06-09 08:38:57+00:00,,2021-06-09 08:38:57+00:00,Open,13382886,RATIS-1379
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,The test certificates under test/src/test/resources/ssl are expired. We need to regenerate them. I suggest to use longer expiry date (10 years instead of 1),[],2021-06-04 13:10:18+00:00,2021-06-14 07:41:01+00:00,2021-06-14 07:52:34+00:00,Resolved,13382143,RATIS-1378
Improvement,[],markgui,Mark Gui,markgui,Mark Gui,Major,"We are using ozone with ratis for our services and we hit an issue with disk out of space. We checked the log and think that it is that ratis has run out of space and ozone pipelines (raftgroups for ratis) created on the full disk are not able to close because it has to take a final snapshot. short log appended below.
{code:java}
2021-05-25 19:10:47,171 [492bc1be-439e-45db-856f-2e58336e2528@group-B26E6BC26E24-StateMachineUpdater] INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine: group-B26E6BC26E24: Taking a snapshot at:(t:5, i:419) file /data1/ratis/c5a9bc6e-fee1-48a8-9100-b26e6bc26e24/sm/snapshot.5_419 2021-05-25 19:10:47,171 [492bc1be-439e-45db-856f-2e58336e2528@group-B26E6BC26E24-StateMachineUpdater] ERROR org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine: group-B26E6BC26E24: Failed to write snapshot at:(t:5, i:419) file /data1/ratis/c5a9bc6e-fee1-48a8-9100-b26e6bc26e24/sm/snapshot.5_419 2021-05-25 19:10:47,171 [492bc1be-439e-45db-856f-2e58336e2528@group-B26E6BC26E24-StateMachineUpdater] ERROR org.apache.ratis.server.impl.StateMachineUpdater: 492bc1be-439e-45db-856f-2e58336e2528@group-B26E6BC26E24-StateMachineUpdater: Failed to take snapshot java.io.IOException: No space left on device at java.io.FileOutputStream.writeBytes(Native Method) at java.io.FileOutputStream.write(FileOutputStream.java:326) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream$OutputStreamEncoder.doFlush(CodedOutputStream.java:3062) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream$OutputStreamEncoder.flushIfNotAvailable(CodedOutputStream.java:3057) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeUInt64NoTag(CodedOutputStream.java:2897) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream.writeInt64NoTag(CodedOutputStream.java:414) at org.apache.ratis.thirdparty.com.google.protobuf.FieldSet.writeElementNoTag(FieldSet.java:657) at org.apache.ratis.thirdparty.com.google.protobuf.FieldSet.writeElement(FieldSet.java:634) at org.apache.ratis.thirdparty.com.google.protobuf.MapEntryLite.writeTo(MapEntryLite.java:110) at org.apache.ratis.thirdparty.com.google.protobuf.MapEntry.writeTo(MapEntry.java:154) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeMessageNoTag(CodedOutputStream.java:2855) at org.apache.ratis.thirdparty.com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeMessage(CodedOutputStream.java:2824) at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3.serializeMapTo(GeneratedMessageV3.java:3224) at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3.serializeLongMapTo(GeneratedMessageV3.java:3140) at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$Container2BCSIDMapProto.writeTo(ContainerProtos.java:14633) at org.apache.ratis.thirdparty.com.google.protobuf.AbstractMessageLite.writeTo(AbstractMessageLite.java:83) at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.persistContainerSet(ContainerStateMachine.java:270) at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:294) at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:265) at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:257) at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:183) at java.lang.Thread.run(Thread.java:748)
{code}
So I think as the consumer of the disk, ratis should be able to mange the free/used space and have some guarantee that operations should not be partial completed due to out of space. We may build a reserved space for each disk in ratis and filter out disks which reach the defined threshold for new raftgroup allocation. Although the problem we hit happened on ozone side, but as the comsumer of the metadata disks, this should better be done in ratis.",[],2021-05-31 08:54:35+00:00,2021-06-10 06:37:42+00:00,2021-06-10 06:37:42+00:00,Resolved,13381241,RATIS-1377
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"[~szetszwo] I find the main used memory caused by SlidingWindow#Client#requests, because when send DataStreamWindowRequest with data, SlidingWindow#Client#requests will hold DataStreamWindowRequest until receive reply. Because DataStreamWindowRequest has data, so the memory used a lot. Still do not know how to improve it.  Not sure whether SlidingWindow is necessary.
 !screenshot-1.png! ",[],2021-05-11 02:49:29+00:00,2021-05-13 02:18:16+00:00,2021-05-13 02:18:16+00:00,Resolved,13377720,RATIS-1376
Bug,[],markgui,Mark Gui,markgui,Mark Gui,Major,"When testing ozone with bad ratis volume, we hit the following log:

``` 

{{2021-05-06 18:19:48,166 [Command processor thread] ERROR org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler: Can't create pipeline RATIS THREE PipelineID=08de41a6-5c9e-48d4-9789-4c09798ecffd
 java.io.IOException: Input/output error
 at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.addGroup(XceiverServerRatis.java:805)
 at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:92)
 at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
 at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:506)
 at java.lang.Thread.run(Thread.java:748)
 Caused by: java.io.IOException: Input/output error
 at java.io.UnixFileSystem.canonicalize0(Native Method)
 at java.io.UnixFileSystem.canonicalize(UnixFileSystem.java:172)
 at java.io.File.getCanonicalPath(File.java:620)
 at org.apache.ratis.server.storage.RaftStorageDirectoryImpl.analyzeStorage(RaftStorageDirectoryImpl.java:129)
 at org.apache.ratis.server.storage.RaftStorageImpl.analyzeAndRecoverStorage(RaftStorageImpl.java:95)
 at org.apache.ratis.server.storage.RaftStorageImpl.<init>(RaftStorageImpl.java:65)
 at org.apache.ratis.server.storage.RaftStorageImpl.<init>(RaftStorageImpl.java:51)
 at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:112)
 at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:193)
 at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$4(RaftServerProxy.java:266)
 at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 ... 1 more}}

```

RaftServer does not catch the IOException and just throw it.

Actually when we have multiple storageDirs, we could try other dirs.",[],2021-05-07 13:05:12+00:00,2021-05-12 03:30:44+00:00,2021-06-03 06:56:43+00:00,Resolved,13377236,RATIS-1375
Task,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Major,"Many IDEs support code style configurations that can be supplied in a git repository. It could be good idea to add code style configurations for most common IDEs like IntelliJ IDEA, Eclipse, NetBeans and VS code. Proper presets should prevent bad indentations in PRs and save reviewers time.",[],2021-05-04 16:54:51+00:00,,2021-05-04 16:54:51+00:00,Open,13376600,RATIS-1374
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"We use StreamInfo#applyToRemotes to transfer data to to other server, and eventually we call OrderedStreamAsync#sendRequest. So StreamInfo#applyToRemotes finished after sending out request, but sometimes OrderedStreamAsync#sendRequest costs hundred millseconds. So we need to make StreamInfo#applyToRemotes async model, and also keep the order of request belongs to the same stream. ",[],2021-04-29 02:25:22+00:00,2021-04-29 06:17:18+00:00,2021-04-29 06:17:38+00:00,Resolved,13375720,RATIS-1373
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-04-28 11:48:51+00:00,2021-04-28 13:35:45+00:00,2021-04-28 13:36:01+00:00,Resolved,13375584,RATIS-1372
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-04-28 09:03:05+00:00,2021-04-28 11:48:19+00:00,2021-04-28 13:36:18+00:00,Resolved,13375551,RATIS-1371
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, after install snapshot is completed, the stateMachine is paused and the stateMachineUpdater is reloaded. Post the reload, if the stateMachine is still in paused state, applyTransaction should not be called on the stateMachine.

It would also be preferarble to move the reitilalize to the BaseStateMachine to esnure the StateMachine transitions to running state post reload of StateMachineUpdater.
{code:java}
  @Override
  public synchronized void reinitialize() throws IOException {
    LOG.info(""Reinitializing "" + this);
    loadSnapshot(storage.findLatestSnapshot());
    if (getLifeCycleState() == LifeCycle.State.PAUSED) {
      getLifeCycle().transition(LifeCycle.State.STARTING);
      getLifeCycle().transition(LifeCycle.State.RUNNING);
    }
{code}",[],2021-04-28 03:48:06+00:00,2021-04-30 07:50:16+00:00,2021-04-30 07:50:16+00:00,Resolved,13375485,RATIS-1370
Bug,[],glengeng,Glen Geng,glengeng,Glen Geng,Major,"For now, if there is no snapshot existed, the returned snapshotIndex is 0.

It is not correctly, since the raft log starts from index 0 (BTW, in raft paper, the first valid log index is 1, but in ratis, it is 0), a snapshot taken at snapshotIndex 0 should contain the log entry 0. The snapshotIndex indicating an empty/fake snapshot should be -1.

 

The fix is as follows: 
{code:java}
diff --git a/ratis-server/src/main/java/org/apache/ratis/server/impl/ServerState.java b/ratis-server/src/main/java/org/apache/ratis/server/impl/ServerState.java
index 728f7e9c..6307ca79 100644
--- a/ratis-server/src/main/java/org/apache/ratis/server/impl/ServerState.java
+++ b/ratis-server/src/main/java/org/apache/ratis/server/impl/ServerState.java
@@ -431,7 +431,7 @@ class ServerState implements Closeable {
 
   long getLatestInstalledSnapshotIndex() {
     final TermIndex ti = latestInstalledSnapshot.get();
-    return ti != null? ti.getIndex(): 0L;
+    return ti != null? ti.getIndex(): -1L;
   }
 
   /**
@@ -440,7 +440,7 @@ class ServerState implements Closeable {
    */
   long getSnapshotIndex() {
     final SnapshotInfo s = getLatestSnapshot();
-    final long latestSnapshotIndex = s != null ? s.getIndex() : 0;
+    final long latestSnapshotIndex = s != null ? s.getIndex() : -1;
     return Math.max(latestSnapshotIndex, getLatestInstalledSnapshotIndex());
   }
{code}
 

This issue is found in the test of bootstrap SCM in SCM HA. 

 

*TL; DR*

*The issue can be reproduced by follow steps:*

1, use follow configuration for SCM HA
{code:java}
  <!-- scm snapshot -->
  <property>
    <name>ozone.scm.ha.ratis.snapshot.threshold</name>
    <value>1</value>
  </property>
  <property>
    <name>ozone.scm.ha.ratis.log.purge.gap</name>
    <value>5</value>
  </property>
  <property>
    <name>ozone.scm.ha.ratis.log.purge.enabled</name>
    <value>true</value>
  </property>
{code}
2, int and start SCM1

3, start DN1, DN2, DN3

4, wait for a while, until there is dozens of raft log entries.

5, bootstrap SCM2

6, start SCM2, SCM1 will be stuck in appendEntries Timeout.

 

 *The RCA is:*

after init SCM1, the raft log is 
{code:java}
[root@9 ~/glengeng/ozone-1.2.0-SNAPSHOT]# ls /tmp/metadata/scm-ha/b7a11f50-85b8-4b93-8a6b-c00705b4e3d4/current/
log_inprogress_0  raft-meta  raft-meta.conf
[root@9 ~/glengeng/ozone-1.2.0-SNAPSHOT]# 
{code}
 

after SCM1 is started, and there is dozens of log entries generated, the raft log is
{code:java}
[root@9 ~/glengeng/ozone-1.2.0-SNAPSHOT]# ls /tmp/metadata/scm-ha/b7a11f50-85b8-4b93-8a6b-c00705b4e3d4/current/
log_inprogress_1  raft-meta  raft-meta.conf
[root@9 ~/glengeng/ozone-1.2.0-SNAPSHOT]# 
{code}
Since purge is enable and purge gap is 5, the file log_0_0 is removed. The leader does not have entry 0 any more.

 

Then SCM2 is bootstrapped and started, we expect SCM2 to download a snapshot from leader, since leader miss log entry 0, and SCM2 is empty.

The follow SCM do receive an installSnapshot request,
{code:java}
021-04-25 19:25:55,933 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: receive installSnapshot: 630b3fbd-861f-4676-8e16-8ae548ed6658->55560a65-e7f7-46f0-b463-f511187fd358#0-t2,notify:(t:2, i:1)
{code}
But due to the default snapshot index is 0, 
{code:java}
if (inProgressInstallSnapshotRequest.compareAndSet(null, firstAvailableLogTermIndex)) {

  // Check if snapshot index is already at par or ahead of the first
  // available log index of the Leader.
  long snapshotIndex = state.getSnapshotIndex();
  if (snapshotIndex + 1 >= firstAvailableLogIndex) {
    // State Machine has already installed the snapshot. Return the
    // latest snapshot index to the Leader.

    inProgressInstallSnapshotRequest.compareAndSet(firstAvailableLogTermIndex, null);
    final InstallSnapshotReplyProto reply = ServerProtoUtils.toInstallSnapshotReplyProto(
        leaderId, getMemberId(), currentTerm, InstallSnapshotResult.ALREADY_INSTALLED, snapshotIndex);
    LOG.info(""{}: StateMachine snapshotIndex is {}"", getMemberId(), snapshotIndex);
    return reply;
  }
{code}
0(snapshotIndex) + 1 == 1(firstAvailableLogIndex), thus follower SCM ignore the  downloading.
{code:java}
2021-04-25 19:25:55,933 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: receive installSnapshot: 630b3fbd-861f-4676-8e16-8ae548ed6658->55560a65-e7f7-46f0-b463-f511187fd358#0-t2,notify:(t:2, i:1)
2021-04-25 19:25:55,940 [grpc-default-executor-0] INFO org.apache.hadoop.hdds.scm.ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2021-04-25 19:25:55,940 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: change Leader from null to 630b3fbd-861f-4676-8e16-8ae548ed6658 at term 2 for installSnapshot, leader elected after 1416ms
2021-04-25 19:25:55,954 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: StateMachine snapshotIndex is 0
2021-04-25 19:25:56,019 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: set new configuration index: 1
configurationEntry {
  peers {
    id: ""630b3fbd-861f-4676-8e16-8ae548ed6658""
    address: ""9.134.50.210:9865""
  }
}
 from snapshot
2021-04-25 19:25:56,022 [grpc-default-executor-0] DEBUG org.apache.ratis.util.LifeCycle: 630b3fbd-861f-4676-8e16-8ae548ed6658|rpc:9.134.50.210:9865|admin:|client:|dataStream:|priority:0: NEW
2021-04-25 19:25:56,022 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: set configuration 1: [630b3fbd-861f-4676-8e16-8ae548ed6658|rpc:9.134.50.210:9865|admin:|client:|dataStream:|priority:0], old=null
2021-04-25 19:25:56,026 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: 55560a65-e7f7-46f0-b463-f511187fd358@group-7587E602AEC2: reply installSnapshot: 630b3fbd-861f-4676-8e16-8ae548ed6658<-55560a65-e7f7-46f0-b463-f511187fd358#0:FAIL-t0,ALREADY_INSTALLED
2021-04-25 19:25:56,026 [grpc-default-executor-0] DEBUG org.apache.ratis.grpc.server.GrpcServerProtocolService: 55560a65-e7f7-46f0-b463-f511187fd358: reply 630b3fbd-861f-4676-8e16-8ae548ed6658<-55560a65-e7f7-46f0-b463-f511187fd358#0:FAIL-t0,ALREADY_INSTALLED
{code}
 

In the leader side, the matchIndex is updated to 0, and the nextIndex is updated to 1.
{code:java}
@Override
public void setSnapshotIndex(long newSnapshotIndex) {
  snapshotIndex.setUnconditionally(newSnapshotIndex, infoIndexChange);
  matchIndex.setUnconditionally(newSnapshotIndex, infoIndexChange);
  nextIndex.setUnconditionally(newSnapshotIndex + 1, infoIndexChange);
}
{code}
{code:java}
2021-04-25 19:23:58,738 [grpc-default-executor-0] INFO org.apache.ratis.grpc.server.GrpcLogAppender: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358-InstallSnapshotResponseHandler: received the first reply 630b3fbd-861f-4676-8e16-8ae548ed6658<-55560a65-e7f7-46f0-b463-f511187fd358#0:FAIL-t0,ALREADY_INSTALLED
2021-04-25 19:23:58,740 [grpc-default-executor-0] INFO org.apache.ratis.grpc.server.GrpcLogAppender: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358-InstallSnapshotResponseHandler: Already Installed Snapshot Index 0.
2021-04-25 19:23:58,741 [grpc-default-executor-0] INFO org.apache.ratis.server.leader.FollowerInfo: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358: snapshotIndex: setUnconditionally 0 -> 0
2021-04-25 19:23:58,741 [grpc-default-executor-0] INFO org.apache.ratis.server.leader.FollowerInfo: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358: matchIndex: setUnconditionally 0 -> 0
2021-04-25 19:23:58,741 [grpc-default-executor-0] INFO org.apache.ratis.server.leader.FollowerInfo: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358: nextIndex: setUnconditionally 0 -> 1
2021-04-25 19:23:58,741 [grpc-default-executor-0] DEBUG org.apache.ratis.server.leader.FollowerInfo: 630b3fbd-861f-4676-8e16-8ae548ed6658@group-7587E602AEC2->55560a65-e7f7-46f0-b463-f511187fd358: commitIndex: updateToMax old=-1, new=0, updated? true
{code}
 

Since matchIndex is monotonically increased, and the nextIndex will at least be matchIndex + 1, 
{code:java}
final long nextIndex = 1 + Optional.ofNullable(request)
    .map(AppendEntriesRequest::getPreviousLog)
    .map(TermIndex::getIndex)
    .orElseGet(getFollower()::getMatchIndex);
{code}
Leader keep sending entries from index 1, but follower is empty, missing entry 0, the cluster stuck in inconsistency append entries.

 

With the fix, the download of checkpoint happened, and the system works well.
{code:java}
2021-04-26 11:23:10,761 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: receive installSnapshot: 6e7bb411-69c5-40ea-8238-bc65cc4e9b55->a0ba8aa4-5cff-4452-9adf-638135a9ebaf#0-t2,notify:(t:2, i:1)
2021-04-26 11:23:10,768 [grpc-default-executor-0] INFO org.apache.hadoop.hdds.scm.ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2021-04-26 11:23:10,768 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: change Leader from null to 6e7bb411-69c5-40ea-8238-bc65cc4e9b55 at term 2 for installSnapshot, leader elected after 1391ms
2021-04-26 11:23:10,787 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 1.
2021-04-26 11:23:11,090 [grpc-default-executor-0] INFO org.apache.hadoop.hdds.scm.ha.SCMStateMachine: Received install snapshot notification from SCM leader: 9.134.50.210:9865 with term index: (t:2, i:1)
2021-04-26 11:23:11,091 [pool-13-thread-1] INFO org.apache.hadoop.hdds.scm.ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
2021-04-26 11:23:11,092 [grpc-default-executor-0] DEBUG org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: Snapshot Installation Request received and is in progress
2021-04-26 11:23:11,164 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: set new configuration index: 1
configurationEntry {
  peers {
    id: ""6e7bb411-69c5-40ea-8238-bc65cc4e9b55""
    address: ""9.134.50.210:9865""
  }
}
 from snapshot
2021-04-26 11:23:11,166 [grpc-default-executor-0] DEBUG org.apache.ratis.util.LifeCycle: 6e7bb411-69c5-40ea-8238-bc65cc4e9b55|rpc:9.134.50.210:9865|admin:|client:|dataStream:|priority:0: NEW
2021-04-26 11:23:11,167 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: set configuration 1: [6e7bb411-69c5-40ea-8238-bc65cc4e9b55|rpc:9.134.50.210:9865|admin:|client:|dataStream:|priority:0], old=null
2021-04-26 11:23:11,171 [grpc-default-executor-0] INFO org.apache.ratis.server.RaftServer$Division: a0ba8aa4-5cff-4452-9adf-638135a9ebaf@group-C00705B4E3D4: reply installSnapshot: 6e7bb411-69c5-40ea-8238-bc65cc4e9b55<-a0ba8aa4-5cff-4452-9adf-638135a9ebaf#0:FAIL-t0,IN_PROGRESS
2021-04-26 11:23:11,171 [grpc-default-executor-0] DEBUG org.apache.ratis.grpc.server.GrpcServerProtocolService: a0ba8aa4-5cff-4452-9adf-638135a9ebaf: reply 6e7bb411-69c5-40ea-8238-bc65cc4e9b55<-a0ba8aa4-5cff-4452-9adf-638135a9ebaf#0:FAIL-t0,IN_PROGRESS
2021-04-26 11:23:11,175 [grpc-default-executor-0] INFO org.apache.ratis.grpc.server.GrpcServerProtocolService: a0ba8aa4-5cff-4452-9adf-638135a9ebaf: Completed INSTALL_SNAPSHOT, lastRequest: 6e7bb411-69c5-40ea-8238-bc65cc4e9b55->a0ba8aa4-5cff-4452-9adf-638135a9ebaf#0-t2,notify:(t:2, i:1)
{code}
 ",[],2021-04-26 03:45:02+00:00,2021-04-26 09:20:01+00:00,2021-04-26 09:20:01+00:00,Resolved,13374967,RATIS-1369
Bug,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Major,"Sonar Qube has detected three possible NPE issues in Ratis RaftServerImpl class. See Sonar Cloud issues for more detailed information:

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiyQwsm5D8rduwfK&resolved=false&rules=java%3AS2259&types=BUG]

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXjptNfQvD9txNV3GCnD&resolved=false&rules=java%3AS2259&types=BUG]

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiyQwsm5D8rduwfL&resolved=false&rules=java%3AS2259&types=BUG]

 ",[],2021-04-24 12:17:24+00:00,,2021-05-14 03:01:17+00:00,Open,13374814,RATIS-1368
Bug,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Minor,"Sonar Qube has detected one possible NPE issue in RaftConfigurationImpl class.

See Sonar Cloud issues for more detailed information:

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXaSQ14g8L9hkQskmM9b&resolved=false&rules=java%3AS2259&types=BUG]

 ",[],2021-04-24 12:09:56+00:00,2021-05-05 11:37:08+00:00,2021-05-05 11:37:08+00:00,Resolved,13374812,RATIS-1367
Bug,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Minor,"Sonar Qube has detected two possible NPE issues in Ratis MetaStateMachine class. See Sonar Cloud issues for more detailed information:

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiOcwsm5D8rduwSB&resolved=false&rules=java%3AS2259&types=BUG]

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiOcwsm5D8rduwSA&resolved=false&rules=java%3AS2259&types=BUG]

 ",[],2021-04-24 11:28:18+00:00,2021-05-14 02:03:27+00:00,2021-05-14 02:04:09+00:00,Resolved,13374805,RATIS-1366
Bug,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Minor,"SonarQube has detected one possible NPE issue in CombinedClientProtocolServerSideTranslatorPB class. After further investigation, it could be deduced that this NPE error can't occur in the current code, because currently switch-case that is causing the problem handles all possible cases. However it is possible that future modifications changes the situation. Because of that it could be a good idea to throw error in the default branch.

See SonarCloud issues for more detailed information:

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXMispqvSBrYCGcXe6dV&resolved=false&rules=java%3AS2259&types=BUG]

 ",[],2021-04-24 11:15:30+00:00,2021-04-26 09:34:44+00:00,2021-04-26 09:34:44+00:00,Resolved,13374802,RATIS-1365
Bug,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Minor,"SonarQube has detected two possible NPE issues in Ratis IOUtils class. See SonarCloud issues for more detailed information:

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiclwsm5D8rduwWe&resolved=false&rules=java%3AS2259&types=BUG]

[https://sonarcloud.io/project/issues?id=apache-ratis&open=AXJWdiclwsm5D8rduwWf&resolved=false&rules=java%3AS2259&types=BUG]

 ",[],2021-04-24 10:21:29+00:00,2021-05-05 11:32:38+00:00,2021-05-05 11:32:38+00:00,Resolved,13374795,RATIS-1364
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"{noformat:title=https://github.com/apache/ratis/runs/2391687907?check_suite_focus=true#step:5:538}
testInstallSnapshotNotificationCount(org.apache.ratis.grpc.TestInstallSnapshotNotificationWithGrpc)  Time elapsed: 1.708 s  <<< FAILURE!
java.lang.AssertionError: expected:<20> but was:<19>
  ...
  at org.apache.ratis.InstallSnapshotNotificationTests.testInstallSnapshotNotificationCount(InstallSnapshotNotificationTests.java:280)
  at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
  at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
  at org.apache.ratis.InstallSnapshotNotificationTests.testInstallSnapshotNotificationCount(InstallSnapshotNotificationTests.java:252)
{noformat}",[],2021-04-20 14:54:11+00:00,2021-04-25 09:31:36+00:00,2021-04-26 09:06:11+00:00,Resolved,13373876,RATIS-1363
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"{noformat}
Test set: org.apache.ratis.grpc.TestRaftReconfigurationWithGrpc
-------------------------------------------------------------------------------
Tests run: 15, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 59.766 s <<< FAILURE! - in org.apache.ratis.grpc.TestRaftReconfigurationWithGrpc
testBootstrapReconfWithSingleNodeAddTwo(org.apache.ratis.grpc.TestRaftReconfigurationWithGrpc)  Time elapsed: 10.691 s  <<< ERROR!
java.lang.NullPointerException
	at org.apache.ratis.RaftTestUtil.waitFor(RaftTestUtil.java:146)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.runTestBootstrapReconf(RaftReconfigurationBaseTest.java:365)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.lambda$testBootstrapReconfWithSingleNodeAddTwo$8(RaftReconfigurationBaseTest.java:317)
	at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:129)
	at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:117)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.testBootstrapReconfWithSingleNodeAddTwo(RaftReconfigurationBaseTest.java:317)
{noformat}

",[],2021-04-20 10:04:10+00:00,2021-04-26 09:06:59+00:00,2021-04-26 09:15:21+00:00,Resolved,13373815,RATIS-1362
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"org.apache.ratis.netty.TestRetryCacheWithNettyRpc
org.apache.ratis.netty.TestRaftExceptionWithNetty
org.apache.ratis.netty.TestRaftSnapshotWithNetty
org.apache.ratis.netty.TestGroupManagementWithNetty
org.apache.ratis.netty.TestRaftReconfigurationWithNetty

started failing recently without any code change ([first failed|https://github.com/apache/ratis/runs/2329275686#step:5:4] on {{master}} for a simple [version number update|https://github.com/apache/ratis/commit/bd3f36bd324257d5898d59f203f7d19c1405a26c]).",[],2021-04-20 07:53:52+00:00,2021-04-20 14:40:41+00:00,2021-04-20 14:41:46+00:00,Resolved,13373787,RATIS-1361
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,Upgrade Ratis Thirdparty to 0.7.0-a398b19-SNAPSHOT for Netty fixes.,[],2021-04-19 11:29:17+00:00,2021-04-20 14:11:23+00:00,2021-04-20 14:28:34+00:00,Resolved,13373593,RATIS-1360
Improvement,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"org.apache.ratis.netty.TestRetryCacheWithNettyRpc
org.apache.ratis.netty.TestRaftExceptionWithNetty
org.apache.ratis.netty.TestRaftSnapshotWithNetty
org.apache.ratis.netty.TestGroupManagementWithNetty
org.apache.ratis.netty.TestRaftReconfigurationWithNetty
https://github.com/apache/ratis/pull/460/checks?check_run_id=2379594469
https://github.com/apache/ratis/runs/2329275686#step:5:5",[],2021-04-19 10:27:50+00:00,,2021-04-20 14:54:27+00:00,Open,13373579,RATIS-1359
Task,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"Test is failing due to for otherRpc server like HadoopRpc, we getServiceException Wrapped with RemoteException.

Because of this caughtException will be false, and test is failing due to that.
catch (ReconfigurationInProgressException e) {
          caughtException.set(true);",[],2021-04-19 06:39:38+00:00,,2021-04-19 06:39:38+00:00,Open,13373462,RATIS-1358
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
    <!--
      ! Can be removed if changing to ASF parent version 19
    -->
{code}
As mentioned in a comment in pom.xml, we can remove quite a few versions if changing the ASF parent version.",[],2021-04-14 12:01:21+00:00,,2021-04-28 09:28:33+00:00,Open,13372287,RATIS-1357
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"In cases, where new member's being added to to an existing ratis ring, raft configuration may not have the peer info of other nodes upfront while adding a new peer to an existing ring, leader Info can still be missing during installSnapshotNotification requests from leader to follower. In such cases, the leader info can be retreived from installSnapshot proto request. The idea here is to fix this case.",[],2021-04-14 11:28:29+00:00,2021-04-19 10:31:48+00:00,2021-04-20 10:32:09+00:00,Resolved,13372276,RATIS-1356
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,Bump Netty to 4.1.61+ in {{ratis-thirdparty}} due to https://github.com/netty/netty/security/advisories/GHSA-f256-j965-7f32,[],2021-04-14 07:16:16+00:00,2021-04-14 13:33:18+00:00,2021-04-17 07:57:48+00:00,Resolved,13372220,RATIS-1355
Task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Since ratis 2.0.0 release is out. We should update the version to 2.1.0-SNAPSHOT.,[],2021-04-12 10:04:54+00:00,2021-04-13 01:23:59+00:00,2021-04-13 01:24:22+00:00,Resolved,13371249,RATIS-1354
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
sh build.sh ../../web-site_output/
Re-generating SVGs
Running RAT license check
RAT check appears to have passed
-e 
Building website to ../../web-site_output/
Start building sites … 
WARN 2021/04/08 20:46:07 Content directory ""/Users/szetszwo/ratis/web-site-fork/content/logservice"" have both index.* and _index.* files, pick one.
WARN 2021/04/08 20:46:07 Content directory ""/Users/szetszwo/ratis/web-site-fork/content/logservice/testing"" have both index.* and _index.* files, pick one.
WARN 2021/04/08 20:46:07 Page.URL is deprecated and will be removed in a future release. Use .Permalink or .RelPermalink. If what you want is the front matter URL value, use .Params.url
{code}",[],2021-04-08 12:48:13+00:00,,2021-04-08 12:48:13+00:00,Open,13370378,RATIS-1353
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The following files are no longer used.
- apache_incubator.png
- logservice/security/index.html",[],2021-04-07 10:56:43+00:00,2021-04-08 00:49:22+00:00,2021-04-08 05:27:45+00:00,Resolved,13370057,RATIS-1352
Bug,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,,[],2021-03-25 09:23:41+00:00,2021-03-30 15:47:40+00:00,2021-03-30 15:47:41+00:00,Resolved,13367517,RATIS-1351
Bug,[],cchenax,cchenaxchen,cchenax,cchenaxchen,Major,"java.io.IOException: java.lang.IllegalStateException
        at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
        at org.apache.ratis.util.IOUtils.toIOException(IOUtils.java:61)
        at org.apache.ratis.util.IOUtils.getFromFuture(IOUtils.java:71)
        at org.apache.ratis.server.impl.RaftServerProxy.getImpls(RaftServerProxy.java:301)
        at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:318)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:461)
        at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:242)
        at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:112)
        at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)",[],2021-03-25 08:09:31+00:00,,2021-04-01 08:12:03+00:00,Open,13367467,RATIS-1350
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-03-24 07:56:23+00:00,2021-04-08 08:22:52+00:00,2021-04-08 08:22:52+00:00,Resolved,13367173,RATIS-1349
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,{{GrpcSslTest}} fail intermittently due to threading issues.  Server may not have started by the time client tries to connect in another thread.,[],2021-03-19 09:07:47+00:00,2021-03-19 09:45:58+00:00,2021-03-19 09:55:22+00:00,Resolved,13366288,RATIS-1348
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should add an ApacheCon Event Banner to our website.
- https://www.apachecon.com/event-images/",[],2021-03-19 09:03:39+00:00,2021-04-08 12:47:57+00:00,2021-04-12 00:46:36+00:00,Resolved,13366283,RATIS-1347
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,Add {{.asf.yaml}} to {{ratis-thirdparty}} repo with similar settings as in the main {{ratis}} repo.,[],2021-03-19 06:36:00+00:00,2021-03-19 08:53:18+00:00,2021-03-19 09:29:11+00:00,Resolved,13366259,RATIS-1346
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should remove ""incubating""/""incubator"" for the following files.
{code}
-- ./dev-support/make_rc.sh ---------------------------------------------------
 83: # Need to include ""incubating"" in the artifact
 84: version=""$(mvnGet project.version)-incubating""
   2 occurrence(s)
-- ./misc/src/main/resources/META-INF/DISCLAIMER ------------------------------
  1: Apache Ratis is an effort undergoing incubation at The Apache Software
  2: Foundation (ASF), sponsored by the Apache Incubator PMC. Incubation is required
  5: a manner consistent with other successful ASF projects. While incubation status
   3 occurrence(s)
-- ./pom.xml ------------------------------------------------------------------
 42:     <connection>scm:git:git://github.com/apache/incubator-ratis-thirdparty.git</connection>
 43:     <developerConnection>scm:git:https://github.com/apache/incubator-ratis-thirdparty.git</developerConnection>
 44:     <url>https://github.com/apache/incubator-ratis-thirdparty</url>
   3 occurrence(s)
-- ./test/pom.xml -------------------------------------------------------------
 27:   <url>https://github.com/apache/incubator-ratis-thirdparty</url>
   1 occurrence(s)
{code}
",[],2021-03-19 01:40:57+00:00,2021-03-22 00:32:37+00:00,2021-03-22 00:32:37+00:00,Resolved,13366220,RATIS-1345
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should remove DISCLAIMER and fix README.md.
{code}
-- ./README.md ----------------------------------------------------------------
 19: These modules are located in a separated repository (https://github.com/apache/incubator-ratis-thirdparty)
 20: but not attached to the core Apache Ratis repository (https://git-wip-us.apache.org/repos/asf?p=incubator-ratis.git)
 25: See also: https://github.com/apache/incubator-ratis/blob/master/BUILDING.md
   3 occurrence(s)
{code}",[],2021-03-19 01:38:42+00:00,2021-03-20 05:56:08+00:00,2021-03-20 05:56:08+00:00,Resolved,13366219,RATIS-1344
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,Add a basic Github Actions check to smoketest commits for ratis-thirdparty repo.,[],2021-03-17 14:07:59+00:00,2021-03-18 13:56:21+00:00,2021-03-19 01:17:23+00:00,Resolved,13365851,RATIS-1343
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"Bump Netty to 4.1.60.Final in {{ratis-thirdparty}} due to the Netty vulnerabilities.
- https://github.com/netty/netty/security/advisories/GHSA-5mcr-gq6c-3hq2
- https://github.com/netty/netty/security/advisories/GHSA-wm47-8v5p-wjpj",[],2021-03-17 13:55:43+00:00,2021-03-19 01:28:24+00:00,2021-04-14 13:18:29+00:00,Resolved,13365849,RATIS-1342
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,"RATIS-1313 added matrix build for unit tests with 3 splits, with fail-fast behavior (if one split fails, other splits are cancelled).  [~szetszwo] pointed out that 

bq. better to always run all the tests since the overall running time is short. This is the reason that we moved the tests to the ratis-test module; see RATIS-399

I propose to run all tests for {{push}} builds, but keep fail-fast behavior for PRs.  The rationale is that any failing test requires a new run, because PRs should be merged only after fully green build.",[],2021-03-17 11:54:38+00:00,2021-03-18 13:57:24+00:00,2021-03-18 14:22:10+00:00,Resolved,13365808,RATIS-1341
Bug,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Minor,"Several Bash scripts in Redis use this common idiom to discover the current source path and then build relative paths from it:

{code}
DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""
{code}

This mostly works well, but it isn't compatible with interactive shells using the {{CDPATH}} environment variable to provide a custom search path for resolving the directory referenced by {{cd}}.  (See [bash man page|https://linux.die.net/man/1/bash] discussion of ""CDPATH"" and how the resolved directory is ""written to the standard output."")

The standard solution is to redirect stdout of {{cd}} to {{/dev/null}}:

{code}
DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" > /dev/null && pwd )""
{code}

Some Ratis scripts already do this, but not all.",[],2021-03-16 05:51:26+00:00,,2021-03-16 05:51:26+00:00,Open,13365411,RATIS-1340
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,The release docs in the ratis-docs sub-module still reference git repos at the incubator location.  Update these to reference the TLP repo locations.,[],2021-03-16 05:13:07+00:00,2021-03-19 16:29:51+00:00,2021-03-19 16:29:51+00:00,Resolved,13365403,RATIS-1339
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,Various developer bootstrapping information on the site still points to incubator repos and locations.  Update these to show the correct locations since graduation to TLP.,[],2021-03-11 04:29:03+00:00,2021-03-16 10:54:41+00:00,2021-03-16 10:54:41+00:00,Resolved,13363726,RATIS-1338
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,The site has posts for release announcements with download links pointing to an old incubator location.  Update these links to point to the new TLP location.,[],2021-03-11 04:27:56+00:00,2021-03-14 11:49:09+00:00,2021-03-14 11:49:09+00:00,Resolved,13363725,RATIS-1337
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,The site still contains download links pointing to the distribution server at incubator sub-paths.  Update these links to point to the new TLP location.,[],2021-03-11 04:27:14+00:00,2021-03-12 07:20:23+00:00,2021-03-12 07:20:23+00:00,Resolved,13363724,RATIS-1336
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,"The site still documents the project mailing lists in the .incubator sub-domain.  Now that the project has graduated to TLP, we can update documentation of the mailing lists.",[],2021-03-11 04:26:21+00:00,2021-03-12 02:01:50+00:00,2021-03-12 02:01:50+00:00,Resolved,13363723,RATIS-1335
Sub-task,[],cnauroth,Chris Nauroth,cnauroth,Chris Nauroth,Major,"The site still contains disclaimers that the project is in the incubator.  Now that it has graduated to TLP, these disclaimers can be removed.  This includes main site landing page, README.md, config.toml, footer.html, header.html and doap.rdf.",[],2021-03-11 04:25:06+00:00,2021-03-11 07:19:19+00:00,2021-03-11 07:19:19+00:00,Resolved,13363721,RATIS-1334
Improvement,[],weichiu,Wei-Chiu Chuang,weichiu,Wei-Chiu Chuang,Minor,"While inspecting an Ozone thread dump, I noticed these two types of threads are not named. Naming them is useful in troubleshooting multi-raft environment (process with more than one raft).",[],2021-03-10 08:33:39+00:00,2021-03-11 09:46:27+00:00,2021-03-11 09:46:35+00:00,Resolved,13363460,RATIS-1333
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"I found this problem during the test of ratis 2.0.0-rc3 and earlier.

I noticed that in some cases the Ozone Manager (with ratis enabled true) couldn't be started any more (see HDDS-4703 for details).

After some investigation I found the following problem:

 1. Ratis server initialized BEFORE om RPC (OzoneManager.startRpcServer)
 2. If the RPC server is failed (due to missing DNS for example) the Ratis server is stopped during the initialization
 3. AtomicOutputStream can leave some tmp files behind (like raft-meta.tmp, if it's not yet renamed)
 4. After DNS problem is fixed the OM couldn't be started anymore as RaftStorageImpl.analyzeAndRecoverStorage requires FORMATTED or empty (!!!) directory. Directory with leftover tmp file is not empty.

{code}
  private StorageState analyzeAndRecoverStorage(boolean toLock) throws IOException {
    StorageState storageState = storageDir.analyzeStorage(toLock);
    if (storageState == StorageState.NORMAL) {
        // ...
    } else if (storageState == StorageState.NOT_FORMATTED &&
        storageDir.isCurrentEmpty()) {
     //never called this if one .tmp file exists from the previous attempts
      format();
      return StorageState.NORMAL;
    } else {
      return storageState;
    }
  }
{code}

The problem is that `cleanMetaTmpFile();` is called only in the first branch, but before checking if the directory is empty or not...",[],2021-03-09 11:37:07+00:00,2021-03-15 01:50:17+00:00,2021-03-20 15:35:51+00:00,Resolved,13363248,RATIS-1332
Task,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"This Jira is to make truststore param a list of trusted CA certificate.
This will be needed for SCM HA.",[],2021-03-08 08:24:24+00:00,2021-03-15 17:40:08+00:00,2021-03-15 17:40:08+00:00,Resolved,13362947,RATIS-1331
Improvement,[],liutaohua,DaweiLiu,liutaohua,DaweiLiu,Minor,,[],2021-03-07 11:14:56+00:00,2021-03-07 12:39:08+00:00,2021-03-08 18:03:03+00:00,Resolved,13362842,RATIS-1330
Bug,[],despondency,Mario Georgiev,despondency,Mario Georgiev,Major,"Build the jar with 
{code:java}
./gradlew uber
 navigate to the build/libs/ and run the uber java -jar <jar-name-uber>
{code}

 Initially thought it only happens on Netty, but switched to GRPC and same thing.

Issue is both on Netty && GRPC, you might have to run the jar a few times to get the hang up. (attached jstack for both of the reproducible test cases)

Am i doing something incorrect in the code, or its just a bug.",[],2021-03-05 17:40:00+00:00,,2021-03-26 04:45:23+00:00,Open,13362663,RATIS-1329
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-03-04 06:55:39+00:00,2021-03-04 12:55:20+00:00,2021-03-04 12:55:20+00:00,Resolved,13362231,RATIS-1328
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"[~szetszwo] Hi, this is just a discussion. 

Currently, when ratis commit log,  ozone will write data to Rocksdb. In my thinking, raft write raft log on disk, and rocksdb also write wal log on disk, there are two log need to be wrote. If rocksdb can avoid writting wal log, and use raft log directly, it can improve performance, but we need to change the code of rocksdb.  

I just throw this idea, because I do not know how to change the code of Rocksdb.  Baidu company has changed mysql to use raft log, and avoid writting binlog.",[],2021-03-03 07:17:01+00:00,,2021-03-07 12:59:59+00:00,Open,13362031,RATIS-1327
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Sample patch to trigger the failure:
{code:java}
diff --git a/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java b/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
index f932fbb7..8039b6b5 100644
--- a/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
+++ b/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
@@ -1569,6 +1569,7 @@ class RaftServerImpl implements RaftServer.Division,
               });
         } catch (Throwable t) {
           inProgressInstallSnapshotRequest.compareAndSet(firstAvailableLogTermIndex, null);
+          LOG.info(""InstallSnapshotFromLeader Failed"", t);
           throw t;
         }
 
diff --git a/ratis-server/src/test/java/org/apache/ratis/InstallSnapshotNotificationTests.java b/ratis-server/src/test/java/org/apache/ratis/InstallSnapshotNotificationTests.java
index a4c25da4..899f5c07 100644
--- a/ratis-server/src/test/java/org/apache/ratis/InstallSnapshotNotificationTests.java
+++ b/ratis-server/src/test/java/org/apache/ratis/InstallSnapshotNotificationTests.java
@@ -86,7 +86,9 @@ public abstract class InstallSnapshotNotificationTests<CLUSTER extends MiniRaftC
     public CompletableFuture<TermIndex> notifyInstallSnapshotFromLeader(
         RaftProtos.RoleInfoProto roleInfoProto,
         TermIndex termIndex) {
-
+      if (roleInfoProto.getFollowerInfo().getLeaderInfo().getId().getId().isEmpty()) {
+        Assert.fail();
+      }
       numSnapshotRequests.incrementAndGet();
 
       final SingleFileSnapshotInfo leaderSnapshotInfo = (SingleFileSnapshotInfo) leaderSnapshotInfoRef.get();
{code}
{code:java}

2021-03-03 10:39:49,176 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:notifyStateMachineToInstallSnapshot(1572)) - InstallSnapshotFromLeader Failed2021-03-03 10:39:49,176 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:notifyStateMachineToInstallSnapshot(1572)) - InstallSnapshotFromLeader Failedjava.lang.AssertionError at org.junit.Assert.fail(Assert.java:86) at org.junit.Assert.fail(Assert.java:95) at org.apache.ratis.InstallSnapshotNotificationTests$StateMachine4InstallSnapshotNotificationTests.notifyInstallSnapshotFromLeader(InstallSnapshotNotificationTests.java:90) at org.apache.ratis.server.impl.RaftServerImpl.notifyStateMachineToInstallSnapshot(RaftServerImpl.java:1552) at org.apache.ratis.server.impl.RaftServerImpl.installSnapshotImpl(RaftServerImpl.java:1432) at org.apache.ratis.server.impl.RaftServerImpl.installSnapshot(RaftServerImpl.java:1316) at org.apache.ratis.server.impl.RaftServerProxy.installSnapshot(RaftServerProxy.java:569) at org.apache.ratis.grpc.server.GrpcServerProtocolService$2.process(GrpcServerProtocolService.java:239) at org.apache.ratis.grpc.server.GrpcServerProtocolService$2.process(GrpcServerProtocolService.java:236) at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:126) at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:255) at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33) at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309) at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292) at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782) at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)
{code}",[],2021-03-03 05:11:42+00:00,2021-03-17 12:43:30+00:00,2021-04-14 11:28:30+00:00,Resolved,13362008,RATIS-1326
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-03-02 23:49:59+00:00,2021-04-08 08:24:11+00:00,2021-04-08 08:24:19+00:00,Resolved,13361975,RATIS-1325
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
-- ./README.md ----------------------------------------------------------------
 48: https://ratis.incubator.apache.org
 56: $ git clone https://github.com/apache/incubator-ratis ratis-site.git
   2 occurrence(s)
-- ./config.toml --------------------------------------------------------------
 14: baseURL = ""https://ratis.incubator.apache.org/""
   1 occurrence(s)
-- ./content/community.md -----------------------------------------------------
 24: The Ratis developer mailing list is: <dev@ratis.incubator.apache.org>.
 26: -   [Subscribe to List](mailto: dev-subscribe@ratis.incubator.apache.org)
 27: -   [Unsubscribe from List](mailto: dev-unsubscribe@ratis.incubator.apache.org)
 38: The Ratis user mailing list is: <user@ratis.incubator.apache.org>.
 40: -   [Subscribe to List](mailto: user-subscribe@ratis.incubator.apache.org)
 41: -   [Unsubscribe from List](mailto: user-unsubscribe@ratis.incubator.apache.org)
   6 occurrence(s)
-- ./content/getting_started.md -----------------------------------------------
 24:  * [Arithmetic example](https://github.com/apache/incubator-ratis/tree/master/ratis-examples/src/main/java/org/apache/ratis/examples/arithmetic): This is a simple distributed calculator that replicates the values defined and allows user to perform arithmetic operations on these replicated values.
 26:  * [FileStore example](https://github.com/apache/incubator-ratis/tree/master/ratis-examples/src/main/java/org/apache/ratis/examples/filestore): This is an example of using Ratis for reading and writing files.
 31: [ratis-examples](https://github.com/apache/incubator-ratis/blob/master/ratis-examples/) sub-project.
   3 occurrence(s)
-- ./content/logservice/testing/vagrant.md ------------------------------------
 18: Please refer to the [documentation](https://github.com/apache/incubator-ratis/blob/master/dev-support/vagrant/README.md) for instructions to use the Vagrant automation.
   1 occurrence(s)
-- ./content/post/0.1.0-alpha.md ----------------------------------------------
 21: This is the first incubator release of Apache Ratis.
   1 occurrence(s)
-- ./content/post/0.3.0.md ----------------------------------------------------
 21: [Download](https://ratis.incubator.apache.org/downloads.html)
 24: See the [changes between 0.2.0 and 0.3.0](https://github.com/apache/incubator-ratis/compare/ratis-0.2.0...ratis-0.3.0) releases. 
   2 occurrence(s)
-- ./content/post/0.4.0.md ----------------------------------------------------
 21: [Download](https://ratis.incubator.apache.org/downloads.html)
 24: See the [changes between 0.3.0 and 0.4.0](https://github.com/apache/incubator-ratis/compare/0.3.0...ratis-0.4.0-rc4) releases. 
   2 occurrence(s)
-- ./content/post/0.5.0.md ----------------------------------------------------
 21: [Download](https://ratis.incubator.apache.org/downloads.html)
 24: See the [changes between 0.4.0 and 0.5.0](https://github.com/apache/incubator-ratis/compare/0.4.0-rc4...ratis-0.5.0-rc0) releases. 
   2 occurrence(s)
-- ./content/post/1.0.0.md ----------------------------------------------------
 21: [Download](https://ratis.incubator.apache.org/downloads.html)
 24: See the [changes between 0.5.0 and 1.0.0](https://github.com/apache/incubator-ratis/compare/ratis-0.5.0-rc0...ratis-1.0.0-rc0) releases. 
   2 occurrence(s)
-- ./content/source.md --------------------------------------------------------
 20: The versioned source code history is available from the [Apache git](https://gitbox.apache.org/repos/asf?p=incubator-ratis.git) repository or 
 21: from the [github mirror](https://github.com/apache/incubator-ratis). It is only for development and not intended for use by the general public. 
   2 occurrence(s)
-- ./layouts/custompage/downloads.html ----------------------------------------
 47:          <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-src.tar.gz"">source</a>
 48:          (<a href=""https://downloads.apache.org/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-src.tar.gz.mds"">checksum</a>
 49:          <a href=""https://downloads.apache.org/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-src.tar.gz.asc"">signature</a>)
 52:           <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-bin.tar.gz"">binary</a>
 53:           (<a href=""https://downloads.apache.org/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-bin.tar.gz.mds"">checksum</a>
 54:           <a href=""https://downloads.apache.org/incubator/ratis/1.0.0/apache-ratis-incubating-1.0.0-bin.tar.gz.asc"">signature</a>)
 65:          <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-src.tar.gz"">source</a>
 66:          (<a href=""https://downloads.apache.org/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-src.tar.gz.mds"">checksum</a>
 67:          <a href=""https://downloads.apache.org/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-src.tar.gz.asc"">signature</a>)
 70:           <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-bin.tar.gz"">binary</a>
 71:           (<a href=""https://downloads.apache.org/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-bin.tar.gz.mds"">checksum</a>
 72:           <a href=""https://downloads.apache.org/incubator/ratis/0.5.0/apache-ratis-incubating-0.5.0-bin.tar.gz.asc"">signature</a>)
 83:          <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-src.tar.gz"">source</a>
 84:          (<a href=""https://downloads.apache.org/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-src.tar.gz.mds"">checksum</a>
 85:          <a href=""https://downloads.apache.org/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-src.tar.gz.asc"">signature</a>)
 88:           <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-bin.tar.gz"">binary</a>
 89:           (<a href=""https://downloads.apache.org/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-bin.tar.gz.mds"">checksum</a>
 90:           <a href=""https://downloads.apache.org/incubator/ratis/0.4.0/apache-ratis-incubating-0.4.0-rc4-bin.tar.gz.asc"">signature</a>)
101:          <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-src.tar.gz"">source</a>
102:          (<a href=""https://downloads.apache.org/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-src.tar.gz.mds"">checksum</a>
103:          <a href=""https://downloads.apache.org/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-src.tar.gz.asc"">signature</a>)
106:           <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-bin.tar.gz"">binary</a>
107:           (<a href=""https://downloads.apache.org/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-bin.tar.gz.mds"">checksum</a>
108:           <a href=""https://downloads.apache.org/incubator/ratis/0.3.0/apache-ratis-incubating-0.3.0-bin.tar.gz.asc"">signature</a>)
119:          <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-src.tar.gz"">source</a>
120:          (<a href=""https://downloads.apache.org/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-src.tar.gz.mds"">checksum</a>
121:          <a href=""https://downloads.apache.org/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-src.tar.gz.asc"">signature</a>)
124:           <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-bin.tar.gz"">binary</a>
125:           (<a href=""https://downloads.apache.org/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-bin.tar.gz.mds"">checksum</a>
126:           <a href=""https://downloads.apache.org/incubator/ratis/0.2.0/apache-ratis-incubating-0.2.0-bin.tar.gz.asc"">signature</a>)
140: <li>Download the release apache-ratis-incubating-X.Y.Z-src.tar.gz from a <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis"">mirror
142: <li>Download the signature file apache-ratis-incubating-X.Y.Z-src.tar.gz.asc from
143: <a href=""https://dist.apache.org/repos/dist/release/incubator/ratis/"">Apache</a>.</li>
144: <li>Download the <a href=""https://dist.apache.org/repos/dist/release/incubator/ratis/KEYS"">Ratis
148: <li>gpg &ndash;verify apache-ratis-incubating-X.Y.Z-src.tar.gz</li>
152: <li>Download the release apache-ratis-incubating-X.Y.Z-src.tar.gz from a <a href=""https://www.apache.org/dyn/closer.cgi/incubator/ratis"">mirror
154: <li>Download the checksum apache-ratis-incubating-X.Y.Z-src.tar.gz.mds from
155: <a href=""https://dist.apache.org/repos/dist/release/incubator/ratis/"">Apache</a>.</li>
156: <li>shasum -a 256 apache-ratis-incubating-X.Y.Z-src.tar.gz</li>
158: <p>All previous releases of Ratis are available from the <a href=""https://archive.apache.org/dist/incubator/ratis/"">Apache release
   40 occurrence(s)
-- ./layouts/index.html -------------------------------------------------------
 23:                           <img class=""pull-right"" src=""apache_incubator.png"" alt=""Apache Incubator""></img>
 24:                           Apache Ratis is an effort undergoing <a href=""https://incubator.apache.org"">incubation</a> at
 25:                           <a href=""https://www.apache.org"">The Apache Software Foundation (ASF)</a>, sponsored by the Apache Incubator PMC.
 26:                           Incubation is required of all newly accepted projects until a further review indicates that the infrastructure,
 28:                           While incubation status is not necessarily a reflection of the completeness or stability of the code,
   5 occurrence(s)
-- ./layouts/partials/footer.html ---------------------------------------------
 19:                 Apache, Apache Ratis, the Apache feather logo, Apache Ratis logo, Apache Incubator logo are trademarks of The Apache Software Foundation.
   1 occurrence(s)
-- ./layouts/partials/header.html ---------------------------------------------
 30:     <link rel=""canonical"" href=""http://ratis.incubator.apache.org/"">
   1 occurrence(s)
-- ./static/doap.rdf ----------------------------------------------------------
 24:   <Project rdf:about=""https://ratis.incubator.apache.org"">
 28:     <homepage rdf:resource=""https://ratis.incubator.apache.org"" />
 29:     <asfext:pmc rdf:resource=""https://ratis.incubator.apache.org"" />
 33:     <mailing-list rdf:resource=""https://ratis.incubator.apache.org/#community"" />
 34:     <download-page rdf:resource=""https://ratis.incubator.apache.org/#download"" />
   5 occurrence(s)
{code}",[],2021-02-25 00:55:33+00:00,2021-03-11 04:31:27+00:00,2021-03-11 04:31:27+00:00,Resolved,13360851,RATIS-1324
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should update the repo links: 
- github.com/apache/incubator-ratis => github.com/apache/ratis .
- https://git-wip-us.apache.org/repos/asf?p=incubator-ratis.git => https://git-wip-us.apache.org/repos/asf?p=ratis.git",[],2021-02-25 00:48:09+00:00,2021-03-19 01:33:30+00:00,2021-03-19 16:29:45+00:00,Resolved,13360850,RATIS-1323
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Blocker,"{code:title=steps to reproduce}
git clone https://github.com/apache/ratis.git
cd ratis
rm -fr .git
mvn -DskipTests clean package
{code}

{code:title=result}
[INFO] Apache Ratis ....................................... FAILURE [  0.890 s]
...
[ERROR] Failed to execute goal org.codehaus.mojo:buildnumber-maven-plugin:1.4:create-metadata (default) on project ratis: Execution default of goal org.codehaus.mojo:buildnumber-maven-plugin:1.4:create-metadata failed.: NullPointerException -> [Help 1]
{code}",[],2021-02-24 16:12:23+00:00,2021-02-25 00:41:17+00:00,2021-02-25 04:15:04+00:00,Resolved,13360675,RATIS-1322
Test,[],ferhui,Hui Fei,ferhui,Hui Fei,Minor,"{quote}
Error:  Tests run: 15, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 60.585 s <<< FAILURE! - in org.apache.ratis.grpc.TestRaftReconfigurationWithGrpc 
[547|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:547]Error:  testBootstrapReconfWithSingleNodeAddTwo(org.apache.ratis.grpc.TestRaftReconfigurationWithGrpc) Time elapsed: 10.759 s <<< FAILURE! 
[548|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:548]java.lang.AssertionError: success=null 
[549|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:549] at org.junit.Assert.fail(Assert.java:88) 
[550|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:550] at org.junit.Assert.assertTrue(Assert.java:41) 
[551|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:551] at org.junit.Assert.assertNotNull(Assert.java:712) 
[552|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:552] at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.assertSuccess(RaftReconfigurationBaseTest.java:457) 
[553|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:553] at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.runTestBootstrapReconf(RaftReconfigurationBaseTest.java:364) 
[554|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:554] at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.lambda$testBootstrapReconfWithSingleNodeAddTwo$8(RaftReconfigurationBaseTest.java:317) 
[555|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:555] at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125) 
[556|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:556] at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113) 
[557|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:557] at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.testBootstrapReconfWithSingleNodeAddTwo(RaftReconfigurationBaseTest.java:317) 
[558|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:558] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
[559|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:559] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) 
[560|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:560] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 
[561|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:561] at java.lang.reflect.Method.invoke(Method.java:498) 
[562|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:562] at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) 
[563|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:563] at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) 
[564|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:564] at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) 
[565|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:565] at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) 
[566|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:566] at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) 
[567|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:567] at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298) 
[568|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:568] at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292) 
[569|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:569] at java.util.concurrent.FutureTask.run(FutureTask.java:266) 
[570|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:570] at java.lang.Thread.run(Thread.java:748) 
[571|https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450#step:4:571]
{quote}

link https://github.com/apache/incubator-ratis/pull/428/checks?check_run_id=1950143450",[],2021-02-22 08:36:13+00:00,,2021-02-22 08:40:12+00:00,Open,13360033,RATIS-1321
Sub-task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,Github Actions workflow should be prepared for git repo rename.,[],2021-02-20 12:26:56+00:00,2021-02-22 09:26:04+00:00,2021-02-22 11:28:21+00:00,Resolved,13359778,RATIS-1320
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The words ""incubating""/""incubator"" found in vagrant.
- ./dev-support/vagrant/README.md --------------------------------------------
{code}
 16: This is a series of scripts for [Vagrant](https://vagrantup.com) to stand-up and test [Apache (Incubating) Ratis](https://ratis.incubator.apache.org/) servers and clients. One needs to have Vagrant and [VirtualBox](https://virtualbox.org) installed to stand-up these tests environments.
   1 occurrence(s)
{code}
- ./dev-support/vagrant/Vagrantfile ------------------------------------------
{code}
 24: RATIS_PATH = ::File.join(VAGRANT_HOME, 'incubator-ratis')
   1 occurrence(s)
{code}
- ./dev-support/vagrant/bin/start_ratis_load_gen.sh --------------------------
{code}
 22: cd ${HOME}/incubator-ratis
   1 occurrence(s)
{code}
- ./dev-support/vagrant/bin/start_ratis_server.sh ----------------------------
{code}
 25: cd ${HOME}/incubator-ratis/
   1 occurrence(s)
{code}
- ./dev-support/vagrant/screenrcs/namazu_hdd_screenrc ------------------------
{code}
 23: screen -t Disk0 0 /home/vagrant/namazu/bin/nmz inspectors fs -original-dir /home/vagrant/test_data/data0 -mount-point /home/vagrant/test_data/data0_slowed/ -autopilot /home/vagrant/incubator-ratis/dev-support/vagrant/namazu_configs/hdd_config.toml
 24: screen -t Disk1 0 /home/vagrant/namazu/bin/nmz inspectors fs -original-dir /home/vagrant/test_data/data1 -mount-point /home/vagrant/test_data/data1_slowed/ -autopilot /home/vagrant/incubator-ratis/dev-support/vagrant/namazu_configs/hdd_config.toml
 25: screen -t Disk2 0 /home/vagrant/namazu/bin/nmz inspectors fs -original-dir /home/vagrant/test_data/data2 -mount-point /home/vagrant/test_data/data2_slowed/ -autopilot /home/vagrant/incubator-ratis/dev-support/vagrant/namazu_configs/hdd_config.toml
   3 occurrence(s)
{code}
- ./dev-support/vagrant/screenrcs/ratis_ratis-hdd-slowdown_screenrc ----------
{code}
 23: screen -t Server0 0 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data0_slowed n0 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 24: screen -t Server1 1 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data1_slowed n1 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 25: screen -t Server2 2 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data2_slowed n2 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 26: screen -t LoadGen 3 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_load_gen.sh n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
   4 occurrence(s)
{code}
- ./dev-support/vagrant/screenrcs/ratis_ratis-server_screenrc ----------------
{code}
 23: screen -t Server0 0 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data0 n0 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 24: screen -t Server1 1 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data1 n1 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 25: screen -t Server2 2 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh /home/vagrant/test_data/data2 n2 n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
 26: screen -t LoadGen 3 /home/vagrant/incubator-ratis/dev-support/vagrant/bin/start_ratis_load_gen.sh n0:127.0.0.1:6000,n1:127.0.0.1:6001,n2:127.0.0.1:6002
   4 occurrence(s)
 {code}",[],2021-02-20 07:28:10+00:00,2021-02-22 15:24:34+00:00,2021-02-23 01:11:01+00:00,Resolved,13359748,RATIS-1319
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"The words ""incubator"" or ""incubating"" found:
 - ./dev-support/make_rc.sh
{code:java}
 82: svn co https://dist.apache.org/repos/dist/dev/incubator/ratis ""$SVNDISTDIR""
119: tar zvxf ""$projectdir/ratis-assembly/target/apache-ratis-incubating-${RATISVERSION}-src.tar.gz""
120: cd ""apache-ratis-incubating-${RATISVERSION}""
130: cp ""$WORKINGDIR/apache-ratis-incubating-${RATISVERSION}/ratis-assembly/target/apache-ratis-incubating-${RATISVERSION}-bin.tar.gz"" ""apache-ratis-incubating-${RATISVERSION}-bin.tar.gz""
131: cp ""$projectdir/ratis-assembly/target/apache-ratis-incubating-${RATISVERSION}-src.tar.gz"" ""apache-ratis-incubating-${RATISVERSION}-src.tar.gz""
182: 10. (If the vote passed): Send out the next voting mail to the incubator mailing list.
 6 occurrence(s)
{code}

 - ./ratis-assembly/pom.xml
{code:java}
131:           <finalName>apache-ratis-incubating-${project.version}</finalName>
   1 occurrence(s)
{code}",[],2021-02-20 05:30:44+00:00,2021-02-20 09:11:25+00:00,2021-02-20 09:11:25+00:00,Resolved,13359739,RATIS-1318
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
-- ./BUILDING.md --------------------------------------------------------------
 35: These modules are located in a separated repository (https://gitbox.apache.org/repos/asf?p=incubator-ratis-thirdparty.git)
 36: but not attached to the core Apache Ratis repository (https://gitbox.apache.org/repos/asf/incubator-ratis.git)
   2 occurrence(s)
-- ./README.md ----------------------------------------------------------------
 40: [Apache Ratis]: http://ratis.incubator.apache.org/
   1 occurrence(s)
{code}",[],2021-02-19 10:04:18+00:00,2021-02-19 10:58:23+00:00,2021-02-19 10:58:24+00:00,Resolved,13359564,RATIS-1317
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Congratulations to the Ratis Community that Apache Ratis is now a Top Level Project (TLP); 

As described in https://incubator.apache.org/guides/transferring.html , we should start working on migrating the podling from the Incubator to the TLP.

Please feel free to create subtasks.",[],2021-02-19 08:28:50+00:00,,2021-02-24 09:32:33+00:00,Open,13359540,RATIS-1316
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"When I try to release ratis 2.0.0 following the [guide|https://cwiki.apache.org/confluence/plugins/servlet/mobile?contentId=120738268#content/view/120738268], first execute ./dev-support/make_rc.sh prepare-src, it succeed, but when I execute  ./dev-support/make_rc.sh prepare-bin, it failed, the error as following shows.

{code:java}
[INFO] Scanning for projects...
[ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] Child module /Users/wangjie/code/ratis/github/remote/release-ratis/incubator-ratis.2.0.0-rc0/apache-ratis-incubating-2.0.0/ratis-server-api of /Users/wangjie/code/ratis/github/remote/release-ratis/incubator-ratis.2.0.0-rc0/apache-ratis-incubating-2.0.0/pom.xml does not exist @
 @
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]
[ERROR]   The project org.apache.ratis:ratis:2.0.0 (/Users/wangjie/code/ratis/github/remote/release-ratis/incubator-ratis.2.0.0-rc0/apache-ratis-incubating-2.0.0/pom.xml) has 1 error
[ERROR]     Child module /Users/wangjie/code/ratis/github/remote/release-ratis/incubator-ratis.2.0.0-rc0/apache-ratis-incubating-2.0.0/ratis-server-api of /Users/wangjie/code/ratis/github/remote/release-ratis/incubator-ratis.2.0.0-rc0/apache-ratis-incubating-2.0.0/pom.xml does not exist
{code}
",[],2021-02-18 10:36:08+00:00,2021-02-19 07:06:36+00:00,2021-02-19 09:12:57+00:00,Resolved,13359268,RATIS-1315
Task,[],softgitron,Roni Juntunen,softgitron,Roni Juntunen,Minor,"Ratis uses currently Sonar for checking general issues and code smells during CI run. In addition to static analysis Sonar could be also used for tracking coverity of the unit tests. Coverity reports are useful for making sure that software is properly tested and amount of test cases is sufficient on new features.

What should be done:
 # Add support for JaCoCo coverage runs
 # Fix or skip test cases that do not work with coverage
 # Make sure that coverage results are sensible
 # Add coverage step to CI pipeline and upload results to Sonar",[],2021-02-12 10:14:45+00:00,,2021-02-14 19:44:19+00:00,Open,13358322,RATIS-1314
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"Run unit tests in few splits using matrix build feature of Github Actions, to reduce feedback time.",[],2021-02-09 16:47:59+00:00,2021-03-12 01:44:51+00:00,2021-03-17 11:58:59+00:00,Resolved,13357798,RATIS-1313
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-02-07 11:52:44+00:00,2021-05-07 08:48:16+00:00,2021-05-10 11:31:32+00:00,Resolved,13357379,RATIS-1312
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"Java 11 needs to be used for running the Sonar check:

{noformat:title=https://github.com/apache/incubator-ratis/runs/1835076880#step:3:5222}
Error:  Failed to execute goal org.sonarsource.scanner.maven:sonar-maven-plugin:3.6.0.1398:sonar (default-cli) on project ratis: 
Error:  
Error:  The version of Java (1.8.0_282) you have used to run this analysis is deprecated and we stopped accepting it. Please update to at least Java 11.
Error:  Temporarily you can set the property 'sonar.scanner.force-deprecated-java-version-grace-period' to 'true' to continue using Java 1.8.0_282
Error:  This will only work until Mon Feb 15 09:00:00 UTC 2021, afterwards all scans will fail.
Error:  You can find more information here: https://sonarcloud.io/documentation/upcoming/
{noformat}",[],2021-02-05 10:01:59+00:00,2021-02-17 07:20:16+00:00,2021-02-17 07:47:45+00:00,Resolved,13357017,RATIS-1311
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,We should implement a LogAppender using Streaming to minimize buffer allocation and buffer copying.,[],2021-02-05 05:46:12+00:00,,2021-02-05 06:33:29+00:00,Open,13356908,RATIS-1310
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,So ApplyTransaction is also called in the log commit order. We can clarify this in the java doc.,[],2021-02-04 19:10:33+00:00,2021-02-05 05:48:24+00:00,2021-02-05 10:32:19+00:00,Resolved,13356832,RATIS-1309
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Critical,"Findbugs fails with:

{code:title=https://github.com/apache/incubator-ratis/runs/1776425308#step:3:2360}
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  04:02 min
[INFO] Finished at: 2021-02-02T03:02:00Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.codehaus.mojo:findbugs-maven-plugin:3.0.0:findbugs (findbugs) on project ratis: Unable to parse configuration of mojo org.codehaus.mojo:findbugs-maven-plugin:3.0.0:findbugs for parameter pluginArtifacts: Cannot assign configuration entry 'pluginArtifacts' with value '${plugin.artifacts}' of type java.util.Collections.UnmodifiableRandomAccessList to property of type java.util.ArrayList -> [Help 1]
{code}

but the CI check is passing (false negative).",[],2021-02-04 12:18:00+00:00,2021-02-22 15:14:47+00:00,2021-02-22 15:42:42+00:00,Resolved,13356749,RATIS-1308
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,Compile and unit CI checks spend substantial time downloading artifacts.  This can be caching Maven dependencies.,[],2021-02-04 12:08:07+00:00,2021-02-08 00:59:30+00:00,2021-02-08 08:47:23+00:00,Resolved,13356747,RATIS-1307
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,"GitHub Actions workflows for Ratis CI have two flavors: post-commit and pull-request.  The main difference between the two is that Sonar is not updated for PRs:

{code}
-        - run: ./dev-support/checks/sonar.sh
-          if: github.repository == 'apache/incubator-ratis'
-          env:
-            SONAR_TOKEN: ${{ secrets.SONARCLOUD_TOKEN }}
-            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
{code}

Similar to HDDS-3822, we can keep only the post-commit definition and execute {{sonar.sh}} conditionally.

The other difference is missing {{Summary of failures}} in the post-commit workflow, but it can be added.",[],2021-02-04 11:58:28+00:00,2021-02-04 23:48:03+00:00,2021-02-08 08:47:40+00:00,Resolved,13356746,RATIS-1306
Bug,[],erose,Ethan Rose,erose,Ethan Rose,Blocker,"After logs have been purged from the leader and followers, the leader repeatedly attempts to send snapshots to the followers, who reject them because there have not been any new transactions to apply. The leader continues to send snapshots infinitely.

Here is an example of the log messages. om1 is the leader, om2 and om3 are followers.

On the leader om1:
{code:java}
om1_1 | 2021-02-02 17:17:23,261 [om1@group-D66704EFC61C->om2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om2-GrpcLogAppender: followerNextIndex = 337 but logStartIndex = -1, notify follower to install snapshot-(t:1, i:337)
om1_1 | 2021-02-02 17:17:23,272 [om1@group-D66704EFC61C->om3-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om3-GrpcLogAppender: followerNextIndex = 337 but logStartIndex = -1, notify follower to install snapshot-(t:1, i:337)
om1_1 | 2021-02-02 17:17:23,286 [om1@group-D66704EFC61C->om3-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om3-GrpcLogAppender: send om1->om3#0-t1,notify:(t:1, i:337)
om1_1 | 2021-02-02 17:17:23,286 [om1@group-D66704EFC61C->om2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om2-GrpcLogAppender: send om1->om2#0-t1,notify:(t:1, i:337)
om1_1 | 2021-02-02 17:17:23,522 [grpc-default-executor-1] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om3-InstallSnapshotResponseHandler: received a reply om1<-om3#0:FAIL-t1,ALREADY_INSTALLED,snapshotIndex=336
om1_1 | 2021-02-02 17:17:23,522 [grpc-default-executor-1] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om3-InstallSnapshotResponseHandler: Already Installed Snapshot Index 336.
om1_1 | 2021-02-02 17:17:23,522 [grpc-default-executor-1] INFO leader.FollowerInfo: om1@group-D66704EFC61C->om3: snapshotIndex: setUnconditionally 0 -> 336
om1_1 | 2021-02-02 17:17:23,522 [grpc-default-executor-1] INFO leader.FollowerInfo: om1@group-D66704EFC61C->om3: matchIndex: setUnconditionally 336 -> 336
om1_1 | 2021-02-02 17:17:23,523 [grpc-default-executor-1] INFO leader.FollowerInfo: om1@group-D66704EFC61C->om3: nextIndex: setUnconditionally 337 -> 337
om1_1 | 2021-02-02 17:17:23,523 [grpc-default-executor-1] INFO leader.FollowerInfo: om1@group-D66704EFC61C->om3: nextIndex: updateToMax old=337, new=337, updated? false
om1_1 | 2021-02-02 17:17:23,570 [grpc-default-executor-1] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om2-InstallSnapshotResponseHandler: received a reply om1<-om2#0:FAIL-t1,ALREADY_INSTALLED,snapshotIndex=336
om1_1 | 2021-02-02 17:17:23,570 [grpc-default-executor-1] INFO server.GrpcLogAppender: om1@group-D66704EFC61C->om2-InstallSnapshotResponseHandler: Already Installed Snapshot Index 336.

{code}
 

On follower om2:
{code:java}
om2_1 | 2021-02-02 17:17:23,306 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive installSnapshot: om1->om2#0-t1,notify:(t:1, i:337)
om2_1 | 2021-02-02 17:17:23,312 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: StateMachine snapshotIndex is 336
om2_1 | 2021-02-02 17:17:23,560 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set new configuration configurationEntry {
om2_1 | peers {
om2_1 | id: ""om1""
om2_1 | address: ""om1:9872""
om2_1 | }
om2_1 | peers {
om2_1 | id: ""om3""
om2_1 | address: ""om3:9872""
om2_1 | }
om2_1 | peers {
om2_1 | id: ""om2""
om2_1 | address: ""om2:9872""
om2_1 | }
om2_1 | }
om2_1 | from snapshot
om2_1 | 2021-02-02 17:17:23,561 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|dataStream:|priority:0, om3|rpc:om3:9872|dataStream:|priority:0, om2|rpc:om2:9872|dataStream:|priority:0], old=null
om2_1 | 2021-02-02 17:17:23,567 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: reply installSnapshot: om1<-om2#0:FAIL-t1,ALREADY_INSTALLED,snapshotIndex=336
om2_1 | 2021-02-02 17:17:23,570 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: om2: Completed INSTALL_SNAPSHOT, lastRequest: om1->om2#0-t1,notify:(t:1, i:337)

{code}
 

These log messages are repeated forever until the cluster is terminated. The term and index numbers do not change.

 

EDIT: I think the cluster not responding was caused by something different. This behavior is still a bug, however.

 ",[],2021-02-03 20:31:13+00:00,2021-02-12 00:01:18+00:00,2021-03-10 20:33:51+00:00,Resolved,13356574,RATIS-1305
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,Please see: https://github.com/apache/incubator-ratis/pull/414,[],2021-02-02 10:08:33+00:00,2021-02-04 23:48:41+00:00,2021-02-05 10:12:37+00:00,Resolved,13356156,RATIS-1304
Task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"{{ratis-thirdparty}} 0.6.0 was released recently, and now 0.6.0-SNAPSHOT is gone from the repos.",[],2021-01-31 09:36:00+00:00,2021-02-08 10:18:51+00:00,2021-02-08 10:18:55+00:00,Resolved,13355715,RATIS-1303
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Trivial,"JvmPauseMonitor prints multiline message in the log.

{noformat}
om_1     | 2021-01-29 14:59:37,955 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$364/0x0000000840497c40@47272cd3] WARN util.JvmPauseMonitor: JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 188209400ns
om_1     |
om_1     | No GCs detected
{noformat}

I think the empty line should be avoided, and the ""No GCs detected"" could fit in the same single line.  Printing each GC pool in its own line, in case of collection, is fine.",[],2021-01-29 16:03:06+00:00,2021-02-02 02:57:00+00:00,2021-03-19 07:47:37+00:00,Resolved,13355467,RATIS-1302
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"A listener is a role that only receives AppendEntries and InstallSnapshot (thus does not serve read and write requests). Listener keeps catch up RaftLog from the leader and will not automatically become a learner (or follower) unless it is promoted. 


  

",[],2021-01-28 22:39:53+00:00,,2021-02-04 02:24:10+00:00,Open,13355291,RATIS-1301
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"Got this exception during Ozone tests:

{code}
2021-01-28 12:29:41 WARN  HttpChannel:600 - /prom
java.lang.NullPointerException: Cannot invoke ""org.apache.ratis.server.raftlog.segmented.LogSegment.getTotalFileSize()"" because ""this.openSegment"" is null
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.getOpenSegmentSizeInBytes(SegmentedRaftLogCache.java:402)
	at org.apache.ratis.server.metrics.SegmentedRaftLogMetrics.lambda$null$6(SegmentedRaftLogMetrics.java:104)
	at io.prometheus.client.dropwizard.DropwizardExports.fromGauge(DropwizardExports.java:62)
	at io.prometheus.client.dropwizard.DropwizardExports.collect(DropwizardExports.java:132)
	at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.findNextElement(CollectorRegistry.java:190)
	at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.nextElement(CollectorRegistry.java:223)
	at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.nextElement(CollectorRegistry.java:144)
	at io.prometheus.client.exporter.common.TextFormat.write004(TextFormat.java:22)
	at org.apache.hadoop.hdds.server.http.PrometheusServlet.doGet(PrometheusServlet.java:66)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
	at java.base/java.lang.Thread.run(Thread.java:832)
{code}

There shouldn't be any NPE, IMHO.",[],2021-01-28 12:31:46+00:00,2021-02-05 05:05:01+00:00,2021-02-05 10:16:38+00:00,Resolved,13355173,RATIS-1300
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-01-28 11:38:55+00:00,2021-01-28 13:18:26+00:00,2021-03-19 07:47:07+00:00,Resolved,13355160,RATIS-1299
New Feature,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"It's time to add the non-voting member, or leaner that is proposed in Raft thesis 4.2.1 (you can find a copy at [1]).

The leaner is useful to maintain high availability when new servers join Raft ring (details at thesis 4.2.1). For Ozone SCM HA effort, we have also discussed the possibility to utilize leaner as the tool to replace SCM nodes online.


[1]: https://github.com/ongardie/dissertation",[],2021-01-27 18:37:00+00:00,,2021-02-08 12:54:20+00:00,Open,13355008,RATIS-1298
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,Please see: https://github.com/apache/incubator-ratis/pull/404,[],2021-01-26 12:53:38+00:00,2021-01-27 11:41:44+00:00,2021-03-19 09:29:11+00:00,Resolved,13354664,RATIS-1297
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,See: https://github.com/apache/incubator-ratis/pull/403,[],2021-01-26 12:41:55+00:00,2021-01-27 03:45:01+00:00,2021-01-27 03:45:04+00:00,Resolved,13354662,RATIS-1296
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-01-25 12:44:58+00:00,2021-01-26 03:38:22+00:00,2021-01-26 04:41:18+00:00,Resolved,13354419,RATIS-1295
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2021-01-22 09:09:01+00:00,,2021-01-22 09:10:24+00:00,Open,13353933,RATIS-1294
Bug,[],elek,Marton Elek,elek,Marton Elek,Trivial,"As [~jmclean] reported during the 0.6.0 vote, this standard phrase is missing from the the thirdpardy NOTICE file:

{code}
This product includes software developed at
The Apache Software Foundation (http://www.apache.org/).
{code}",[],2021-01-22 05:47:03+00:00,,2021-01-26 12:57:26+00:00,Open,13353905,RATIS-1293
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"Found this problem during the Ozone tests:

{code}
java.lang.NullPointerException
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.getOpenSegmentSizeInBytes(SegmentedRaftLogCache.java:402)
        at org.apache.ratis.server.metrics.SegmentedRaftLogMetrics.lambda$null$6(SegmentedRaftLogMetrics.java:104)
        at io.prometheus.client.dropwizard.DropwizardExports.fromGauge(DropwizardExports.java:62)
        at io.prometheus.client.dropwizard.DropwizardExports.collect(DropwizardExports.java:132)
        at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.findNextElement(CollectorRegistry.java:190)
        at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.nextElement(CollectorRegistry.java:223)
        at io.prometheus.client.CollectorRegistry$MetricFamilySamplesEnumeration.nextElement(CollectorRegistry.java:144)
        at io.prometheus.client.exporter.common.TextFormat.write004(TextFormat.java:22)
        at org.apache.hadoop.hdds.server.http.PrometheusServlet.doGet(PrometheusServlet.java:66)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
        at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
        at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
        at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
{code}",[],2021-01-20 15:09:15+00:00,2021-02-05 05:06:13+00:00,2021-02-05 05:06:13+00:00,Resolved,13353555,RATIS-1292
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2021-01-20 01:06:43+00:00,,2021-01-20 07:25:14+00:00,Open,13353403,RATIS-1291
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"Ratis has 3 different services (for non-stream interface):

* client
* server
* admin

These are all exposed on the same port.  It should be possible to start these on distinct ports and with different TLS configuration.",[],2021-01-18 12:58:22+00:00,2021-01-23 09:09:34+00:00,2021-01-23 09:49:31+00:00,Resolved,13353073,RATIS-1290
Improvement,[],cchenax,cchenaxchen,cchenax,cchenaxchen,Major,"when ratis created the storagedir on the bad disk,it would throw java.nio.file.AccessDeniedException",[],2021-01-18 12:47:31+00:00,2021-01-20 10:53:05+00:00,2021-02-02 05:54:22+00:00,Resolved,13353070,RATIS-1289
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2021-01-18 01:26:46+00:00,,2021-01-18 06:09:36+00:00,Open,13352946,RATIS-1288
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"RATIS-1158 collapsed multiple exception proto types to a single type called ""ThrowableProto"". This breaks wire compatibility for clients using 1.0.0 ratis protocol library.",[],2021-01-15 08:52:48+00:00,2021-01-19 23:42:43+00:00,2021-01-19 23:42:44+00:00,Resolved,13352438,RATIS-1287
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,See: https://github.com/apache/incubator-ratis/pull/394,[],2021-01-13 09:29:17+00:00,2021-01-13 12:39:56+00:00,2021-01-13 12:40:09+00:00,Resolved,13351953,RATIS-1286
Improvement,[],umamaheswararao,Uma Maheswara Rao G,umamaheswararao,Uma Maheswara Rao G,Major,"Comment 1: There are wrong link in ratis website. 

{quote}

*Getting started*

Ratis is a [Raft|https://raft.github.io/%22] protocol _library_ in Java. It’s not a standalone server application like Zookeeper or Consul.

{quote}

Comment 2: I notice the download links on your front page and not using the  correct links [1], they shouldn’t  point directly to the download area

[1] https://www.apache.org/dist/incubator/ratis/1.0.0/ <https://www.apache.org/dist/incubator/ratis/1.0.0/>",[],2021-01-11 01:10:11+00:00,2021-01-28 11:38:18+00:00,2021-01-28 20:08:08+00:00,Resolved,13351345,RATIS-1285
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"Run the test 20 times, will failed at the Assert.assertEquals(leader.getId(), lastServerLeaderId);
{code:java}
  @Test
  public void testLateServerStart() throws Exception {
    for (int k = 0; k < 20; k ++) {
      final int numServer = 3;
      ...
      Assert.assertEquals(leader.getId(), lastServerLeaderId);
    }
 }
{code}
",[],2021-01-08 01:29:44+00:00,,2021-01-08 01:31:00+00:00,Open,13350988,RATIS-1284
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-1282, RaftServerImpl should use the same condition to check the Pre-Vote phase and the Election phase.",[],2021-01-07 09:23:21+00:00,2021-01-08 02:55:15+00:00,2021-01-08 02:55:46+00:00,Resolved,13350837,RATIS-1283
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This is a followup work of RATIS-993 to reduce the code duplication between preVote and vote.,[],2021-01-06 14:35:17+00:00,2021-01-07 12:00:44+00:00,2021-01-07 12:00:47+00:00,Resolved,13350681,RATIS-1282
Bug,[],ferhui,Hui Fei,ferhui,Hui Fei,Major,"This UT always timeout, even though I increase the time.
{code:java}
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 60.201 s <<< FAILURE! - in org.apache.ratis.grpc.TestRetryCacheWithGrpc
[ERROR] testRetryOnResourceUnavailableException(org.apache.ratis.grpc.TestRetryCacheWithGrpc)  Time elapsed: 60.022 s  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 60000 milliseconds
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.PrintStream.write(PrintStream.java:480)
	at org.apache.maven.surefire.booter.ForkingRunListener.writeTestOutput(ForkingRunListener.java:208)
	at org.apache.maven.surefire.report.ConsoleOutputCapture$ForwardingPrintStream.write(ConsoleOutputCapture.java:60)
	at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
	at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291)
	at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:295)
	at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:141)
	at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:229)
	at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:59)
	at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:324)
	at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
	at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
	at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
	at org.apache.log4j.Category.callAppenders(Category.java:206)
	at org.apache.log4j.Category.forcedLog(Category.java:391)
	at org.apache.log4j.Category.log(Category.java:856)
	at org.slf4j.impl.Log4jLoggerAdapter.debug(Log4jLoggerAdapter.java:253)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:727)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:415)
	at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$678/122031867.apply(Unknown Source)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:410)
	at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$603/413337014.get(Unknown Source)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:410)
	at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$601/602116397.apply(Unknown Source)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124)
	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:409)
	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:415)
	at org.apache.ratis.grpc.TestRetryCacheWithGrpc.testRetryOnResourceUnavailableException(TestRetryCacheWithGrpc.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)

In {code}
The first while clause in TestRetryCacheWithGrpc#testRetryOnResourceUnavailableException
{code:java}
while (!failure.get()) {
  long cid = callId;
  r = cluster.newRaftClientRequest(clientId, leaderProxy.getId(), callId++,
      new RaftTestUtil.SimpleMessage(""message""));
  CompletableFuture<RaftClientReply> f = leaderProxy.submitClientRequestAsync(r);
  f.exceptionally(e -> {
      if (e.getCause() instanceof ResourceUnavailableException) {
        RetryCacheTestUtil.isFailed(RetryCacheTestUtil.get(leader, clientId, cid));
        failure.set(true);
      }
      return null;
  });
}

{code}
There are 2 requests here, and because followers call blockWriteStateMachineData, the first request will be blocked, and ELEMENT_LIMIT_KEY is 1, the second request will fail and receive ResourceUnavailableException.

After quittng the first while clause. followers call unblockWriteStateMachineData

In the second while clause

{code}

while (failure.get()) {
  try {
  // retry until the request failed with ResourceUnavailableException succeeds.
  leaderProxy.submitClientRequestAsync(r).get();
  } catch (Exception e) {
    failure.set(false);
  }
}

{code}

There are 2 cases: 1. If the first request has been done, the 3rd request will be handled, and later requests will hit retrycache, and server will always return success. It couldn't get Exception and enter infinite loop. 2. If the first request hasn't been done, and the 3rd request has been reach the server, it will get   ResourceUnavailableException and set failure true, and quit the loop.

Mostly the case 1 occurs, and this UT nearly always fails

 

So i suggest that quit the loop when request handled successfully as the comments say
{quote}// retry until the request failed with ResourceUnavailableException succeeds.
{quote}",[],2021-01-06 09:14:47+00:00,2021-01-19 06:21:33+00:00,2021-01-19 06:25:26+00:00,Resolved,13350625,RATIS-1281
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,A RoutingTable should be validated before building it.,[],2021-01-01 10:07:54+00:00,2021-01-04 07:04:08+00:00,2021-01-04 07:04:45+00:00,Resolved,13348656,RATIS-1280
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2021-01-01 09:00:20+00:00,,2021-01-01 09:30:08+00:00,Open,13348653,RATIS-1279
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-12-30 12:07:30+00:00,2020-12-31 03:25:24+00:00,2020-12-31 03:25:24+00:00,Resolved,13348466,RATIS-1278
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"

 !screenshot-3.png! 

As the following image and code shows, the code check the byteWritten of STREAM_HEADER, i.e. 0,  equals to 10000, of course failed.

 !screenshot-2.png! 


{code:java}
static boolean checkSuccessRemoteWrite(List<CompletableFuture<DataStreamReply>> replyFutures, long bytesWritten) {
    for (CompletableFuture<DataStreamReply> replyFuture : replyFutures) {
      final DataStreamReply reply = replyFuture.join();
      if (!reply.isSuccess() || reply.getBytesWritten() != bytesWritten) {
        + System.err.println(""succ:"" + reply.isSuccess() + "" reply written:"" + reply.getBytesWritten() +
        +    "" expected:"" + bytesWritten + "" clientId:"" + reply.getClientId() + "",type:"" + reply.getType() + "",streamId"" +
        +    reply.getStreamId() + "",offset:"" + reply.getStreamOffset() + "",datalength:"" + reply.getDataLength());
        return false;
      }
    }
    return true;
  }
{code}
",[],2020-12-30 11:29:51+00:00,2020-12-31 10:41:51+00:00,2020-12-31 10:41:51+00:00,Resolved,13348460,RATIS-1277
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-30 09:02:23+00:00,2020-12-30 14:21:45+00:00,2020-12-30 14:21:45+00:00,Resolved,13348434,RATIS-1276
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As reported by [~yjxxtd], the scripts in ratis-example no longer can print log messages after RATIS-1272; see [his comment|https://issues.apache.org/jira/browse/RATIS-1272?focusedCommentId=17256338&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17256338] for the details.",[],2020-12-30 08:28:07+00:00,2020-12-30 09:49:47+00:00,2020-12-30 09:49:47+00:00,Resolved,13348431,RATIS-1275
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-29 08:24:51+00:00,2020-12-29 10:49:40+00:00,2020-12-29 10:49:40+00:00,Resolved,13348254,RATIS-1274
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"For example, there are 3 servers: server1, server2, server3, and server1 is leader. When split-brain happens, server2 was elected as new leader, but server1 still think it's leader, when client read from server1, if server2 has processed write request, client will read old data from server1.

",[],2020-12-28 11:48:58+00:00,,2021-01-20 07:35:32+00:00,Open,13348118,RATIS-1273
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In some modules, slf4j-log4j12 is not used so that the dependency should be removed.

In some other modules, slf4j-log4j12 is used only in the tests.  Then, it should use test scope.",[],2020-12-28 10:59:19+00:00,2020-12-28 11:36:40+00:00,2020-12-30 08:57:53+00:00,Resolved,13348109,RATIS-1272
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should bump mockito for the following todo in /LogSegment.
{code}
public class LogSegment implements Comparable<Long> {
  //TODO: This class needs to be made final to address checkstyle issue. However, TestCacheEviction fails as Mockito
  // cannot spy final class. This problem can be fixed when stable version of Mockito 2.x is available which provides
  // a feature to mock final class/method.
{code}",[],2020-12-27 18:05:14+00:00,2020-12-28 01:13:38+00:00,2020-12-28 01:13:38+00:00,Resolved,13348033,RATIS-1271
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When the primaryDataStreamServer is not set in RaftClient.Builder, use the first server in the group as the default.",[],2020-12-27 16:52:50+00:00,2020-12-27 23:32:15+00:00,2020-12-27 23:32:16+00:00,Resolved,13348027,RATIS-1270
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Add a new AdminApi for RaftClient.  Then, move setConfiguration and transferLeadership to there.",[],2020-12-27 07:26:14+00:00,2020-12-27 23:32:57+00:00,2020-12-27 23:32:57+00:00,Resolved,13347992,RATIS-1269
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"What's the problem ?
For example, when s0 is leader, and s1 askForVote, in the first rpc of askForVote, s0 can not vote for s1, even though s1's log catch up. When s1 askForVote the second time, s0 has become follower in the first askForVote, so s0 can vote for s1, waste one rpc call.

What's the reason ?
As the following code shows, when s0 is leader, role.getFollowerState().orElse(null) should return null,
then can not pass check if (fs != null && candidate != null) because fs is null, so s0 can not vote for s1.


{code:java}
      FollowerState fs = role.getFollowerState().orElse(null);
      if (shouldWithholdVotes(candidateTerm)) {
        ...
      } else if (state.recognizeCandidate(candidateId, candidateTerm)) {
        final boolean termUpdated = changeToFollower(candidateTerm, true, ""recognizeCandidate:"" + candidateId);
        RaftPeer candidate = getRaftConf().getPeer(candidateId);
        if (fs != null && candidate != null) {
         ...
       }
{code}

How to fix ?

After leader final boolean termUpdated = changeToFollower(candidateTerm, true, ""recognizeCandidate:"" + candidateId);, we can get fs again.",[],2020-12-27 02:38:32+00:00,2021-01-05 09:55:11+00:00,2021-01-05 10:45:42+00:00,Resolved,13347981,RATIS-1268
Bug,[],ferhui,Hui Fei,ferhui,Hui Fei,Major,"When run ratis examples , get the following errors.
{quote}
Found /Users/fermi/projects/incubator-ratis/ratis-examples/target/ratis-examples-1.1.0-SNAPSHOT.jar
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 3
	at org.apache.ratis.examples.common.SubCommandBase.lambda$parsePeers$0(SubCommandBase.java:46)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546)
	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260)
	at java.util.stream.ReferencePipeline.toArray(ReferencePipeline.java:438)
	at org.apache.ratis.examples.common.SubCommandBase.parsePeers(SubCommandBase.java:48)
	at org.apache.ratis.examples.common.SubCommandBase.getPeers(SubCommandBase.java:52)
	at org.apache.ratis.examples.common.SubCommandBase.getPeer(SubCommandBase.java:84)
	at org.apache.ratis.examples.arithmetic.cli.Server.run(Server.java:60)
	at org.apache.ratis.examples.common.Runner.main(Runner.java:63)

{quote}",[],2020-12-25 12:22:14+00:00,2020-12-28 09:44:52+00:00,2020-12-28 09:44:52+00:00,Resolved,13347875,RATIS-1267
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-25 07:53:50+00:00,2020-12-27 23:33:07+00:00,2020-12-27 23:33:07+00:00,Resolved,13347848,RATIS-1266
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"As the attached log shows, there are 3 servers: s0, s1, s2,  and s2 is the leader, then we change s0 with the highest priority, so s2 will yieldLeaderToHigherPriorityPeer(s0) when s0's log catch up. In yieldLeaderToHigherPriorityPeer, s2 will step down.
But when s2 step down,  which server will request vote is almost random, if s0 can not request vote in a short time, the leader election will last a long time.

As the attached log shows, election happen 8 times and last 14 seconds, but s0 only try start leader election at the 6th time, and can not get the leadership.

{code:java}
2020-12-25 10:11:34,995     s1: start s1@group-241716F733F8-LeaderElection2          fail because s0 reject
2020-12-25 10:11:37,228      s2: start s2@group-241716F733F8-LeaderElection3        fail because s0 reject
2020-12-25 10:11:39,345     s1: start s1@group-241716F733F8-LeaderElection4         fail because s0 reject
2020-12-25 10:11:41,600      s1: start s1@group-241716F733F8-LeaderElection5         fail because s0 reject
2020-12-25 10:11:43,710      s2: start s2@group-241716F733F8-LeaderElection6        fail because s0 reject

2020-12-25 10:11:46,248     s0: start s0@group-241716F733F8-LeaderElection7         fail because s1 start election after 200ms, s1's request vote arrives s2 before s0, so s1 voted for itself and rejected s0 at 2020-12-25 10:11:47,267, and s2 voted for s1 at 2020-12-25 10:11:46,469 and rejected s0 at 2020-12-25 10:11:47,267

2020-12-25 10:11:46,461      s1: start s1@group-241716F733F8-LeaderElection8         fail because s0 reject
2020-12-25 10:11:48,597      s2: start s2@group-241716F733F8-LeaderElection9        fail because s0 reject
{code}

",[],2020-12-25 02:30:11+00:00,,2020-12-25 08:00:17+00:00,Open,13347806,RATIS-1265
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-24 23:49:06+00:00,2020-12-25 01:31:29+00:00,2020-12-25 01:31:29+00:00,Resolved,13347801,RATIS-1264
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-24 11:52:55+00:00,2020-12-24 15:44:30+00:00,2020-12-24 15:44:36+00:00,Resolved,13347742,RATIS-1263
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"There are two case violate linearizable read, for example, there are 3 servers: server1, server2, server3, and server1 is leader

Case 1.  server1: applyIndex = 2, commitIndex = 2, server2: applyIndex = 1, commitIndex = 2. When server1 step down, server2 become leader, and client read from server2,
because server2's applyIndex less than commitIndex, client will read old data.

Case 2.  when split-brain happens, server2 was elected as new leader, but server1 still think it's leader, when client read from server1, if server2 has processed write request, client will read old data from server1. As [~glengeng] explained, RATIS-981 still exist dirty-read in server.getMaxTimeoutMs(), i.e. 300ms,  if split-brain happens.


etcd / sofa-jraft / pingcap all support linearizable read which has been explained in raft paper, we can implement it in ratis.  It's important in Ozone HA.

pingcap's linearizable read: https://en.pingcap.com/blog/lease-read",[],2020-12-24 06:56:47+00:00,,2020-12-24 12:33:15+00:00,Open,13347700,RATIS-1262
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-24 00:52:47+00:00,2020-12-25 11:09:40+00:00,2020-12-25 11:09:40+00:00,Resolved,13347665,RATIS-1261
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-23 01:27:48+00:00,2020-12-24 00:50:59+00:00,2020-12-24 00:51:08+00:00,Resolved,13347461,RATIS-1260
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Finally, we are ready to move RaftServer and the related interfaces to raft-server-api.",[],2020-12-23 01:03:26+00:00,2020-12-23 06:06:55+00:00,2020-12-23 06:06:55+00:00,Resolved,13347459,RATIS-1259
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-12-22 19:24:23+00:00,,2021-01-06 06:24:04+00:00,Open,13347420,RATIS-1258
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-1252, we should refactor RaftServerMetrics and move its interface to raft-server-api.",[],2020-12-22 13:26:47+00:00,2020-12-22 23:37:24+00:00,2020-12-22 23:37:25+00:00,Resolved,13347355,RATIS-1257
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In LeaderStateImpl.updateCommit, it gets entriesToCommit using the majority index and then updateCommitIndex.  However, updateCommitIndex may update to a lower index than the majority index.  Therefore, entriesToCommit may contain non-committed entries.",[],2020-12-21 05:35:06+00:00,2020-12-22 02:41:36+00:00,2021-02-02 05:56:56+00:00,Resolved,13347075,RATIS-1256
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"RaftLog should be separated into interface and implementation.  Then, move the interface to raft-server-api",[],2020-12-21 03:26:33+00:00,2020-12-22 13:27:32+00:00,2020-12-22 13:27:32+00:00,Resolved,13347066,RATIS-1255
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-21 01:52:57+00:00,2020-12-24 00:52:00+00:00,2020-12-24 00:52:07+00:00,Resolved,13347063,RATIS-1254
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-20 08:31:59+00:00,2020-12-22 10:30:36+00:00,2020-12-22 10:30:37+00:00,Resolved,13346996,RATIS-1253
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- The code in RaftLogMetrics specific to SegmentedRaftLog should be moved out to a new class, say SegmentedRaftLogMetrics.
- A few methods in RaftLogMetrics should be moved to ratis-server-api.  Then, we can move RaftLog to ratis-server-api in the next JIRA.",[],2020-12-20 02:53:20+00:00,2020-12-20 23:34:18+00:00,2020-12-20 23:34:18+00:00,Resolved,13346976,RATIS-1252
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Move StateMachine, TransactionContext and the related classes to ratis-server-api.",[],2020-12-18 18:37:51+00:00,2020-12-20 01:09:46+00:00,2020-12-20 01:09:48+00:00,Resolved,13346854,RATIS-1251
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Separate the APIs from RaftStorage and the related classes.  Then, move them to the ratis-server-api module.",[],2020-12-18 02:34:29+00:00,2020-12-18 05:16:55+00:00,2020-12-18 05:16:55+00:00,Resolved,13346694,RATIS-1250
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-17 11:39:54+00:00,2020-12-20 08:31:32+00:00,2020-12-20 08:31:32+00:00,Resolved,13346577,RATIS-1249
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-17 11:26:20+00:00,2020-12-21 08:57:52+00:00,2020-12-21 08:57:52+00:00,Resolved,13346572,RATIS-1248
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-17 08:28:59+00:00,2020-12-27 23:33:20+00:00,2020-12-27 23:33:20+00:00,Resolved,13346527,RATIS-1247
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RaftStorageDirectory.LogPathAndIndex is for SegmentedRaftLog.  It should be moved to org.apache.ratis.server.raftlog.segmented.,[],2020-12-17 08:15:01+00:00,2020-12-18 00:57:50+00:00,2020-12-18 00:57:52+00:00,Resolved,13346522,RATIS-1246
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"In HA case, such as there are three server: server1, server2, server3, server1 is the leader, if we want to rolling upgrade leader, we can upgrade server2,  and then assign server2 with the highest priority, and server1 stop accepting client request, then server2 will try to grab the leader once catch up the log, if we want to rollback, we can assign server1 with the highest priority and server2 stop accepting client request.",[],2020-12-17 06:15:37+00:00,2020-12-17 08:26:05+00:00,2020-12-17 08:26:05+00:00,Resolved,13346496,RATIS-1245
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- Move MetaFile to RaftStorageMetadataFile.
- Move RaftLog.Metadata to RaftStorageMetadata.",[],2020-12-16 17:05:05+00:00,2020-12-16 23:37:13+00:00,2020-12-16 23:37:13+00:00,Resolved,13346394,RATIS-1244
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Create ratis-server-api module and move the easy interfaces to there.,[],2020-12-16 10:05:22+00:00,2020-12-16 13:21:24+00:00,2020-12-16 13:21:24+00:00,Resolved,13346322,RATIS-1243
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-1181, we separate the server APIs from their implementations.  In this JIRA, we move the server APIs to a new maven module ratis-server-api",[],2020-12-16 09:58:23+00:00,2020-12-24 00:53:59+00:00,2021-03-01 01:48:25+00:00,Resolved,13346320,RATIS-1242
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Critical,"*Steps to reproduce*
* Setup a 3 node ratis group.
* Write some transactions into the quorum.
* Bring 1 peer down. 
* Write more transactions into the quorum (other 2 nodes), take a snapshot at the last txn and purge logs from the remaining 2 nodes.
* Start the node that was brought down.


Leader falls into a possible irrecoverable state with respect to appending log entries to the follower.

First time the follower comes back
{code}
2020-12-15 15:42:01,069 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(110)) - omNode-3@group-523986131536->omNode-2-GrpcLogAppender: Leader has not got in touch with Follower omNode-3@group-523986131536->omNode-2(c-1,m0,n409, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=8398) yet, just keep nextIndex unchanged and retry.
2020-12-15 15:42:01,570 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:setLeader(260)) - omNode-2@group-523986131536: change Leader from null to omNode-3 at term 3 for appendEntries, leader elected after 954ms
2020-12-15 15:42:01,570 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1249)) - omNode-2@group-523986131536: Failed appendEntries as previous log entry ((t:3, i:408)) is not found
2020-12-15 15:42:01,571 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1215)) - omNode-2@group-523986131536: inconsistency entries. Reply:omNode-3<-omNode-2#11187658:FAIL,INCONSISTENCY,nextIndex:205,term:2,followerCommit:203
2020-12-15 15:42:01,572 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(46)) - omNode-3@group-523986131536->omNode-2: nextIndex: updateUnconditionally 409 -> 205
2020-12-15 15:42:01,572 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] ERROR leader.LogAppenderDaemon (LogAppenderDaemon.java:run(86)) - omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon failed
org.apache.ratis.server.raftlog.RaftLogIOException: Log entry not found: index = 205
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:283)
        at org.apache.ratis.server.leader.LogAppenderBase.newAppendEntriesRequest(LogAppenderBase.java:143)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:210)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:144)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:77)
        at java.lang.Thread.run(Thread.java:748)
2020-12-15 15:42:01,572 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServer$Division (LeaderStateImpl.java:restart(497)) - omNode-3@group-523986131536-LeaderStateImpl: Restarting GrpcLogAppender for omNode-3@group-523986131536->omNode-2
{code}


After the above, the leader falls into this error loop.

{code}
2020-12-15 15:42:01,574 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] ERROR leader.LogAppenderDaemon (LogAppenderDaemon.java:run(86)) - omNode-3@group-523986131536->omNode-2-GrpcLogAp
pender-LogAppenderDaemon failed
org.apache.ratis.server.raftlog.RaftLogIOException: Log entry not found: index = 0
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:283)
        at org.apache.ratis.server.leader.LogAppenderBase.newAppendEntriesRequest(LogAppenderBase.java:143)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:210)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:144)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:77)
        at java.lang.Thread.run(Thread.java:748)
2020-12-15 15:42:01,575 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServer$Division (LeaderStateImpl.java:restart(497)) - omNode-3@group-523986131536-LeaderStateImp
l: Restarting GrpcLogAppender for omNode-3@group-523986131536->omNode-2
2020-12-15 15:42:01,575 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(43)) - Unregistering Metrics Registry : ratis_grpc.log_a
ppender.omNode-3@group-523986131536
2020-12-15 15:42:01,575 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max
= 16MB (=16777216) (default)
2020-12-15 15:42:01,575 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 3355
4432 (custom)
2020-12-15 15:42:01,576 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1
024 (custom)
2020-12-15 15:42:01,576 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (de
fault)
2020-12-15 15:42:01,576 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 3000ms (default
)
2020-12-15 15:42:01,576 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled
 = false (custom)
2020-12-15 15:42:01,576 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(36)) - Creating Metrics Registry : ratis_grpc.log_a
ppender.omNode-3@group-523986131536
2020-12-15 15:42:01,577 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] ERROR leader.LogAppenderDaemon (LogAppenderDaemon.java:run(86)) - omNode-3@group-523986131536->omNode-2-GrpcLogAp
pender-LogAppenderDaemon failed
org.apache.ratis.server.raftlog.RaftLogIOException: Log entry not found: index = 0
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:283)
        at org.apache.ratis.server.leader.LogAppenderBase.newAppendEntriesRequest(LogAppenderBase.java:143)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:210)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:144)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:77)
        at java.lang.Thread.run(Thread.java:748)
2020-12-15 15:42:01,578 [omNode-3@group-523986131536->omNode-2-GrpcLogAppender-LogAppenderDaemon] INFO  server.RaftServer$Division (LeaderStateImpl.java:restart(497)) - omNode-3@group-523986131536-LeaderStateImpl: Restarting GrpcLogAppender for omNode-3@group-523986131536->omNode-2
{code}",[],2020-12-15 23:45:40+00:00,2020-12-22 03:24:55+00:00,2021-02-02 05:53:26+00:00,Resolved,13346216,RATIS-1241
Sub-task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,bq. add[...] a new {{streamReadOnly(..)}} method to {{DataStreamApi}} and then work on {{DataStreamInput}} ([comment|https://issues.apache.org/jira/browse/RATIS-1086?focusedCommentId=17248105&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17248105]),[],2020-12-14 09:40:22+00:00,,2021-04-20 14:48:19+00:00,Open,13345812,RATIS-1240
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The TermIndexImpl in ServerImplUtils should be moved to TermIndex.  Similarly, the toTermIndex(..) methods in ServerProtoUtils should also be moved to TermIndex.",[],2020-12-14 09:20:43+00:00,2020-12-14 12:43:22+00:00,2020-12-14 12:43:22+00:00,Resolved,13345806,RATIS-1239
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-14 06:16:03+00:00,2020-12-14 07:00:33+00:00,2020-12-14 07:00:40+00:00,Resolved,13345777,RATIS-1238
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,There are a few methods in ServerProtoUtils for converting protos to strings.  Let's move them out to a new public ServerStringUtils class.,[],2020-12-14 01:05:33+00:00,2020-12-14 06:22:55+00:00,2020-12-14 06:22:59+00:00,Resolved,13345761,RATIS-1237
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Some methods in ServerProtoUtils are used by the leader only.  They should be moved to the org.apache.ratis.server.leader package.,[],2020-12-13 10:49:13+00:00,2020-12-13 23:32:24+00:00,2020-12-13 23:32:24+00:00,Resolved,13345725,RATIS-1236
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Ratis website lists the old slack workspace. This should be updated to the channel being used currently.,[],2020-12-11 16:21:00+00:00,2020-12-16 09:03:17+00:00,2020-12-16 09:03:17+00:00,Resolved,13345554,RATIS-1235
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"[~szetszwo] Hi, my network bandwidth is only 10000Mb / s, because primary need to stream data to two peers, the max IO speed for peer is only 5000Mb / s, about 625MB / s. So I can not test the max throughput of ratis streaming and ozone cluster.

Besides, ozone has the balance leader feature, for example, if ozone cluster has 6 pipeline, 3 datanodes, each datanode has 2 leader, the 10000Mb /s can be used fully for each datanode. So with this 10000Mb / s network bandwidth, we can not compare ozone and DataStreamApi, unless we change DataStreamApi to primary -> peer -> peer, or we need machine with bigger network bandwidth, but I do not have.

Actually, I test the performance of ozone and DataStreamApi with high load, they are almost similar.",[],2020-12-11 14:39:40+00:00,2020-12-17 01:17:05+00:00,2020-12-17 01:17:07+00:00,Resolved,13345539,RATIS-1234
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-1230, the StateMachineData methods in ServerProtoUtils should be moved to LogProtoUtils.",[],2020-12-11 10:09:55+00:00,2020-12-13 09:26:01+00:00,2020-12-13 09:26:01+00:00,Resolved,13345479,RATIS-1233
Improvement,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"During ingroups, it checks for in ratis storage directory location for all directories which match with UUID, as ratis group ID is represented with UUID. For any other directory it logs at Warn, I believe we can move this statement to debug level, as anyway those directories are not related to Ratis, as by default ratis creates directories in ratis.storage.dir only UUID.
",[],2020-12-10 20:07:32+00:00,2020-12-11 10:03:49+00:00,2020-12-11 17:43:59+00:00,Resolved,13345372,RATIS-1232
Improvement,[],vladsz83,Vladimir Steshin,vladsz83,Vladimir Steshin,Major,"* Prepared separated, centralized place for JVM settings for further extending and development. Can be used for handy test experiments.
* Node id is now read from the log, not by remote JMX call. Faster, simpler, more reliable. JMX fails sometimes on small timeouts because node id is not published yet. Started node always prints its node id on info level.
* failure_detection_timeout is now global variable with default value. To run cluster experiments with different settings and on various node count.
* ZooKeeperSPI got parameter 'session_timeout' according to the documentation.
* To reduce node failure detection time in 2.8, restored 'soLinger' setting in TCPDiscoverySPI which depends on the Ignite version. No need in > 2.9.0. Impossible for < 2.8.0.
* Restored logging of the ipfilter crashing nodes.
* Introduced 'forceSync' setting for ZooKeeper server to avoid slow disk problem.
* Simplified await timeout on 'Node failure event'. Discovered sensitive delays on ssh, log reads and other non-manageable timeouts",[],2020-12-10 15:52:44+00:00,2020-12-10 15:53:59+00:00,2020-12-10 15:54:12+00:00,Closed,13345320,RATIS-1231
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,There are quite a few LogEntryProto methods in org.apache.ratis.server.impl.ServerProtoUtils.  They should be moved to the org.apache.ratis.server.raftlog package.,[],2020-12-10 15:06:10+00:00,2020-12-11 07:18:38+00:00,2020-12-11 07:18:38+00:00,Resolved,13345310,RATIS-1230
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-10 11:01:46+00:00,2020-12-11 07:51:09+00:00,2020-12-11 07:51:11+00:00,Resolved,13345272,RATIS-1229
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-10 02:16:32+00:00,2020-12-10 02:58:40+00:00,2020-12-10 02:58:45+00:00,Resolved,13345182,RATIS-1228
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RaftServerRpcWithProxy is an abstract class.  Its constructor and the abstract impl methods are for subclasses.  They should be protected instead of public.,[],2020-12-10 00:31:30+00:00,2020-12-10 05:32:50+00:00,2020-12-10 05:32:52+00:00,Resolved,13345165,RATIS-1227
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In DataStreamManagement.newStreamInfo(..), when the server is the primary, it should get the other peers from the current RaftConfiguration to create a StreamInfo.  Then, it can support configuration change and also multiple raft groups.
",[],2020-12-09 15:01:33+00:00,2020-12-09 23:35:39+00:00,2020-12-09 23:35:39+00:00,Resolved,13345100,RATIS-1226
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After RATIS-1224, RaftServerConstants only has StartupOption, which it only used in RaftStorage.  We may move StartupOption to RaftStorage and remove RaftServerConstants.",[],2020-12-09 10:47:37+00:00,2020-12-09 12:52:39+00:00,2020-12-09 12:52:39+00:00,Resolved,13345046,RATIS-1225
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, call ids are generated in RaftClientImpl.  However, callId is useful for other calls.  We should define a public CallId class.",[],2020-12-09 07:56:12+00:00,2020-12-09 10:40:41+00:00,2020-12-09 10:45:02+00:00,Resolved,13345010,RATIS-1224
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-09 04:11:56+00:00,2020-12-09 12:05:21+00:00,2020-12-09 12:05:21+00:00,Resolved,13344978,RATIS-1223
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-09 03:16:41+00:00,,2020-12-10 11:00:32+00:00,Open,13344972,RATIS-1222
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-08 15:02:50+00:00,2020-12-08 15:04:01+00:00,2020-12-08 15:04:01+00:00,Resolved,13344858,RATIS-1221
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,,[],2020-12-08 14:23:41+00:00,2020-12-09 03:52:58+00:00,2020-12-09 03:52:58+00:00,Resolved,13344837,RATIS-1220
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RaftConfiguration is a public API but it is in org.apache.ratis.server.impl.  We should define an interface and move it to org.apache.ratis.server.,[],2020-12-08 08:17:24+00:00,2020-12-09 03:45:24+00:00,2020-12-09 03:45:24+00:00,Resolved,13344742,RATIS-1219
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-08 07:18:55+00:00,2020-12-08 15:09:54+00:00,2020-12-08 15:10:05+00:00,Resolved,13344732,RATIS-1218
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-08 01:33:57+00:00,2020-12-08 08:28:08+00:00,2020-12-08 08:28:08+00:00,Resolved,13344688,RATIS-1217
Improvement,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"{code}
      try {
        state.appendLog(context);
      } catch (StateMachineException e) {
        // the StateMachineException is thrown by the SM in the preAppend stage.
        // Return the exception in a RaftClientReply.
        RaftClientReply exceptionReply = newExceptionReply(request, e);
        cacheEntry.failWithReply(exceptionReply);
        // leader will step down here
        if (getInfo().isLeader()) {
          leaderState.submitStepDownEvent(LeaderState.StepDownReason.STATE_MACHINE_EXCEPTION);
        }
        return CompletableFuture.completedFuture(exceptionReply);
      }
{code}

The state machine can throw a StateMachine exception, which has a flag to disable leader step down action. The default for this flag would be true.",[],2020-12-07 17:46:32+00:00,2020-12-11 01:16:30+00:00,2020-12-11 01:16:30+00:00,Resolved,13344631,RATIS-1216
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-07 11:23:00+00:00,2020-12-07 13:29:39+00:00,2021-02-02 05:55:51+00:00,Resolved,13344543,RATIS-1215
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,LogAppenderBase current include the default LogAppender implementation.  The JIRA is to move the default implementation to a new class and change LogAppenderBase to abstract.,[],2020-12-07 07:58:01+00:00,2020-12-07 08:49:29+00:00,2020-12-07 08:49:41+00:00,Resolved,13344507,RATIS-1214
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-12-07 03:17:56+00:00,2020-12-07 06:05:54+00:00,2020-12-07 06:05:54+00:00,Resolved,13344477,RATIS-1213
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-07 01:03:46+00:00,2020-12-07 03:22:38+00:00,2020-12-07 03:22:44+00:00,Resolved,13344461,RATIS-1212
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"It failed quite a few times recently.
{code}
Error:  Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 12.994 s <<< FAILURE! - in org.apache.ratis.server.simulation.TestLogAppenderWithSimulatedRpc
679
Error:  testUnlimitedElementBuffer(org.apache.ratis.server.simulation.TestLogAppenderWithSimulatedRpc)  Time elapsed: 1.531 s  <<< ERROR!
org.apache.ratis.server.raftlog.RaftLogIOException: java.lang.NullPointerException
	at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:342)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.get(SegmentedRaftLog.java:275)
	at org.apache.ratis.RaftTestUtil.countEntries(RaftTestUtil.java:480)
	at org.apache.ratis.LogAppenderTests.runTest(LogAppenderTests.java:213)
	at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:123)
	at org.apache.ratis.server.impl.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:111)
	at org.apache.ratis.LogAppenderTests.testUnlimitedElementBuffer(LogAppenderTests.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.util.Objects.requireNonNull(Objects.java:203)
	at org.apache.ratis.server.raftlog.segmented.LogSegment$LogEntryLoader.load(LogSegment.java:235)
	at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:340)
	... 19 more
{code}",[],2020-12-07 00:35:13+00:00,2020-12-07 12:01:10+00:00,2020-12-07 12:01:10+00:00,Resolved,13344460,RATIS-1211
Sub-task,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"In OM HA to support upgrades with out any additional steps like prepareUpgrade for express upgrade,  a new proposal is coming up to change in the way request is processed and also in the future to support rolling upgrades. In the previous approach request logic is executed by the leader/follower OMs.

In the new approach, only leader OM processes the request and submits only the information which needs to be persisted to DB to ratis. So, with this approach after isLeaderReady() check, we first need to check retry cache to see if this is a retry request before processing the request in OM for idempotency/correctness.

This Jira is to propose to expose retry cache and also expose a method to just query retry cache. As current queryCacheResult, if not exists, adds a new entry to cache.

Scenario:
Leader processed the request and submitted to OM, leader adds to it log, and send to followers, just before applyTransaction leader change happened. In ratis all pending requests are responded with NotLeaderException. So, when the new OM before becoming ready, it should process all the requests, as the previous transaction is in majority this transaction will be applied by new leader OM and then becomes ready. So, when the client retries on new OM with same clientID and callID OM leader before processing it should detect is retry request for that it needs to check ratis retry cache. 


",[],2020-12-06 18:04:16+00:00,2020-12-08 05:28:04+00:00,2020-12-08 05:28:05+00:00,Resolved,13344445,RATIS-1210
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"Not sure what happened.  If 3 servers are on different machines, DataStreamApi with type DirectByteBuffer seems slower than AsyncApi.  If 3 servers are on same machine, DataStreamApi with type DirectByteBuffer is better than AsyncApi.
DataStreamApi command:
`${BIN}/client.sh filestore datastream --size 100000000 --numFiles 10 --bufferSize 4000000 --type DirectByteBuffer --peers ${PEERS}`
AsyncApi command:
`${BIN}/client.sh filestore loadgen --size 100000000 --numFiles 10 --bufferSize 4000000 --peers ${PEERS}`",[],2020-12-06 10:47:44+00:00,2020-12-10 03:41:46+00:00,2020-12-10 03:42:06+00:00,Resolved,13344418,RATIS-1209
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,LogAppender should be defined as an interface so that the ServerFactory interface can be moved out from the org.apache.ratis.server.impl package.,[],2020-12-06 05:58:57+00:00,2020-12-07 05:34:25+00:00,2020-12-07 05:34:33+00:00,Resolved,13344403,RATIS-1208
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"Currently we use channelId_streamId as the stream key, but if we start the first client, and finish the streaming, then we start the second client, error happens because of duplicated stream key. Because the channel id of the second client is same as the first client, and streamId is both 0, so duplicated stream key happens.    So we can use clientid_streamid as the stream key, to achieve this, we need put clientid in DataStreamPacketImpl

{code:java}
final StreamMap.Key key = new StreamMap.Key(ctx.channel().id(), request.getStreamId());
{code}
",[],2020-12-06 05:10:50+00:00,2020-12-30 09:00:01+00:00,2020-12-30 09:02:19+00:00,Resolved,13344398,RATIS-1207
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In LogAppender.AppenderDaemon, it synchronized on a LifeCycle object.  Since LifeCycle is implemented using an AtomicReference, LifeCycle should provide some atomic operations to avoid external synchronization.",[],2020-12-05 02:58:15+00:00,2020-12-06 00:47:05+00:00,2020-12-06 00:47:05+00:00,Resolved,13344323,RATIS-1206
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,LogAppender currently uses RaftServerImpl and LeaderStateImpl.  This JIRA is to change it to use the public APIs RaftServer.Division and LeaderState.,[],2020-12-04 10:21:50+00:00,2020-12-04 13:04:30+00:00,2020-12-04 13:04:30+00:00,Resolved,13344209,RATIS-1205
Task,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,,[],2020-12-04 07:27:26+00:00,2020-12-04 07:41:16+00:00,2020-12-04 07:41:16+00:00,Resolved,13344172,RATIS-1204
Improvement,[],KellyShao,KellyShao,KellyShao,KellyShao,Minor,"* Issue:
 ** The method *testRetryCacheEntryCount* in *TestRetryCacheMetrics.java* class is flaky. Everytime when we trigger *testRetryCacheHitMissCount* method before *testRetryCacheEntryCount*, the *testRetryCacheEntryCount* will failed with error message: 
{code:java}
[ERROR] test1RetryCacheEntryCount(org.apache.ratis.server.impl.TestRetryCacheMetrics)  Time elapsed: 0.004 s  <<< FAILURE!
java.lang.AssertionError: expected:<1> but was:<0>
{code}
 * Root cause:
 ** The root cause is that the variable *retryCache* in this class is only initialized once in *@BeforeClass*, and cleared only at the end of the *testRetryCacheEntryCount* method. But, the *testRetryCacheHitMissCount* doesn't clear it.
 ** So, when *testRetryCacheHitMissCount* is triggered before *testRetryCacheEntryCount*, the line _checkEntryCount(0);_ within *testRetryCacheEntryCount* will failed.

 * Solution:
 ** Added an *@After* method in order to tear down *retryCache* after each test.
{code:java}
@After
public void tearDown() {
    retryCache.close();
    checkEntryCount(0);
}      {code}
 ** Deleted 2 lines of code in *testRetryCacheEntryCount* to avoid duplication.
{code:java}
retryCache.close();
checkEntryCount(0);
{code}

* The flaky test is found by running https://github.com/idflakies/iDFlakies",[],2020-12-04 04:32:55+00:00,2020-12-04 05:49:43+00:00,2020-12-04 05:49:44+00:00,Resolved,13344148,RATIS-1203
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"If you change  the FileStore state machine implementation to 

 
{code:java}
  @Override
  public CompletableFuture<DataStream> stream(RaftClientRequest request) {
    return CompletableFuture.completedFuture(null);
  }
{code}

This will create a NPE at https://github.com/apache/incubator-ratis/blob/04ff37ef6fdef100cb7a424ba9f7b438aec2c9ba/ratis-netty/src/main/java/org/apache/ratis/netty/server/DataStreamManagement.java#L243.

However, it seems like the exception in thread in executor cannot be caught by 
{code:java}
      @Override
      public void exceptionCaught(ChannelHandlerContext ctx, Throwable throwable) {
        Optional.ofNullable(requestRef.getAndSetNull())
            .ifPresent(request -> requests.replyDataStreamException(throwable, request, ctx));
      }
{code}

as the exception is printed directly. 

{code:java}
2020-12-03 20:22:08,680 WARN  server.DataStreamManagement (DataStreamManagement.java:sendDataStreamException(329)) - Failed to process DataStreamRequestByteBuf:STREAM_CLOSE,id=0,offset=2097152,length=0
java.util.concurrent.CompletionException: java.lang.NullPointerException
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.ratis.netty.server.DataStreamManagement.writeTo(DataStreamManagement.java:243)
	at org.apache.ratis.netty.server.DataStreamManagement$LocalStream.lambda$null$1(DataStreamManagement.java:80)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	... 5 more
{code}




",[],2020-12-04 03:48:44+00:00,2020-12-04 06:42:27+00:00,2020-12-04 06:42:27+00:00,Resolved,13344141,RATIS-1202
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-12-04 03:14:29+00:00,2020-12-07 05:05:55+00:00,2020-12-07 05:05:55+00:00,Resolved,13344140,RATIS-1201
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"LogAppender.SnapshotRequestIter implementing Iterable<InstallSnapshotRequestProto> is to convert a snapshot to a list of requests.  The leader sends these requests to followers for installing the snapshot.  In this JIRA, we refactor it from an inner class to a standalone class.

A bigger picture is to move LogAppender from org.apache.ratis.server.impl to org.apache.ratis.server.leader so that LogAppender becomes a public API.",[],2020-12-03 18:19:31+00:00,2020-12-04 06:24:42+00:00,2020-12-04 06:24:43+00:00,Resolved,13344078,RATIS-1200
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After added the public APIs RaftServer.Division and DivisionInfo, we may change RaftServerProxy and RaftServerImpl to package private.

If there is a need, we may add new methods to RaftServer.Division and DivisionInfo.",[],2020-12-03 08:13:18+00:00,2020-12-03 10:50:36+00:00,2020-12-03 10:50:39+00:00,Resolved,13343937,RATIS-1199
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-12-03 07:48:09+00:00,2020-12-04 10:32:43+00:00,2021-02-02 05:55:08+00:00,Resolved,13343933,RATIS-1198
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As discussed in https://github.com/apache/incubator-ratis/pull/312 , getRoleInfoProto() found be useful for state machine.

We also add the following methods
- getCurrentTerm()
- getLastAppliedIndex()
- getFollowerNextIndices()",[],2020-12-03 06:08:38+00:00,2020-12-03 07:10:56+00:00,2020-12-03 07:11:03+00:00,Resolved,13343915,RATIS-1197
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"Just like STREAM_DATA_SYNC, we can use STREAM_DATA_HEADER, STREAM_DATA_CLOSE, this two RPC call not only stream header and close, but also stream data, thus we can save two RPC call.",[],2020-12-03 01:39:32+00:00,2020-12-17 15:25:10+00:00,2020-12-17 15:25:21+00:00,Resolved,13343884,RATIS-1196
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"After a log purge is done to the last log index, RaftLog#getLastEntryTermIndex will return a *null*. In RaftLog#validateLogEntry, when the last term index is null, the expectation is that the new entry to be appended is lastSnapshotIndex + 1. However, the 'lastSnapshotIndex' in RaftLog is updated only through installSnapshot calls. Hence, the validation fails and all further appends will fail until a restart.

{code}
java.lang.IllegalStateException: Difference between entry index and RaftLog's latest snapshot index -1 is greater than 1 and in between log entries are not present, entry: term: 2
index: 326
stateMachineLogEntry {
  logData: ""\b\v\022\000\032\023client-46A48A10F5C6\""\033\n\006hadoop\032\f192.168.48.7\""\003om1Za\n_\n\006hadoop\022\006hadoop\032\004vol3 \377\377\377\377\377\377\377\377\377\0012\017\b\001\022\006hadoop\032\001\200 \0002\016\b\002\022\005users\032\001\200 \0008\215\343\333\251\342.@\000H\000P\215\343\333\251\342.X\377\377\377\377\377\377\377\377\377\001""
  clientId: ""\000\f\356MU\026<\331\234;\216\t\352\237\371\027""
  callId: 1
}
{code}

cc [~hanishakoneru] / [~msingh]",[],2020-12-02 22:43:02+00:00,2020-12-08 08:23:47+00:00,2021-02-02 06:05:35+00:00,Resolved,13343879,RATIS-1195
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Critical,"In SegmentedRaftLog#syncWithSnapshot, if the snapshot index is the last open segment index, then the open segment is finalized and closed (which releases the SegmentedRaftLogOutputStream). In the next step, while rolling the open segment in the cache, a new open segment is created. However, the output stream has already been closed. This causes the peer to terminate when a transaction comes in after the syncWithSnapshot call.

{code}
    @Override
    public void execute() throws IOException {
      if (stateMachineDataPolicy.isSync() && stateMachineFuture != null) {
        stateMachineDataPolicy.getFromFuture(stateMachineFuture, () -> this + ""-writeStateMachineData"");
      }

      raftLogMetrics.onRaftLogAppendEntry();
      Preconditions.assertTrue(out != null);
      Preconditions.assertTrue(lastWrittenIndex + 1 == entry.getIndex(),
{code}

Instead of creating a new open segment here, we should let any new transaction coming in to the system create a new open segment through the StartOpenSegment call which re-initializes the output stream.",[],2020-12-02 22:04:22+00:00,2020-12-03 06:06:05+00:00,2021-02-02 05:59:06+00:00,Resolved,13343872,RATIS-1194
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Add getRaftLog() to RaftServer.Division so that state machine such as LogStateMachine is able to access RaftLog.,[],2020-12-02 13:44:29+00:00,2020-12-03 01:17:28+00:00,2020-12-03 01:17:35+00:00,Resolved,13343780,RATIS-1193
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Server states such as isLeader, isLeaderReady, etc. are useful for StateMachine implementations to determine the current server states.  This JIRA is to add a public API so that implementations do not have to access RaftServerImpl directly.",[],2020-12-02 08:03:06+00:00,2020-12-02 11:15:35+00:00,2020-12-10 20:17:10+00:00,Resolved,13343709,RATIS-1192
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,FollowerInfo is in org.apache.ratis.server.impl but it is used outside the impl package.  We should define an interface so that the implementation can be hidden.,[],2020-12-01 16:29:07+00:00,2020-12-02 01:21:26+00:00,2020-12-02 01:21:26+00:00,Resolved,13343603,RATIS-1191
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The abstract newRaftServer method in MiniRaftCluster requires the implementations to return a RaftServerProxy objects.  It is unnecessary since the implementations only has to setup RaftProperties and Parameters.

After this change, almost all the test code does not require RaftServerProxy/RaftServerImpl.",[],2020-12-01 06:41:59+00:00,2020-12-01 08:27:07+00:00,2020-12-01 08:27:14+00:00,Resolved,13343474,RATIS-1190
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This is a continuing work of RATIS-1188 to change the other MiniRaftCluster methods to return RaftServer.Division.  This is also a test only change.,[],2020-11-30 13:35:13+00:00,2020-12-01 05:36:13+00:00,2020-12-01 05:36:13+00:00,Resolved,13343312,RATIS-1189
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This is a test-only change to avoid unnecessary use of RaftServerImpl.,[],2020-11-30 01:58:29+00:00,2020-11-30 12:08:32+00:00,2020-11-30 12:08:32+00:00,Resolved,13343203,RATIS-1188
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,LeaderElectionMetrics does not really need RaftServerImpl.  It should avoid using it.,[],2020-11-29 14:33:19+00:00,2020-11-29 23:36:25+00:00,2020-11-29 23:36:25+00:00,Resolved,13343169,RATIS-1187
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We should also change the FileStore example CLI to use Streaming after RATIS-1111.,[],2020-11-28 07:54:35+00:00,2020-12-06 10:21:37+00:00,2020-12-06 11:04:21+00:00,Resolved,13343085,RATIS-1186
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We may pass a handler to JvmPauseMonitor instead of passing a RaftServerProxy object.

Then, JvmPauseMonitor becomes a general utility class.  It should be moved to  org.apache.ratis.util.",[],2020-11-27 19:10:33+00:00,2020-11-29 01:05:44+00:00,2020-11-29 01:05:45+00:00,Resolved,13343035,RATIS-1185
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RaftServerMetrics currently is in org.apache.ratis.server.impl.  It should be moved to org.apache.ratis.server.metrics and avoid using the private impl APIs.,[],2020-11-27 03:50:19+00:00,2020-11-27 15:57:34+00:00,2020-11-27 15:57:34+00:00,Resolved,13342895,RATIS-1184
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We should add getId() and getPeer() so that StateMachine implementations can access peer info without using the private APIs.,[],2020-11-26 09:13:24+00:00,2020-11-26 23:47:26+00:00,2020-11-26 23:47:30+00:00,Resolved,13342793,RATIS-1183
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should move the RaftServerProxy.LOG and RaftServerImpl.LOG to the public interfaces RaftServer and RaftServer.Division, respectively.",[],2020-11-26 06:39:05+00:00,2020-11-26 07:41:29+00:00,2020-11-26 07:41:29+00:00,Resolved,13342760,RATIS-1182
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,StateMachine implementations such as Ozone need to access server methods such as RaftServerImpl.isLeader()/isLeaderReady().  We should define public APIs.,[],2020-11-26 02:17:20+00:00,2020-12-16 09:55:55+00:00,2021-03-01 01:48:25+00:00,Resolved,13342737,RATIS-1181
Bug,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"Right now we have isLeader() but it says false when it is leader and not ready. There is no way to figure out if it is leader and not ready from this API, we need to call isLeader and isLeaderReady for that.

This Jira exposes the ServerStatus with the following info.
NOT_LEADER, LEADER_AND_READY, and LEADER_AND_NOT_READY.

The purpose of Jira is to avoid multiple calls like isLeader and isLeaderReady, trying to achieve the same with a single API.

",[],2020-11-25 23:18:52+00:00,2020-12-10 20:17:10+00:00,2020-12-10 20:17:10+00:00,Resolved,13342724,RATIS-1180
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As discussed in RATIS-1176, there are more efficient APIs for sending out files, e.g. using Netty DefaultFileRegion.  This JIRA is to add a new API to DataStreamOutput for writing a File
{code}
 CompletableFuture<DataStreamReply> writeAsync(File);
{code}",[],2020-11-25 16:18:19+00:00,2020-11-26 02:13:05+00:00,2020-11-26 10:47:45+00:00,Resolved,13342649,RATIS-1179
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-25 08:22:57+00:00,2020-12-01 14:30:27+00:00,2020-12-01 14:30:28+00:00,Resolved,13342549,RATIS-1178
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Minor,"When a follower is in candidate state but unable to get votes and also unable to get new leader info, the JMXBeanServer query to getLeaderId can throw a NPE. 
{code:java}
2020-11-23 00:26:04,060 ERROR org.apache.hadoop.jmx.JMXJsonServlet: getting attribute LeaderId of Ratis:service=RaftServer,group=group-......,id=... threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
       at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
        at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)
        at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)
        at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:763)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1651)
        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1638)
        at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1666)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1638)
        at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1638)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:567)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1377)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:507)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1292)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
        at org.eclipse.jetty.server.Server.handle(Server.java:501)
        at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
        at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
        at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
        at org.apache.ratis.server.impl.RaftServerImpl$RaftServerJmxAdapter.getLeaderId(RaftServerImpl.java:1559)
        at sun.reflect.GeneratedMethodAccessor109.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
        at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
        at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
        at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
        at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
        ... 46 more
{code}
This happens because {{RaftServerJmxAdapter#getLeaderId()}} does not check whether leaderId is null before calling toString() on it.",[],2020-11-24 21:36:53+00:00,2020-11-25 01:00:48+00:00,2021-02-02 05:58:03+00:00,Resolved,13342475,RATIS-1177
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-1175, we provided a WritableByteChannel view of DataStreamOutput in order to support FileChannel.transferTo.  However, [~runzhiwang] pointed out that sun.nio.ch.FileChannelImpl.transferTo has three submethods
- transferToDirectly (fastest)
- transferToTrustedChannel
- transferToArbitraryChannel (slowest, requires buffer copying)

Unfortunately, our current implementation only able to use transferToArbitraryChannel.

There are several ideas below to improve the performance.  We should benchmark them.
# Improve the current implementation of WritableByteChannel so that it may be able to use a faster transferTo method.
# Use [FileChannel.map(..)|https://docs.oracle.com/javase/8/docs/api/java/nio/channels/FileChannel.html#map-java.nio.channels.FileChannel.MapMode-long-long-] and pass MappedByteBuffer to our DataStreamOutput.writeAsync method.
# Add a new API
{code}
//DataStreamOutput
 CompletableFuture<DataStreamReply> writeAsync(File);
{code}
Internally, use Netty DefaultFileRegion for zero-copy file transfer:
https://github.com/netty/netty/blob/4.1/example/src/main/java/io/netty/example/file/FileServerHandler.java#L53

The data flow of client -> primary -> peer as follows
1.  If stream file and do not calculate checksum, we use transferTo. In client, there are 1 DMA copy and 1 DMA gather copy, no CPU copy. In primary, there are
3 DMA copy and 3 CPU copy. In peer, there are 2 DMA copy and 2 CPU copy. 
 !screenshot-6.png! 

2. If stream file and calculate checksum, we use MapByteBuffer. In client, there are 2 DMA copy and 1 CPU copy.  In primary, there are
3 DMA copy and 3 CPU copy. In peer, there are 2 DMA copy and 2 CPU copy. 
 !screenshot-7.png! 

3. If stream data not in file and calculate checksum, we use DirectByteBuffer. In client, there are 2 DMA copy and 2 CPU copy. In primary, there are
3 DMA copy and 3 CPU copy. In peer, there are 2 DMA copy and 2 CPU copy. 

 !screenshot-8.png! 

4. we should avoid reading data into heap such as HeapByteBuffer. In client, there are 2 DMA copy and 4 CPU copy.   In primary, there are
3 DMA copy and 3 CPU copy. In peer, there are 2 DMA copy and 2 CPU copy. 
 !screenshot-9.png! 

5. The following is flow before ratis streaming and use ProtoBuf to send data. In client there are 2 DMA copy and 4 CPU copy. In leader, there are 3 DMA copy and 7 CPU copy. In follower, there are 2 DMA copy and 5 CPU copy.
 !screenshot-5.png! 
",[],2020-11-24 14:01:36+00:00,,2020-12-07 02:19:48+00:00,Open,13342373,RATIS-1176
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As mentioned by [~yjxxtd] in this comment, we should support the Java API [FileChannel#transferTo|https://docs.oracle.com/javase/8/docs/api/java/nio/channels/FileChannel.html#transferTo-long-long-java.nio.channels.WritableByteChannel-], i.e. sendfile of linux, which used by kafka, since it is efficient.",[],2020-11-24 06:56:51+00:00,2020-11-24 14:02:47+00:00,2020-11-24 14:02:47+00:00,Resolved,13342287,RATIS-1175
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-24 03:36:39+00:00,2020-12-02 11:56:03+00:00,2020-12-02 11:56:12+00:00,Resolved,13342258,RATIS-1174
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In StateMachine,
- StateMachineDataChannel is an inner interface in StateMachine so that we may simply rename it to DataChannel.
- We should also rename the DataStream.getWritableByteChannel() to DataStream.getDataChannel() .",[],2020-11-24 03:18:40+00:00,2020-11-24 06:29:57+00:00,2020-11-24 06:29:57+00:00,Resolved,13342256,RATIS-1173
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-11-23 23:01:52+00:00,2020-11-23 23:07:23+00:00,2020-11-23 23:07:23+00:00,Resolved,13342229,RATIS-1172
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The stream parameter can be null in some error cases.  We should let the state machine to decide if it can recover the data by itself or complete the future exceptionally.,[],2020-11-23 10:19:58+00:00,2020-11-24 01:45:15+00:00,2020-11-24 01:51:06+00:00,Resolved,13342098,RATIS-1171
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-23 02:14:04+00:00,2020-11-23 09:06:27+00:00,2020-11-23 09:06:27+00:00,Resolved,13342018,RATIS-1170
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In TestDataStreamNetty, testDataStreamSingleServer() and testDataStreamMultipleServer() do not use a MiniRaftCluster.  Let's move them to DataStreamClusterTests.  After the move, all the remaining tests in TestDataStreamNetty are mock tests.",[],2020-11-22 11:11:25+00:00,2020-11-22 23:36:20+00:00,2020-11-22 23:36:51+00:00,Resolved,13341977,RATIS-1169
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,There are quite a few useful utility classes and methods in DataStreamBaseTest.  Let's move the to a new files.,[],2020-11-20 10:14:28+00:00,2020-11-21 02:16:10+00:00,2020-11-21 02:16:10+00:00,Resolved,13341761,RATIS-1168
Bug,[],cxorm,Yi-Sheng Lien,cxorm,Yi-Sheng Lien,Trivial,"In [website|https://ratis.incubator.apache.org/#gettingstarted],  Ratis is a [Raft|https://raft.github.io/%22] protocol _library_ in Java. It’s not a standalone server application like Zookeeper or Consul.

The link to [raft.github.io|https://raft.github.io/] is broken caused by having a redundant "" .

This jira is for fixing it.",[],2020-11-19 14:36:29+00:00,2021-03-15 02:40:48+00:00,2021-03-15 02:47:30+00:00,Resolved,13341600,RATIS-1167
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Once a log entry is created for a DataStream, the server should link log entry with the DataStream so that the StateMachine must not delete the data unless the log entry is truncated.",[],2020-11-19 06:37:50+00:00,2020-11-20 01:43:03+00:00,2020-11-20 01:43:14+00:00,Resolved,13341506,RATIS-1166
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"ClientId and callId (or streamId) are often used as a key class.  For examples,
- RetryCache.CacheKey,
- MessageStreamRequests.Key, and
- DataStreamBaseTest.MultiDataStreamStateMachine.Key.

This JIRA is to add a new class ClientInvocationId for such purpose.",[],2020-11-19 01:45:55+00:00,2020-11-19 06:13:47+00:00,2020-11-19 06:13:48+00:00,Resolved,13341469,RATIS-1165
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should replace the deprecated RaftServerConstants.INVALID_LOG_INDEX with RaftLog.INVALID_LOG_INDEX.
",[],2020-11-18 10:58:21+00:00,2020-11-18 23:42:39+00:00,2020-11-18 23:42:42+00:00,Resolved,13341297,RATIS-1164
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- The refCount field in RefCountingMap.Payload is not thread-safe.
{code}
//RefCountingMap.Payload
    private int refCount;
{code}

- Also, there are a few javac warnings in ratis-metrics.
{code}
[WARNING] /Users/tszwosze/ratis/apache-ratis/ratis-metrics/src/main/java/org/apache/ratis/metrics/impl/RefCountingMap.java:[51,15] [unchecked] unchecked call to Payload(V) as a member of the raw type Payload
  where V is a type-variable:
    V extends Object declared in class Payload
[WARNING] /Users/tszwosze/ratis/apache-ratis/ratis-metrics/src/main/java/org/apache/ratis/metrics/impl/RefCountingMap.java:[46,35] [unchecked] unchecked method invocation: method compute in class ConcurrentHashMap is applied to given types
  required: K#1,BiFunction<? super K#1,? super V#1,? extends V#1>
  found: K#2,BiFunction<K#2,Payload<V#2>,Payload<V#2>>
  where K#1,V#1,K#2,V#2 are type-variables:
    K#1 extends Object declared in class ConcurrentHashMap
    V#1 extends Object declared in class ConcurrentHashMap
    K#2 extends Object declared in class RefCountingMap
    V#2 extends Object declared in class RefCountingMap
[WARNING] /Users/tszwosze/ratis/apache-ratis/ratis-metrics/src/main/java/org/apache/ratis/metrics/impl/RefCountingMap.java:[46,35] [unchecked] unchecked cast
  required: Payload<V>
  found:    Payload
  where V is a type-variable:
    V extends Object declared in class RefCountingMap
[WARNING] /Users/tszwosze/ratis/apache-ratis/ratis-metrics/src/main/java/org/apache/ratis/metrics/MetricRegistriesLoader.java:[68,81] [unchecked] unchecked cast
  required: Class<MetricRegistries>
  found:    Class<CAP#1>
  where CAP#1 is a fresh type-variable:
    CAP#1 extends Object from capture of ?
[INFO] 
{code}
",[],2020-11-18 08:44:09+00:00,2020-11-18 23:44:09+00:00,2020-11-18 23:44:17+00:00,Resolved,13341260,RATIS-1163
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This JIRA is to add a MiniRaftCluster subclass with
- SupportedRpcType#GRPC, and
- SupportedDataStreamType.NETTY.
",[],2020-11-17 13:34:24+00:00,2020-11-18 04:00:24+00:00,2020-11-23 22:46:00+00:00,Resolved,13341057,RATIS-1162
Improvement,[],glengeng,Glen Geng,glengeng,Glen Geng,Minor,"This is a followup of Jira https://issues.apache.org/jira/browse/RATIS-748

 

According to the basic raft algorithm, the logic of advancing commit index for follower and leader is different.

*For follower:*

When receiving an AppendEntries Request, the logic is 
{code:java}
If leaderCommit > commitIndex: set commitIndex = min(leaderCommit, index of last new entry)
{code}
 

*For leader:*

The majority commit should only be used on the log entry that created by current leader, thus need a term check.
{code:java}
If there exists an N such that N > commitIndex, a majority of matchIndex[i] ≥ N, and log[N].term == currentTerm: set commitIndex = N{code}
 

*For current ratis:*

We apply the advancing commit index logic of leader to follower, which will make follower's commit index to lag behind for situations like:

1, when failover happened

2, it is an empty follower that join the raft group by membership change.
{code:java}
  /**
   * Update the last committed index.
   * @param majorityIndex the index that has achieved majority.
   * @param currentTerm the current term.
   * @return true if update is applied; otherwise, return false, i.e. no update required.
   */
  public boolean updateLastCommitted(long majorityIndex, long currentTerm) {
    try(AutoCloseableLock writeLock = writeLock()) {
      final long oldCommittedIndex = getLastCommittedIndex();
      final long newCommitIndex = Math.min(majorityIndex, getFlushIndex());
      if (oldCommittedIndex < newCommitIndex) {
        // Only update last committed index for current term. See §5.4.2 in
        // paper for details.
        final TermIndex entry = getTermIndex(newCommitIndex);
        if (entry != null && entry.getTerm() == currentTerm) {
          commitIndex.updateIncreasingly(newCommitIndex, traceIndexChange);
          return true;
        }
      }
    }
    return false;
  }
{code}
 

*Intention of this Jira*

We want to prove the we can safely change the advancing commit index logic of follower for current ratis.

 
  ",[],2020-11-17 12:28:38+00:00,2020-11-26 10:37:01+00:00,2021-02-02 05:59:14+00:00,Resolved,13341044,RATIS-1161
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The closeAsync() method should be idempotent, i.e. it should return the same results if called multiple times.

Also, write-after-close should fail.",[],2020-11-16 14:58:21+00:00,2020-11-16 23:47:34+00:00,2020-11-23 21:54:36+00:00,Resolved,13340849,RATIS-1160
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,cc [~yjxxtd] [~szetszwo],[],2020-11-16 04:27:13+00:00,2020-11-16 07:01:47+00:00,2020-11-16 07:44:00+00:00,Resolved,13340753,RATIS-1159
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
//Raft.proto
message StateMachineExceptionProto {
  string exceptionClassName = 1;
  string errorMsg = 2;
  bytes stacktrace = 3;
}

message AlreadyClosedExceptionProto {
  string exceptionClassName = 1;
  string errorMsg = 2;
  bytes stacktrace = 3;
}

message DataStreamExceptionProto {
  string exceptionClassName = 1;
  string errorMsg = 2;
  bytes stacktrace = 3;
}
{code}
StateMachineExceptionProto, AlreadyClosedExceptionProto and DataStreamExceptionProto have exactly the same structure.  They should use the same proto to avoid code duplication.",[],2020-11-15 11:35:47+00:00,2020-11-16 02:07:27+00:00,2021-01-19 14:52:23+00:00,Resolved,13340698,RATIS-1158
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"It is possible that client chooses to write small packets. One optimization could be buffer and then send multiple packets through wires to reduce per packet cost.

This idea will need a benchmark to find a good threshold for ""small"" packet.

 

For example, a client might choose use Ratis streaming to save lots of small files.",[],2020-11-13 21:27:08+00:00,,2020-12-07 02:17:37+00:00,In Progress,13340595,RATIS-1157
Bug,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"task.execute() failed, we store the exception in logIOException, we notify StateMachine but does not shut down server, it will pick next task and fail the task exceptionally and notify statemachine.


This Jira is to discuss do we need to bring the old behavior of shutting down the server.

{code:java}
try {
        Task task = queue.poll(ONE_SECOND);
        if (task != null) {
          task.stopTimerOnDequeue();
          try {
            if (logIOException != null) {
              throw logIOException;
            } else {
              Timer.Context executionTimeContext =
                  raftLogMetrics.getRaftLogTaskExecutionTimer(task.getClass().getSimpleName().toLowerCase()).time();
              task.execute();
              executionTimeContext.stop();
            }
          } catch (IOException e) {
            if (task.getEndIndex() < lastWrittenIndex) {
              LOG.info(""Ignore IOException when handling task "" + task
                  + "" which is smaller than the lastWrittenIndex.""
                  + "" There should be a snapshot installed."", e);
            } else {
              task.failed(e);
              if (logIOException == null) {
                logIOException = new RaftLogIOException(""Log already failed""
                    + "" at index "" + task.getEndIndex()
                    + "" for task "" + task, e);
              }
              continue;
            }
          }
          task.done();
        }
{code}

cc [~arp] [~hanishakoneru] [~msingh] [~szetszwo]
",[],2020-11-13 21:07:57+00:00,,2020-11-13 21:08:56+00:00,Open,13340593,RATIS-1156
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, there are quite many different ways to create DataStreamReplyByteBuffer objects.  In addition, we will serialise exceptions to the buffer in DataStreamReplyByteBuffer; see RATIS-1153.  It is better to use the builder pattern to build DataStreamReplyByteBuffer objects.",[],2020-11-13 18:39:21+00:00,2020-11-15 01:28:51+00:00,2020-11-15 01:28:51+00:00,Resolved,13340576,RATIS-1155
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"In Ozone, for a single block there will be multiple putBlock opertions.  In case of using streaming for block write , ratis log transaction should be created for all these operations() (as happens with stream.close()). In such cases, it would be useful to add a flush() semantic in streaming which ensures one block can be wriiten over a single streaming channel with multiple commits happening in between.",[],2020-11-13 07:01:31+00:00,2020-11-18 05:42:09+00:00,2020-11-18 05:42:58+00:00,Resolved,13340441,RATIS-1154
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"https://netty.io/4.1/api/io/netty/channel/ChannelInboundHandler.html#exceptionCaught-io.netty.channel.ChannelHandlerContext-java.lang.Throwable-
{code}
//ChannelInboundHandler
void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception
{code}
We should implement the above method to handle exceptions in NettyServerStreamRpc.",[],2020-11-13 02:24:13+00:00,2020-11-16 08:58:13+00:00,2020-11-16 08:58:13+00:00,Resolved,13340409,RATIS-1153
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Update gRPC to 1.33.0 for Ratis,[],2020-11-12 18:23:44+00:00,2021-02-09 11:57:54+00:00,2021-02-17 11:26:32+00:00,Resolved,13340316,RATIS-1152
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"NettyServerStreamRpc should focus on RPC implementation.  The requests handling code should be moved to a new class. 

The JIRA is for code refactoring but not changing any logics.",[],2020-11-12 10:07:41+00:00,2020-11-12 12:20:50+00:00,2020-11-12 18:36:46+00:00,Resolved,13340175,RATIS-1151
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"When primary or peer WritableByteChannel#write throw exception, we should return it to client.


{code:java}
static long writeTo(ByteBuf buf, DataStream stream) {
    final WritableByteChannel channel = stream.getWritableByteChannel();
    long byteWritten = 0;
    for (ByteBuffer buffer : buf.nioBuffers()) {
      try {
        byteWritten += channel.write(buffer);
      } catch (Throwable t) {
        throw new CompletionException(t);
      }
    }
    return byteWritten;
  }
{code}
",[],2020-11-12 09:32:07+00:00,2020-11-15 11:06:36+00:00,2020-11-15 11:06:36+00:00,Resolved,13340160,RATIS-1150
New Feature,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, a ratis leader can run into multiple jvm pause cycles either bcoz of gc/high IO activity etc. In case of frequent occurrences as such, a leader can voluntarily step down and call into stateMachine for any further action to be taken. A slow leader will potentially slow down the whole pipeline and may lead to client request failures.",[],2020-11-12 06:36:02+00:00,2020-11-17 09:40:10+00:00,2020-11-17 09:40:10+00:00,Resolved,13340131,RATIS-1149
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-1145, we changed the remote stream to wait for its own previous write.  Indeed, the remote streams should just submit the async calls.  Then, the sliding window will take care the async calls.",[],2020-11-11 11:53:33+00:00,2020-11-11 13:18:00+00:00,2020-11-11 13:18:00+00:00,Resolved,13339967,RATIS-1148
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Minor,"The TestMultiRaftGroup test on MiniRaftClusterWithNetty fails with following exception:
{code:java}
[INFO] Running org.apache.ratis.TestMultiRaftGroup
[ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 19.134 s <<< FAILURE! - in org.apache.ratis.TestMultiRaftGroup
[ERROR] testMultiRaftGroup[2](org.apache.ratis.TestMultiRaftGroup)  Time elapsed: 1.136 s  <<< ERROR!
java.io.IOException: s11: Failed to start NettyRpcService
	at org.apache.ratis.netty.server.NettyRpcService.startImpl(NettyRpcService.java:141)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:222)
	at org.apache.ratis.server.impl.RaftServerRpcWithProxy.start(RaftServerRpcWithProxy.java:70)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$start$3(RaftServerProxy.java:323)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:222)
	at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:321)
	at org.apache.ratis.MiniRaftCluster.startServers(MiniRaftCluster.java:426)
	at org.apache.ratis.MiniRaftCluster.start(MiniRaftCluster.java:294)
	at org.apache.ratis.server.impl.GroupManagementBaseTest.runMultiGroupTest(GroupManagementBaseTest.java:256)
	at org.apache.ratis.TestMultiRaftGroup.runTestMultiRaftGroup(TestMultiRaftGroup.java:73)
	at org.apache.ratis.TestMultiRaftGroup.runTestMultiRaftGroup(TestMultiRaftGroup.java:59)
	at org.apache.ratis.TestMultiRaftGroup.testMultiRaftGroup(TestMultiRaftGroup.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:550)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at org.apache.ratis.thirdparty.io.netty.handler.logging.LoggingHandler.bind(LoggingHandler.java:221)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel.bind(AbstractChannel.java:248)
	at org.apache.ratis.thirdparty.io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
{code}
",[],2020-11-11 04:36:21+00:00,2021-03-07 10:43:13+00:00,2021-03-08 18:02:51+00:00,Resolved,13339886,RATIS-1147
Bug,[],lasaro,Lasaro Camargos,lasaro,Lasaro Camargos,Critical,"I am trying to build the ratis code using the instructions from the pages, that is, clone the repo and `mvn clean package`. I am seeing an error regarding the Generated annotation in the gRPC generated code, seen below. Fails on both jdk 12 and 13; works on 8; didn't test on other versions.

{noformat}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.7.0:compile (default-compile) on project ratis-proto: Compilation failure: Compilation failure:
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/grpc/RaftServerProtocolServiceGrpc.java:[20,17] error: package javax.annotation does not exist
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/FileTransferExampleServiceGrpc.java:[20,17] error: package javax.annotation does not exist
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/hadoop/RaftServerProtocolServiceGrpc.java:[20,17] error: package javax.annotation does not exist
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/grpc/AdminProtocolServiceGrpc.java:[20,17] error: package javax.annotation does not exist
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/grpc/RaftClientProtocolServiceGrpc.java:[20,17] error: package javax.annotation does not exist
[ERROR] /Users/lcamargos/ufu/incubator-ratis/ratis-proto/target/generated-sources/org/apache/ratis/proto/hadoop/CombinedClientProtocolServiceGrpc.java:[20,17] error: package javax.annotation does not exist
{noformat}",[],2020-11-10 18:04:50+00:00,2020-11-12 06:29:58+00:00,2020-11-12 07:04:25+00:00,Resolved,13339811,RATIS-1146
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, the local write and the remote writes wait for completing the previous reply.  Instead, each local/remote write should only wait for its own previous write.

Also, the ByteBuf may be released too early or may not be released at all.",[],2020-11-10 16:59:36+00:00,2020-11-11 01:18:49+00:00,2020-11-11 01:18:49+00:00,Resolved,13339798,RATIS-1145
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-10 09:20:38+00:00,2020-11-10 16:52:31+00:00,2020-11-11 00:23:22+00:00,Resolved,13339695,RATIS-1144
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-10 08:05:42+00:00,2020-11-12 06:00:58+00:00,2020-11-12 06:01:14+00:00,Resolved,13339677,RATIS-1143
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-10 07:52:27+00:00,2020-11-10 09:29:12+00:00,2020-11-10 09:29:17+00:00,Resolved,13339674,RATIS-1142
Improvement,[],weichiu,Wei-Chiu Chuang,weichiu,Wei-Chiu Chuang,Major,"See the attachment. I'm running a write benchmark for Ozone, and the DataNode's SegmentedRaftLogWriter spent 4% time on Class.getSimpleName(). While 4% isn't a lot, Ratis performance is the major bottleneck on the Ozone DN write path. It would be great to remove this overhead.

Also see https://stackoverflow.com/questions/17369304/why-is-class-getsimplename-not-cached OpenJDK11 caches this call, but not for JDK8 where most of the production workloads are running.",[],2020-11-09 23:56:52+00:00,2020-11-11 14:52:38+00:00,2020-11-11 14:52:39+00:00,Resolved,13339628,RATIS-1141
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"When all RaftPeer can be a primary server, sending headers will cause deadlock. Do not create DataStreamOutput for non-primary server",[],2020-11-09 23:54:47+00:00,2020-11-10 07:42:20+00:00,2020-11-10 07:57:48+00:00,Resolved,13339627,RATIS-1140
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We should use RaftPeer.Bulider instead of the constructors.,[],2020-11-09 07:13:53+00:00,2020-11-09 12:25:27+00:00,2020-11-09 12:25:27+00:00,Resolved,13339446,RATIS-1139
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The address of the data stream server are required by both clients and servers for streaming data.  We should add it to the RaftPeer.,[],2020-11-07 17:31:09+00:00,2020-11-09 04:06:20+00:00,2020-11-09 04:06:20+00:00,Resolved,13339334,RATIS-1138
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We should rename the existing StreamRequestTypeProto to MessageStreamRequestTypeProto in order to avoid confusion with data stream.,[],2020-11-07 05:37:00+00:00,2020-11-07 14:32:50+00:00,2020-11-07 14:32:50+00:00,Resolved,13339277,RATIS-1137
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, we use WriteRequestTypeProto for data stream request.  It is better to add a new type DataStreamRequestTypeProto so that the state machine won't have to guess it.
",[],2020-11-07 05:14:53+00:00,2020-11-18 23:41:08+00:00,2020-11-18 23:41:09+00:00,Resolved,13339275,RATIS-1136
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-11-07 01:41:14+00:00,2020-11-07 03:27:56+00:00,2020-11-07 04:01:52+00:00,Resolved,13339264,RATIS-1135
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
  /** Create a stream to write data to the given group. */
  DataStreamOutput stream(RaftGroupId groupId);
{code}
This above method becomes useless.  It should be removed.",[],2020-11-06 08:08:58+00:00,2020-11-06 11:33:32+00:00,2020-11-06 11:33:32+00:00,Resolved,13339126,RATIS-1134
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-05 08:16:34+00:00,2020-11-06 08:01:42+00:00,2020-11-06 08:01:42+00:00,Resolved,13338958,RATIS-1133
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-11-05 08:07:55+00:00,2020-11-06 02:37:21+00:00,2020-11-06 05:22:50+00:00,Resolved,13338955,RATIS-1132
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,There are roughly 10 nofityXxx(..) methods in the StateMachine interface.  All these methods are optional.  It is better move them to some separated APIs.,[],2020-11-05 04:21:56+00:00,2020-11-05 14:45:19+00:00,2020-11-05 14:45:19+00:00,Resolved,13338930,RATIS-1131
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-11-04 19:11:15+00:00,2020-11-15 03:25:43+00:00,2020-11-15 08:00:57+00:00,Resolved,13338890,RATIS-1130
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"DataStreamOutput is a public user API.  The rpc related APIs shown below should be moved out.
{code}
//DataStreamOutput.java
  /** Get the future of the header request. */
  CompletableFuture<DataStreamReply> getHeaderFuture();

  /** Peer close asynchronously. */
  CompletableFuture<DataStreamReply> closeForwardAsync();

  /** Create a transaction asynchronously once the stream data is replicated to all servers */
  CompletableFuture<DataStreamReply> startTransactionAsync();
{code}",[],2020-11-04 15:35:25+00:00,2020-11-04 23:48:46+00:00,2020-11-04 23:48:46+00:00,Resolved,13338855,RATIS-1129
Improvement,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"If a Follower is lagging behind and needs to install snapshot to catch up, it can miss any configuration changes that were applied on the Leader. When installing snapshot, the configuration change must also be propagated and applied on the follower. ",[],2020-11-03 00:11:13+00:00,2020-11-04 06:51:22+00:00,2021-02-02 06:01:12+00:00,Resolved,13338523,RATIS-1128
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Add a stream(RaftGroupId) method to DataStreamApi so that a DataStreamClient can send data to multiple groups.  It is useful in RATIS-1084.,[],2020-11-02 01:40:35+00:00,2020-11-02 07:23:13+00:00,2020-11-03 14:17:54+00:00,Resolved,13338327,RATIS-1127
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"When I run 
{code:java}
runTestDataStream(1, 1, 10, 1_000_000, 100);
{code} with 10 streams in TestDataStreamNetty, it's easy to pass. But when I run {code:java}
runTestDataStream(1, 1, 11, 1_000_000, 100);
{code} with 11 streams in TestDataStreamNetty, it always fail.
",[],2020-11-02 01:36:16+00:00,2020-11-02 08:24:06+00:00,2020-11-03 14:06:20+00:00,Resolved,13338325,RATIS-1126
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,TestDataStream no long tests right state machine after RATIS-1124. It is because RaftServer uses its own map to keep state machine so the original state machines used to test server's writes no long work.,[],2020-11-01 18:05:09+00:00,2020-11-02 01:49:56+00:00,2020-11-02 01:49:57+00:00,Resolved,13338312,RATIS-1125
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,,[],2020-10-31 07:50:46+00:00,2020-10-31 10:06:35+00:00,2020-10-31 17:33:23+00:00,Resolved,13338197,RATIS-1124
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Continuing the work in RATIS-1121, this JIRA is to add tests and fix bugs for multiple  DataStream clients.",[],2020-10-30 07:27:54+00:00,2020-10-31 06:46:02+00:00,2020-10-31 06:46:02+00:00,Resolved,13338020,RATIS-1123
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-10-30 06:26:43+00:00,2020-11-04 11:25:49+00:00,2020-11-04 11:26:56+00:00,Resolved,13338009,RATIS-1122
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This JIRA is to add tests and fix bugs for multiple streams.,[],2020-10-30 03:22:59+00:00,2020-10-31 01:14:26+00:00,2020-10-31 01:14:26+00:00,Resolved,13337997,RATIS-1121
Improvement,[],dengziming,dengziming,dengziming,dengziming,Minor,"in the leader election approach, the candidate will change to leader in advance if majority voters vote for it. we can also terminate the approach if majority voters reject it.",[],2020-10-30 01:39:28+00:00,2020-11-04 05:29:06+00:00,2020-11-04 05:29:06+00:00,Resolved,13337976,RATIS-1120
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Critical,"When StateMachineUpdater encounters an exception while applying the log to StateMachine, it shuts down the RaftServerImpl.
{code:java}
#StateMachineUpdater
public void run() {
 try {
  ...
  ...
  final MemoizedSupplier<List<CompletableFuture<Message>>> futures = applyLog();
  ...
 } catch (Throwable t) {
   ...
   server.shutdown(); # RaftServerImpl#shutdown()
 }{code}
The RaftServerImpl#shutdown() in turn calls the StateMachineUpdater#stopAndJoin() which waits for the StateMachineUpdater thread to die. This creates a circular dependency on the StateMachineUpdater thread to exit. In the process, StateMachineUpdater#stop() is never called and hence StateMachine is never informed that the RaftServer is shutdown.
{code:java}
StateMachineUpdater#run() on exception -> RaftServerImpl#shutdown() -> ServerState#close() -> StateMachineUpdater#stopAndJoin() -> updates stopIndex and waits for updater thread to die.{code}
 

 

 

 

 ",[],2020-10-29 23:06:12+00:00,2020-11-03 08:16:24+00:00,2021-02-02 06:00:43+00:00,Resolved,13337961,RATIS-1119
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Like RATIS-1117, we might also remove start() for DataStreamServerRpc",[],2020-10-29 18:39:43+00:00,2020-10-30 02:33:24+00:00,2020-10-30 02:33:24+00:00,Resolved,13337919,RATIS-1118
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The startClient() method is useless since the client should be started once it has been built.,[],2020-10-29 11:12:28+00:00,2020-10-30 01:55:44+00:00,2020-10-30 01:55:50+00:00,Resolved,13337859,RATIS-1117
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code:java}
public enum SupportedDataStreamType implements DataStreamFactory {
{code}
Just found that somehow SupportedDataStreamType implements DataStreamFactory. It should be 
{code:java}
public enum SupportedDataStreamType implements DataStreamType {
{code}
where DataStreamType is currently missing.",[],2020-10-29 10:45:47+00:00,2020-10-29 13:12:41+00:00,2020-10-29 18:24:22+00:00,Resolved,13337854,RATIS-1116
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Current server does 

 
{code:java}
if (Header) {    
  streams.computeIfAbsent(request.getStreamId(), id ->createStream());
  ...  
}
{code}
 

 

It is possible that clients send multiple headers so the entry already exists. We might choose to send a reply with error message without accepting duplicated headers. 

 ",[],2020-10-28 21:02:17+00:00,2020-12-07 02:14:50+00:00,2020-12-07 02:14:50+00:00,Resolved,13337747,RATIS-1115
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
  private final ConcurrentMap<Long, CompletableFuture<DataStream>> streams = new ConcurrentHashMap<>();
  private final ConcurrentMap<Long, List<DataStreamOutput>> peersStreamOutput = new ConcurrentHashMap<>();
{code}
The two ConcurrentMaps above should be merged.",[],2020-10-28 18:16:46+00:00,2020-10-28 23:58:21+00:00,2020-10-28 23:58:21+00:00,Resolved,13337725,RATIS-1114
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Update gRPC to 1.33.0,[],2020-10-28 16:03:40+00:00,2020-11-11 13:57:57+00:00,2020-11-11 13:57:57+00:00,Resolved,13337699,RATIS-1113
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"currently, a leader voluntarily steps down if it doesn't receive heartbeat from both followers for a period of leader election timeout(5s). But same node can get relected again. The idea is to avoid this.
{code:java}
2020-10-19 05:01:31,639 WARN org.apache.ratis.server.impl.RaftServerImpl: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220-LeaderState: Lost leadership on term: 1. Election timeout: 5200ms. In charge for: 4532364ms. Conf: 0: [7792870e-e2e1-4b9d-84ee-1855f82ea08c:10.17.234.24:9858:0, 14f34f1f-5102-4ba8-91ed-3694e3705af6:10.17.234.17:9858:0, 459b68fc-2f29-413e-a773-0d9be7fd9511:10.17.234.18:9858:0], old=null. Followers: [14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220->7792870e-e2e1-4b9d-84ee-1855f82ea08c(c234581,m234581,n234603, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=5501), 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220->459b68fc-2f29-413e-a773-0d9be7fd9511(c234865,m234866,n234938, attendVote=true, lastRpcSendTime=18, lastRpcResponseTime=5501)]
2020-10-19 05:01:31,640 INFO org.apache.ratis.server.impl.RaftServerImpl: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220: changes role from    LEADER to FOLLOWER at term 1 for stepDown. -------------> Stepping down




2020-10-19 05:01:36,900 INFO org.apache.ratis.server.impl.LeaderElection: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220-LeaderElection14: Election PASSED; received 1 response(s) [14f34f1f-5102-4ba8-91ed-3694e3705af6<-7792870e-e2e1-4b9d-84ee-1855f82ea08c#0:OK-t2] and 0 exception(s); 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220:t2, leader=null, voted=14f34f1f-5102-4ba8-91ed-3694e3705af6, raftlog=14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220-SegmentedRaftLog:OPENED:c234866,f234937,i234937, conf=0: [7792870e-e2e1-4b9d-84ee-1855f82ea08c:10.17.234.24:9858:0, 14f34f1f-5102-4ba8-91ed-3694e3705af6:10.17.234.17:9858:0, 459b68fc-2f29-413e-a773-0d9be7fd9511:10.17.234.18:9858:0], old=null
2020-10-19 05:01:36,901 INFO org.apache.ratis.server.impl.RaftServerImpl: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220: changes role from CANDIDATE to LEADER at term 2 for changeToLeader---------------------> become leader again in the next term


2020-10-19 05:01:36,901 INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Leader change notification received for group: group-7A1D5C0EE220 with new leaderId: 14f34f1f-5102-4ba8-91ed-3694e3705af6
2020-10-19 05:01:36,902 INFO org.apache.ratis.server.impl.RaftServerImpl: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220: change Leader from null to 14f34f1f-5102-4ba8-91ed-3694e3705af6 at term 2 for becomeLeader, leader elected after 50ms
2020-10-19 05:01:37,339 INFO org.apache.ratis.grpc.client.GrpcClientProtocolService: Failed RaftClientRequest:client-0F18033B24C7->14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220, cid=1896, seq=0, Watch-ALL_COMMITTED(234813), Message:<EMPTY>, reply=RaftClientReply:client-0F18033B24C7->14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220, cid=1896, FAILED org.apache.ratis.protocol.LeaderNotReadyException: 14f34f1f-5102-4ba8-91ed-3694e3705af6@group-7A1D5C0EE220 is in LEADER state but not ready yet., logIndex=0, commits[14f34f1f-5102-4ba8-91ed-3694e3705af6:c234939, 7792870e-e2e1-4b9d-84ee-1855f82ea08c:c234602, 459b68fc-2f29-413e-a773-0d9be7fd9511:c234938]


{code}",[],2020-10-28 09:14:38+00:00,2020-11-04 14:53:33+00:00,2020-11-04 14:53:33+00:00,Resolved,13337612,RATIS-1112
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We may use the FileStore to compare the performance between the StreamingApi and the AsyncApi.,[],2020-10-28 09:05:41+00:00,2020-12-04 02:50:36+00:00,2020-12-04 02:50:36+00:00,Resolved,13337611,RATIS-1111
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,Discussion of the Details: https://github.com/apache/incubator-ratis/pull/231,[],2020-10-28 02:37:30+00:00,2020-10-28 13:00:39+00:00,2020-10-28 20:41:57+00:00,Resolved,13337556,RATIS-1110
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"When Ratis receives a Configuration change request (SetConfiguration), the StateMachine is only notified of index update.
{code:java}
CompletableFuture<Message> applyLogToStateMachine(LogEntryProto next) {
  if (!next.hasStateMachineLogEntry()) {
    stateMachine.notifyIndexUpdate(next.getTerm(), next.getIndex());
  } else if (next.hasStateMachineLogEntry()) {
  ......{code}
This Jira aims to add a method in StateMachine interface to notify StateMachine about configuration change.",[],2020-10-27 23:52:50+00:00,2020-11-03 09:11:18+00:00,2020-11-03 14:16:20+00:00,Resolved,13337533,RATIS-1109
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-10-27 20:38:02+00:00,2020-10-29 10:12:52+00:00,2020-10-29 17:12:30+00:00,Resolved,13337513,RATIS-1108
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-10-27 06:47:35+00:00,2020-10-27 10:00:38+00:00,2020-10-27 11:02:44+00:00,Resolved,13337352,RATIS-1107
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-10-26 01:38:40+00:00,2020-10-27 03:57:22+00:00,2020-10-27 06:45:59+00:00,Resolved,13337119,RATIS-1106
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We propose refactoring the encoder and decoder as the following:
- Similar to DataStreamReplyHeader, we should add DataStreamRequestHeader.
- Move the encoder/decoder logic to NettyDataStreamUtils.
- After above, the encoder/decoder classes become trivial.  We may simply remove them.",[],2020-10-23 07:17:18+00:00,2020-10-24 01:38:21+00:00,2020-10-28 01:09:02+00:00,Resolved,13336868,RATIS-1105
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,Per discussion at here: https://github.com/apache/incubator-ratis/pull/228#discussion_r509012392,[],2020-10-21 23:31:01+00:00,2020-10-22 07:42:01+00:00,2020-10-23 07:17:50+00:00,Resolved,13336599,RATIS-1104
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Currently, there are a few similar methods for adding RaftPeers:
 - RaftClientRpc
{code:java}
  void addServers(Iterable<RaftPeer> servers);
{code}

 - RaftServerRpc
{code:java}
  void addPeers(Iterable<RaftPeer> peers);
{code}

 - DataStreamServerRpc
{code:java}
  void addPeers(Collection<RaftPeer> peers);
{code}
This issue is to standardise the method by adding a new interface.",[],2020-10-21 01:23:20+00:00,2020-10-21 01:58:14+00:00,2020-10-21 01:58:16+00:00,Resolved,13336389,RATIS-1103
Bug,[],smeng,Siyao Meng,smeng,Siyao Meng,Major,"The warning message in {{MetricRegistriesImpl#create}} should read {{addReport*er*Registration}}. It was missing the ""er"". It confused me for a bit when I'm trying to follow the message.

{code}
  @Override
  public RatisMetricRegistry create(MetricRegistryInfo info) {
    return registries.put(info, () -> {
      if (reporterRegistrations.isEmpty()) {
        LOG.warn(
            ""First MetricRegistry has been created without registering reporters. You may need to call"" +
                "" MetricRegistries.global().addReporterRegistration(...) before."");
      }
      RatisMetricRegistry registry = factory.create(info);
      reporterRegistrations.forEach(reg -> reg.accept(registry));
      return registry;
    });
  }
{code}",[],2020-10-20 21:53:47+00:00,2020-10-23 04:55:04+00:00,2020-10-29 05:33:20+00:00,Resolved,13336376,RATIS-1102
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,https://github.com/apache/incubator-ratis/pull/225/checks?check_run_id=1281324912,[],2020-10-20 20:47:15+00:00,2020-10-21 14:38:51+00:00,2020-10-21 14:38:51+00:00,Resolved,13336371,RATIS-1101
Improvement,[],weichiu,Wei-Chiu Chuang,weichiu,Wei-Chiu Chuang,Major,"Upon restart, Ozone Manager won't start and emitted the following error:

 
{code:java}
2020-10-19 12:04:10,639 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7553 entries from segment file /var/lib/hadoop-ozone/fake_om/ratis/1b9ac7ae-cd52-3ab1-8089-942f8267f22a/current/log_25657965-25665517
2020-10-19 12:04:10,639 ERROR org.apache.hadoop.ozone.om.OzoneManagerStarter: OM start failed with exception
java.io.IOException: java.lang.IllegalStateException
 at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
 at org.apache.ratis.util.IOUtils.toIOException(IOUtils.java:61)
 at org.apache.ratis.util.IOUtils.getFromFuture(IOUtils.java:70)
 at org.apache.ratis.server.impl.RaftServerProxy.getImpls(RaftServerProxy.java:289)
 at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:301)
 at org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer.start(OzoneManagerRatisServer.java:367)
 at org.apache.hadoop.ozone.om.OzoneManager.start(OzoneManager.java:1138)
 at org.apache.hadoop.ozone.om.OzoneManagerStarter$OMStarterHelper.start(OzoneManagerStarter.java:125)
 at org.apache.hadoop.ozone.om.OzoneManagerStarter.startOm(OzoneManagerStarter.java:79)
 at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:67)
 at org.apache.hadoop.ozone.om.OzoneManagerStarter.call(OzoneManagerStarter.java:38)
 at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
 at picocli.CommandLine.access$1100(CommandLine.java:145)
 at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
 at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
 at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
 at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
 at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
 at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
 at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
 at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
 at org.apache.hadoop.ozone.om.OzoneManagerStarter.main(OzoneManagerStarter.java:51)
Caused by: java.lang.IllegalStateException
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:36)
 at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.validateAdding(SegmentedRaftLogCache.java:400)
 at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.addSegment(SegmentedRaftLogCache.java:405)
 at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.loadSegment(SegmentedRaftLogCache.java:367)
 at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:249)
 at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:217)
 at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:276)
 at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:191)
 at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:121)
 at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:123)
 at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:213){code}
 

Looking at the code and checking the ratis log directory, I realized there is a gap in ratis log files (7659964 vs 25657965). 

 

File this Jira to make this error message easier to understand, without the need to look at the code.

 ",[],2020-10-19 20:22:36+00:00,,2020-10-19 20:22:36+00:00,Open,13336138,RATIS-1100
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Because DataStreamServer needs to forward messages to other peers, at a moment it needs to build connection with other servers. This should be handled by DataStreamServer automatically.",[],2020-10-19 01:47:46+00:00,2020-10-21 00:26:09+00:00,2020-10-21 00:26:09+00:00,Resolved,13335978,RATIS-1099
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, a ""OK"" reply is hardcoded in NettyServerStreamRpc.  We should add a isSuccess() in DataStreamReply.  Also, we may add byteWritten in DataStreamReply.",[],2020-10-15 01:15:02+00:00,2020-10-21 23:18:54+00:00,2020-10-21 23:18:54+00:00,Resolved,13335510,RATIS-1098
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In DataStreamOutputImpl, it generates a messageId incrementally for each packet in the stream.  It should use stream offset instead.",[],2020-10-14 15:21:46+00:00,2020-10-15 07:16:41+00:00,2020-10-15 07:16:41+00:00,Resolved,13335441,RATIS-1097
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, Ratis does a writeStatemachine and readstateMachine data which calls into stateMachine which may actual read actual data from disk. If the disk is overloaded/slow, it can timeout and slow down the whole pipeline. the idea is to add a metric to track these timeouts.",[],2020-10-14 11:05:52+00:00,,2020-10-14 11:07:41+00:00,Open,13335387,RATIS-1096
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"There are some async methods in RaftClientImpl.  We should move them to AsyncImpl.

Similarly, we should move the related methods from RaftClientImpl to BlockingImpl.",[],2020-10-13 06:14:35+00:00,2020-10-13 10:56:58+00:00,2020-10-13 10:56:58+00:00,Resolved,13335137,RATIS-1095
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-10-12 23:50:30+00:00,2020-10-13 04:09:14+00:00,2020-10-13 04:09:14+00:00,Resolved,13335099,RATIS-1094
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-10-12 22:20:28+00:00,2020-10-13 05:52:01+00:00,2020-10-13 05:52:01+00:00,Resolved,13335090,RATIS-1093
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The methods groupAdd, groupRemove, getGroupList and getGroupInfo in RaftClient are for group management.  All these methods act on a particular server instead of the Raft service.  Let's move the to a new interface, say GroupManagementApi.",[],2020-10-12 10:35:16+00:00,2020-10-12 11:22:32+00:00,2020-10-12 11:22:32+00:00,Resolved,13334983,RATIS-1092
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The methods in RaftClient fall into different categories
# group management: groupAdd, groupRemove, getGroupList and getGroupInfo
# blocking methods: send, sendReadOnly, sendStaleRead and sendWatch
# async methods: sendAsync, sendReadOnlyAsync, sendStaleReadAsync and sendWatchAsync

It is better to move the related methods to its own interfaces such as
# GroupManagementApi
# BlockingApi
# AsyncApi",[],2020-10-12 10:29:20+00:00,,2020-10-12 10:29:20+00:00,Open,13334981,RATIS-1091
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Once the streaming feature has become usable, we should implement RaftClient.getDataStreamApi().",[],2020-10-11 14:27:33+00:00,2020-11-05 07:16:00+00:00,2020-11-05 07:16:00+00:00,Resolved,13334875,RATIS-1090
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As discussed in RATIS-1030, we should add 
{code}
  /** @return the {@link DataStreamApi}. */
  DataStreamApi getDataStreamApi();
{code}
so that it is easier for the users to use the API.",[],2020-10-11 14:25:19+00:00,2020-10-12 08:40:44+00:00,2020-10-12 10:30:46+00:00,Resolved,13334873,RATIS-1089
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"While closing a open log segment using the SegmentedRaftLogWorker#closeLogSegment method, the corresponding cache segment also needs to be rolled (close and open a new empty one). Else,  the cache will go out of sync with the on disk log segment state.

cc [~lokeshjain] / [~hanishakoneru]",[],2020-10-09 19:53:27+00:00,2020-10-20 07:51:49+00:00,2021-02-02 05:59:48+00:00,Resolved,13334710,RATIS-1088
Test,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"Let's add new tests for the following cases:

We cannot add a new node to a single node raft ring. The setConfiguration request times out as it does not get a quorum (2 nodes in the ring but the 2nd new node has not started up yet). The timeout is very less to start the 2nd node to startup and respond to the setConfiguration request.",[],2020-10-08 03:56:39+00:00,2020-10-09 21:22:20+00:00,2020-10-09 21:22:21+00:00,Resolved,13334341,RATIS-1087
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As suggested by [~shashikant], we may use Streaming to support read requests.  Since Streaming is implemented with zero buffer copying, it is anticipated that Streaming will have a better performance when the return payload is large.",[],2020-10-02 05:25:58+00:00,,2021-04-20 14:49:16+00:00,Open,13330493,RATIS-1086
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In a stream request, the client should send a RaftClientRequest (without data) as the header so that the state machine at the server can process the request as a normal RaftClientRequest.

We may consider using Protobuf to encode RaftClientRequest.  The raw data will be streamed after the RaftClientRequest.",[],2020-10-02 00:26:53+00:00,2020-10-14 01:44:43+00:00,2020-10-14 03:24:21+00:00,Resolved,13330474,RATIS-1085
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to multi-raft, streaming should also support multiple groups.",[],2020-10-01 10:23:11+00:00,2020-11-03 02:40:35+00:00,2020-11-03 14:18:47+00:00,Resolved,13330330,RATIS-1084
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Once the stream data has been replicated to all server, the leader should create a Raft transaction.  When the leader send the transaction to the other server by appendEntries, it only has to send the stream data ID instead of sending the stream data.",[],2020-10-01 10:16:21+00:00,2020-11-04 15:03:12+00:00,2020-11-04 15:03:12+00:00,Resolved,13330326,RATIS-1083
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Once a stream server has received data from client, it should forward the data to the other servers.  For simplicity, a star topology is used in this JIRA.  In the future, the star topology will be replaced by pipelines in order to avoid additional cross rack traffic.",[],2020-10-01 09:59:21+00:00,2020-10-20 02:24:41+00:00,2020-10-20 02:24:41+00:00,Resolved,13330323,RATIS-1082
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,NettyServerStreamRpc currently writes data to a (hard coded) local file.  It should write to the StateMachine.,[],2020-10-01 09:54:03+00:00,2020-10-06 00:44:27+00:00,2020-10-07 12:26:28+00:00,Resolved,13330321,RATIS-1081
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-759, we added StreamApi to send large messages to Raft.  We are going to add another DataStream api (RATIS-979) to stream data outside Raft.  In order to distinguish two APIs, it is better to rename StreamApi to MessageStreamApi.

",[],2020-09-30 07:21:16+00:00,2020-09-30 10:23:59+00:00,2020-10-01 10:07:03+00:00,Resolved,13330108,RATIS-1080
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"1. Can add javadoc to encoder/decoder to document encoding format for a series of bytes.
2. Can add a logging when decoder has seen a message that does not have a correct encoding format.",[],2020-09-29 21:46:10+00:00,2020-10-29 22:45:41+00:00,2020-10-29 22:45:42+00:00,Resolved,13330046,RATIS-1079
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- Move the netty specific classes to ratis-netty, in particular, DataStreamRequestServer.
- Move the server classes to server package and client classes to client packages.
- Rename impl classes to the implementation specific names, e.g. DataStreamReplyImpl -> DataStreamReplyByteBuffer.",[],2020-09-28 12:33:56+00:00,2020-09-29 01:08:02+00:00,2020-09-29 10:09:00+00:00,Resolved,13329743,RATIS-1078
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"There are two convention of metric naming convention 
`public static final String RAFT_LOG_WORKER_QUEUE_SIZE = ""workerQueueSize"";`
`public static final String RATIS_GRPC_METRICS_REQUEST_RETRY_COUNT = ""num_retries"";`

We can have a unified convention.
",[],2020-09-26 01:06:42+00:00,,2021-01-19 22:32:54+00:00,Open,13329506,RATIS-1077
Bug,[],glengeng,Glen Geng,glengeng,Glen Geng,Major,"according to reply from grpc community

[https://github.com/grpc/grpc-java/issues/7449|https://github.com/apache/incubator-ratis/pull/206]

[https://github.com/grpc/grpc-java/issues/7442]
{quote}A channel can be used throughout the lifetime of the application. There shouldn't be a case that the application needs to shut down and recreate it.
{quote}
{quote}We would like to let {{StreamObserver.onError()}} to call {{ManagedChannel.resetConnectBackoff()}} as one of the recovery step: for non-backoff state channel, it would be a no-op; for backoff state channel, it will trigger an immediate re-connect to avoid restarted followers from timeout.
{quote}
 

We've handled this issue for the ManagedChannel in GrpcServerProtocolClient in RATIS-1072. Just file this Jira to track the same problem in GrpcClientProtocolClient. There should not be any safety issues for GrpcClientProtocolClient, but since 
{quote}The overhead for creating a channel is big.
{quote}
remove un-necessary shutdown and re-create grpc channel may improve performance of client operations.

 

BTW, ozone may suffer the same issue, since it also use ManagedChannel in:
{code:java}
org.apache.hadoop.ozone.container.replication.GrpcReplicationClient
org.apache.hadoop.hdds.scm.XceiverClientGrpc
{code}","['MultiRaft', 'dense-storage']",2020-09-25 05:12:15+00:00,,2021-04-20 14:43:38+00:00,Open,13329334,RATIS-1076
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,https://sonarcloud.io/project/issues?id=apache_incubator-ratis&issues=AXJWdiRzwsm5D8rduwS_&open=AXJWdiRzwsm5D8rduwS_,[],2020-09-25 04:05:40+00:00,2020-09-25 05:58:37+00:00,2020-09-25 13:42:35+00:00,Resolved,13329329,RATIS-1075
Bug,[],glengeng,Glen Geng,glengeng,Glen Geng,Major,"GrpcLogAppender improperly decrease nextIndex to 1, which will trigger installSnapshot request to followers, and make pipeline be vulnerable.

 

*Below is the interaction log between leader and the follower.*

Follower side, received an install snapshot request, and closed the pipeline.
{code:java}
ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,719 [grpc-default-executor-628] INFO org.apache.ratis.server.impl.RaftServerImpl: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8: receive installSnapshot: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb->591f38ce-0b11-4003-8528-7a5802f89ea8#0-t514,notify:(t:392, i:992920)
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,719 [grpc-default-executor-628] INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Leader change notification received for group: group-622E07D885D8 with new leaderId: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,719 [grpc-default-executor-628] INFO org.apache.ratis.server.impl.RaftServerImpl: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8: change Leader from null to 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb at term 514 for installSnapshot, leader elected after 50593ms
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,719 [grpc-default-executor-628] INFO org.apache.ratis.server.impl.RaftServerImpl: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8: notifyInstallSnapshot: nextIndex is 2248004 but the leader's first available index is 992920.
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,719 [grpc-default-executor-628] WARN org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Install snapshot notification received from Leader with termIndex: (t:392, i:992920), terminating pipeline: group-622E07D885D8
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,720 [grpc-default-executor-628] ERROR org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=433c67af-f834-4959-bcf7-622e07d885d8.Reason : 591f38ce-0b11-4003-8528-7a5802f89ea8 closes pipeline when installSnapshot from leader because leader snapshot doesn't contain any data to replay, all the log entries prior to the snapshot might have been purged.So follower should not try to install snapshot from leader butcan close the pipeline here. It's in follower state for 1761ms
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,720 [grpc-default-executor-628] INFO org.apache.ratis.server.impl.RaftServerImpl: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8: StateMachine successfully installed snapshot index 992920. Reloading the StateMachine.
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,720 [grpc-default-executor-628] INFO org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 2248003 -> 992920
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,720 [grpc-default-executor-628] INFO org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 2248001 -> 992920
 ozone-root-datanode-172.16.90.69.log.9:2020-09-21 19:28:49,720 [grpc-default-executor-628] INFO org.apache.ratis.server.impl.RaftServerImpl: 591f38ce-0b11-4003-8528-7a5802f89ea8@group-622E07D885D8: reply installSnapshot: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb<-591f38ce-0b11-4003-8528-7a5802f89ea8#0:FAIL-t514,IN_PROGRESS{code}
 

Leader side, just take charge, got vote from another follower, but miss vote from this follower
{code:java}
ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:21,499 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.impl.LeaderElection: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143: begin an election at term 510 for 2248004: [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb:172.16.90.54:9858:0, 591f38ce-0b11-4003-8528-7a5802f89ea8:172.16.90.69:9858:1, e5596d61-c021-4a4b-89bc-6d8e6d4f1baf:172.16.90.56:9858:0], old=null
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,580 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.impl.LeaderElection: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143: Election PASSED; received 1 response(s) [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb<-e5596d61-c021-4a4b-89bc-6d8e6d4f1baf#0:OK-t510] and 0 exception(s); 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8:t510, leader=null, voted=6769b0ef-fb4a-4235-bcf0-f1623fcd74cb, raftlog=6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-SegmentedRaftLog:OPENED:c2248003,f2248004,i2248004, conf=2248004: [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb:172.16.90.54:9858:0, 591f38ce-0b11-4003-8528-7a5802f89ea8:172.16.90.69:9858:1, e5596d61-c021-4a4b-89bc-6d8e6d4f1baf:172.16.90.56:9858:0], old=null
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,580 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.impl.RoleInfo: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb: shutdown LeaderElection
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,580 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.impl.RaftServerImpl: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8: changes role from CANDIDATE to LEADER at term 510 for changeToLeader
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,580 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Leader change notification received for group: group-622E07D885D8 with new leaderId: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,588 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.impl.RaftServerImpl: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8: change Leader from null to 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb at term 510 for becomeLeader, leader elected after 20419ms
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,588 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:26,588 [6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8-LeaderElection143] INFO org.apache.ratis.server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default){code}
 

Due to Grpc exception, leader decrease next index of follower to 1. Since leader has purged log, it has no choice but send out an installSnapshot request to follower, which will trigger follower to close the pipeline.
{code:java}
ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:51,531 [grpc-default-executor-345] WARN org.apache.ratis.grpc.server.GrpcLogAppender: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8->591f38ce-0b11-4003-8528-7a5802f89ea8-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:51,531 [grpc-default-executor-345] INFO org.apache.ratis.server.impl.FollowerInfo: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8->591f38ce-0b11-4003-8528-7a5802f89ea8: nextIndex: updateUnconditionally 2248006 -> 1
 ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:51,672 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$601/1151550579@71fbee17] INFO org.apache.ratis.grpc.server.GrpcLogAppender: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8->591f38ce-0b11-4003-8528-7a5802f89ea8-GrpcLogAppender: followerNextIndex = 1 but logStartIndex = 992920, notify follower to install snapshot-(t:392, i:992920){code}
 

*Here is the RCA*

According to raft algo, for the given follower, the initial value of matchIndex is 0, the initial value of nextIndex is lastLogIndex + 1.

 

In GrpcLogAppender::AppendLogResponseHandler
{code:java}
public void onError(Throwable t) {
  if (!isAppenderRunning()) {
    LOG.info(""{} is stopped"", GrpcLogAppender.this);
    return;
  }
  GrpcUtil.warn(LOG, () -> this + "": Failed appendEntries"", t);
  grpcServerMetrics.onRequestRetry(); // Update try counter
  AppendEntriesRequest request = pendingRequests.remove(GrpcUtil.getCallId(t), GrpcUtil.isHeartbeat(t));
  resetClient(request);
}
{code}
since this is not exception thrown back from GrpcServerProtocolService, callId will not be set, request will be null.

 
{code:java}
private synchronized void resetClient(AppendEntriesRequest request) {
  try {
    rpcService.getProxies().getProxy(getFollowerId()).resetConnectBackoff();
  } catch (IOException ie) {
    LOG.warn(this + "": Failed to reset channel by "" + ie);
  }

  appendLogRequestObserver = null;
  firstResponseReceived = false;

  // clear the pending requests queue and reset the next index of follower
  final long nextIndex = 1 + Optional.ofNullable(request)
      .map(AppendEntriesRequest::getPreviousLog)
      .map(TermIndex::getIndex)
      .orElseGet(getFollower()::getMatchIndex);

  pendingRequests.clear();
  getFollower().decreaseNextIndex(nextIndex);
}
{code}
request is null, nextIndex will be calculated from matchIndex.

 

Since leader has never talked with this follower, its matchIndex will be 0, thus nextIndex will be matchIndex + 1,  0 + 1 = 1. Just shown as this trace:
{code:java}
ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:51,531 [grpc-default-executor-345] WARN org.apache.ratis.grpc.server.GrpcLogAppender: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8->591f38ce-0b11-4003-8528-7a5802f89ea8-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception ozone-root-datanode-172.16.90.54.log.3:2020-09-21 19:28:51,531 [grpc-default-executor-345] INFO org.apache.ratis.server.impl.FollowerInfo: 6769b0ef-fb4a-4235-bcf0-f1623fcd74cb@group-622E07D885D8->591f38ce-0b11-4003-8528-7a5802f89ea8: nextIndex: updateUnconditionally 2248006 -> 1{code}
 

*The fix is simple* 

If leader has talked with follower, matchIndex will catchup, thus won't be 0, the calculation logic for nextIndex is fine.

otherwise, matchIndex is 0, we just keep nextIndex unchanged, and retry. 

 ","['MultiRaft', 'dense-storage']",2020-09-23 11:01:33+00:00,2020-09-25 04:58:10+00:00,2020-09-25 13:43:46+00:00,Resolved,13328975,RATIS-1074
Task,[],krisden,Kevin Risden,krisden,Kevin Risden,Minor,Ratis third party had most of the version declarations in the root pom. This moves the remaining dependencies to the root pom so that versions are managed in one location.,[],2020-09-22 17:09:00+00:00,2020-09-30 14:16:59+00:00,2020-09-30 17:04:40+00:00,Resolved,13328830,RATIS-1073
Improvement,[],glengeng,Glen Geng,glengeng,Glen Geng,Major,"[link title|http://example.com/] 

When InstallSnapshotResponseHandler::onError() or AppendLogResponseHandler::onError() is called, it will:
 # call rpcService.getProxies().resetProxy(getFollowerId()).
 # set appendLogRequestObserver to be null.

The recovery steps for this BiDi streaming call is actually: 
 # call ManagedChannel.shutdown()
 # re-create the channel from NettyChannelBuilder
 # re-create the async stub from the channel.
 # re-create a StreamObserver<OurRequest> from the async stub.

 

*Above steps is un-necessary and dangerous.*

 

*It is un-necessary:*

according to the [reply from grpc|[https://github.com/grpc/grpc-java/issues/7442]]]
{quote}Yes, you don't need to recreate the channel (and stub) for starting a new RPC call. The overhead for creating a channel is big.

Receiving {{StreamObserver.onError()}} only indicates that specific RPC has been terminated. The connection should be still there. So you can definitely start new RPCs on the existing connection.
{quote}
 

*It is dangerous:*

In multi-raft configuraiton, if two leaders sit in DN1, their followers sit in DN2, their steaming call will share the managed channel in the same GrpcServerProtocolClient that targeting from DN1 to DN2.

If leader1 calls StreamObserver::onError(), it will shut down and re-create the underlying channel. In the same time, leader2's streaming call will be affected, and call StreamObserver::onError() to shut down and re-create the channel as well. The consequences is, the channel will be continually shutdown and re-create.

 

*trace from DN consisting of the leaders:*

We can see that, the channel targetting 172.16.0.69 is continually shutdown and re-create in every 3s.
{quote}2020-09-18 19:47:04,025 [grpc-default-executor-93] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134495, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:07,025 [grpc-default-executor-115] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134499, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:10,026 [grpc-default-executor-106] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134503, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:13,026 [grpc-default-executor-115] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134507, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:16,027 [grpc-default-executor-106] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134511, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:19,027 [grpc-default-executor-114] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134532, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:22,027 [grpc-default-executor-105] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134540, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:25,028 [grpc-default-executor-104] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134544, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:28,028 [grpc-default-executor-117] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134548, target=172.16.90.69:9858}}. 
 2020-09-18 19:47:31,028 [grpc-default-executor-114] WARN org.apache.ratis.grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper\{delegate=ManagedChannelImpl{logId=134552, target=172.16.90.69:9858}}. 
  
{quote}
*trace from DN consisting of the followers:*

Streams of different raft-group is continually affected. The (term, index) indicate that they belong to different raft-group, (t:9, i:8713), (t:7, i:12312),(t:3, i:213868),(t:10, i:12504), meanwhile raft peer id df173506-6978-47e5-8aef-034cafd221a6 means they are from leaders on the same DN.
{quote}2020-09-18 19:51:49,498 [grpc-default-executor-113] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#320-t9, previous=(t:9, i:8713), leaderCommit=8714, initializing? false, entries: size=1, first=(t:9, i:8714), METADATAENTRY(c:8713): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:52,499 [grpc-default-executor-104] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#608-t7, previous=(t:7, i:12312), leaderCommit=12313, initializing? false, entries: size=1, first=(t:7, i:12313), METADATAENTRY(c:12312): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:52,499 [grpc-default-executor-109] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#1250591-t3, previous=(t:3, i:213868), leaderCommit=213869, initializing? false, entries: size=1, first=(t:3, i:213869), METADATAENTRY(c:213865): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:52,499 [grpc-default-executor-112] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#601-t10, previous=(t:10, i:12504), leaderCommit=12505, initializing? false, entries: size=1, first=(t:10, i:12505), METADATAENTRY(c:12504): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:55,499 [grpc-default-executor-109] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#785-t10, previous=(t:10, i:6660), leaderCommit=6661, initializing? false, entries: size=1, first=(t:10, i:6661), METADATAENTRY(c:6660): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:55,499 [grpc-default-executor-104] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#701-t6, previous=(t:6, i:9305), leaderCommit=9306, initializing? false, entries: size=1, first=(t:6, i:9306), METADATAENTRY(c:9305): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:58,499 [grpc-default-executor-114] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#611-t7, previous=(t:7, i:12312), leaderCommit=12313, initializing? false, entries: size=1, first=(t:7, i:12313), METADATAENTRY(c:12312): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:58,499 [grpc-default-executor-112] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#604-t10, previous=(t:10, i:12504), leaderCommit=12505, initializing? false, entries: size=1, first=(t:10, i:12505), METADATAENTRY(c:12504): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2020-09-18 19:51:58,499 [grpc-default-executor-113] WARN org.apache.ratis.grpc.server.GrpcServerProtocolService: 591f38ce-0b11-4003-8528-7a5802f89ea8: installSnapshot onError, lastRequest: df173506-6978-47e5-8aef-034cafd221a6->591f38ce-0b11-4003-8528-7a5802f89ea8#324-t9, previous=(t:9, i:8713), leaderCommit=8714, initializing? false, entries: size=1, first=(t:9, i:8714), METADATAENTRY(c:8713): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
  
{quote}
*The fix is simple* 

We can reuse the the channel and stub, just need {{step 4}} to re-create the {{StreamObserver.}}

 ","['MultiRaft', 'dense-storage']",2020-09-21 02:59:15+00:00,2020-09-28 11:27:19+00:00,2021-02-02 06:01:39+00:00,Resolved,13328442,RATIS-1072
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-09-19 23:05:38+00:00,,2020-09-28 01:22:31+00:00,Open,13328374,RATIS-1071
Task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Hadoop-ozone has a MiniChaosOzoneCluster that can kill OM or DN randomly. Ratis might have a similar implementation to test whether Ratis has correct implementation under a situation that random nodes could fail. 

 

Ozone failure injection could be a reference: https://github.com/apache/hadoop-ozone/tree/676610ef40b0f8701d950b347fb916d28268f1da/hadoop-ozone/fault-injection-test",[],2020-09-19 06:04:58+00:00,,2020-09-19 21:10:25+00:00,Open,13328336,RATIS-1070
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Currently Ratis hasn't enabled Checkstyle on src/test. 

This can be easily done by add 


{code:xml}
<includeTestSourceDirectory>true</includeTestSourceDirectory>
{code}


but more change will happen to fix style issues existing in testing code.",[],2020-09-17 03:45:42+00:00,,2020-09-17 17:49:56+00:00,Open,13327953,RATIS-1069
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,It could be either controlled by Ratis or by applications. Need a detailed design (can use Ozone use case as an example to propose the design),[],2020-09-16 18:34:14+00:00,,2020-09-16 18:39:51+00:00,Open,13327906,RATIS-1068
Improvement,[],Zhangg,Lei Zhang,Zhangg,Lei Zhang,Major,"just like

--peers=n0:[xx:xx:xx:xx]:6000,n1:[xx:xx:xx:xx]:6001,n2:[xx:xx:xx:xx]:6002",[],2020-09-15 08:34:26+00:00,,2020-11-26 02:53:32+00:00,Open,13327620,RATIS-1067
Improvement,[],Zhangg,Lei Zhang,Zhangg,Lei Zhang,Major,"The docs[1] that describe client command will added duplicate peers parameters.
 
${BIN}/client.sh filestore loadgen --size 1048576 --numFiles 1000 --peers ${PEERS}
 
I think the QUORUM_OPTS parameter should not be used in client.sh, just like server.sh.
 
[1] [https://github.com/apache/incubator-ratis/blob/master/ratis-examples/README.md#filestore-client]",[],2020-09-15 07:14:13+00:00,2020-12-02 12:58:54+00:00,2020-12-02 12:58:54+00:00,Resolved,13327600,RATIS-1066
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-09-14 06:48:17+00:00,,2020-09-14 06:48:17+00:00,Open,13327362,RATIS-1065
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-09-14 06:48:03+00:00,2020-09-22 15:34:08+00:00,2020-09-23 04:19:54+00:00,Resolved,13327361,RATIS-1064
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-09-14 05:07:07+00:00,2020-09-15 22:13:02+00:00,2020-09-15 22:13:03+00:00,Resolved,13327348,RATIS-1063
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"It is better to print ""term=""  to make it more readable when printing ServerState:

",[],2020-09-14 04:00:44+00:00,2020-09-19 07:35:41+00:00,2020-09-19 07:35:42+00:00,Resolved,13327337,RATIS-1062
Task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"It is not an unusual requirement to generate and maintain a series of monotonic increasing unique numbers in a distributed environment, and provide API like ""long getNextUniqueID()"", which guarantees uniqueness of the returned number. 

Currently hadoop-zone has a requirement in SCM HA where it must guarantee generating unique container ID. 

Ratis might be a place to serve such common need. E.g. Ratis leader might be the place to maintain this state and increase the number and reach the consensus among Ratis ring. 

To make this functionality more generic, Ratis might allow applications to specify a state and a function to change the state. Ratis will only need to keep agreeing the new state when having API calls.  Ratis shall offer API to access the state.",[],2020-09-12 17:52:04+00:00,,2020-10-19 02:06:11+00:00,Open,13327233,RATIS-1061
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"
{code:java}
[ERROR] testRestorePriority(org.apache.ratis.netty.TestRaftReconfigurationWithNetty)  Time elapsed: 46.338 s  <<< ERROR!
java.lang.IllegalStateException: 
No leader yet  for group-68AB444462CB: printing group-68AB444462CB
  s0:  RUNNING [
   FOLLOWER s0@group-68AB444462CB:t1, leader=null, voted=s2, raftlog=s0@group-68AB444462CB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [], old=null STARTING
     LEADER s0@group-754DA2993F51:t2, leader=s0, voted=s0, raftlog=s0@group-754DA2993F51-SegmentedRaftLog:OPENED:c2,f2,i2, conf=1: [s0:0.0.0.0:33817:0, s1:0.0.0.0:44367:0, s2:0.0.0.0:42831:0], old=null RUNNING] size=2
  s1:  RUNNING [
   FOLLOWER s1@group-68AB444462CB:t1, leader=null, voted=s2, raftlog=s1@group-68AB444462CB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [], old=null STARTING
   FOLLOWER s1@group-754DA2993F51:t2, leader=s0, voted=s0, raftlog=s1@group-754DA2993F51-SegmentedRaftLog:OPENED:c2,f2,i2, conf=1: [s0:0.0.0.0:33817:0, s1:0.0.0.0:44367:0, s2:0.0.0.0:42831:0], old=null RUNNING] size=2
 s2:  RUNNING [
   FOLLOWER s2@group-68AB444462CB:t197, leader=null, voted=s2, raftlog=s2@group-68AB444462CB-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [s0:0.0.0.0:33817:0, s1:0.0.0.0:44367:1, s2:0.0.0.0:42831:2], old=null RUNNING
   FOLLOWER s2@group-754DA2993F51:t2, leader=s0, voted=s0, raftlog=s2@group-754DA2993F51-SegmentedRaftLog:OPENED:c2,f2,i2, conf=1: [s0:0.0.0.0:33817:0, s1:0.0.0.0:44367:0, s2:0.0.0.0:42831:0], old=null RUNNING] size=2
	at org.apache.ratis.MiniRaftCluster.newIllegalStateExceptionForNoLeaders(MiniRaftCluster.java:506)
	at org.apache.ratis.RaftTestUtil.lambda$waitForLeader$1(RaftTestUtil.java:93)
	at org.apache.ratis.MiniRaftCluster.getLeader(MiniRaftCluster.java:539)
	at org.apache.ratis.MiniRaftCluster.getLeader(MiniRaftCluster.java:532)
	at org.apache.ratis.RaftTestUtil.lambda$waitForLeader$3(RaftTestUtil.java:101)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.JavaUtils.attemptRepeatedly(JavaUtils.java:146)
	at org.apache.ratis.RaftTestUtil.waitForLeader(RaftTestUtil.java:100)
	at org.apache.ratis.RaftTestUtil.waitForLeader(RaftTestUtil.java:80)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.checkPriority(RaftReconfigurationBaseTest.java:75)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.lambda$testRestorePriority$0(RaftReconfigurationBaseTest.java:115)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.testRestorePriority(RaftReconfigurationBaseTest.java:91)
{code}

",[],2020-09-09 23:37:42+00:00,,2021-01-20 07:28:12+00:00,Open,13326754,RATIS-1060
Bug,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"exportInfo might be null: https://github.com/apache/incubator-ratis/blob/61f038b6bea2934e910e8504df0d8c79d6d34799/ratis-logservice/src/main/java/org/apache/ratis/logservice/server/LogStateMachine.java#L624


if so, NPE will be thrown at https://github.com/apache/incubator-ratis/blob/61f038b6bea2934e910e8504df0d8c79d6d34799/ratis-logservice/src/main/java/org/apache/ratis/logservice/server/LogStateMachine.java#L631",[],2020-09-09 23:09:33+00:00,2020-09-10 02:21:26+00:00,2020-09-10 05:40:58+00:00,Resolved,13326752,RATIS-1059
Bug,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Response is initialized as NULL:  https://github.com/apache/incubator-ratis/blob/61f038b6bea2934e910e8504df0d8c79d6d34799/ratis-hadoop/src/main/java/org/apache/ratis/hadooprpc/client/CombinedClientProtocolServerSideTranslatorPB.java#L56

And the it could pass through the following SWITCH statement so remains as NULL: https://github.com/apache/incubator-ratis/blob/61f038b6bea2934e910e8504df0d8c79d6d34799/ratis-hadoop/src/main/java/org/apache/ratis/hadooprpc/client/CombinedClientProtocolServerSideTranslatorPB.java#L76

And then NPE will be thrown at here https://github.com/apache/incubator-ratis/blob/61f038b6bea2934e910e8504df0d8c79d6d34799/ratis-hadoop/src/main/java/org/apache/ratis/hadooprpc/client/CombinedClientProtocolServerSideTranslatorPB.java#L82",[],2020-09-09 22:49:11+00:00,2020-09-14 15:54:44+00:00,2020-09-14 15:54:44+00:00,Resolved,13326751,RATIS-1058
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Right now NettyClientRpc does not support 


{code:java}
public interface RaftClientRpc extends Closeable {
  /** Async call to send a request. */
  default CompletableFuture<RaftClientReply> sendRequestAsync(RaftClientRequest request) {
    throw new UnsupportedOperationException(getClass() + "" does not support this method."");
  }

  /** Async call to send a request. */
  default CompletableFuture<RaftClientReply> sendRequestAsyncUnordered(RaftClientRequest request) {
    throw new UnsupportedOperationException(getClass() + "" does not support ""
        + JavaUtils.getCurrentStackTraceElement().getMethodName());
  }
}
{code}
",[],2020-09-08 22:30:06+00:00,,2020-09-09 02:56:59+00:00,Open,13326564,RATIS-1057
New Feature,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"In RATIS-979, streaming api was defined and netty client supported the streaming API.

We can also have an implementation for grpc client.",[],2020-09-08 22:23:01+00:00,2020-09-29 21:44:33+00:00,2020-09-29 21:44:33+00:00,Resolved,13326563,RATIS-1056
Sub-task,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,,[],2020-09-08 14:48:01+00:00,2020-09-09 08:24:26+00:00,2020-09-09 08:24:26+00:00,Resolved,13326506,RATIS-1055
Bug,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Minor,"https://sonarcloud.io/project/issues?id=apache_incubator-ratis&open=AXMispqvSBrYCGcXe6dV&resolved=false&types=BUG

From the above link, we can find that, there are 90 issue from ""SonarCloud Code Analysis"", this ticket aimed to resolve all of these issue until the ""SonarCloud Code Analysis"" getting green.",[],2020-09-08 14:18:36+00:00,2020-10-29 15:59:24+00:00,2020-10-29 15:59:24+00:00,Resolved,13326499,RATIS-1054
Sub-task,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,,[],2020-09-08 09:06:38+00:00,2020-09-08 14:33:56+00:00,2020-09-08 17:06:34+00:00,Resolved,13326419,RATIS-1053
Sub-task,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,,[],2020-09-08 08:51:42+00:00,2020-09-08 14:34:35+00:00,2020-09-08 17:05:29+00:00,Resolved,13326413,RATIS-1052
Sub-task,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Minor,,[],2020-09-08 08:27:28+00:00,2020-09-08 14:34:59+00:00,2020-09-08 14:34:59+00:00,Resolved,13326402,RATIS-1051
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"Ozone frequently uses a snapshot version from Ratis and sometimes a custom dev build is required.

It would be more safe to persist the version and scm revision to the Ratis jar files which can be read and printed out with 'ozone version' (or from any other upstream project)  ",[],2020-09-04 12:10:54+00:00,2020-09-07 11:31:49+00:00,2020-09-07 11:34:13+00:00,Resolved,13326073,RATIS-1050
Task,[],vivekratnavel,Vivek Ratnavel Subramanian,vivekratnavel,Vivek Ratnavel Subramanian,Major,This metric should keep track of last leader election time. ,[],2020-09-03 08:41:17+00:00,2020-10-23 16:31:18+00:00,2020-10-23 16:31:18+00:00,Resolved,13325875,RATIS-1049
Bug,[],burcukozkan,Burcu Ozkan,burcukozkan,Burcu Ozkan,Major,"I am testing fault tolerance of Ratis, more specifically whether it can tolerate random message losses. Simply, I drop some of the messages and do not deliver them to the recipient. 

In some tests, I observe executions in which the Ratis servers cannot elect a leader. The servers continuously start leader election but none of them succeed.

You can find the execution logs together with the list of exchanged and dropped messages (the messages marked by ""-D"" are dropped) in the attachments.
",[],2020-08-31 12:38:07+00:00,,2020-08-31 12:44:36+00:00,Open,13325336,RATIS-1048
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-31 12:37:03+00:00,2020-08-31 18:36:40+00:00,2020-08-31 18:38:15+00:00,Resolved,13325335,RATIS-1047
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Netty jars provides native epoll which is better in performance over NIO. However because of netty shading, the .so files are not shaded correctly. This jira shades the jar's correctly.

https://netty.io/wiki/native-transports.html",[],2020-08-28 08:09:25+00:00,2020-09-29 14:08:53+00:00,2020-09-29 14:08:53+00:00,Resolved,13324994,RATIS-1046
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,We should be able to detect a follower is lagging behind based on a configuration (what metrics to decide the lagging is TBD). ,[],2020-08-27 22:02:15+00:00,,2020-08-27 22:03:36+00:00,Open,13324922,RATIS-1045
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,This JIRA proposes to add Resume() to RaftServerImpl. Resume() should transit server from PAUSED to RUNNING.  ,[],2020-08-27 21:59:49+00:00,2020-09-23 20:01:38+00:00,2020-09-23 20:01:38+00:00,Resolved,13324921,RATIS-1044
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,This JIRA should add a Pause() in RatisServerImpl. What Pause() does is transiting servers state to PAUSING state. After that call server should pause itself (e.g. no longer accepts new entries). Then change state to PAUSED. ,[],2020-08-27 21:58:18+00:00,2020-09-25 00:01:30+00:00,2020-09-25 13:19:49+00:00,Resolved,13324920,RATIS-1043
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"I tested Ozone with freon key generator and teragen (2 mappers, 10G) and found that the during the teragen execution the Ozone client spends a lot of time waiting for the watchForCommit call.

In ozone the minimum HB timeout is 5 seconds (max is 5.2) and the HB thread in GrpcLogAppender can sleep (min.hb.timeout / 2) if there is no outstanding requests. But we need faster response from the followers when we wait the results of watch for commit.

Lokesh created a patch for me (thanks) which checks if the lastCommitIndex is the same on the follower and the leader and sends out additional heartbeats if they don't match.

Ozone teragen 10 (mappers=2) performance is improved with 15% with this approach. ",[],2020-08-26 13:07:10+00:00,2020-09-23 05:43:20+00:00,2020-09-23 05:43:27+00:00,Resolved,13324651,RATIS-1042
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a client tries to connect to a Raft group, it should first try the higher priority servers.",[],2020-08-25 17:17:22+00:00,2020-08-31 04:57:41+00:00,2020-08-31 04:57:41+00:00,Resolved,13324518,RATIS-1041
Task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-08-25 06:40:43+00:00,2020-08-25 06:44:26+00:00,2020-08-25 06:44:26+00:00,Resolved,13324391,RATIS-1040
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This is a follower up of RATIS-1038 for updating the ratis-thirdparty version.,[],2020-08-18 22:53:01+00:00,2020-08-18 23:05:18+00:00,2020-08-18 23:05:39+00:00,Resolved,13323445,RATIS-1039
Sub-task,[],ansh.khanna,Ansh Khanna,ansh.khanna,Ansh Khanna,Major,"Fixes this issue, needed for zero-copy streaming.

[https://github.com/netty/netty/issues/10245]",[],2020-08-13 20:45:12+00:00,2020-08-14 21:24:16+00:00,2020-08-14 21:25:33+00:00,Resolved,13322610,RATIS-1038
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In the benchmark in RATIS-997, we found that flatbuffers java implementation actually was inefficient.  Since we are not going to use it, we should remove the dependency.",[],2020-08-13 20:06:15+00:00,2020-08-14 10:02:05+00:00,2020-08-14 10:02:05+00:00,Resolved,13322605,RATIS-1037
Bug,[],vivekratnavel,Vivek Ratnavel Subramanian,vivekratnavel,Vivek Ratnavel Subramanian,Major,ratis_leader_election_electionCount metric should track the number of leader elections and not the election timeouts.,[],2020-08-13 17:42:55+00:00,2020-10-23 11:22:15+00:00,2020-10-23 16:31:18+00:00,Resolved,13322584,RATIS-1036
Task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-12 03:14:35+00:00,,2020-08-12 03:14:35+00:00,Open,13322177,RATIS-1035
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-12 00:55:50+00:00,2020-08-31 04:53:05+00:00,2020-08-31 04:53:13+00:00,Resolved,13322164,RATIS-1034
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"In a leader election, the server(s) with the highest priority must *always* win unless they are ineligible or unavailable.  A server is ineligible when its log is lagging behind.",[],2020-08-12 00:55:03+00:00,2020-08-27 06:01:01+00:00,2020-08-27 06:01:01+00:00,Resolved,13322163,RATIS-1033
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-12 00:51:17+00:00,2020-08-25 17:18:19+00:00,2020-08-25 17:18:19+00:00,Resolved,13322161,RATIS-1032
Sub-task,[],ansh.khanna,Ansh Khanna,ansh.khanna,Ansh Khanna,Major,This is the server side code of RATIS-1012.,[],2020-08-10 22:59:22+00:00,2020-08-17 18:47:51+00:00,2020-08-18 22:50:03+00:00,Resolved,13321892,RATIS-1031
Sub-task,[],ansh.khanna,Ansh Khanna,ansh.khanna,Ansh Khanna,Major,This is the client side code of RATIS-1012.,[],2020-08-10 22:58:54+00:00,2020-08-13 19:57:22+00:00,2020-10-11 14:30:27+00:00,Resolved,13321891,RATIS-1030
Bug,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"metrics variable [1] will not be initialized when identifier is not null.

[1]: https://github.com/apache/incubator-ratis/blob/349c365e81d76b210df7a97704217178e3f7f826/ratis-grpc/src/main/java/org/apache/ratis/grpc/metrics/intercept/server/MetricServerInterceptor.java#L71",[],2020-08-09 05:52:22+00:00,2020-08-12 10:46:56+00:00,2020-08-12 10:46:56+00:00,Resolved,13321674,RATIS-1029
Task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,Also fix existing import *,[],2020-08-09 03:42:24+00:00,,2020-08-11 22:27:59+00:00,Open,13321667,RATIS-1028
Task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,,[],2020-08-08 00:58:57+00:00,2020-08-11 00:21:44+00:00,2020-08-11 00:21:45+00:00,Resolved,13321605,RATIS-1027
Sub-task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"
{code:java}
[ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 126.882 s <<< FAILURE! - in org.apache.ratis.TestMultiRaftGroup
[ERROR] testMultiRaftGroup[2](org.apache.ratis.TestMultiRaftGroup)  Time elapsed: 100.015 s  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 100 seconds
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:312)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:304)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequestWithRetry(RaftClientImpl.java:317)
	at org.apache.ratis.client.impl.RaftClientImpl.setConfiguration(RaftClientImpl.java:238)
	at org.apache.ratis.server.impl.GroupManagementBaseTest.runMultiGroupTest(GroupManagementBaseTest.java:229)
	at org.apache.ratis.TestMultiRaftGroup.runTestMultiRaftGroup(TestMultiRaftGroup.java:73)
	at org.apache.ratis.TestMultiRaftGroup.runTestMultiRaftGroup(TestMultiRaftGroup.java:59)
	at org.apache.ratis.TestMultiRaftGroup.testMultiRaftGroup(TestMultiRaftGroup.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)

[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   TestMultiRaftGroup.testMultiRaftGroup:55->runTestMultiRaftGroup:59->runTestMultiRaftGroup:73 » TestTimedOut
{code}
",[],2020-08-06 17:29:12+00:00,,2020-08-07 04:55:27+00:00,Open,13321347,RATIS-1026
Bug,[],ljain,Lokesh Jain,hanishakoneru,Hanisha Koneru,Major,Ozone Manager Ratis server tries to purge logs up to the snapshotIndex after a snapshot is taken. But it only purges the logs which have been cached in memory. This could lead to older logs not being purged and consuming disk space. ,[],2020-08-06 10:17:29+00:00,2020-09-08 06:59:54+00:00,2020-09-08 06:59:54+00:00,Resolved,13321278,RATIS-1025
Task,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Remove TODO:
https://github.com/apache/incubator-ratis/blob/c48b0e4507208f0ffa4618efd33bd98a8f9b4649/ratis-server/src/main/java/org/apache/ratis/server/raftlog/memory/MemoryRaftLog.java#L174

which requires to add unit tests for MemoryRaftLog entry truncation ",[],2020-08-06 07:02:51+00:00,2020-08-10 17:06:05+00:00,2020-08-10 19:18:20+00:00,Resolved,13321247,RATIS-1024
Improvement,[],amaliujia,Rui Wang,amaliujia,Rui Wang,Major,"Remove the TODO: 

https://github.com/apache/incubator-ratis/blob/c48b0e4507208f0ffa4618efd33bd98a8f9b4649/ratis-server/src/main/java/org/apache/ratis/server/storage/SnapshotManager.java#L118",[],2020-08-05 06:35:40+00:00,2020-08-12 10:14:26+00:00,2020-08-12 10:14:26+00:00,Resolved,13321019,RATIS-1023
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-05 01:58:45+00:00,,2020-08-05 04:36:53+00:00,Open,13320994,RATIS-1022
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-08-05 01:02:07+00:00,2020-08-05 05:02:08+00:00,2020-09-21 03:00:08+00:00,Resolved,13320986,RATIS-1021
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"2020-08-04T01:31:56.2654317Z 2020-08-04 01:31:56,250 [Time-limited test] ERROR ratis.MiniRaftCluster (MiniRaftCluster.java:runWithNewCluster(128)) - Failed org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
2020-08-04T01:31:56.2656778Z java.lang.NullPointerException
2020-08-04T01:31:56.2659498Z 	at java.util.Objects.requireNonNull(Objects.java:203)
2020-08-04T01:31:56.2667188Z 	at org.apache.ratis.server.impl.RaftStateMachineExceptionTests.runTestRetryOnExceptionDuringReplication(RaftStateMachineExceptionTests.java:171)
2020-08-04T01:31:56.2667762Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
2020-08-04T01:31:56.2668106Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
2020-08-04T01:31:56.2668464Z 	at org.apache.ratis.server.impl.RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication(RaftStateMachineExceptionTests.java:146)
2020-08-04T01:31:56.2671117Z 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
2020-08-04T01:31:56.2678777Z 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
2020-08-04T01:31:56.2679143Z 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
2020-08-04T01:31:56.2679475Z 	at java.lang.reflect.Method.invoke(Method.java:498)
2020-08-04T01:31:56.2679807Z 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
2020-08-04T01:31:56.2680145Z 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
2020-08-04T01:31:56.2680586Z 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
2020-08-04T01:31:56.2682462Z 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
2020-08-04T01:31:56.2685654Z 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
2020-08-04T01:31:56.2688378Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
2020-08-04T01:31:56.2804041Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
2020-08-04T01:31:56.2804579Z 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020-08-04T01:31:56.2804907Z 	at java.lang.Thread.run(Thread.java:748)",[],2020-08-04 10:58:09+00:00,,2020-08-04 10:58:48+00:00,Open,13320844,RATIS-1020
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-08-04 10:45:52+00:00,,2020-08-04 10:57:53+00:00,Open,13320842,RATIS-1019
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-08-04 09:14:42+00:00,2020-08-04 11:19:13+00:00,2020-08-04 13:02:47+00:00,Resolved,13320826,RATIS-1018
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"2020-07-17T19:27:46.4194040Z java.io.IOException: s2: Failed to start NettyRpcService
2020-07-17T19:27:46.4194366Z 	at org.apache.ratis.netty.server.NettyRpcService.startImpl(NettyRpcService.java:140)
2020-07-17T19:27:46.4194771Z 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:214)
2020-07-17T19:27:46.4195087Z 	at org.apache.ratis.server.impl.RaftServerRpcWithProxy.start(RaftServerRpcWithProxy.java:69)
2020-07-17T19:27:46.4195380Z 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$start$3(RaftServerProxy.java:305)
2020-07-17T19:27:46.4195735Z 	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:214)
2020-07-17T19:27:46.4196124Z 	at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:303)
2020-07-17T19:27:46.4196380Z 	at org.apache.ratis.MiniRaftCluster.startServers(MiniRaftCluster.java:425)
2020-07-17T19:27:46.4196633Z 	at org.apache.ratis.MiniRaftCluster.start(MiniRaftCluster.java:294)
2020-07-17T19:27:46.4196888Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:123)
2020-07-17T19:27:46.4197154Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
2020-07-17T19:27:46.4197408Z 	at org.apache.ratis.RetryCacheTests.testRetryOnNewLeader(RetryCacheTests.java:122)
2020-07-17T19:27:46.4197665Z 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
2020-07-17T19:27:46.4202375Z 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
2020-07-17T19:27:46.4202729Z 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
2020-07-17T19:27:46.4203273Z 	at java.lang.reflect.Method.invoke(Method.java:498)
2020-07-17T19:27:46.4203487Z 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
2020-07-17T19:27:46.4203658Z 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
2020-07-17T19:27:46.4203825Z 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
2020-07-17T19:27:46.4204045Z 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
2020-07-17T19:27:46.4204249Z 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
2020-07-17T19:27:46.4204413Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
2020-07-17T19:27:46.4204582Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
2020-07-17T19:27:46.4204741Z 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020-07-17T19:27:46.4204896Z 	at java.lang.Thread.run(Thread.java:748)
2020-07-17T19:27:46.4205045Z Caused by: java.net.BindException: Address already in use
2020-07-17T19:27:46.4205190Z 	at sun.nio.ch.Net.bind0(Native Method)
2020-07-17T19:27:46.4205339Z 	at sun.nio.ch.Net.bind(Net.java:433)
2020-07-17T19:27:46.4205433Z 	at sun.nio.ch.Net.bind(Net.java:425)
2020-07-17T19:27:46.4205596Z 	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:220)
2020-07-17T19:27:46.4205771Z 	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
2020-07-17T19:27:46.4205955Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:550)
2020-07-17T19:27:46.4206227Z 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
2020-07-17T19:27:46.4206417Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
2020-07-17T19:27:46.4206604Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
2020-07-17T19:27:46.4206790Z 	at org.apache.ratis.thirdparty.io.netty.handler.logging.LoggingHandler.bind(LoggingHandler.java:221)
2020-07-17T19:27:46.4206966Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
2020-07-17T19:27:46.4207161Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
2020-07-17T19:27:46.4207584Z 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
2020-07-17T19:27:46.4207759Z 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel.bind(AbstractChannel.java:248)
2020-07-17T19:27:46.4208120Z 	at org.apache.ratis.thirdparty.io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
2020-07-17T19:27:46.4208334Z 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
2020-07-17T19:27:46.4216918Z 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
2020-07-17T19:27:46.4217074Z 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
2020-07-17T19:27:46.4217314Z 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
2020-07-17T19:27:46.4224782Z 	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
2020-07-17T19:27:46.4225113Z 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
2020-07-17T19:27:46.4225281Z 	... 1 more",[],2020-08-03 11:16:31+00:00,,2020-08-03 11:18:29+00:00,Open,13320653,RATIS-1017
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-08-03 09:23:20+00:00,2020-08-04 13:02:47+00:00,2020-08-04 13:02:47+00:00,Resolved,13320622,RATIS-1016
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"2020-08-02T07:51:40.4122117Z [ERROR] testBasicInstallSnapshot(org.apache.ratis.server.simulation.TestRaftSnapshotWithSimulatedRpc)  Time elapsed: 2.224 s  <<< FAILURE!
2020-08-02T07:51:40.4123608Z java.lang.AssertionError: Unexpected exit.
2020-08-02T07:51:40.4125581Z 	at org.apache.ratis.util.ExitUtils.assertNotTerminated(ExitUtils.java:109)
2020-08-02T07:51:40.4127583Z 	at org.apache.ratis.BaseTest.assertNoFailures(BaseTest.java:75)
2020-08-02T07:51:40.4129936Z 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
2020-08-02T07:51:40.4131908Z 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
2020-08-02T07:51:40.4134053Z 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
2020-08-02T07:51:40.4136869Z 	at java.lang.reflect.Method.invoke(Method.java:498)
2020-08-02T07:51:40.4139743Z 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
2020-08-02T07:51:40.4142397Z 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
2020-08-02T07:51:40.4144762Z 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
2020-08-02T07:51:40.4147563Z 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
2020-08-02T07:51:40.4149760Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
2020-08-02T07:51:40.4152113Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
2020-08-02T07:51:40.4153780Z 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020-08-02T07:51:40.4155400Z 	at java.lang.Thread.run(Thread.java:748)
2020-08-02T07:51:40.4157463Z Caused by: org.apache.ratis.util.ExitUtils$ExitException: s3.serverHandler0 is terminating.
2020-08-02T07:51:40.4161382Z 	at org.apache.ratis.util.ExitUtils.terminate(ExitUtils.java:141)
2020-08-02T07:51:40.4163711Z 	at org.apache.ratis.util.ExitUtils.terminate(ExitUtils.java:151)
2020-08-02T07:51:40.4166998Z 	at org.apache.ratis.server.simulation.RequestHandler$HandlerDaemon.run(RequestHandler.java:137)
2020-08-02T07:51:40.4170409Z Caused by: java.lang.IllegalStateException: ILLEGAL TRANSITION: In SimpleStateMachine4Testing:s3:group-5C3F3E592635, PAUSED -> PAUSING
2020-08-02T07:51:40.4172401Z 	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
2020-08-02T07:51:40.4174848Z 	at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:115)
2020-08-02T07:51:40.4176945Z 	at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:155)
2020-08-02T07:51:40.4179235Z 	at org.apache.ratis.statemachine.SimpleStateMachine4Testing.pause(SimpleStateMachine4Testing.java:226)
2020-08-02T07:51:40.4180979Z 	at org.apache.ratis.server.impl.ServerState.installSnapshot(ServerState.java:400)
2020-08-02T07:51:40.4182963Z 	at org.apache.ratis.server.impl.RaftServerImpl.checkAndInstallSnapshot(RaftServerImpl.java:1194)
2020-08-02T07:51:40.4184872Z 	at org.apache.ratis.server.impl.RaftServerImpl.installSnapshotImpl(RaftServerImpl.java:1147)
2020-08-02T07:51:40.4186699Z 	at org.apache.ratis.server.impl.RaftServerImpl.installSnapshot(RaftServerImpl.java:1122)
2020-08-02T07:51:40.4188567Z 	at org.apache.ratis.server.impl.RaftServerProxy.installSnapshot(RaftServerProxy.java:471)
2020-08-02T07:51:40.4190604Z 	at org.apache.ratis.server.simulation.SimulatedServerRpc$1.handleRequest(SimulatedServerRpc.java:151)
2020-08-02T07:51:40.4192589Z 	at org.apache.ratis.server.simulation.SimulatedServerRpc$1.handleRequest(SimulatedServerRpc.java:137)
2020-08-02T07:51:40.4195221Z 	at org.apache.ratis.server.simulation.RequestHandler.handleRequest(RequestHandler.java:91)
2020-08-02T07:51:40.4197792Z 	at org.apache.ratis.server.simulation.RequestHandler$HandlerDaemon.run(RequestHandler.java:124)",[],2020-08-02 23:48:47+00:00,,2020-08-03 13:30:28+00:00,Open,13320573,RATIS-1015
Test,[],glengeng,Glen Geng,glengeng,Glen Geng,Major," 

After merge  LeaderState::checkLeadership(), some test case become hard to pass under GitHub CI, such as GroupManagementBaseTest and TestMultiRaftGroup.

Such case need do node restart operation or membership change operation, which will make leader vulnerable, especially resources is limited.

 

[https://github.com/apache/incubator-ratis/runs/927310008?check_suite_focus=true]

[https://github.com/apache/incubator-ratis/runs/926606136?check_suite_focus=true]

 

!image-2020-07-31-12-33-35-755.png!

 

!image-2020-07-31-12-34-08-384.png!

 

!image-2020-07-31-12-40-11-183.png!

Current walk around is to enlarge election timeout a little bit, e.g., from [150ms,300ms] to [300ms, 600ms], because larger election timeout will make leader become more stable.

 

TODO:

1) do we have better way besides changing election timeout ?

2) are there other test cases affected by LeaderState::checkLeadership() ?

 ",[],2020-07-31 03:36:02+00:00,,2020-07-31 05:44:07+00:00,Open,13320311,RATIS-1014
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-07-31 02:07:17+00:00,2020-07-31 09:39:02+00:00,2020-07-31 09:40:09+00:00,Resolved,13320305,RATIS-1013
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Since we are getting good results from RATIS-1009, we will continue to work on the first ratis streaming implementation using netty with zero buffer copying.",[],2020-07-30 17:39:24+00:00,2020-08-18 22:50:46+00:00,2020-08-18 22:50:46+00:00,Resolved,13320245,RATIS-1012
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to ratis rpc, ratis streaming should define a set of internal APIs in order to support pluggable implementations.

The APIs must support asynchronous event driven.",[],2020-07-30 17:33:11+00:00,2020-08-06 16:38:11+00:00,2020-08-06 16:50:54+00:00,Resolved,13320244,RATIS-1011
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Include download links, announcement and relevant information related to release 1.0.0 in the project website.",[],2020-07-28 07:33:42+00:00,2020-08-12 08:28:44+00:00,2020-08-12 08:28:44+00:00,Resolved,13319690,RATIS-1010
Sub-task,[],ansh.khanna,Ansh Khanna,ansh.khanna,Ansh Khanna,Major,Patch: [https://github.com/apache/incubator-ratis/pull/155],[],2020-07-24 23:09:29+00:00,2020-07-30 17:29:55+00:00,2020-07-30 17:29:55+00:00,Resolved,13319239,RATIS-1009
Bug,[],glengeng,Glen Geng,glengeng,Glen Geng,Major,"If raft server use Grpc, when append entries blocked at follower side (e.g., by calling SimpleStateMachine4Testing::blockWriteStateMachineData), leader should still be able to send heartbeat (size of entries of append entries request be 0) to followers, and receive response of heartbeat from follower side, since we have the code

 
{code:java}
@Override
public void onNext(REQUEST request) {
  if (!replyInOrder(request)) {
    try {
      process(request).thenAccept(this::handleReply);
    } catch (Throwable e) {
      handleError(e, request);
    }
    return;
  }

  final PendingServerRequest<REQUEST> current = new PendingServerRequest<>(request);
  final PendingServerRequest<REQUEST> previous = previousOnNext.getAndSet(current);
  final CompletableFuture<Void> previousFuture = Optional.ofNullable(previous)
      .map(PendingServerRequest::getFuture){code}
 

 

But test case ""testUpdateViaHeartbeat"" shows that after calling SimpleStateMachine4Testing::blockWriteStateMachineData, leader do send heartbeats, but ServerRequestStreamObserver::onNext at GrpcServerProtocolService was not called, until follower finish handling the append entries request that blocked by blockWriteStateMachineData.

 

*How to reproduce this issue ?*

checkout to master,  add following debug info
{code:java}
gengbin@GLENGENG-MB0 incubator-ratis % git diff
diff --git a/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcLogAppender.java b/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcLogAppender.java
index 4eb5cb9d..97c4679e 100644
--- a/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcLogAppender.java
+++ b/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcLogAppender.java
@@ -207,6 +207,8 @@ public class GrpcLogAppender extends LogAppender {
         getServer().getId(), null, proto);
     request.startRequestTimer();
     s.onNext(proto);
+    LOG.info(""pending log size: {}, pending hb size: {}"",
+        pendingRequests.logRequests.size(), pendingRequests.heartbeats.size());
     scheduler.onTimeout(requestTimeoutDuration,
         () -> timeoutAppendRequest(request.getCallId(), request.isHeartbeat()),
         LOG, () -> ""Timeout check failed for append entry request: "" + request);
diff --git a/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcServerProtocolService.java b/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcServerProtocolService.java
index 21a6c560..272d3c0b 100644
--- a/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcServerProtocolService.java
+++ b/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/GrpcServerProtocolService.java
@@ -106,6 +106,8 @@ class GrpcServerProtocolService extends RaftServerProtocolServiceImplBase {
 
     @Override
     public void onNext(REQUEST request) {
+      LOG.info(""receive request, in order or not: {}"",  replyInOrder(request));
+
       if (!replyInOrder(request)) {
         try {
           process(request).thenAccept(this::handleReply);
diff --git a/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java b/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
index 3c4a3d88..2bb3d7e0 100644
--- a/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
+++ b/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java
@@ -933,13 +933,9 @@ public class RaftServerImpl implements RaftServerProtocol, RaftServerAsynchronou
 
   static void logAppendEntries(boolean isHeartbeat, Supplier<String> message) {
     if (isHeartbeat) {
-      if (LOG.isTraceEnabled()) {
-        LOG.trace(""HEARTBEAT: "" + message.get());
-      }
+        LOG.info(""HEARTBEAT: "" + message.get());
     } else {
-      if (LOG.isDebugEnabled()) {
         LOG.debug(message.get());
-      }
     }
   }
 
diff --git a/ratis-test/src/test/java/org/apache/ratis/grpc/TestRaftWithGrpc.java b/ratis-test/src/test/java/org/apache/ratis/grpc/TestRaftWithGrpc.java
index 0f1d71db..00cd4833 100644
--- a/ratis-test/src/test/java/org/apache/ratis/grpc/TestRaftWithGrpc.java
+++ b/ratis-test/src/test/java/org/apache/ratis/grpc/TestRaftWithGrpc.java
@@ -17,18 +17,23 @@
  */
 package org.apache.ratis.grpc;
 
+import org.apache.log4j.Level;
 import org.apache.ratis.MiniRaftCluster;
 import org.apache.ratis.RaftBasicTests;
 import org.apache.ratis.RaftTestUtil;
 import org.apache.ratis.client.RaftClient;
+import org.apache.ratis.grpc.server.GrpcLogAppender;
 import org.apache.ratis.protocol.RaftClientReply;
+import org.apache.ratis.server.RaftServerConfigKeys;
 import org.apache.ratis.server.impl.BlockRequestHandlingInjection;
+import org.apache.ratis.server.impl.RaftServerImpl;
 import org.apache.ratis.server.impl.RaftServerTestUtil;
 import org.apache.ratis.server.protocol.TermIndex;
 import org.apache.ratis.server.raftlog.RaftLog;
 import org.apache.ratis.statemachine.SimpleStateMachine4Testing;
 import org.apache.ratis.statemachine.StateMachine;
 import org.apache.ratis.util.JavaUtils;
+import org.apache.ratis.util.Log4jUtils;
 import org.apache.ratis.util.TimeDuration;
 import org.junit.Assert;
 import org.junit.Test;
@@ -47,6 +52,11 @@ public class TestRaftWithGrpc
         SimpleStateMachine4Testing.class, StateMachine.class);
   }
 
+  {
+    Log4jUtils.setLogLevel(RaftServerImpl.LOG, Level.DEBUG);
+    Log4jUtils.setLogLevel(GrpcLogAppender.LOG, Level.DEBUG);
+  }
+
   @Override
   @Test
   public void testWithLoad() throws Exception {
@@ -67,7 +77,12 @@ public class TestRaftWithGrpc
 
   @Test
   public void testUpdateViaHeartbeat() throws Exception {
+    final TimeDuration oldTimeoutMax = RaftServerConfigKeys.Rpc.timeoutMax(getProperties());
+    RaftServerConfigKeys.Rpc.setTimeoutMax(getProperties(), TimeDuration.valueOf(5, TimeUnit.SECONDS));
+
     runWithNewCluster(NUM_SERVERS, this::runTestUpdateViaHeartbeat);
+
+    RaftServerConfigKeys.Rpc.setTimeoutMax(getProperties(), oldTimeoutMax);
   }
 
   void runTestUpdateViaHeartbeat(MiniRaftClusterWithGrpc cluster) throws Exception {
{code}
 

*How to prove this ?*

run test case testUpdateViaHeartbeat

 
{code:java}
2020-07-21 17:12:50,603 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:block(135)) - block WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:50,603 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:block(135)) - block WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:50,603 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:block(135)) - block WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:50,604 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:block(135)) - block WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:50,627 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 0, pending hb size: 1
2020-07-21 17:12:50,627 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 0, pending hb size: 1
2020-07-21 17:12:50,627 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 0, pending hb size: 1
2020-07-21 17:12:50,627 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 0, pending hb size: 1
2020-07-21 17:12:50,627 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:50,627 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:50,627 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:50,627 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:50,628 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:50,628 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:50,628 [grpc-default-executor-6] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:50,628 [ForkJoinPool.commonPool-worker-9] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s4#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0
2020-07-21 17:12:50,628 [grpc-default-executor-7] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:50,628 [ForkJoinPool.commonPool-worker-11] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s3#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0
2020-07-21 17:12:50,628 [ForkJoinPool.commonPool-worker-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s0#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0
2020-07-21 17:12:50,628 [ForkJoinPool.commonPool-worker-9] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s2#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0
2020-07-21 17:12:50,629 [grpc-default-executor-7] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s4-AppendLogResponseHandler: received a reply s1<-s4#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0, request=AppendEntriesRequest:cid=69,entriesCount=0,lastEntry=null
2020-07-21 17:12:50,629 [grpc-default-executor-6] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s3-AppendLogResponseHandler: received a reply s1<-s3#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0, request=AppendEntriesRequest:cid=69,entriesCount=0,lastEntry=null
2020-07-21 17:12:50,629 [grpc-default-executor-2] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s0-AppendLogResponseHandler: received a reply s1<-s0#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0, request=AppendEntriesRequest:cid=69,entriesCount=0,lastEntry=null
2020-07-21 17:12:50,629 [grpc-default-executor-6] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s2-AppendLogResponseHandler: received a reply s1<-s2#69:OK,SUCCESS,nextIndex:1,term:1,followerCommit:0, request=AppendEntriesRequest:cid=69,entriesCount=0,lastEntry=null
2020-07-21 17:12:50,643 [grpc-default-executor-6] DEBUG impl.RaftServerImpl (RaftServerImpl.java:submitClientRequestAsync(587)) - s3@group-6CFE864C49B6: receive client request(RaftClientRequest:client-DE8B7308F86F->s3@group-6CFE864C49B6, cid=0, seq=1*, Watch(0), Message:<EMPTY>)
2020-07-21 17:12:50,668 [grpc-default-executor-6] DEBUG impl.RaftServerImpl (RaftServerImpl.java:submitClientRequestAsync(587)) - s1@group-6CFE864C49B6: receive client request(RaftClientRequest:client-DE8B7308F86F->s1@group-6CFE864C49B6, cid=0, seq=1*, Watch(0), Message:<EMPTY>)
2020-07-21 17:12:50,669 [grpc-default-executor-6] DEBUG impl.RaftServerImpl (LeaderState.java:addWatchReqeust(358)) - s1@group-6CFE864C49B6-LeaderState: addWatchRequest RaftClientRequest:client-DE8B7308F86F->s1@group-6CFE864C49B6, cid=0, seq=1*, Watch(0), Message:<EMPTY>
2020-07-21 17:12:50,674 [grpc-default-executor-2] DEBUG impl.RaftServerImpl (RaftServerImpl.java:submitClientRequestAsync(587)) - s1@group-6CFE864C49B6: receive client request(RaftClientRequest:client-DE8B7308F86F->s1@group-6CFE864C49B6, cid=1, seq=2, RW, Message:616263)
2020-07-21 17:12:50,685 [grpc-default-executor-2] DEBUG impl.RaftServerImpl (LeaderState.java:addPendingRequest(340)) - s1@group-6CFE864C49B6-LeaderState: addPendingRequest at RaftClientRequest:client-DE8B7308F86F->s1@group-6CFE864C49B6, cid=1, seq=2, RW, Message:616263, entry=(t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:50,686 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 0
2020-07-21 17:12:50,686 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 0
2020-07-21 17:12:50,686 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 0
2020-07-21 17:12:50,686 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 0
2020-07-21 17:12:50,687 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: true
2020-07-21 17:12:50,687 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: true
2020-07-21 17:12:50,687 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: true
2020-07-21 17:12:50,687 [grpc-default-executor-0] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s2@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: (t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:50,687 [grpc-default-executor-2] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s3@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: (t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:50,687 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: true
2020-07-21 17:12:50,687 [grpc-default-executor-6] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s0@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: (t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:50,688 [grpc-default-executor-7] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s4@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:0), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: (t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:50,765 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 1
2020-07-21 17:12:50,765 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 1
2020-07-21 17:12:50,765 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 1
2020-07-21 17:12:50,765 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 1
2020-07-21 17:12:50,843 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 2
2020-07-21 17:12:50,843 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 2
2020-07-21 17:12:50,843 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 2
2020-07-21 17:12:50,843 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 2
2020-07-21 17:12:50,922 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 3
2020-07-21 17:12:50,922 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 3
2020-07-21 17:12:50,922 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 3
2020-07-21 17:12:50,922 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 3
2020-07-21 17:12:51,003 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 4
2020-07-21 17:12:51,003 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 4
2020-07-21 17:12:51,003 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 4
2020-07-21 17:12:51,003 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 4
2020-07-21 17:12:51,083 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 5
2020-07-21 17:12:51,083 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 5
2020-07-21 17:12:51,083 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 5
2020-07-21 17:12:51,083 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 5
2020-07-21 17:12:51,159 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 6
2020-07-21 17:12:51,159 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 6
2020-07-21 17:12:51,159 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 6
2020-07-21 17:12:51,159 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 6
2020-07-21 17:12:51,236 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 7
2020-07-21 17:12:51,236 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 7
2020-07-21 17:12:51,236 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 7
2020-07-21 17:12:51,236 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 7
2020-07-21 17:12:51,317 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 8
2020-07-21 17:12:51,317 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 8
2020-07-21 17:12:51,317 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 8
2020-07-21 17:12:51,317 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 8
2020-07-21 17:12:51,397 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 9
2020-07-21 17:12:51,397 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 9
2020-07-21 17:12:51,397 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 9
2020-07-21 17:12:51,397 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 9
2020-07-21 17:12:51,477 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 10
2020-07-21 17:12:51,477 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 10
2020-07-21 17:12:51,477 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 10
2020-07-21 17:12:51,477 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 10
2020-07-21 17:12:51,554 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 11
2020-07-21 17:12:51,554 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 11
2020-07-21 17:12:51,554 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 11
2020-07-21 17:12:51,554 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 11
2020-07-21 17:12:51,634 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 12
2020-07-21 17:12:51,634 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 12
2020-07-21 17:12:51,634 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 12
2020-07-21 17:12:51,634 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 12
2020-07-21 17:12:51,714 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 13
2020-07-21 17:12:51,714 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 13
2020-07-21 17:12:51,714 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 13
2020-07-21 17:12:51,714 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 13
2020-07-21 17:12:51,793 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 14
2020-07-21 17:12:51,793 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 14
2020-07-21 17:12:51,794 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 14
2020-07-21 17:12:51,794 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 14
2020-07-21 17:12:51,871 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 15
2020-07-21 17:12:51,871 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 15
2020-07-21 17:12:51,871 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 15
2020-07-21 17:12:51,871 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 15
2020-07-21 17:12:51,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 16
2020-07-21 17:12:51,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 16
2020-07-21 17:12:51,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 16
2020-07-21 17:12:51,946 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 16
2020-07-21 17:12:52,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 17
2020-07-21 17:12:52,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 17
2020-07-21 17:12:52,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 17
2020-07-21 17:12:52,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 17
2020-07-21 17:12:52,104 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 18
2020-07-21 17:12:52,104 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 18
2020-07-21 17:12:52,104 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 18
2020-07-21 17:12:52,104 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 18
2020-07-21 17:12:52,183 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 19
2020-07-21 17:12:52,183 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 19
2020-07-21 17:12:52,183 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 19
2020-07-21 17:12:52,183 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 19
2020-07-21 17:12:52,263 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 20
2020-07-21 17:12:52,263 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 20
2020-07-21 17:12:52,263 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 20
2020-07-21 17:12:52,263 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 20
2020-07-21 17:12:52,339 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 21
2020-07-21 17:12:52,339 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 21
2020-07-21 17:12:52,344 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 21
2020-07-21 17:12:52,344 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 21
2020-07-21 17:12:52,415 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 22
2020-07-21 17:12:52,415 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 22
2020-07-21 17:12:52,424 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 22
2020-07-21 17:12:52,424 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 22
2020-07-21 17:12:52,493 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 23
2020-07-21 17:12:52,493 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 23
2020-07-21 17:12:52,504 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 23
2020-07-21 17:12:52,504 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 23
2020-07-21 17:12:52,572 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 24
2020-07-21 17:12:52,572 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 24
2020-07-21 17:12:52,583 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 24
2020-07-21 17:12:52,585 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 24
2020-07-21 17:12:52,650 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 25
2020-07-21 17:12:52,650 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 25
2020-07-21 17:12:52,662 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 25
2020-07-21 17:12:52,662 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 25
2020-07-21 17:12:52,728 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 26
2020-07-21 17:12:52,728 
{code}
{code:java}
2020-07-21 17:12:55,306 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 59
2020-07-21 17:12:55,322 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 59
2020-07-21 17:12:55,327 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 59
2020-07-21 17:12:55,379 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 60
2020-07-21 17:12:55,386 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 60
2020-07-21 17:12:55,403 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 60
2020-07-21 17:12:55,404 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 60
2020-07-21 17:12:55,458 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 61
2020-07-21 17:12:55,461 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 61
2020-07-21 17:12:55,483 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 61
2020-07-21 17:12:55,484 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 61
2020-07-21 17:12:55,536 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 62
2020-07-21 17:12:55,538 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 62
2020-07-21 17:12:55,559 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 62
2020-07-21 17:12:55,563 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 62
2020-07-21 17:12:55,614 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@66633814] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 63
2020-07-21 17:12:55,617 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@427cb8b9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 63
2020-07-21 17:12:55,637 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@5d0b025a] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 63
2020-07-21 17:12:55,640 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/387080925@7d13f127] INFO  server.GrpcLogAppender (GrpcLogAppender.java:sendRequest(210)) - pending log size: 1, pending hb size: 63
2020-07-21 17:12:55,641 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:unblock(142)) - unblock WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:55,641 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:unblock(142)) - unblock WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:55,641 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:unblock(142)) - unblock WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:55,642 [Time-limited test] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:unblock(142)) - unblock WRITE_STATE_MACHINE_DATA
2020-07-21 17:12:55,642 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,642 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,642 [Timer-0] INFO  ratis.MiniRaftCluster (MiniRaftCluster.java:lambda$null$5(297)) - TIMED-PRINT: printing ALL groups
  s3:  RUNNING  FOLLOWER s3@group-6CFE864C49B6:t1, leader=s1, voted=s1, raftlog=s3@group-6CFE864C49B6-SegmentedRaftLog:OPENED:c0,f0,i1, conf=0: [s3:0.0.0.0:62545, s4:0.0.0.0:62546, s0:0.0.0.0:62542, s1:0.0.0.0:62543, s2:0.0.0.0:62544], old=null RUNNING
  s4:  RUNNING  FOLLOWER s4@group-6CFE864C49B6:t1, leader=s1, voted=s1, raftlog=s4@group-6CFE864C49B6-SegmentedRaftLog:OPENED:c0,f0,i1, conf=0: [s3:0.0.0.0:62545, s4:0.0.0.0:62546, s0:0.0.0.0:62542, s1:0.0.0.0:62543, s2:0.0.0.0:62544], old=null RUNNING
  s0:  RUNNING  FOLLOWER s0@group-6CFE864C49B6:t1, leader=s1, voted=s1, raftlog=s0@group-6CFE864C49B6-SegmentedRaftLog:OPENED:c0,f0,i1, conf=0: [s3:0.0.0.0:62545, s4:0.0.0.0:62546, s0:0.0.0.0:62542, s1:0.0.0.0:62543, s2:0.0.0.0:62544], old=null RUNNING
  s1:  RUNNING    LEADER s1@group-6CFE864C49B6:t1, leader=s1, voted=s1, raftlog=s1@group-6CFE864C49B6-SegmentedRaftLog:OPENED:c0,f1,i1, conf=0: [s3:0.0.0.0:62545, s4:0.0.0.0:62546, s0:0.0.0.0:62542, s1:0.0.0.0:62543, s2:0.0.0.0:62544], old=null RUNNING
  s2:  RUNNING  FOLLOWER s2@group-6CFE864C49B6:t1, leader=s1, voted=s1, raftlog=s2@group-6CFE864C49B6-SegmentedRaftLog:OPENED:c0,f0,i1, conf=0: [s3:0.0.0.0:62545, s4:0.0.0.0:62546, s0:0.0.0.0:62542, s1:0.0.0.0:62543, s2:0.0.0.0:62544], old=null RUNNING
2020-07-21 17:12:55,642 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,642 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,643 [grpc-default-executor-7] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,642 [ForkJoinPool.commonPool-worker-4] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s3@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s3#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,642 [ForkJoinPool.commonPool-worker-11] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s2@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s2#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,642 [ForkJoinPool.commonPool-worker-9] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s0@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s0#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,642 [ForkJoinPool.commonPool-worker-2] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(938)) - s4@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s4#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,642 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,642 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,643 [ForkJoinPool.commonPool-worker-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s2#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,643 [grpc-default-executor-1] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s2-AppendLogResponseHandler: received a reply s1<-s2#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:1)
2020-07-21 17:12:55,643 [grpc-default-executor-3] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s3-AppendLogResponseHandler: received a reply s1<-s3#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:1)
2020-07-21 17:12:55,643 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,643 [ForkJoinPool.commonPool-worker-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s4#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,643 [grpc-default-executor-6] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,644 [grpc-default-executor-7] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,644 [ForkJoinPool.commonPool-worker-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s3#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,644 [grpc-default-executor-1] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s2-AppendLogResponseHandler: received a reply s1<-s2#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=71,entriesCount=0,lastEntry=null
2020-07-21 17:12:55,644 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,644 [s1@group-6CFE864C49B6-StateMachineUpdater] DEBUG impl.StateMachineUpdater (StateMachineUpdater.java:applyLog(227)) - s1@group-6CFE864C49B6-StateMachineUpdater: applying nextIndex=1
2020-07-21 17:12:55,644 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,645 [grpc-default-executor-1] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s3-AppendLogResponseHandler: received a reply s1<-s3#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=71,entriesCount=0,lastEntry=null
2020-07-21 17:12:55,644 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,644 [ForkJoinPool.commonPool-worker-9] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s0#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,645 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,644 [grpc-default-executor-4] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s4-AppendLogResponseHandler: received a reply s1<-s4#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:1)
2020-07-21 17:12:55,644 [grpc-default-executor-5] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s0-AppendLogResponseHandler: received a reply s1<-s0#70:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:1)
2020-07-21 17:12:55,645 [s1@group-6CFE864C49B6-StateMachineUpdater] INFO  statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:put(197)) - s1: put 1, abc -> (t:1, i:1), STATEMACHINELOGENTRY, client-DE8B7308F86F, cid=1
2020-07-21 17:12:55,645 [grpc-default-executor-0] DEBUG server.GrpcLogAppender (GrpcLogAppender.java:onNext(259)) - s1@group-6CFE864C49B6->s4-AppendLogResponseHandler: received a reply s1<-s4#71:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0, request=AppendEntriesRequest:cid=71,entriesCount=0,lastEntry=null
2020-07-21 17:12:55,645 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,645 [ForkJoinPool.commonPool-worker-9] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s2#72:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,646 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s2@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,645 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,645 [grpc-default-executor-7] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,646 [ForkJoinPool.commonPool-worker-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s0@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s0#72:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,644 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,644 [ForkJoinPool.commonPool-worker-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s4#72:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,646 [grpc-default-executor-6] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,646 [grpc-default-executor-7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,646 [ForkJoinPool.commonPool-worker-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s3#72:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,646 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
2020-07-21 17:12:55,646 [ForkJoinPool.commonPool-worker-11] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s4@group-6CFE864C49B6: succeeded to handle AppendEntries. Reply: s1<-s4#73:OK,SUCCESS,nextIndex:2,term:1,followerCommit:0
2020-07-21 17:12:55,647 [grpc-default-executor-6] INFO  impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(936)) - HEARTBEAT: s3@group-6CFE864C49B6: receive appendEntries(s1, 1, (t:1, i:1), 0, false, commits[s1:c0, s3:c0, s4:c0, s0:c0, s2:c0], entries: []
2020-07-21 17:12:55,646 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onNext(109)) - receive request, in order or not: false
{code}
 

 ",['pull-request-available'],2020-07-21 09:15:57+00:00,2020-07-27 13:04:09+00:00,2020-07-27 13:04:09+00:00,Resolved,13318449,RATIS-1008
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-07-17 12:52:08+00:00,,2020-07-31 02:44:34+00:00,Open,13317408,RATIS-1007
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Exclude netty 3.10 from Ratis dependencies,[],2020-07-17 09:29:10+00:00,2020-07-17 10:07:40+00:00,2020-07-17 10:07:40+00:00,Resolved,13317367,RATIS-1006
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-07-16 08:19:45+00:00,,2020-07-31 02:44:11+00:00,Open,13317115,RATIS-1005
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-07-16 07:16:56+00:00,,2020-07-20 06:17:59+00:00,Open,13317105,RATIS-1004
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-07-16 01:42:34+00:00,,2020-07-16 01:43:56+00:00,Open,13317059,RATIS-1003
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Ratis leader currently sees appendEntries timeout while appending entries to a follower. This is seen usually only for one of the followers. This leads to write failures and test timeouts in Ozone.,[],2020-07-14 16:21:53+00:00,,2020-07-14 16:24:46+00:00,Open,13316733,RATIS-1002
Improvement,[],glengeng,Glen Geng,glengeng,Glen Geng,Major," During SCM-HA, SCM not only needs to know whether it is a leader, but also needs to know which term it is in charge of.

 

Assume such a case: underlying raft node was leader on term 1, then step down as follower on term 2, then init election and become leader again on term 3. If term is not exposed together with leader information, SCM can not distinguish a leader of term 1 from that of term 3.

 

BTW the way, according to [~nanda]'s design, leader SCM need propagate its term to Datanode, RaftServerImpl::getRoleInfoProto() will be a good place to expose term from Ratis to SCM

 ",[],2020-07-14 07:51:42+00:00,2020-07-16 09:02:01+00:00,2020-12-02 08:32:53+00:00,Resolved,13316634,RATIS-1001
Improvement,[],ggezer,Göktürk Gezer,ggezer,Göktürk Gezer,Critical,"For when raft-server functionality is leveraged in a single-leader topology, it is always useful to be able to know the local raft-server's role and make necessary transitions in cluster accordingly.",[],2020-07-10 22:55:49+00:00,,2020-08-19 07:24:47+00:00,Open,13316248,RATIS-1000
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,,[],2020-07-09 07:55:05+00:00,2020-07-09 09:12:52+00:00,2020-07-13 03:16:28+00:00,Resolved,13315820,RATIS-999
Bug,[],glengeng,Glen Geng,glengeng,Glen Geng,Major," 

I assume that {{shouldWithholdVotes()}} is used to handle request vote request with higher candidate term from disruptive server, but currently it just ignored such requests, since it only take effect when {{(state.getCurrentTerm() >= candidateTerm)}} .

shouldWithholdVotes() should be triggered for handling higher term. If currentTerm is larger or equal to candidateTerm, just reject the request vote, no need further handling.

 

Current code is 
{code:java}
private boolean shouldWithholdVotes(long candidateTerm) {
  if (state.getCurrentTerm() < candidateTerm) {
    return false; 
  } else if (isLeader()) {
    return true; 
  } else {
    // following a leader and not yet timeout
    return isFollower() && state.hasLeader()
        && role.getFollowerState().map(FollowerState::shouldWithholdVotes).orElse(false);
  }
}
{code}
Modify to 
{code:java}
private boolean shouldWithholdVotes(long candidateTerm) {
  if (state.getCurrentTerm() >= candidateTerm) {
    return false; 
  } else if (isLeader()) {
    return true; 
  } else {
    // following a leader and not yet timeout
    return isFollower() && state.hasLeader()
        && role.getFollowerState().map(FollowerState::shouldWithholdVotes).orElse(false);
  }
}
{code}
 ",['pull-request-available'],2020-07-08 03:32:47+00:00,,2020-08-08 06:05:48+00:00,Open,13315533,RATIS-998
Sub-task,[],ansh.khanna,Ansh Khanna,ansh.khanna,Ansh Khanna,Major,"According to the [FlatBuffers white paper|https://google.github.io/flatbuffers/flatbuffers_white_paper.html],
{quote}
You define your object types in a schema, which can then be compiled to C++ or Java for low to zero overhead reading & writing. ...
{quote}
In this JIRA, we investigate if it can be used to achieve zero buffer copying in Ratis Streaming.",[],2020-07-08 01:18:10+00:00,2020-07-17 18:54:02+00:00,2020-09-29 09:30:28+00:00,Resolved,13315517,RATIS-997
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,Currently ratis-docs is not included in source and binary tar. Further ratis-docs is the last module built. This causes failure in package phase of ratis-assembly.,[],2020-07-07 07:30:51+00:00,2020-07-08 06:28:16+00:00,2020-07-13 03:17:36+00:00,Resolved,13315328,RATIS-996
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-07-03 09:49:31+00:00,,2020-07-03 09:49:31+00:00,Open,13314869,RATIS-995
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-07-02 23:48:38+00:00,,2020-07-02 23:49:39+00:00,Open,13314788,RATIS-994
New Feature,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"For example, leader is s1, and s2, s3 are the followers. If there is something wrong with s3's network, and s3 lose connection with leader in a short time interval,  s3 will trigger election. when s3's network recovery, leader will step down which is unnecessary. So I want to add pre vote before real vote.

1. if s3 want to request vote, it first send a pre vote request.
2. when s1 and s2 receive pre vote request of s3, they check their electionTimeout to decide whether should trigger leader election.
3. If s1 and s2 refuse to trigger a new leader election, s3 still keep as follower.",[],2020-07-02 12:35:01+00:00,2021-01-06 14:32:15+00:00,2021-01-07 01:38:59+00:00,Resolved,13314679,RATIS-993
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !image-2020-07-02-19-16-47-996.png! ,[],2020-07-02 11:16:50+00:00,2020-07-09 11:38:12+00:00,2020-07-09 11:38:15+00:00,Resolved,13314659,RATIS-992
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,,[],2020-06-30 09:52:21+00:00,2020-07-01 11:10:41+00:00,2020-07-01 11:10:41+00:00,Resolved,13314259,RATIS-991
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"https://github.com/apache/incubator-ratis-thirdparty/blob/38b1c0c4201ec0856aed3230fd16ba26cb929e57/pom.xml#L76-L77
{code}
    <!--Version of flatbuffers to be shaded -->
    <shaded.flatbuffers.version>1.11.0</shaded.flatbuffers.version>
{code}
Currently, the flatbuffers version is 1.11.0 in ratis-thirdparty.  However, 1.11.0 seems not supporting methods using ByteBuffer so that it does not support zero buffer copying.  We should update it 1.12.0 or above.",[],2020-06-29 18:55:06+00:00,,2020-06-30 04:26:21+00:00,Open,13314122,RATIS-990
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Blocker,,[],2020-06-29 09:24:12+00:00,2020-06-30 10:44:43+00:00,2020-06-30 10:44:43+00:00,Resolved,13313994,RATIS-989
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-06-26 06:11:47+00:00,,2020-06-28 07:30:30+00:00,Open,13313549,RATIS-988
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Critical,"This happens in ozone production. 
1. leader notify follower install snapshot-(t:3, i:999697) infinitely
 !screenshot-1.png! 
2. follower install snapshot infinitely
 !screenshot-2.png! ",[],2020-06-24 03:37:27+00:00,2020-06-24 08:45:37+00:00,2020-06-24 08:45:37+00:00,Resolved,13313163,RATIS-987
Improvement,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Minor,"[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.7.0:compile (default-compile) on project ratis-thirdparty-test: Compilation failure
[ERROR] /Users/xyao/Downloads/ratis-thirdparty-0.5.0-incubating/test/target/generated-sources/org/apache/ratis/thirdparty/demo/GreeterGrpc.java:[20,18] cannot find symbol
[ERROR]   symbol:   class Generated
[ERROR]   location: package javax.annotation
[ERROR]",[],2020-06-23 23:13:20+00:00,,2020-06-24 20:40:46+00:00,Patch Available,13313129,RATIS-986
Improvement,[],rajesh.balamohan,Rajesh Balamohan,rajesh.balamohan,Rajesh Balamohan,Major,"!Screenshot 2020-06-23 at 12.33.41 PM.png|width=979,height=211!

Can be notified on conditional basis, as opposed to notifying for all calls; provides an option to reduce sync contention.

 ",[],2020-06-23 07:22:25+00:00,,2020-06-23 07:23:17+00:00,Open,13312980,RATIS-985
Test,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"{code:java}
java.lang.AssertionError
401	at org.junit.Assert.fail(Assert.java:86)
402	at org.junit.Assert.assertTrue(Assert.java:41)
403	at org.junit.Assert.assertTrue(Assert.java:52)
404	at org.apache.ratis.retry.TestMultipleLinearRandomRetry.testMultipleLinearRandomRetry(TestMultipleLinearRandomRetry.java:77)
405	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
406	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
407	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
408	at java.lang.reflect.Method.invoke(Method.java:498)
409	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
410	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
411	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
412	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
413	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
414	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
415	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
416	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
417	at java.lang.Thread.run(Thread.java:748)
{code}",[],2020-06-22 07:09:20+00:00,2020-09-10 10:19:20+00:00,2020-09-10 10:19:20+00:00,Resolved,13312774,RATIS-984
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"1. There are server s0, s1, s2, all start leader election. But s2 has not start askForVotes.

{code:java}
2020-06-21 03:46:27,958 [Thread-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s0: start LeaderElection
2020-06-21 03:46:27,963 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s0@group-D88B65C78887-LeaderElection1: begin an election at term 1 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
{code}


{code:java}
2020-06-21 03:46:27,990 [Thread-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s1: start LeaderElection
2020-06-21 03:46:27,998 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s1@group-D88B65C78887-LeaderElection2: begin an election at term 1 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
{code}



{code:java}
2020-06-21 03:46:28,064 [Thread-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s2: start LeaderElection
{code}


2. s0 was elected as leader

{code:java}
2020-06-21 03:46:28,093 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - s0@group-D88B65C78887-LeaderElection1: Election PASSED; received 2 response(s) [s0<-s1#0:FAIL-t1, s0<-s2#0:OK-t1] and 0 exception(s); s0@group-D88B65C78887:t1, leader=null, voted=s0, raftlog=s0@group-D88B65C78887-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21 03:46:28,093 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - s0: shutdown LeaderElection
2020-06-21T03:46:28.0975768Z 2020-06-21 03:46:28,094 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s0@group-D88B65C78887: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-21 03:46:28,094 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - s0@group-D88B65C78887: change Leader from null to s0 at term 1 for becomeLeader, leader elected after 474ms
{code}

3. s2 start askForVotes which did not start in step1. Then a new leader election happens.

{code:java}
2020-06-21 03:46:28,096 [s2@group-D88B65C78887-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s2@group-D88B65C78887-LeaderElection3: begin an election at term 2 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
{code}

all the log as following:

{code:java}
2020-06-21T03:46:27.9598769Z 2020-06-21 03:46:27,958 [Thread-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s0: start LeaderElection
2020-06-21T03:46:27.9637021Z 2020-06-21 03:46:27,963 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s0@group-D88B65C78887-LeaderElection1: begin an election at term 1 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:27.9912697Z 2020-06-21 03:46:27,990 [Thread-8] INFO  impl.FollowerState (FollowerState.java:run(108)) - s1@group-D88B65C78887-FollowerState: change to CANDIDATE, lastRpcTime:244ms, electionTimeout:243ms
2020-06-21T03:46:27.9918514Z 2020-06-21 03:46:27,990 [Thread-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - s1: shutdown FollowerState
2020-06-21T03:46:27.9919033Z 2020-06-21 03:46:27,990 [Thread-8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s1@group-D88B65C78887: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-21T03:46:27.9920005Z 2020-06-21 03:46:27,990 [Thread-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s1: start LeaderElection
2020-06-21T03:46:27.9994968Z 2020-06-21 03:46:27,998 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s1@group-D88B65C78887-LeaderElection2: begin an election at term 1 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:28.0312909Z 2020-06-21 03:46:28,026 [nioEventLoopGroup-2-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb2e2f1c, L:/0.0.0.0:40443] READ: [id: 0x13e9fc9d, L:/10.1.0.4:40443 - R:/10.1.0.4:57104]
2020-06-21T03:46:28.0313672Z 2020-06-21 03:46:28,027 [nioEventLoopGroup-5-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87dcc8c6, L:/0.0.0.0:46669] READ: [id: 0x9d66979b, L:/10.1.0.4:46669 - R:/10.1.0.4:55756]
2020-06-21T03:46:28.0348907Z 2020-06-21 03:46:28,034 [nioEventLoopGroup-7-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeefdb82d, L:/0.0.0.0:41589] READ: [id: 0xd8486e82, L:/10.1.0.4:41589 - R:/10.1.0.4:60724]
2020-06-21T03:46:28.0525870Z 2020-06-21 03:46:28,048 [Thread-9] INFO  impl.FollowerState (FollowerState.java:run(108)) - s2@group-D88B65C78887-FollowerState: change to CANDIDATE, lastRpcTime:300ms, electionTimeout:300ms
2020-06-21T03:46:28.0526704Z 2020-06-21 03:46:28,049 [Thread-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - s2: shutdown FollowerState
2020-06-21T03:46:28.0527414Z 2020-06-21 03:46:28,049 [Thread-9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s2@group-D88B65C78887: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-21T03:46:28.0528112Z 2020-06-21 03:46:28,050 [nioEventLoopGroup-7-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeefdb82d, L:/0.0.0.0:41589] READ COMPLETE
2020-06-21T03:46:28.0528860Z 2020-06-21 03:46:28,050 [nioEventLoopGroup-7-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeefdb82d, L:/0.0.0.0:41589] READ: [id: 0xb6163b29, L:/10.1.0.4:41589 - R:/10.1.0.4:60726]
2020-06-21T03:46:28.0535812Z 2020-06-21 03:46:28,053 [nioEventLoopGroup-7-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeefdb82d, L:/0.0.0.0:41589] READ COMPLETE
2020-06-21T03:46:28.0625519Z 2020-06-21 03:46:28,061 [nioEventLoopGroup-5-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87dcc8c6, L:/0.0.0.0:46669] READ COMPLETE
2020-06-21T03:46:28.0649289Z 2020-06-21 03:46:28,064 [nioEventLoopGroup-2-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb2e2f1c, L:/0.0.0.0:40443] READ COMPLETE
2020-06-21T03:46:28.0668601Z 2020-06-21 03:46:28,064 [Thread-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s2: start LeaderElection
2020-06-21T03:46:28.0812923Z 2020-06-21 03:46:28,076 [nioEventLoopGroup-8-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s2@group-D88B65C78887: changes role from CANDIDATE to FOLLOWER at term 1 for recognizeCandidate:s1
2020-06-21T03:46:28.0821817Z 2020-06-21 03:46:28,081 [nioEventLoopGroup-8-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - s2: shutdown LeaderElection
2020-06-21T03:46:28.0827947Z 2020-06-21 03:46:28,082 [nioEventLoopGroup-8-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s2: start FollowerState
2020-06-21T03:46:28.0874158Z 2020-06-21 03:46:28,086 [nioEventLoopGroup-8-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s2@group-D88B65C78887: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:s0
2020-06-21T03:46:28.0874951Z 2020-06-21 03:46:28,086 [nioEventLoopGroup-8-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - s2: shutdown FollowerState
2020-06-21T03:46:28.0875242Z 2020-06-21 03:46:28,086 [nioEventLoopGroup-8-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s2: start FollowerState
2020-06-21T03:46:28.0879248Z 2020-06-21 03:46:28,087 [Thread-18] INFO  impl.FollowerState (FollowerState.java:run(117)) - s2@group-D88B65C78887-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-21T03:46:28.0920027Z 2020-06-21 03:46:28,090 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - s1@group-D88B65C78887-LeaderElection2: Election REJECTED; received 2 response(s) [s1<-s0#0:FAIL-t1, s1<-s2#0:FAIL-t1] and 0 exception(s); s1@group-D88B65C78887:t1, leader=null, voted=s1, raftlog=s1@group-D88B65C78887-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:28.0920482Z 2020-06-21 03:46:28,090 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s1@group-D88B65C78887: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-21T03:46:28.0920938Z 2020-06-21 03:46:28,090 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - s1: shutdown LeaderElection
2020-06-21T03:46:28.0921255Z 2020-06-21 03:46:28,091 [s1@group-D88B65C78887-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s1: start FollowerState
2020-06-21T03:46:28.0969648Z 2020-06-21 03:46:28,093 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - s0@group-D88B65C78887-LeaderElection1: Election PASSED; received 2 response(s) [s0<-s1#0:FAIL-t1, s0<-s2#0:OK-t1] and 0 exception(s); s0@group-D88B65C78887:t1, leader=null, voted=s0, raftlog=s0@group-D88B65C78887-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:28.0975340Z 2020-06-21 03:46:28,093 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - s0: shutdown LeaderElection
2020-06-21T03:46:28.0975768Z 2020-06-21 03:46:28,094 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s0@group-D88B65C78887: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-21T03:46:28.0976322Z 2020-06-21 03:46:28,094 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - s0@group-D88B65C78887: change Leader from null to s0 at term 1 for becomeLeader, leader elected after 474ms
2020-06-21T03:46:28.0976760Z 2020-06-21 03:46:28,096 [s2@group-D88B65C78887-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - s2@group-D88B65C78887-LeaderElection3: begin an election at term 2 for -1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:28.0980726Z 2020-06-21 03:46:28,097 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-21T03:46:28.0982068Z 2020-06-21 03:46:28,097 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-21T03:46:28.1035314Z 2020-06-21 03:46:28,100 [s0@group-D88B65C78887-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.s0@group-D88B65C78887
2020-06-21T03:46:28.1035877Z 2020-06-21 03:46:28,100 [s0@group-D88B65C78887-LeaderElection1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2020-06-21T03:46:28.1036291Z 2020-06-21 03:46:28,101 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 4096 (default)
2020-06-21T03:46:28.1036789Z 2020-06-21 03:46:28,101 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2020-06-21T03:46:28.1063137Z 2020-06-21 03:46:28,104 [s2@group-D88B65C78887-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - s2@group-D88B65C78887-LeaderElection3: Election REJECTED; received 0 response(s) [] and 0 exception(s); s2@group-D88B65C78887:t2, leader=null, voted=s2, raftlog=s2@group-D88B65C78887-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null
2020-06-21T03:46:28.1063623Z 2020-06-21 03:46:28,105 [nioEventLoopGroup-2-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb2e2f1c, L:/0.0.0.0:40443] READ: [id: 0xd7a24ea3, L:/10.1.0.4:40443 - R:/10.1.0.4:57112]
2020-06-21T03:46:28.1090607Z 2020-06-21 03:46:28,106 [nioEventLoopGroup-2-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb2e2f1c, L:/0.0.0.0:40443] READ COMPLETE
2020-06-21T03:46:28.1098274Z 2020-06-21 03:46:28,107 [nioEventLoopGroup-5-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87dcc8c6, L:/0.0.0.0:46669] READ: [id: 0xdb116403, L:/10.1.0.4:46669 - R:/10.1.0.4:55764]
2020-06-21T03:46:28.1107308Z 2020-06-21 03:46:28,108 [nioEventLoopGroup-5-1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87dcc8c6, L:/0.0.0.0:46669] READ COMPLETE
2020-06-21T03:46:28.1108298Z 2020-06-21 03:46:28,108 [nioEventLoopGroup-6-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s1@group-D88B65C78887: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:s2
2020-06-21T03:46:28.1109906Z 2020-06-21 03:46:28,108 [nioEventLoopGroup-6-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - s1: shutdown FollowerState
2020-06-21T03:46:28.1110658Z 2020-06-21 03:46:28,109 [Thread-20] INFO  impl.FollowerState (FollowerState.java:run(117)) - s1@group-D88B65C78887-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-21T03:46:28.1111310Z 2020-06-21 03:46:28,109 [nioEventLoopGroup-6-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s1: start FollowerState
2020-06-21T03:46:28.1163725Z 2020-06-21 03:46:28,116 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 10s (default)
2020-06-21T03:46:28.1164839Z 2020-06-21 03:46:28,116 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-21T03:46:28.1186640Z 2020-06-21 03:46:28,118 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-21T03:46:28.1251657Z 2020-06-21 03:46:28,124 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-21T03:46:28.1253791Z 2020-06-21 03:46:28,124 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 8KB (=8192) (custom)
2020-06-21T03:46:28.1259948Z 2020-06-21 03:46:28,125 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 0 (default)
2020-06-21T03:46:28.1291098Z 2020-06-21 03:46:28,128 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-21T03:46:28.1294354Z 2020-06-21 03:46:28,128 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 8KB (=8192) (custom)
2020-06-21T03:46:28.1294744Z 2020-06-21 03:46:28,128 [s0@group-D88B65C78887-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 0 (default)
2020-06-21T03:46:28.1330073Z 2020-06-21 03:46:28,132 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s0: start LeaderState
2020-06-21T03:46:28.1442268Z 2020-06-21 03:46:28,143 [s0@group-D88B65C78887-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - s0@group-D88B65C78887-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-21T03:46:28.1676758Z 2020-06-21 03:46:28,163 [s0@group-D88B65C78887-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - s0@group-D88B65C78887: set configuration 0: [s0:0.0.0.0:40443, s1:0.0.0.0:46669, s2:0.0.0.0:41589], old=null at 0
2020-06-21T03:46:28.1716372Z 2020-06-21 03:46:28,167 [nioEventLoopGroup-3-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - s0@group-D88B65C78887: change Leader from s0 to null at term 2 for updateCurrentTerm
2020-06-21T03:46:28.1716975Z 2020-06-21 03:46:28,167 [nioEventLoopGroup-3-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s0@group-D88B65C78887: changes role from    LEADER to FOLLOWER at term 2 for recognizeCandidate:s2
{code}

",[],2020-06-21 06:50:30+00:00,2020-06-22 04:17:34+00:00,2020-06-22 04:17:34+00:00,Resolved,13312659,RATIS-983
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"This happens in test, but it maybe also happen in production.

For example, leader is s3 and follower is s4.
1. kill s4, and restart s4.

{code:java}
2020-06-19 07:03:18,095 [Thread-6194] INFO  ratis.MiniRaftCluster (MiniRaftCluster.java:killServer(458)) - killServer s4
2020-06-19 07:03:18,095 [Thread-6194] INFO  ratis.MiniRaftCluster (MiniRaftCluster.java:newRaftServer(330)) - newRaftServer: s4, group-5BD7E8A01610:[s3:0.0.0.0:43375, s4:0.0.0.0:33719, s0:0.0.0.0:34867, s1:0.0.0.0:33783, s2:0.0.0.0:40473], format? false
{code}

2. s4 start and set configuration from storage at [setRaftConf(raftConf.getLogEntryIndex(), raftConf) |https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/ServerState.java#L170] and s4 will change to RUNNING at [lifeCycle.transition(RUNNING)|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L213]


{code:java}
2020-06-19 07:03:18,127 [pool-16-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - s4@group-5BD7E8A01610: set configuration 0: [s3:0.0.0.0:43375, s4:0.0.0.0:33719, s0:0.0.0.0:34867, s1:0.0.0.0:33783, s2:0.0.0.0:40473], old=null at 0
2020-06-19 07:03:18,153 [Thread-6194] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - s4@group-5BD7E8A01610: start as a follower, conf=0: [s3:0.0.0.0:43375, s4:0.0.0.0:33719, s0:0.0.0.0:34867, s1:0.0.0.0:33783, s2:0.0.0.0:40473], old=null
2020-06-19 07:03:18,153 [Thread-6194] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s4@group-5BD7E8A01610: changes role from      null to FOLLOWER at term 1 for startAsFollower
{code}


3. s3 send append entry request to s4, and s4 change to RUNNING at [lifeCycle.compareAndTransition(STARTING, RUNNING)|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L1003]


{code:java}
2020-06-19 07:03:18,162 [nioEventLoopGroup-59-1] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(918)) - s4@group-5BD7E8A01610: receive appendEntries(s3, 1, (t:1, i:0), 0, false, commits[s3:c0, s4:c0, s0:c0, s1:c0, s2:c0], entries: (t:1, i:1), STATEMACHINELOGENTRY, client-9414EC4E73DA, cid=3000
{code}



4. If change to RUNNING in step3 happens before step2, then step2 will throw exception.

{code:java}

2020-06-19 07:03:18,169 [Thread-6194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s4: start FollowerState
2020-06-19 07:03:18,174 [Thread-6194] ERROR netty.TestRaftWithNetty (ExitUtils.java:terminate(133)) - Terminating with exit status -1: Failed to kill/restart server: s4
2020-06-19T07:03:18.1918474Z java.lang.IllegalStateException: ILLEGAL TRANSITION: In s4, RUNNING -> RUNNING
2020-06-19T07:03:18.1918899Z 	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
2020-06-19T07:03:18.1919240Z 	at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:115)
2020-06-19T07:03:18.1919558Z 	at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:155)
2020-06-19T07:03:18.1919878Z 	at org.apache.ratis.server.impl.RaftServerImpl.startAsFollower(RaftServerImpl.java:214)
2020-06-19T07:03:18.1920206Z 	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:186)
2020-06-19T07:03:18.1920520Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
2020-06-19T07:03:18.1920839Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
2020-06-19T07:03:18.1921330Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
2020-06-19T07:03:18.1921639Z 	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
2020-06-19T07:03:18.1921951Z 	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
2020-06-19T07:03:18.1922261Z 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
2020-06-19T07:03:18.1922575Z 	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
2020-06-19T07:03:18.1922885Z 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
2020-06-19T07:03:18.1925464Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
2020-06-19T07:03:18.1940816Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
2020-06-19T07:03:18.1953283Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
2020-06-19T07:03:18.1967610Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
2020-06-19T07:03:18.1980549Z 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
2020-06-19T07:03:18.1991620Z 	at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:301)
2020-06-19T07:03:18.1991958Z 	at org.apache.ratis.MiniRaftCluster.restartServer(MiniRaftCluster.java:312)
2020-06-19T07:03:18.1992275Z 	at org.apache.ratis.MiniRaftCluster.restartServer(MiniRaftCluster.java:304)
2020-06-19T07:03:18.1992609Z 	at org.apache.ratis.RaftBasicTests.lambda$killAndRestartServer$2(RaftBasicTests.java:100)
2020-06-19T07:03:18.1992920Z 	at java.lang.Thread.run(Thread.java:748)

{code}
",[],2020-06-19 08:01:03+00:00,2020-06-24 08:29:47+00:00,2020-06-30 23:51:35+00:00,Resolved,13312404,RATIS-982
Improvement,[],nanda,Nanda kumar,nanda,Nanda kumar,Major,"We should make sure that the stale leader steps down to the candidate state before the next leader election.

Proposal:
In the heartbeat thread in the Leader node, we should check if the last response time of the follower is less than the leader election timeout. If the majority of the follower’s last response time is less than the leader election timeout, the current leader is still the active leader. Majority of the followers are heartbeating to the current leader, so there can’t be a new leader.

If the majority of follower’s last response time is greater than the leader election timeout, the current leader should step down and become a candidate.

With this check, we can be sure that the current leader will step down and become a candidate before the new leader election starts in case of a network partition.
",['pull-request-available'],2020-06-18 09:09:54+00:00,2020-07-31 05:43:58+00:00,2020-07-31 05:44:06+00:00,Resolved,13312174,RATIS-981
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"2020-06-18T00:46:43.5446126Z 2020-06-18 00:46:43,543 [Thread-12] INFO  impl.FollowerState (FollowerState.java:run(117)) - s2@group-3E7C5CE5BBB6-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-18T00:46:43.6287348Z 2020-06-18 00:46:43,624 [nioEventLoopGroup-5-1] DEBUG impl.RaftServerImpl (RaftServerImpl.java:requestVote(841)) - s1@group-3E7C5CE5BBB6 replies to vote request: s0<-s1#0:OK-t1. Peer's state: s1@group-3E7C5CE5BBB6:t1, leader=null, voted=s0, raftlog=s1@group-3E7C5CE5BBB6-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:33663, s1:0.0.0.0:42355, s2:0.0.0.0:43021], old=null
2020-06-18T00:46:43.6302903Z 2020-06-18 00:46:43,625 [nioEventLoopGroup-9-1] DEBUG impl.RaftServerImpl (RaftServerImpl.java:requestVote(841)) - s2@group-3E7C5CE5BBB6 replies to vote request: s0<-s2#0:OK-t1. Peer's state: s2@group-3E7C5CE5BBB6:t1, leader=null, voted=s0, raftlog=s2@group-3E7C5CE5BBB6-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:33663, s1:0.0.0.0:42355, s2:0.0.0.0:43021], old=null
2020-06-18T00:46:43.6400885Z 2020-06-18 00:46:43,635 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - s0@group-3E7C5CE5BBB6-LeaderElection1: Election PASSED; received 1 response(s) [s0<-s1#0:OK-t1] and 0 exception(s); s0@group-3E7C5CE5BBB6:t1, leader=null, voted=s0, raftlog=s0@group-3E7C5CE5BBB6-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s0:0.0.0.0:33663, s1:0.0.0.0:42355, s2:0.0.0.0:43021], old=null
2020-06-18T00:46:43.6401898Z 2020-06-18 00:46:43,636 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - s0: shutdown LeaderElection
2020-06-18T00:46:43.6402754Z 2020-06-18 00:46:43,636 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - s0@group-3E7C5CE5BBB6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
{color:#DE350B}2020-06-18T00:46:43.6403983Z 2020-06-18 00:46:43,636 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - s0@group-3E7C5CE5BBB6: change Leader from null to s0 at term 1 for becomeLeader, leader elected after 618ms{color}
2020-06-18T00:46:43.6404833Z 2020-06-18 00:46:43,639 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-18T00:46:43.6416295Z 2020-06-18 00:46:43,639 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-18T00:46:43.6440194Z 2020-06-18 00:46:43,643 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.s0@group-3E7C5CE5BBB6
2020-06-18T00:46:43.6442875Z 2020-06-18 00:46:43,643 [s0@group-3E7C5CE5BBB6-LeaderElection1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2020-06-18T00:46:43.6500584Z 2020-06-18 00:46:43,646 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 4096 (default)
2020-06-18T00:46:43.6509832Z 2020-06-18 00:46:43,650 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2020-06-18T00:46:43.6641705Z 2020-06-18 00:46:43,656 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 10s (default)
2020-06-18T00:46:43.6648171Z 2020-06-18 00:46:43,658 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-18T00:46:43.6651041Z 2020-06-18 00:46:43,658 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-18T00:46:43.6697072Z 2020-06-18 00:46:43,669 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-18T00:46:43.6713970Z 2020-06-18 00:46:43,669 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 4MB (=4194304) (default)
2020-06-18T00:46:43.6714691Z 2020-06-18 00:46:43,670 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 0 (default)
2020-06-18T00:46:43.6761166Z 2020-06-18 00:46:43,674 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-18T00:46:43.6803817Z 2020-06-18 00:46:43,674 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 4MB (=4194304) (default)
2020-06-18T00:46:43.6804409Z 2020-06-18 00:46:43,676 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 0 (default)
2020-06-18T00:46:43.6805103Z 2020-06-18 00:46:43,678 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s0: start LeaderState
2020-06-18T00:46:43.6910694Z 2020-06-18 00:46:43,690 [s0@group-3E7C5CE5BBB6-LeaderElection1] DEBUG raftlog.RaftLog (SegmentedRaftLog.java:appendImpl(454)) - truncateIndex=-1, arrayIndex=0
2020-06-18T00:46:43.6944267Z 2020-06-18 00:46:43,693 [s0@group-3E7C5CE5BBB6-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - s0@group-3E7C5CE5BBB6-SegmentedRaftLogWorker: Starting segment from index:0
{color:#DE350B}2020-06-18T00:46:43.7132697Z 2020-06-18 00:46:43,712 [Thread-14] INFO  impl.FollowerState (FollowerState.java:run(108)) - s1@group-3E7C5CE5BBB6-FollowerState: change to CANDIDATE, lastRpcTime:175ms, {color}electionTimeout:169ms",[],2020-06-18 01:22:13+00:00,2020-06-19 01:05:57+00:00,2020-06-19 01:07:11+00:00,Resolved,13312088,RATIS-980
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In this JIRA, we design and implement Ratis Streaming with zero buffer copying and asynchronous event driven.",[],2020-06-17 18:50:11+00:00,,2021-05-27 02:56:22+00:00,Open,13312025,RATIS-979
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-06-16 04:17:44+00:00,2020-06-22 06:36:25+00:00,2020-06-22 06:36:25+00:00,Resolved,13311621,RATIS-978
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"1. s0 reply to s3, but s3 failed to read message.

{code:java}
2020-06-15T02:09:05.5568987Z 2020-06-15 02:09:05,554 [Thread-82] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(916)) - s0@group-E95D39D4BA60: succeeded to handle AppendEntries. Reply: s3<-s0#9:OK,SUCCESS,nextIndex:2,term:2,followerCommit:0,matchIndex:1
2020-06-15T02:09:05.6204785Z 2020-06-15 02:09:05,605 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - s3@group-E95D39D4BA60->s0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
{code}

2. The stack is as follow:

{code:java}
2020-06-15T02:09:05.6092588Z org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
2020-06-15T02:09:05.6092751Z 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:533)
2020-06-15T02:09:05.6092920Z 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:449)
2020-06-15T02:09:05.6093083Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)
2020-06-15T02:09:05.6093245Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$500(ClientCallImpl.java:66)
2020-06-15T02:09:05.6093420Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:689)
2020-06-15T02:09:05.6093787Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$900(ClientCallImpl.java:577)
2020-06-15T02:09:05.6093967Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInternal(ClientCallImpl.java:670)
2020-06-15T02:09:05.6094134Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:643)
2020-06-15T02:09:05.6094300Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
2020-06-15T02:09:05.6094460Z 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
2020-06-15T02:09:05.6094615Z 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
2020-06-15T02:09:05.6094846Z 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
2020-06-15T02:09:05.6094997Z 	at java.lang.Thread.run(Thread.java:748)
2020-06-15T02:09:05.6095159Z Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: Invalid protobuf byte sequence
2020-06-15T02:09:05.6095316Z 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:524)
2020-06-15T02:09:05.6095480Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parse(ProtoLiteUtils.java:218)
2020-06-15T02:09:05.6095649Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parse(ProtoLiteUtils.java:118)
2020-06-15T02:09:05.6095816Z 	at org.apache.ratis.thirdparty.io.grpc.MethodDescriptor.parseResponse(MethodDescriptor.java:275)
2020-06-15T02:09:05.6095972Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInternal(ClientCallImpl.java:658)
2020-06-15T02:09:05.6096126Z 	... 6 more
2020-06-15T02:09:05.6096283Z Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
2020-06-15T02:09:05.6096473Z 	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:102)
2020-06-15T02:09:05.6096697Z 	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:627)
2020-06-15T02:09:05.6096864Z 	at org.apache.ratis.proto.RaftProtos$AppendEntriesReplyProto.<init>(RaftProtos.java:16335)
{code}


Another stack.

{code:java}
2020-06-15T04:48:06.1567901Z 2020-06-15 04:48:06,155 [Thread-296] DEBUG impl.RaftServerImpl (RaftServerImpl.java:logAppendEntries(916)) - s1@group-1D71FE491F6A: succeeded to handle AppendEntries. Reply: <ByteString@3d2c5532 size=2 contents=""s3"">  <-  <ByteString@5b64bed size=2 contents=""s1""> group:<ByteString@24ec82ef size=16 contents=""\\p\001\222r\003@\030\226b\035q\376I\037j"">#74:OK,SUCCESS,nextIndex:3,term:2,followerCommit:1,matchIndex:2
2020-06-15T04:48:06.2709970Z java.lang.AssertionError
2020-06-15T04:48:06.2710285Z 	at org.junit.Assert.fail(Assert.java:86)
2020-06-15T04:48:06.2710573Z 	at org.junit.Assert.assertTrue(Assert.java:41)
2020-06-15T04:48:06.2710881Z 	at org.junit.Assert.assertTrue(Assert.java:52)
2020-06-15T04:48:06.2711370Z 	at org.apache.ratis.grpc.TestRaftWithGrpc.lambda$null$6(TestRaftWithGrpc.java:99)
2020-06-15T04:48:06.2711707Z 	at org.apache.ratis.util.function.CheckedRunnable.lambda$asCheckedSupplier$0(CheckedRunnable.java:32)
2020-06-15T04:48:06.2712016Z 	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
2020-06-15T04:48:06.2712316Z 	at org.apache.ratis.util.JavaUtils.attemptRepeatedly(JavaUtils.java:146)
2020-06-15T04:48:06.2712612Z 	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:180)
2020-06-15T04:48:06.2712905Z 	at org.apache.ratis.grpc.TestRaftWithGrpc.lambda$null$7(TestRaftWithGrpc.java:93)
2020-06-15T04:48:06.2713189Z 	at org.apache.ratis.util.JavaUtils.runAsUnchecked(JavaUtils.java:89)
2020-06-15T04:48:06.2713484Z 	at org.apache.ratis.util.JavaUtils.runAsUnchecked(JavaUtils.java:83)
2020-06-15T04:48:06.2713785Z 	at org.apache.ratis.grpc.TestRaftWithGrpc.lambda$runTestUpdateViaHeartbeat$8(TestRaftWithGrpc.java:93)
2020-06-15T04:48:06.2714249Z 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
2020-06-15T04:48:06.2714570Z 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647)
2020-06-15T04:48:06.2714882Z 	at org.apache.ratis.grpc.TestRaftWithGrpc.runTestUpdateViaHeartbeat(TestRaftWithGrpc.java:92)
2020-06-15T04:48:06.2715192Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
2020-06-15T04:48:06.2715499Z 	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
2020-06-15T04:48:06.2715805Z 	at org.apache.ratis.grpc.TestRaftWithGrpc.testUpdateViaHeartbeat(TestRaftWithGrpc.java:53)
2020-06-15T04:48:06.2716106Z 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
2020-06-15T04:48:06.2716402Z 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
2020-06-15T04:48:06.2716707Z 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
2020-06-15T04:48:06.2717012Z 	at java.lang.reflect.Method.invoke(Method.java:498)
2020-06-15T04:48:06.2717318Z 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
2020-06-15T04:48:06.2717627Z 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
2020-06-15T04:48:06.2717928Z 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
2020-06-15T04:48:06.2718228Z 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
2020-06-15T04:48:06.2718545Z 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
2020-06-15T04:48:06.2766658Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
2020-06-15T04:48:06.2767094Z 	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
2020-06-15T04:48:06.2767640Z 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020-06-15T04:48:06.2767986Z 	at java.lang.Thread.run(Thread.java:748)
2020-06-15T04:48:06.2768844Z 2020-06-15 04:48:06,264 [grpc-default-executor-8] ERROR server.GrpcLogAppender (GrpcLogAppender.java:onError(332)) - grpc error stack
2020-06-15T04:48:06.2769220Z org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
2020-06-15T04:48:06.2769558Z 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:533)
2020-06-15T04:48:06.2769901Z 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:449)
2020-06-15T04:48:06.2770245Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)
2020-06-15T04:48:06.2770692Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$500(ClientCallImpl.java:66)
2020-06-15T04:48:06.2771051Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:689)
2020-06-15T04:48:06.2771568Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$900(ClientCallImpl.java:577)
2020-06-15T04:48:06.2771947Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInternal(ClientCallImpl.java:670)
2020-06-15T04:48:06.2772301Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:643)
2020-06-15T04:48:06.2772635Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
2020-06-15T04:48:06.2772969Z 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
2020-06-15T04:48:06.2773301Z 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
2020-06-15T04:48:06.2773631Z 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
2020-06-15T04:48:06.2774050Z 	at java.lang.Thread.run(Thread.java:748)
2020-06-15T04:48:06.2774488Z Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: Invalid protobuf byte sequence
2020-06-15T04:48:06.2774799Z 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:524)
2020-06-15T04:48:06.2775113Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parse(ProtoLiteUtils.java:218)
2020-06-15T04:48:06.2775431Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parse(ProtoLiteUtils.java:118)
2020-06-15T04:48:06.2775748Z 	at org.apache.ratis.thirdparty.io.grpc.MethodDescriptor.parseResponse(MethodDescriptor.java:275)
2020-06-15T04:48:06.2776618Z 	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInternal(ClientCallImpl.java:658)
2020-06-15T04:48:06.2776889Z 	... 6 more
2020-06-15T04:48:06.2777205Z Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
2020-06-15T04:48:06.2777518Z 	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:84)
2020-06-15T04:48:06.2777791Z 	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawByte(CodedInputStream.java:1238)
2020-06-15T04:48:06.2778063Z 	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawVarint64SlowPath(CodedInputStream.java:1126)
2020-06-15T04:48:06.2778328Z 	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawVarint64(CodedInputStream.java:1119)
2020-06-15T04:48:06.2778588Z 	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readUInt64(CodedInputStream.java:757)
2020-06-15T04:48:06.2778843Z 	at org.apache.ratis.proto.RaftProtos$AppendEntriesReplyProto.<init>(RaftProtos.java:16376)
2020-06-15T04:48:06.2779093Z 	at org.apache.ratis.proto.RaftProtos$AppendEntriesReplyProto.<init>(RaftProtos.java:16297)
2020-06-15T04:48:06.2779348Z 	at org.apache.ratis.proto.RaftProtos$AppendEntriesReplyProto$1.parsePartialFrom(RaftProtos.java:17411)
2020-06-15T04:48:06.2779582Z 	at org.apache.ratis.proto.RaftProtos$AppendEntriesReplyProto$1.parsePartialFrom(RaftProtos.java:17405)
2020-06-15T04:48:06.2779829Z 	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:86)
2020-06-15T04:48:06.2780077Z 	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
2020-06-15T04:48:06.2780390Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parseFrom(ProtoLiteUtils.java:223)
2020-06-15T04:48:06.2783772Z 	at org.apache.ratis.thirdparty.io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.parse(ProtoLiteUtils.java:215)
2020-06-15T04:48:06.2784921Z 	... 9 more
{code}
",[],2020-06-15 00:17:37+00:00,2020-06-22 05:51:22+00:00,2020-06-30 23:53:53+00:00,Resolved,13311369,RATIS-977
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-06-12 15:02:13+00:00,2020-06-30 23:53:52+00:00,2020-06-30 23:53:53+00:00,Resolved,13311152,RATIS-976
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-06-12 10:15:14+00:00,2020-06-12 14:04:09+00:00,2020-06-12 15:55:53+00:00,Resolved,13311109,RATIS-975
Bug,[],cyrusjackson25,Cyrus Jackson,cyrusjackson25,Cyrus Jackson,Minor,"Build is failing on Windows machine. 
The module Apache Ratis Documentation is throwing file not found error.

!image-2020-06-11-22-20-25-428.png!",[],2020-06-11 16:51:17+00:00,2020-06-25 10:34:39+00:00,2020-06-30 10:03:21+00:00,Resolved,13310946,RATIS-974
Bug,[],andywu,Andy Wu,andywu,Andy Wu,Major,"I am building a server based on ratis. After a while, I cannot send message to that server. Then I check ratis server, connection seems got closed on the server side. Was wondering if anyone saw this exception before. 

[Server side log]
{quote}[grpc-nio-worker-ELG-3-22] [NettyServerHandler] [line 216] [id: 0x7dbdc6d8, L:/ip1:9091 - R:/ip1:52484] INBOUND GO_AWAY: lastStreamId=0 errorCode=0 length=0 bytes=
{quote}
Also see some error message like:

{quote}DEBUG 2020-06-11 01:27:44,697 [grpc-default-executor-2995] [GrpcClientProtocolService] [line 262] 1502-OrderedRequestStreamObserver1502: Failed onNext for client-8C15C5E709A7->s46#37936775-578308* in 1502-OrderedRequestStreamObserver1502 
java.lang.IllegalStateException: Entry already exists for key 578308 in map SlidingWindow$Server:1502-OrderedRequestStreamObserver1502:requests
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:75) ~[ratis-common-0.5.0.jar:0.5.0]
	at org.apache.ratis.util.CollectionUtils.putNew(CollectionUtils.java:94) ~[ratis-common-0.5.0.jar:0.5.0]
	at org.apache.ratis.util.SlidingWindow$RequestMap.putNewRequest(SlidingWindow.java:126) ~[ratis-common-0.5.0.jar:0.5.0]
	at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:420) ~[ratis-common-0.5.0.jar:0.5.0]
	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:355) ~[ratis-grpc-0.5.0.jar:0.5.0]
	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:245) [ratis-grpc-0.5.0.jar:0.5.0]
	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168) [ratis-grpc-0.5.0.jar:0.5.0]
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:779) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) [ratis-thirdparty-misc-0.3.0.jar:0.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_232]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_232]{quote}


",[],2020-06-11 01:12:35+00:00,,2020-06-11 01:43:43+00:00,Open,13310788,RATIS-973
Task,[],gxcheng,Guangxu Cheng,gxcheng,Guangxu Cheng,Major,,[],2020-06-10 13:05:15+00:00,2020-06-10 13:06:02+00:00,2020-06-10 13:06:02+00:00,Resolved,13310650,RATIS-972
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently, Ratis uses protobufs to serialize/de-serialize data during server/server communication. This causes multiple buffer copies. This can be avoided by using flatbuffers. 
The idea here is to use flatbuffers for server to server communication.",[],2020-06-09 14:15:42+00:00,,2020-06-09 14:49:01+00:00,Open,13310408,RATIS-971
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently, Ratis uses protobufs to serialize/de-serialize data during client send and also when it is received on the server. This causes multiple buffer copies. This can be avoided by using flatbuffers. ",[],2020-06-09 14:14:18+00:00,,2020-06-09 14:49:12+00:00,Open,13310407,RATIS-970
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Add flatbuffers to Ratis thirdparty.,[],2020-06-08 11:07:15+00:00,2020-06-11 06:21:51+00:00,2020-08-13 20:12:27+00:00,Resolved,13310113,RATIS-969
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-06-05 13:28:10+00:00,2020-06-05 13:29:02+00:00,2020-06-05 13:29:02+00:00,Resolved,13309729,RATIS-968
Task,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,"In some applications, some servers in a raft group are more preferable to be the leader than the other servers.  For example, a server is colocated with other resources so that having the server as the leader is more efficient than the other servers.

In this JIRA, we propose adding _priority_ to each server so that the higher priority server(s) will always win the leader election when they are available.",[],2020-06-04 06:20:30+00:00,2020-08-31 07:56:57+00:00,2020-12-14 01:26:36+00:00,Resolved,13309355,RATIS-967
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, a raft log entry can potentially consist of different types of entries:

1) Configuration

2) MetaData

3) StateMachine 

 

Idea here is track the count for the same for a given raft server impl.",[],2020-06-03 16:28:19+00:00,2020-06-11 07:42:44+00:00,2020-06-11 07:42:44+00:00,Resolved,13309228,RATIS-966
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, a single raft server instance can contain multiple raftServerImpl belonging to different raft groups. The idea here is to track the number of RaftGroups a raft server is part of.",[],2020-06-03 16:25:56+00:00,2020-07-30 07:59:27+00:00,2020-07-30 08:27:15+00:00,Resolved,13309227,RATIS-965
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-06-02 12:40:50+00:00,2020-06-03 05:53:09+00:00,2020-06-03 05:53:09+00:00,Resolved,13308947,RATIS-964
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Update gRPC to 1.29.0,[],2020-05-31 17:37:13+00:00,2020-06-23 19:38:47+00:00,2020-06-23 19:38:47+00:00,Resolved,13308585,RATIS-963
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Update gRPC to 1.29.0,[],2020-05-31 17:35:28+00:00,2020-06-11 06:18:41+00:00,2020-06-11 06:19:37+00:00,Resolved,13308584,RATIS-962
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
//StateMachine
CompletableFuture<?> writeStateMachineData(LogEntryProto entry)
{code}
In StateMachine, we have writeStateMachineData to write the state machine data in the given log entry.  It is inefficient to process state machine data in a log entry when the data size is large.

In this JIRA, we add new APIs to support streaming state machine data.",[],2020-05-30 01:57:46+00:00,2020-06-12 09:20:43+00:00,2020-06-12 09:20:43+00:00,Resolved,13308429,RATIS-960
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, the StateMachine interface has quite a few methods related to state machine data as below:
- writeStateMachineData
- readStateMachineData
- flushStateMachineData
- truncateStateMachineData

We propose moving them to a new DataApi interface.",[],2020-05-30 01:39:35+00:00,2020-06-03 15:10:01+00:00,2020-06-03 15:10:01+00:00,Resolved,13308426,RATIS-959
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, MessageOutputStream only support one request per stream.  In this JIRA, we will change it to support multiple requests.",[],2020-05-30 01:33:54+00:00,2020-06-18 14:41:03+00:00,2020-06-18 14:41:03+00:00,Resolved,13308425,RATIS-958
Improvement,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Update the .asf.yaml file to enable Jira notifications.

Once a PR is opened, the corresponding Jira should get a new label ""pull request available"", the worklog should be updated and the PR should be linked in the jira.",['pull-request-available'],2020-05-29 04:10:51+00:00,2020-06-03 06:01:29+00:00,2021-03-19 09:29:11+00:00,Resolved,13308223,RATIS-957
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS3457&types=CODE_SMELL],[],2020-05-28 22:14:25+00:00,,2020-07-27 15:06:42+00:00,Open,13308184,RATIS-956
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS1214&types=CODE_SMELL],[],2020-05-28 22:09:23+00:00,,2020-05-28 22:09:23+00:00,Open,13308180,RATIS-955
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS899&types=VULNERABILITY],[],2020-05-28 22:06:36+00:00,,2020-05-28 22:06:36+00:00,Open,13308179,RATIS-954
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS2755&types=VULNERABILITY],[],2020-05-28 22:05:21+00:00,2020-12-03 01:15:34+00:00,2020-12-03 07:52:19+00:00,Resolved,13308177,RATIS-953
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS2259&types=BUG],[],2020-05-28 17:07:59+00:00,,2021-04-24 12:10:16+00:00,Open,13308105,RATIS-952
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS2095&types=BUG],[],2020-05-28 17:06:27+00:00,,2020-05-28 17:06:27+00:00,Open,13308104,RATIS-951
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"InterruptedException should not be ignored, either the method should be re-interrupted or an exception should be thrown again.

[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS2142&types=BUG]

 

Catch Exception instead of Throwable

[https://sonarcloud.io/project/issues?id=apache_incubator-ratis&resolved=false&rules=java%3AS1181]

 

This Jira aims to address all occurrences of this violation in Ratis.

Issues in Native API can be ignore as it will be removed by RATIS-757",['pull-request-available'],2020-05-28 17:03:14+00:00,2020-11-05 05:54:54+00:00,2020-11-05 05:56:08+00:00,Resolved,13308101,RATIS-950
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"As sonar has been enabled for Ratis, this umbrella Jira is logged to track all Sonar fixes.

[https://sonarcloud.io/dashboard?id=apache_incubator-ratis]

 

Sub tasks will be created shortly in a way that similar violations are addressed in one Jira to make it easy for the reviewers too.","['codesmell', 'sonar']",2020-05-28 16:58:31+00:00,,2021-01-11 15:15:10+00:00,Open,13308098,RATIS-949
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"RATIS-940 enabled the Sonar check for all the commits but it doesn't work for forked repositories (unless somebody set an own SONAR_TOKEN).

The fix is the same as HDDS-2627, we can restrict the execution to the apache repostiroy.

Thanks to [~ljain] who reported this issue:

Example failure:

https://github.com/lokeshj1703/incubator-ratis/runs/716253801

Note: PRs are not affected as they work well (no sonar check there) only the builds of forked repos. ",[],2020-05-28 10:21:58+00:00,2020-06-02 11:57:36+00:00,2020-06-02 11:57:36+00:00,Resolved,13307995,RATIS-948
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,RequestTypeDependentRetryPolicy currently has single timeout for all request types. The Jira aims to add timeout for every request type.,[],2020-05-28 09:30:13+00:00,2020-05-28 10:22:40+00:00,2020-05-28 10:22:40+00:00,Resolved,13307971,RATIS-947
Bug,[],burcukozkan,Burcu Ozkan,burcukozkan,Burcu Ozkan,Major,"I am testing fault tolerance of Ratis, more specifically whether it can tolerate random message losses. Simply, I drop some of the messages and do not deliver them to the recipient. 

In some tests where the servers have inconsistent logs, I observe executions in which the follower fails to synchronize with the leader.  The servers indefinitely exchange AppendEntries request and its failing reply, logging the following messages repeatedly:
{noformat}
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 19 -> 17
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1097)) - s0@group-AD42E7C24DDE: Failed appendEntries as previous log entry ((t:20, i:16)) is not found
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308912:FAIL,INCONSISTENCY,nextIndex:16,term:20,followerCommit:16
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 19 -> 16 {noformat}
This occurs when gRPC adapter is used, I did not observe the problem using Netty.

Here is the part of the logs before the repeated messages:
{noformat}
...
impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - s0: start FollowerState
impl.RaftServerImpl (ServerState.java:setLeader(255)) - s0@group-AD42E7C24DDE: change Leader from null to s1 at term 20 for appendEntries, leader elected after 3ms
client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(283)) - Failed RaftClientRequest:client-A0592557AEC3->s0@group-AD42E7C24DDE, cid=7, seq=0, RW, Message:6d3130, reply=RaftClientReply:client-A0592557AEC3->s0@group-AD42E7C24DDE, cid=7, FAILED org.apache.ratis.protocol.NotLeaderException: Server s0@group-AD42E7C24DDE is not the leader, logIndex=0, commits[s0:c14, s1:c13, s2:c13]
client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(283)) - Failed RaftClientRequest:client-3A32B89816B9->s0@group-AD42E7C24DDE, cid=8, seq=0, RW, Message:6d3131, reply=RaftClientReply:client-3A32B89816B9->s0@group-AD42E7C24DDE, cid=8, FAILED org.apache.ratis.protocol.NotLeaderException: Server s0@group-AD42E7C24DDE is not the leader, logIndex=0, commits[s0:c14, s1:c13, s2:c13]
client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(283)) - Failed RaftClientRequest:client-73072E12695E->s0@group-AD42E7C24DDE, cid=6, seq=0, RW, Message:6d3132, reply=RaftClientReply:client-73072E12695E->s0@group-AD42E7C24DDE, cid=6, FAILED org.apache.ratis.protocol.NotLeaderException: Server s0@group-AD42E7C24DDE is not the leader, logIndex=0, commits[s0:c14, s1:c13, s2:c13]
server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(321)) - s0@group-AD42E7C24DDE->s1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1088)) - s0@group-AD42E7C24DDE: Failed appendEntries: the first entry (index 15) is already committed (commit index: 16)
statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:put(200)) - s0: put 15, m11 -> (t:19, i:15), STATEMACHINELOGENTRY, client-3A32B89816B9, cid=8
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308907:FAIL,INCONSISTENCY,nextIndex:17,term:20,followerCommit:16
statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:put(200)) - s0: put 16, m10 -> (t:19, i:16), STATEMACHINELOGENTRY, client-A0592557AEC3, cid=7
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 17 -> 17
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s0@group-AD42E7C24DDE->s2: nextIndex: updateUnconditionally 18 -> 15
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s0@group-AD42E7C24DDE->s1: nextIndex: updateUnconditionally 18 -> 15
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1097)) - s0@group-AD42E7C24DDE: Failed appendEntries as previous log entry ((t:20, i:16)) is not found
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308908:FAIL,INCONSISTENCY,nextIndex:16,term:20,followerCommit:16
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 17 -> 16
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1088)) - s0@group-AD42E7C24DDE: Failed appendEntries: the first entry (index 16) is already committed (commit index: 16)
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308909:FAIL,INCONSISTENCY,nextIndex:17,term:20,followerCommit:16
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 17 -> 17
[ForkJoinPool.commonPool-worker-3] INFO client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(283)) - Failed RaftClientRequest:client-73072E12695E->s2@group-AD42E7C24DDE, cid=6, seq=0, RW, Message:6d3132, reply=RaftClientReply:client-73072E12695E->s2@group-AD42E7C24DDE, cid=6, FAILED org.apache.ratis.protocol.NotLeaderException: Server s2@group-AD42E7C24DDE is not the leader s1:0.0.0.0:49936, logIndex=0, commits[s2:c16, s0:c16, s1:c16]
[ForkJoinPool.commonPool-worker-1] INFO client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(283)) - Failed RaftClientRequest:client-3A32B89816B9->s2@group-AD42E7C24DDE, cid=8, seq=0, RW, Message:6d3131, reply=RaftClientReply:client-3A32B89816B9->s2@group-AD42E7C24DDE, cid=8, FAILED org.apache.ratis.protocol.NotLeaderException: Server s2@group-AD42E7C24DDE is not the leader s1:0.0.0.0:49936, logIndex=0, commits[s2:c16, s0:c16, s1:c16]
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1097)) - s0@group-AD42E7C24DDE: Failed appendEntries as previous log entry ((t:20, i:16)) is not found
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308910:FAIL,INCONSISTENCY,nextIndex:16,term:20,followerCommit:16
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 18 -> 16
statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:put(200)) - s1: put 17, m10 -> (t:20, i:17), STATEMACHINELOGENTRY, client-A0592557AEC3, cid=7
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1088)) - s0@group-AD42E7C24DDE: Failed appendEntries: the first entry (index 16) is already committed (commit index: 16)
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308911:FAIL,INCONSISTENCY,nextIndex:17,term:20,followerCommit:16
statemachine.SimpleStateMachine4Testing (SimpleStateMachine4Testing.java:put(200)) - s2: put 17, m10 -> (t:20, i:17), STATEMACHINELOGENTRY, client-A0592557AEC3, cid=7
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 19 -> 17
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1097)) - s0@group-AD42E7C24DDE: Failed appendEntries as previous log entry ((t:20, i:16)) is not found
impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1063)) - s0@group-AD42E7C24DDE: inconsistency entries. Reply:s1<-s0#308912:FAIL,INCONSISTENCY,nextIndex:16,term:20,followerCommit:16
impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - s1@group-AD42E7C24DDE->s0: nextIndex: updateUnconditionally 19 -> 16
..
{noformat}
I attached a file listing the messages sent or dropped in the execution. Each line lists the sender/receiver of the message together with some message information, and the number of times the message is sent/received. The messages marked with ""-D"" are dropped. You can also find the full log of the execution in the attachment.",[],2020-05-25 10:12:13+00:00,,2020-05-25 10:30:11+00:00,Open,13307203,RATIS-946
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-25 07:24:34+00:00,,2020-09-07 11:35:36+00:00,Open,13307158,RATIS-945
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"While reading the code, it appears that the FileStoreStateMachine#read expects 

FileStoreRequestProto.RequestCase.WRITEHEADER instead of the READHEADER

It also attempts to process a Write Header and send as a Read Response.
{code:java}
public CompletableFuture<ByteString> read(LogEntryProto entry) {
.
.
.
 if (proto.getRequestCase() != FileStoreRequestProto.RequestCase.WRITEHEADER) {
 return null;
 }

 final WriteRequestHeaderProto h = proto.getWriteHeader();
 CompletableFuture<ExamplesProtos.ReadReplyProto> reply =
 files.read(h.getPath().toStringUtf8(), h.getOffset(), h.getLength());

 return reply.thenApply(ExamplesProtos.ReadReplyProto::getData);
}
{code}
 

 May be I am just missing something here.",[],2020-05-25 05:46:43+00:00,2020-06-11 13:49:10+00:00,2020-06-11 13:49:10+00:00,Resolved,13307138,RATIS-944
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Minor,Discovered in [https://github.com/apache/incubator-ratis/pull/108],[],2020-05-25 05:24:41+00:00,2020-05-28 09:02:47+00:00,2020-05-28 17:35:17+00:00,Resolved,13307133,RATIS-943
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-19 09:24:14+00:00,2020-05-28 09:39:23+00:00,2020-06-02 09:22:13+00:00,Resolved,13305861,RATIS-942
Improvement,[],clay4megtr,Shang Lou,clay4megtr,Shang Lou,Major,fix some error handing,[],2020-05-18 14:19:11+00:00,,2020-06-03 06:46:08+00:00,Open,13305690,RATIS-941
New Feature,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"As [~elek] added the Github based post commit checks in RATIS-697, we can also add the Sonar check to continuously inspect the code quality and improve.

 

I have already reached out to INFRA and got the incubator-ratis project added to Apache's Sonar Cloud.

Further, all folks who had access to Ozone Sonar Cloud will already be given access to Ratis Sonar Cloud instance by default.

 

This Jira aims to enable the sonar check via Github.",[],2020-05-18 03:18:29+00:00,2020-05-27 13:49:38+00:00,2020-05-27 14:51:38+00:00,Resolved,13305576,RATIS-940
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-17 07:11:22+00:00,2020-06-03 07:01:48+00:00,2020-06-03 07:01:48+00:00,Resolved,13305456,RATIS-939
Bug,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,"➜  ozone-0.6.0-SNAPSHOT git:(HDDS-3581) ✗ bin/ozone admin pipeline list -ffc 3
Pipeline[ Id: 11d968b1-6c49-47aa-b43b-c67dceb8d48f, Nodes: 35b3e41c-f445-4da0-bbfe-4c216b503060{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}3feb5f0b-47d0-4f64-8a6e-f2035b6f808e{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}af17177a-9003-42d5-bd11-0e76e21f819d{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:3, State:OPEN, leaderId:35b3e41c-f445-4da0-bbfe-4c216b503060, CreationTimestamp2020-05-15T07:17:38.117Z]
➜  ozone-0.6.0-SNAPSHOT git:(HDDS-3581) ✗ bin/ozone admin pipeline list -ffc 2
Pipeline[ Id: 6403f8d7-e452-4501-aad9-05cd790ede04, Nodes: 35b3e41c-f445-4da0-bbfe-4c216b503060{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}3feb5f0b-47d0-4f64-8a6e-f2035b6f808e{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}af17177a-9003-42d5-bd11-0e76e21f819d{ip: 127.0.0.1, host: localhost, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:2, State:ALLOCATED, leaderId:null, CreationTimestamp2020-05-15T07:17:38.119Z]

",[],2020-05-15 07:58:03+00:00,,2020-05-15 08:23:45+00:00,Open,13305136,RATIS-938
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"When an open log segment is loaded, it always logs a warning that the segment is corrupted.
{code:java}
Segment file is corrupted: expected to have -43 entries but only 8 entries read successfully
{code}

LogSegment#loadSegment() has the following check for corruption:
{code:java}
final int expectedEntryCount = Math.toIntExact(end - start + 1);
final boolean corrupted = entryCount != expectedEntryCount;
if (corrupted) {
  LOG.warn(""Segment file is corrupted: expected to have {} entries but only {} entries read successfully"",
      expectedEntryCount, entryCount);
}
{code}
But the _end_ is always INVALID_LOG_INDEX (-1) for an open segment.
Before this check, entries are appended to the segment. So the _end_ variable should be updated with the correct endIndex of the segment before checking for corruption.",[],2020-05-14 17:54:01+00:00,2020-06-01 20:35:28+00:00,2020-06-01 20:35:28+00:00,Resolved,13305005,RATIS-937
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,"With RATIS-932, dependency on shaded Ratis thirdparty has been removed. This has caused the ratis-hadoop protocol to break.

This jira purposes to fix this by using the protobuf 2.5.0 for the rpc communication and then converting to Protobuf 3.5.0 at rpc endpoint.",[],2020-05-11 16:58:00+00:00,2020-07-06 05:50:32+00:00,2020-07-06 05:50:32+00:00,Resolved,13304165,RATIS-936
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-11 11:36:00+00:00,2020-06-02 09:16:09+00:00,2020-06-02 09:17:12+00:00,Resolved,13304088,RATIS-935
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,ExceptionDependentRetry$Builder setters are currently set to package-private access. They need to be made public so that ozone can use them.,[],2020-05-11 06:53:28+00:00,2020-05-11 07:26:11+00:00,2020-05-11 07:26:11+00:00,Resolved,13304026,RATIS-934
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira removes the ratis thirdparty module in Ratis third-party. This will simplify the dependency management in Ratis.,[],2020-05-07 11:21:10+00:00,2020-05-13 12:22:50+00:00,2021-03-20 02:44:17+00:00,Resolved,13303363,RATIS-933
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis both takes a direct as well as a transitive dependency via Ratis thirdparty.
This removes the dependency on Ratis third-party hadoop.",[],2020-05-07 11:07:12+00:00,2020-05-11 05:21:19+00:00,2020-05-11 05:21:19+00:00,Resolved,13303358,RATIS-932
Bug,[],alphapo,JiabaoYan,alphapo,JiabaoYan,Major,"h1. In the log service, when creating a log, add a raft group to all group peers, where the group peers are not all peers currently registered",[],2020-05-07 06:05:37+00:00,,2021-04-20 14:44:08+00:00,Open,13303275,RATIS-931
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"One thread move and another thread delete at the same time, then both fail.
 !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-05-07 05:26:54+00:00,2020-05-18 05:51:18+00:00,2020-06-17 13:34:02+00:00,Resolved,13303273,RATIS-930
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-07 01:00:17+00:00,2020-05-08 08:59:55+00:00,2020-05-08 08:59:55+00:00,Resolved,13303241,RATIS-929
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,!image-2020-05-06-15-13-57-035.png!,[],2020-05-06 07:12:52+00:00,2020-05-06 09:07:44+00:00,2020-05-06 09:07:44+00:00,Resolved,13303039,RATIS-927
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-06 03:53:01+00:00,,2020-05-06 03:53:01+00:00,Open,13303018,RATIS-926
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?* 
 As the image shows, there are 2066 instances of RaftServerImpl, most of them are Closed, and should be GC, but actually not.

!screenshot-1.png!

*What's the reason ?*
 You can find from the image 2040 RaftServerImpl were held by RaftServerMetrics::metricsMap which is a staic map 
 !screenshot-2.png!",[],2020-05-06 03:44:01+00:00,,2020-05-06 05:52:42+00:00,Open,13303016,RATIS-925
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-06 01:32:18+00:00,2020-08-10 10:54:09+00:00,2020-08-10 10:54:09+00:00,Resolved,13303006,RATIS-924
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"If a segment is evicted from Segment Cache before it is rolled over and applyTransaction thread tries to read this segment, it can lead to FileNotFoundException.

Please refer to [~msingh]'s comment in HDDS-3382.",['pull-request-available'],2020-05-05 21:52:56+00:00,2020-06-02 18:36:51+00:00,2020-06-02 18:36:51+00:00,Resolved,13302975,RATIS-923
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis takes a dependency on Hadoop both directly and transitively via Ratis third party. 
This becomes difficult to manage because of CVEs reported in different versions of Hadoop.",[],2020-05-05 12:40:59+00:00,2020-09-09 12:14:50+00:00,2020-09-09 12:14:50+00:00,Resolved,13302862,RATIS-922
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-05 09:52:17+00:00,2020-06-11 07:58:05+00:00,2020-06-11 07:58:05+00:00,Resolved,13302843,RATIS-921
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-05 09:23:39+00:00,2020-05-08 11:59:04+00:00,2020-05-08 11:59:04+00:00,Resolved,13302838,RATIS-920
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,The Jira aims to exclude unwanted dependencies which get added as part of hadoop dependency.,[],2020-05-04 11:33:25+00:00,2020-10-05 05:46:19+00:00,2020-10-05 05:46:19+00:00,Resolved,13302620,RATIS-919
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-02 15:54:33+00:00,2020-06-30 23:53:24+00:00,2020-06-30 23:53:25+00:00,Resolved,13302443,RATIS-918
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-05-02 14:39:45+00:00,,2020-05-02 14:51:25+00:00,Open,13302440,RATIS-917
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-05-01 04:46:53+00:00,,2020-05-01 04:47:57+00:00,Open,13302256,RATIS-916
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"I would like to propose the following improvements for unit tests:

# include stack trace for test failures in results
# include thread name in log message format

Example for stack trace:

{code}
-------------------------------------------------------------------------------
Test set: org.apache.ratis.server.simulation.TestRaftSnapshotWithSimulatedRpc
-------------------------------------------------------------------------------
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 3.468 s <<< FAILURE! - in org.apache.ratis.server.simulation.TestRaftSnapshotWithSimulatedRpc
testBasicInstallSnapshot(org.apache.ratis.server.simulation.TestRaftSnapshotWithSimulatedRpc)  Time elapsed: 1.676 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.ratis.statemachine.RaftSnapshotBaseTest.verifyTakeSnapshotMetric(RaftSnapshotBaseTest.java:261)
	at org.apache.ratis.statemachine.RaftSnapshotBaseTest.testBasicInstallSnapshot(RaftSnapshotBaseTest.java:240)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}

For example without stack trace see RATIS-889.",[],2020-04-30 10:47:54+00:00,2020-05-05 05:38:35+00:00,2020-05-05 07:36:49+00:00,Resolved,13302058,RATIS-915
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-30 05:45:17+00:00,2020-05-03 05:19:42+00:00,2020-05-03 05:19:42+00:00,Resolved,13301990,RATIS-914
Sub-task,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,There are a few remaining checkstyle violations (possibly introduced in new code since the fixes).,[],2020-04-29 10:33:18+00:00,2020-04-30 04:05:43+00:00,2020-04-30 05:20:37+00:00,Resolved,13301767,RATIS-913
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"It looks like the  RATIS-910 generate new failed UT. This type of failed UT did not happen in previous commit.
https://github.com/apache/incubator-ratis/runs/625933249
https://github.com/apache/incubator-ratis/runs/626750611
 !screenshot-1.png! ",[],2020-04-29 03:02:11+00:00,2020-04-29 15:04:54+00:00,2020-04-29 15:04:54+00:00,Resolved,13301700,RATIS-912
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"Can not elect a leader for a long time.
 !screenshot-1.png! ",[],2020-04-28 09:55:45+00:00,2020-05-03 05:16:42+00:00,2020-05-03 05:16:42+00:00,Resolved,13301505,RATIS-911
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira is to track update of Ratis third-party after 0.4.0 release.,[],2020-04-28 09:35:04+00:00,2020-04-28 12:38:56+00:00,2020-04-28 12:38:56+00:00,Resolved,13301500,RATIS-910
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"When leader election times out, candidate should change to follower so that it can restart leader election process. New leader election is started when server transitions from follower to candidate. If server remains in candidate state, new leader election will not be started.

In TestStateMachineShutdownWithGrpc, it was seen that all the servers see leader election timeout and remain in CANDIDATE state. Therefore new leader is never elected.",[],2020-04-28 07:12:22+00:00,,2020-04-28 07:12:22+00:00,Open,13301463,RATIS-909
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 06:17:50+00:00,,2020-04-28 06:18:10+00:00,Open,13301456,RATIS-908
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 06:10:57+00:00,,2020-04-28 06:11:51+00:00,Open,13301454,RATIS-907
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 06:04:54+00:00,,2020-04-28 06:05:19+00:00,Open,13301450,RATIS-906
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 03:10:54+00:00,,2020-04-28 03:11:26+00:00,Open,13301437,RATIS-905
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 03:09:35+00:00,2020-06-13 08:22:50+00:00,2020-06-13 08:22:50+00:00,Resolved,13301436,RATIS-904
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-28 00:37:38+00:00,2020-06-24 08:33:04+00:00,2020-06-24 08:33:04+00:00,Resolved,13301423,RATIS-903
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-28 00:35:56+00:00,2020-06-30 23:51:35+00:00,2020-06-30 23:51:35+00:00,Resolved,13301422,RATIS-902
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 00:31:24+00:00,2020-05-08 09:01:50+00:00,2020-05-08 09:01:50+00:00,Resolved,13301421,RATIS-901
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 00:28:57+00:00,2020-05-28 09:00:17+00:00,2020-05-28 09:00:17+00:00,Resolved,13301420,RATIS-900
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-28 00:25:56+00:00,2020-06-30 23:59:39+00:00,2020-06-30 23:59:39+00:00,Resolved,13301417,RATIS-899
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-28 00:05:47+00:00,,2020-04-28 00:57:43+00:00,Open,13301414,RATIS-898
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 00:03:50+00:00,,2020-04-28 00:04:24+00:00,Open,13301413,RATIS-897
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-28 00:02:48+00:00,,2020-04-28 00:03:19+00:00,Open,13301412,RATIS-896
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-28 00:00:54+00:00,2020-06-18 14:43:51+00:00,2020-06-18 14:43:51+00:00,Resolved,13301411,RATIS-895
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-1.png! 
 !screenshot-2.png! ",[],2020-04-27 23:58:26+00:00,,2020-04-27 23:59:37+00:00,Open,13301410,RATIS-894
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major," !screenshot-2.png! 
 !screenshot-3.png! ",[],2020-04-27 23:55:03+00:00,,2020-05-25 02:23:26+00:00,Open,13301409,RATIS-893
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-27 23:51:41+00:00,2020-05-29 07:02:12+00:00,2020-06-30 23:59:39+00:00,Resolved,13301408,RATIS-892
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major, !screenshot-1.png! ,[],2020-04-27 23:49:07+00:00,2020-04-27 23:52:48+00:00,2020-04-27 23:52:48+00:00,Resolved,13301407,RATIS-891
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,,[],2020-04-27 10:27:08+00:00,,2021-04-20 14:44:28+00:00,Open,13301222,RATIS-890
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
Test set: org.apache.ratis.grpc.TestRaftSnapshotWithGrpc
-------------------------------------------------------------------------------
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 4.84 s <<< FAILURE! - in org.apache.ratis.grpc.TestRaftSnapshotWithGrpc
testBasicInstallSnapshot(org.apache.ratis.grpc.TestRaftSnapshotWithGrpc)  Time elapsed: 2.308 s  <<< FAILURE!
java.lang.AssertionError
{code}",[],2020-04-27 10:25:47+00:00,2020-05-03 05:12:47+00:00,2020-05-03 05:51:42+00:00,Resolved,13301220,RATIS-889
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
testRestartLogAppender(org.apache.ratis.grpc.TestLogAppenderWithGrpc)  Time elapsed: 2.817 s  <<< FAILURE!testRestartLogAppender(org.apache.ratis.grpc.TestLogAppenderWithGrpc)  Time elapsed: 2.817 s  <<< FAILURE!java.lang.AssertionError: expected:<1> but was:<2> at org.apache.ratis.grpc.TestLogAppenderWithGrpc.runTestRestartLogAppender(TestLogAppenderWithGrpc.java:129) at org.apache.ratis.grpc.TestLogAppenderWithGrpc.testRestartLogAppender(TestLogAppenderWithGrpc.java:96)
{code}",[],2020-04-27 10:23:43+00:00,2020-06-30 23:57:44+00:00,2020-06-30 23:57:44+00:00,Resolved,13301219,RATIS-888
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,,[],2020-04-27 06:39:45+00:00,2020-04-27 06:44:57+00:00,2020-04-27 06:44:57+00:00,Resolved,13301170,RATIS-887
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,,[],2020-04-26 10:20:59+00:00,2020-04-26 10:37:58+00:00,2020-04-26 10:37:58+00:00,Resolved,13301067,RATIS-886
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*
 !screenshot-1.png! 

*What's the reason ?*    
I think the author of following code want to try 10 seconds until followerState.getLastAppliedIndex() >= leaderLastIndex, but actually JavaUtils.attemptRepeatedly will not retry unless the statement throw exception as the image shows.
{code:java}
    // make sure the restarted follower can catchup
    final ServerState followerState = cluster.getRaftServerImpl(followerId).getState();
    JavaUtils.attemptRepeatedly(() -> followerState.getLastAppliedIndex() >= leaderLastIndex,
        10, ONE_SECOND, ""follower catchup"", LOG);

{code}

 !screenshot-2.png! 

*How to fix ?*    
I fix all the error use of JavaUtils.attemptRepeatedly to check boolean condition.",[],2020-04-26 09:40:48+00:00,2020-04-27 10:38:37+00:00,2020-04-27 10:38:37+00:00,Resolved,13301063,RATIS-885
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*
 !screenshot-1.png! 

*What's the reason ?*

As the images shows, flushCount.incrementAndGet() happens in the 1st statement: stateMachine.flushStateMachineData(lastWrittenIndex), ratisMetricRegistry.get(RAFT_LOG_FLUSH_TIME) increase after the 2nd statement: timerContext.stop(). If the test Assert.assertEquals(expectedFlush, tm.getCount()) happens between 1st and 2nd statement, then the expectedFlush will be tm.getCount() + 1, so the test fail.
 !screenshot-2.png! 

*How to fix ?*
Retry check expectedFlush == tm.getCount()",[],2020-04-26 07:37:05+00:00,2020-04-30 17:39:46+00:00,2020-04-30 17:39:46+00:00,Resolved,13301054,RATIS-884
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*
 !screenshot-1.png! 

*What's the reason ?*
The reason is follower update commitInfoCache after leader.

The stack of follower update commitInfoCache is: 
RaftServerImpl::appendEntriesAsync
-> state.updateStateMachine 
-> StateMachineUpdater::applyLog 
-> RaftServerImpl::applyLogToStateMachine
-> RaftServerImpl::replyPendingRequest 
-> RaftServerImpl::getCommitInfos 
-> infos.add(commitInfoCache.update(getPeer(), state.getLog().getLastCommittedIndex())) 
-> CommitInfoCache::update.

The stack of leader update commitInfoCache is: 
follower finish RaftServerImpl::appendEntriesAsync and return reply
-> GrpcLogAppender::runAppenderImpl 
-> GrpcLogAppender::appendLog 
->LogAppender::createRequest 
->LeaderState::newAppendEntriesRequestProto 
->RaftServerImpl::getCommitInfos 
->LeaderState::updateFollowerCommitInfos
->CommitInfoCache::update.


Because follower need to notify thread StateMachineUpdater to update CommitInfoCache, we can not ensure follower update CommitInfoCache before leader.

*How to fix ?*
Follower update CommitInfoCache before return reply to leader.",[],2020-04-26 03:43:46+00:00,2020-05-18 05:54:45+00:00,2020-05-18 05:54:45+00:00,Resolved,13301018,RATIS-883
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,The Jira aims to add ExponentialBackoffRetry policy. The policy increases sleep time exponentially with randomness on successive retries.,['pull-request-available'],2020-04-24 13:12:50+00:00,2020-04-29 07:48:26+00:00,2020-04-29 07:48:26+00:00,Resolved,13300805,RATIS-882
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"For the failed [TestRaftWithGrpc::testStateMachineMetrics|https://builds.apache.org/job/PreCommit-RATIS-Build/1305/testReport/org.apache.ratis.grpc/TestRaftWithGrpc/testStateMachineMetrics/], the reason is the [RaftServerMetrics::getPeerCommitIndexGauge|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L141] happens before [RaftServerMetrics::addPeerCommitIndexGauge|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L122].  
When some RaftServerImpl [setRole(RaftPeerRole.LEADER, ""changeToLeader"")|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L345], the statement [waitForLeader|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/test/java/org/apache/ratis/RaftBasicTests.java#L446] succ to get leader and test begin, but [role.startLeaderState|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L349] ->
 [new LeaderState|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RoleInfo.java#L94] ->
[LeaderState::addSenders|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L409]->[RaftServerMetrics::addFollower|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L106] -> [RaftServerMetrics::addPeerCommitIndexGauge|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L122] has not finished.

!screenshot-1.png! ",[],2020-04-24 11:55:54+00:00,2020-04-28 05:25:36+00:00,2020-04-28 05:26:27+00:00,Resolved,13300790,RATIS-881
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Update github description and disable merge options apart from Squash and merge,[],2020-04-24 08:57:42+00:00,2020-04-25 09:24:04+00:00,2021-03-19 09:29:11+00:00,Resolved,13300747,RATIS-880
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
java.lang.AssertionError: Failed to get async resultjava.lang.AssertionError: Failed to get async result
 at org.apache.ratis.RaftAsyncTests.runTestNoRetryWaitOnNotLeaderException(RaftAsyncTests.java:435) at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125) at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113) at org.apache.ratis.RaftAsyncTests.testNoRetryWaitOnNotLeaderException(RaftAsyncTests.java:407) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.lang.Thread.run(Thread.java:748)Caused by: java.util.concurrent.TimeoutException at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771) at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915) at org.apache.ratis.util.TimeDuration.apply(TimeDuration.java:289) at org.apache.ratis.RaftAsyncTests.runTestNoRetryWaitOnNotLeaderException(RaftAsyncTests.java:433) ... 16 morejava.lang.IllegalStateException: Failed: first exception was set
 at org.apache.ratis.BaseTest.assertNoFailures(BaseTest.java:72) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.IllegalStateException: Unexpected getSleepTime: ClientRetryEvent:attempt=1,request=RaftClientRequest:client-7928BDA9D90A->s0@group-970F01270564, cid=2857, seq=1*, RW, abc,cause=org.apache.ratis.protocol.NotLeaderException: Server s0@group-970F01270564 is not the leader s1:0.0.0.0:57704 at org.apache.ratis.RaftAsyncTests.lambda$null$15(RaftAsyncTests.java:426) at org.apache.ratis.client.impl.OrderedAsync.scheduleWithTimeout(OrderedAsync.java:214) at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequestWithRetry$6(OrderedAsync.java:200) at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870) at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852) at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:358) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$000(GrpcClientProtocolClient.java:264) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onNext(GrpcClientProtocolClient.java:278) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onNext(GrpcClientProtocolClient.java:269) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:429) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInternal(ClientCallImpl.java:599) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:584) at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 more
{code}",['pull-request-available'],2020-04-23 11:32:47+00:00,2020-04-27 06:39:57+00:00,2020-04-27 06:39:57+00:00,Resolved,13300534,RATIS-879
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*

 When run hadoop-ozone for 4 days, datanode memory leak.  When dump heap, I found there are 460710 instances of GrpcLogAppender. But there are only 6 instances of SenderList, and each SenderList contains 1-2 instance of GrpcLogAppender. And there are a lot of logs related to [LeaderState::restartSender|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L428].
 {code:java}INFO impl.RaftServerImpl: 1665f5ea-ab17-4a0e-af6d-6958efd322fa@group-F64B465F37B5-LeaderState: Restarting GrpcLogAppender for 1665f5ea-ab17-4a0e-af6d-6958efd322fa@group-F64B465F37B5-\u003e229cbcc1-a3b2-4383-9c0d-c0f4c28c3d4a\n"",""stream"":""stderr"",""time"":""2020-04-06T03:59:53.37892512Z""}{code} 

 So there are a lot of GrpcLogAppender did not stop the Daemon Thread when removed from senders. 
 !screenshot-2.png! 

 !screenshot-3.png! 
 
*Why [LeaderState::restartSender|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L428] so many times ?*
1. As the image shows, when remove group, SegmentedRaftLog will close, then GrpcLogAppender throw exception when find the SegmentedRaftLog was closed. Then GrpcLogAppender will be [restarted|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LogAppender.java#L94], and the new GrpcLogAppender throw exception again when find the SegmentedRaftLog was closed, then GrpcLogAppender will be restarted again ... . It results in an infinite restart of GrpcLogAppender.
2. Actually, when remove group, GrpcLogAppender will be stoped: RaftServerImpl::shutdown -> [RoleInfo::shutdownLeaderState|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L266] -> LeaderState::stop -> LogAppender::stopAppender, then SegmentedRaftLog will be closed:  RaftServerImpl::shutdown -> [ServerState:close|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L271] ... . Though RoleInfo::shutdownLeaderState called before ServerState:close, but the GrpcLogAppender was stopped asynchronously. So infinite restart of GrpcLogAppender happens, when GrpcLogAppender stop after SegmentedRaftLog close.
 !screenshot-4.png! 

More details please refer it here [RATIS-840|https://issues.apache.org/jira/browse/RATIS-840].",[],2020-04-23 08:04:06+00:00,,2020-06-29 11:04:15+00:00,Open,13300479,RATIS-878
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently StateMachineUpdater#takeSnapshot checks whether index of snapshott taken is greater than lastAppliedIndex. It should ideally check stateMachineLastAppliedIndex which reflects the index till which state machine has already applied the log entry.,[],2020-04-23 07:35:17+00:00,2020-04-23 07:49:23+00:00,2020-04-23 07:49:23+00:00,Resolved,13300471,RATIS-877
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,This Jira aims to add a max timeout in RequestTypeDependentRetryPolicy. If a timeout of 1 minute is configured then all retries after 1 minute of request creation will fail.,['pull-request-available'],2020-04-22 11:26:14+00:00,2020-04-27 11:49:44+00:00,2020-04-27 11:49:44+00:00,Resolved,13300249,RATIS-876
Improvement,[],elek,Marton Elek,elek,Marton Elek,Trivial,Reported by [~arp]  during a 0.4.0 rc vote.,[],2020-04-22 09:05:01+00:00,2020-04-22 10:06:55+00:00,2020-04-22 10:06:56+00:00,Resolved,13300214,RATIS-875
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"This Jira aims to fix the following:
 # Before sending an appendEntry request to follower, leader checks the validity of the request be verifying if the follower has the previous log entry. But if the follower had installed a snapshot, the previous could be missing and the appendEntry would still be valid. Hence, the SnapshotIndex should be factored in while checking the validity of appendEntry request. Leader should store Follower's SnapshotIndex for this.
 # When follower receives appendEntry request, it checks the validity of log entry - the first index of the log entry is exactly 1 more than the last log index. During this check, the snapshotIndex should also be considered i.e. the first index of the log entry can be 1 more than the last log index or the snapshotIndex.
 # After Ratis server is restared, it loads all the available log segments. But logs with end index < last snapshot index should not be loaded. There can be gaps in the log segments upto the snapshotIndex if a snapshot was installed from leader node. ",[],2020-04-21 23:21:42+00:00,2020-05-12 22:10:52+00:00,2020-05-12 22:10:52+00:00,Resolved,13300111,RATIS-874
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"This Jira aims to address the following:
# When Follower is in the process of installing snapshot and it gets an append entry, it replies with result INCONSISTENCY and the follower next index is updated to the snapshot index being installed. This should not happen as the snapshot installation is still in progress. Follower's next index on the leader should remain the same.
# After InstallSnapshot is done, Leader should update the commitIndex of the Follower to the installed snapshot index.
# After InstallSnapshot, when reloading StateMachine, any previously open LogSegment should be closed, if the last entry in the open log is already included in the snapshot.
# When Follower is notified to install snapshot through StateMachine, the reply should indicate the same. It would help with debugging if the Install Snapshot success reply and Install Snapshot notified replies are distinct.",[],2020-04-21 23:13:48+00:00,2020-05-12 22:10:42+00:00,2020-05-12 22:10:42+00:00,Resolved,13300110,RATIS-873
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,The duration for which a client request entry is kept inside the retry cache should be long enough to cover all the retries made by the client. Retry cache would need to keep the metadata for all client requests until that duration is over. It can therefore require a large amount of heap in order to handle client requests. Since active heap usage is high it can also increase the frequency of JVM garbage collection.,[],2020-04-21 11:58:14+00:00,,2020-09-20 17:29:23+00:00,Open,13299977,RATIS-872
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.examples.filestore/TestFileStoreWithGrpc/testFileStore/]
{code:java}
Error Message test timed out after 100 seconds Stacktrace org.junit.runners.model.TestTimedOutException: test timed out after 100 seconds{code}",[],2020-04-21 09:44:56+00:00,,2021-04-20 14:44:50+00:00,Open,13299950,RATIS-870
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"The issue was discovered in [https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.grpc/TestServerRestartWithGrpc/testRestartFollower/]
{code:java}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.ratis.server.ServerRestartTests.runTestRestartFollower(ServerRestartTests.java:122)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.server.ServerRestartTests.testRestartFollower(ServerRestartTests.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}",[],2020-04-21 09:42:09+00:00,,2020-09-10 04:11:10+00:00,Open,13299949,RATIS-869
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.server.simulation/TestRaftWithSimulatedRpc/testWithLoad/]
{code:java}
org.junit.runners.model.TestTimedOutException: test timed out after 100 seconds
{code}",[],2020-04-21 09:39:42+00:00,2020-07-10 08:04:22+00:00,2020-07-10 08:04:22+00:00,Resolved,13299948,RATIS-868
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major," 

The issue was observed here:

[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.logservice.server/TestMetaServer/testListLogs/]
{code:java}
ava.lang.AssertionError: expected:<19> but was:<20>
	at org.apache.ratis.logservice.server.TestMetaServer.testJMXCount(TestMetaServer.java:339)
	at org.apache.ratis.logservice.server.TestMetaServer.testListLogs(TestMetaServer.java:331)
{code}
 

The reason is:
1. when create log, it will call [RaftClientImpl::sendRequestWithRetry|https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/impl/RaftClientImpl.java#L285], if throw TimeoutIOException, it will retry at [final RaftClientReply reply = sendRequest(request)|https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/impl/RaftClientImpl.java#L296], So JMXCount will increase many times at [timerContext = metricRegistry.timer(type.name()).time()|https://github.com/apache/incubator-ratis/blob/master/ratis-logservice/src/main/java/org/apache/ratis/logservice/server/MetaStateMachine.java#L224] when retry happens.  Then JMXCount i.e. 20 not equal to createCount i.e. 19
2. The TimeoutIOException is as follows:

{code:java}
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.999977899s. [buffered_nanos=1460409, remote_addr=localhost/127.0.0.1:9001]
{code}

",[],2020-04-21 09:34:19+00:00,2020-06-02 11:37:28+00:00,2020-06-02 11:37:28+00:00,Resolved,13299943,RATIS-867
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.server.simulation/TestServerRestartWithSimulatedRpc/testRestartWithCorruptedLogHeader/]
{code:java}
attempt #2/10: java.lang.AssertionError: expected:<1> but was:<0>, sleep 100ms and then retry.
java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.ratis.server.ServerRestartTests.getOpenLogFile(ServerRestartTests.java:179)
	at org.apache.ratis.server.ServerRestartTests.lambda$runTestRestartWithCorruptedLogHeader$2(ServerRestartTests.java:191)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.JavaUtils.attemptRepeatedly(JavaUtils.java:146)
	at org.apache.ratis.server.ServerRestartTests.runTestRestartWithCorruptedLogHeader(ServerRestartTests.java:191)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.server.ServerRestartTests.testRestartWithCorruptedLogHeader(ServerRestartTests.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}",[],2020-04-21 09:32:12+00:00,,2021-04-20 14:45:37+00:00,Open,13299942,RATIS-866
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"The failure was observed here:

[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.grpc/TestRaftWithGrpc/testStateMachineMetrics/]
{code:java}
org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.ratis.RaftBasicTests.checkFollowerCommitLagsLeader(RaftBasicTests.java:494)
	at org.apache.ratis.RaftBasicTests.testStateMachineMetrics(RaftBasicTests.java:469)
	at org.apache.ratis.grpc.TestRaftWithGrpc.lambda$testStateMachineMetrics$1(TestRaftWithGrpc.java:65)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.grpc.TestRaftWithGrpc.testStateMachineMetrics(TestRaftWithGrpc.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


2ND INSTANCE
-----------
org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
java.util.NoSuchElementException
	at java.util.TreeMap.key(TreeMap.java:1327)
	at java.util.TreeMap.firstKey(TreeMap.java:290)
	at java.util.Collections$UnmodifiableSortedMap.firstKey(Collections.java:1808)
	at org.apache.ratis.server.impl.RaftServerMetrics.getPeerCommitIndexGauge(RaftServerMetrics.java:159)
	at org.apache.ratis.RaftBasicTests.checkFollowerCommitLagsLeader(RaftBasicTests.java:487)
	at org.apache.ratis.RaftBasicTests.testStateMachineMetrics(RaftBasicTests.java:458)
	at org.apache.ratis.grpc.TestRaftWithGrpc.lambda$testStateMachineMetrics$1(TestRaftWithGrpc.java:65)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.grpc.TestRaftWithGrpc.testStateMachineMetrics(TestRaftWithGrpc.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}",[],2020-04-21 09:30:41+00:00,2020-04-27 06:56:01+00:00,2020-04-28 06:28:21+00:00,Resolved,13299939,RATIS-865
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"The test failure was observed here:

[https://builds.apache.org/job/PreCommit-RATIS-Build/1299/testReport/org.apache.ratis.grpc/TestRaftStateMachineExceptionWithGrpc/testRetryOnExceptionDuringReplication/]
{code:java}
org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
java.lang.NullPointerException
	at java.util.Objects.requireNonNull(Objects.java:203)
	at org.apache.ratis.server.impl.RaftStateMachineExceptionTests.runTestRetryOnExceptionDuringReplication(RaftStateMachineExceptionTests.java:170)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.server.impl.RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication(RaftStateMachineExceptionTests.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}",[],2020-04-21 09:29:07+00:00,,2020-04-27 07:08:43+00:00,Open,13299937,RATIS-864
Task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,There are multiple unit test failures in ratis off late. The aim here is to list every failure and try to fix them.,[],2020-04-21 09:26:42+00:00,,2021-04-20 14:45:12+00:00,Open,13299934,RATIS-863
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, many third library dpendencies are hardcoded in the dependency tag in the pom file. Idea is to define the jar version as a proerty in the pom file and reuse the defined version in the dependency tag as done in https://issues.apache.org/jira/browse/RATIS-860.",[],2020-04-21 08:01:59+00:00,,2020-04-21 08:06:18+00:00,Open,13299905,RATIS-861
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, dependency of log4j in ozone is added as following:
{code:java}
<dependency>
  <groupId>log4j</groupId>
  <artifactId>log4j</artifactId>
  <version>1.2.17</version>
{code}
Idea here is to add log4j.version as a property in pom.xml and reuse the same while defining the dependency.",[],2020-04-21 07:47:03+00:00,2020-04-21 11:42:16+00:00,2020-04-21 11:42:16+00:00,Resolved,13299901,RATIS-860
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"I also open the same jira in ozone: https://issues.apache.org/jira/browse/HDDS-3459. I think both ozone and ratis should avoid this happens.
*What's the problem ?*
There are 3 datanodes in a group: leader, follower1, follower2. Steps to reproduce the problem are as following:
1. follower2 report close pipeline
2. scm send close pipeline command
3. leader and follower1 remove group, but follower2 socket timeout and does not remove group
4.  follower2 then begin infinite LeaderElection at least 6 hours, leader and follower1 response group not found

You can see find it in following screenshot.
1. follower2 report close pipeline
 !screenshot-1.png! 
2. Scm close pipeline:
 !screenshot-2.png! 
 !screenshot-3.png! 
3. leader remove group
 !screenshot-4.png! 

   follower1 remove group
 !screenshot-5.png! 

 follower2 socket timeout
 !screenshot-6.png! 

4. follower2 then begin infinite LeaderElection at least 6 hours
 !screenshot-7.png! ",[],2020-04-20 12:32:04+00:00,2020-04-21 13:31:18+00:00,2020-04-21 13:31:18+00:00,Resolved,13299674,RATIS-859
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"The reason is testStateMachineMetrics happens before addPeerCommitIndexGauge sometimes.
 !image-2020-04-19-17-14-57-504.png! ",[],2020-04-19 09:14:13+00:00,2020-04-27 07:55:17+00:00,2020-04-27 07:55:17+00:00,Resolved,13299450,RATIS-858
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*

The {color:#DE350B}static{color} variable [RaftServerMetrics::metricsMap|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L71] is type of HashMap, which is not thread safe. But entry will be [put|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerMetrics.java#L76] into metricsMap by different thread, when create each RaftServerImpl instance.",[],2020-04-19 06:53:32+00:00,2020-04-21 10:23:39+00:00,2020-04-26 05:58:12+00:00,Resolved,13299444,RATIS-857
Improvement,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"When InstallSnapshot is disabled and Ratis logs are purged, Leader sends InstallSnapshot notification to Follower. Follower then tells its State Machine to install the snapshot.

 
We should give time for the Follower State Machine to download and install the snapshot. So instead of sending installSnapshot notification for each heartbeat, it would be better if there is a time gap between the sending the notifications.",[],2020-04-18 02:39:15+00:00,,2020-04-18 02:39:15+00:00,Open,13299267,RATIS-856
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"with RATIS-852 and RATIS-847 resolved, release 0.4.0 third party",[],2020-04-17 08:38:41+00:00,2020-04-28 14:21:56+00:00,2020-04-28 14:21:56+00:00,Resolved,13299011,RATIS-855
Improvement,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Major,The download links for signatures/checksums/KEYS should be updated from dist.apache.org to https://downloads.apache.org/incubator/ratis/,['newbie'],2020-04-16 22:06:04+00:00,,2020-08-29 14:16:58+00:00,Open,13298911,RATIS-854
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"When NotLeaderException provides leader information, the client request should be retried immediately on the suggested leader. Currently Unordered requests in raft client use the default policy to determine sleep time and thus may sleep even if NotLeaderException provides leader information.",[],2020-04-16 11:21:24+00:00,2020-04-22 11:03:29+00:00,2020-04-22 11:03:30+00:00,Resolved,13298784,RATIS-853
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"GrpcSslTest fails with CertificateExpiredException

{code}
[INFO] Running org.apache.ratis.thirdparty.demo.GrpcSslTest
2020-04-16 11:40:30,624 [Thread-0] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/server.pem

2020-04-16 11:40:30,624 [main] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/client.pem

2020-04-16 11:40:30,627 [Thread-0] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/server.crt

2020-04-16 11:40:30,629 [main] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/ca.crt

2020-04-16 11:40:30,629 [Thread-0] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/client.crt

2020-04-16 11:40:30,630 [main] INFO  demo.GrpcSslTest (GrpcSslTest.java:getResource(37)) - Getting Resource: /Users/mukul/code/apache/ratis/thirdparty/test/target/test-classes/ssl/client.crt

2020-04-16 11:40:31,224 [Thread-0] INFO  demo.GrpcServer (GrpcSslServer.java:start(69)) - GrpcSslServer started, listening on 50005
2020-04-16 11:40:31,454 [main] WARN  demo.GrpcSslClient (GrpcSslClient.java:greet(86)) - RPC failed: {0}
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:235)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:216)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:141)
	at org.apache.ratis.thirdparty.demo.GreeterGrpc$GreeterBlockingStub.hello(GreeterGrpc.java:156)
	at org.apache.ratis.thirdparty.demo.GrpcSslClient.greet(GrpcSslClient.java:82)
	at org.apache.ratis.thirdparty.demo.GrpcSslTest.testSslClientServer(GrpcSslTest.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:383)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:344)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:417)
Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1735)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:775)
	at javax.net.ssl.SSLEngine.wrap(SSLEngine.java:509)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1052)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:943)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1401)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1233)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1280)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:498)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:437)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: sun.security.validator.ValidatorException: PKIX path validation failed: java.security.cert.CertPathValidatorException: validity check failed
	at sun.security.validator.PKIXValidator.doValidate(PKIXValidator.java:362)
	at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:270)
	at sun.security.validator.Validator.validate(Validator.java:262)
	at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:330)
	at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:289)
	at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.OpenSslTlsv13X509ExtendedTrustManager.checkServerTrusted(OpenSslTlsv13X509ExtendedTrustManager.java:223)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:255)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:701)
	at org.apache.ratis.thirdparty.io.netty.internal.tcnative.SSL.readFromSSL(Native Method)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.readPlaintextData(ReferenceCountedOpenSslEngine.java:594)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1179)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1296)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler$SslEngineType$1.unwrap(SslHandler.java:200)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1338)
	... 21 more
Caused by: java.security.cert.CertPathValidatorException: validity check failed
	at sun.security.provider.certpath.PKIXMasterCertPathValidator.validate(PKIXMasterCertPathValidator.java:135)
	at sun.security.provider.certpath.PKIXCertPathValidator.validate(PKIXCertPathValidator.java:233)
	at sun.security.provider.certpath.PKIXCertPathValidator.validate(PKIXCertPathValidator.java:141)
	at sun.security.provider.certpath.PKIXCertPathValidator.engineValidate(PKIXCertPathValidator.java:80)
	at java.security.cert.CertPathValidator.validate(CertPathValidator.java:292)
	at sun.security.validator.PKIXValidator.doValidate(PKIXValidator.java:357)
	... 35 more
Caused by: java.security.cert.CertificateExpiredException: NotAfter: Tue Dec 03 11:16:38 IST 2019
	at sun.security.x509.CertificateValidity.valid(CertificateValidity.java:274)
	at sun.security.x509.X509CertImpl.checkValidity(X509CertImpl.java:629)
	at org.apache.ratis.thirdparty.io.netty.handler.ssl.OpenSslX509Certificate.checkValidity(OpenSslX509Certificate.java:57)
	at sun.security.provider.certpath.BasicChecker.verifyValidity(BasicChecker.java:190)
	at sun.security.provider.certpath.BasicChecker.check(BasicChecker.java:144)
	at sun.security.provider.certpath.PKIXMasterCertPathValidator.validate(PKIXMasterCertPathValidator.java:125)
	... 40 more
2020-04-16 11:40:31,459 [main] INFO  demo.GrpcSslTest (GrpcSslTest.java:testSslClientServer(74)) - Greet result:
[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.975 s <<< FAILURE! - in org.apache.ratis.thirdparty.demo.GrpcSslTest
[ERROR] testSslClientServer(org.apache.ratis.thirdparty.demo.GrpcSslTest)  Time elapsed: 0.863 s  <<< FAILURE!
java.lang.AssertionError
	at org.apache.ratis.thirdparty.demo.GrpcSslTest.testSslClientServer(GrpcSslTest.java:75)
{code}",[],2020-04-16 06:12:37+00:00,2020-04-16 07:13:15+00:00,2020-04-16 07:13:15+00:00,Resolved,13298711,RATIS-852
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently raft client changes the leader on receiving ResourceUnavailableException. It should not change the leader as the exception only signifies load on the leader.,[],2020-04-16 05:50:58+00:00,2020-04-16 10:56:06+00:00,2020-04-16 10:56:06+00:00,Resolved,13298706,RATIS-851
Improvement,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"Ratis logs are purged only up to the least commit index on all the peers. But if one peer is down, it stop log purging on all the peers. If the Ratis server takes snapshots, then we can purge logs up to the snapshot index even if some peer has not committed up to that index. When the peer rejoins the ring, instead of ratis logs, it can get the snapshot to catch up.",[],2020-04-14 19:35:44+00:00,2020-04-23 07:29:43+00:00,2020-04-23 17:24:59+00:00,Resolved,13298379,RATIS-850
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*
!image-2020-04-14-21-07-42-831.png!

*What the reason ?*
I test with the patch, the failed unit test will not happen again.
 !screenshot-1.png! ",[],2020-04-14 13:06:10+00:00,2020-04-27 10:07:25+00:00,2020-04-27 10:07:25+00:00,Resolved,13298271,RATIS-849
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Minor,"*Why unit test TestRaftSnapshotWithGrpc.testBasicInstallSnapshot failed?*
In the test, leader take snapshot, then add two followers, then [leader restart|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/test/java/org/apache/ratis/statemachine/RaftSnapshotBaseTest.java#L234], then [verifyTakeSnapshotMetric|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/test/java/org/apache/ratis/statemachine/RaftSnapshotBaseTest.java#L236]. 
It must be failed when verifyTakeSnapshotMetric after restarting leader. Because restart leader will create a new instance of RaftServer, the metric of take snapshot is clean.

*How to fix ?*
verifyTakeSnapshotMetric after leader take snapshot.",[],2020-04-14 09:34:41+00:00,2020-05-03 05:15:40+00:00,2020-05-03 05:15:40+00:00,Resolved,13298224,RATIS-848
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"The Jira aims to upgrade netty(4.1.48.Final), grpc(1.28.1), protobuf(3.11.0) and netty.tcnative(2.0.28.Final) version in ratis-thirdparty.",[],2020-04-14 06:49:24+00:00,2020-04-16 07:55:38+00:00,2020-04-16 07:55:51+00:00,Resolved,13298196,RATIS-847
Improvement,[],esa.hekmat,Isa Hekmatizadeh,esa.hekmat,Isa Hekmatizadeh,Major,"Create a very very simple example that just maintains a counter value across the cluster to illustrate ""How to use Ratis"" in the simplest way.",[],2020-04-09 12:00:35+00:00,2020-05-14 16:33:13+00:00,2020-05-14 16:33:13+00:00,Resolved,13297361,RATIS-846
Sub-task,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ? *
As the image shows, there are 1885 instances of  RaftServerImpl, most of them are Closed, and should be GC, but actually not. You can find from the image 
 1513 RaftServerImpl were held by ManagermentFactory->jxmMBeanServer->HashMap, 372 RaftServerImpl were held by Datanode ReportManager Thread -> prometheus -> HashMap. So 1513 RaftServerImpl leak in ratis, and 372 leak in ozone. If RaftServerImpl can not GC, there are a lot of related resource can not be GC, such as the [DirectByteBuffer|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/raftlog/segmented/SegmentedRaftLogWorker.java#L150]  in SegmentRaftLogWorker, which result 1GB memory leak out of heap.

h3. *{color:#DE350B}1.  1885 instances of RaftServerImpl {color}*
 !screenshot-4.png! 

h3. *{color:#DE350B}2. 1513 RaftServerImpl were held by ManagermentFactory->jxmMBeanServer->HashMap, 372 RaftServerImpl were held by Datanode ReportManager Thread -> prometheus -> HashMap{color}*
 !screenshot-5.png! 

h3. *{color:#DE350B}3. 1513 RaftServerImpl were held by ManagermentFactory->jxmMBeanServer->HashMap{color}*
 !screenshot-6.png! 

h3. *{color:#DE350B}4. 372 RaftServerImpl were held by Datanode ReportManager Thread -> prometheus -> HashMap{color}*
 !screenshot-7.png! 

h3. *{color:#DE350B}5. 2038 DirectByteBuffer, and 1885 held by RaftServerImpl.{color}*
 !screenshot-8.png! 
 !screenshot-9.png! 

h3. *{color:#DE350B}6. 1033 DirectByteBuffer were held by ManagermentFactory, 802 DirectByteBuffer were held by Datanode ReportManager Thread, total 1885.{color}*
 !screenshot-10.png! 

h3. *{color:#DE350B}7. The reason RaftServerImpl held by ManagermentFactory->jxmMBeanServer->HashMap is ratis start [JmxReporter|https://github.com/apache/incubator-ratis/blob/master/ratis-metrics/src/main/java/org/apache/ratis/metrics/MetricsReporting.java#L47], but does not stop it. {color}*

h3. *{color:#DE350B}8. The reason RaftServerImpl held by Datanode ReportManager Thread -> prometheus -> HashMap is ozone call the ratis function to  [register|https://github.com/apache/hadoop-ozone/blob/master/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/HddsDatanodeService.java#L189] metric in prometheus, but does not unregister it.{color}*",[],2020-04-07 03:50:26+00:00,2020-05-15 09:05:19+00:00,2020-05-15 09:05:19+00:00,Resolved,13296726,RATIS-845
Bug,[],burcukozkan,Burcu Ozkan,burcukozkan,Burcu Ozkan,Major,"While running a Netty cluster, RaftClient is blocked after it submits a request to the leader which is partitioned from the cluster.

The attached test reproduces the problem. In the test, after the client connects to the leader, the leader is disconnected and another node is elected as the new leader. However, the client waits indefinitely for a reply from the previous one.

The test passes for Grpc and HadoopRpc, but fails with TestTimedOutException for Netty.",[],2020-04-06 16:08:42+00:00,2020-04-27 11:39:54+00:00,2020-04-27 11:40:19+00:00,Resolved,13296557,RATIS-844
Sub-task,[],esa.hekmat,Isa Hekmatizadeh,esa.hekmat,Isa Hekmatizadeh,Major,create the base structure for documentation,[],2020-04-06 14:28:47+00:00,2020-04-15 11:29:44+00:00,2021-03-03 01:21:51+00:00,Resolved,13296527,RATIS-843
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,GrpcClientProtocolClient uses NotLeaderException event for LeaderNotReadyException. It should be changed to LeaderNotReadyException.,[],2020-04-06 12:04:18+00:00,2020-04-13 09:47:03+00:00,2020-04-13 09:47:03+00:00,Resolved,13296504,RATIS-842
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,OrderedAsync#sendRequest does not require exception checks for NotLeaderException as RafClientReply is already checked for these exceptions in GrpcClientProtocolClient$AsyncStreamObservers.,[],2020-04-06 10:15:58+00:00,2020-04-23 12:28:22+00:00,2020-04-23 12:28:22+00:00,Resolved,13296488,RATIS-841
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Blocker,"*What's the problem ?*

 When run hadoop-ozone for 4 days, datanode memory leak.  When dump heap, I found there are 460710 instances of GrpcLogAppender. But there are only 6 instances of SenderList, and each SenderList contains 1-2 instance of GrpcLogAppender. And there are a lot of logs related to [LeaderState::restartSender|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L428].
 {code:java}INFO impl.RaftServerImpl: 1665f5ea-ab17-4a0e-af6d-6958efd322fa@group-F64B465F37B5-LeaderState: Restarting GrpcLogAppender for 1665f5ea-ab17-4a0e-af6d-6958efd322fa@group-F64B465F37B5-\u003e229cbcc1-a3b2-4383-9c0d-c0f4c28c3d4a\n"",""stream"":""stderr"",""time"":""2020-04-06T03:59:53.37892512Z""}{code} 

 So there are a lot of GrpcLogAppender did not stop the Daemon Thread when removed from senders. 

 !image-2020-04-06-14-27-28-485.png! 

 !image-2020-04-06-14-27-39-582.png! 
 
*Why [LeaderState::restartSender|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L428] so many times ?*
1. As the image shows, when remove group, SegmentedRaftLog will close, then GrpcLogAppender throw exception when find the SegmentedRaftLog was closed. Then GrpcLogAppender will be [restarted|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LogAppender.java#L94], and the new GrpcLogAppender throw exception again when find the SegmentedRaftLog was closed, then GrpcLogAppender will be restarted again ... . It results in an infinite restart of GrpcLogAppender.
2. Actually, when remove group, GrpcLogAppender will be stoped: RaftServerImpl::shutdown -> [RoleInfo::shutdownLeaderState|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L266] -> LeaderState::stop -> LogAppender::stopAppender, then SegmentedRaftLog will be closed:  RaftServerImpl::shutdown -> [ServerState:close|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L271] ... . Though RoleInfo::shutdownLeaderState called before ServerState:close, but the GrpcLogAppender was stopped asynchronously. So infinite restart of GrpcLogAppender happens, when GrpcLogAppender stop after SegmentedRaftLog close.
 !screenshot-1.png! 

*Why GrpcLogAppender did not stop the Daemon Thread when removed from senders ?*
 I find a lot of GrpcLogAppender blocked inside logs4j. I think it's GrpcLogAppender restart too fast, then blocked in logs4j.
 !screenshot-2.png! 

*Can the new GrpcLogAppender work normally ?*
1. Even though without the above problem, the new created GrpcLogAppender still can not work normally. 
2. When creat a new GrpcLogAppender, a new FollowerInfo will also be created: LeaderState::addAndStartSenders -> 
LeaderState::addSenders->RaftServerImpl::newLogAppender -> [new FollowerInfo|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/RaftServerImpl.java#L129]
3. When the new created GrpcLogAppender append entry to follower, then the follower response SUCCESS.
4. Then LeaderState::updateCommit -> [LeaderState::getMajorityMin | https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L599] -> 
[voterLists.get(0) | https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L607]. {color:#DE350B}Error happens because voterLists.get(0) return the FollowerInfo of the old GrpcLogAppender, not the FollowerInfo of the new GrpcLogAppender. {color}
5. Because the majority commit got from the FollowerInfo of the old GrpcLogAppender never changes. So even though follower has append entry successfully, the leader can not update commit. So the new created GrpcLogAppender can never work normally.
6. The reason of unit test of runTestRestartLogAppender can pass is that it did not stop the old GrpcLogAppender, and  the old GrpcLogAppender append entry to follower, not the new GrpcLogAppender. If stop the old GrpcLogAppender, runTestRestartLogAppender will fail.
",[],2020-04-06 06:27:06+00:00,2020-04-29 09:47:28+00:00,2020-06-30 23:57:44+00:00,Resolved,13296415,RATIS-840
Bug,[],runzhiwang,Jie Wang,runzhiwang,Jie Wang,Major,"*What's the problem ?*

When run hadoop-ozone for 4 days, datanode memory leak.  When dump heap, I found there are 460710 instances of GrpcLogAppender. But there are only 6 instances of SenderList, and each SenderList contains 1-2 instance of GrpcLogAppender. So there are a lot of GrpcLogAppender did not stop the Daemon Thread when removed from senders.

!image-2020-04-06-13-48-10-703.png!*!image-2020-04-06-13-59-14-146.png!*

 

*What's the reason ?*

From the code, when [removeSender|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L431], it did not call LogAppender::stopAppender.

 

*How to fix ?*

To avoid forgetting stopAppender,  I stopAppender in [SenderList ::removeAll|https://github.com/apache/incubator-ratis/blob/master/ratis-server/src/main/java/org/apache/ratis/server/impl/LeaderState.java#L173].

 ",[],2020-04-06 05:51:24+00:00,2020-04-06 06:29:02+00:00,2020-04-19 08:14:52+00:00,Resolved,13296412,RATIS-839
Improvement,[],meijies,Jeremy Mei,meijies,Jeremy Mei,Major,"Epoll has better performance than java NIO, we can use Epoll when it available, such as running at linux system. How do you think? ",[],2020-04-04 09:32:10+00:00,,2020-04-05 14:06:52+00:00,Open,13296177,RATIS-838
Improvement,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,"*What's the problem ?*
Before send [normal request|https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/impl/OrderedAsync.java#L243], ratis client will send an [empty request|https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/impl/OrderedAsync.java#L235] to server to check the leader state,  which cost about 5 millseconds, it's a waste, because leader change rarely. 

*How to improve ?*
I think it can be improved by send normal request directly to server, without sending the empty request. If the server was not leader, response client with the NotLeaderException and client retry the request. [~msingh] [~shashikant] What do you think ? If you agree with it, I will submit an PR.


Besides one RPC call cost 5 millsecons is also weired, I will find out the root cause.",[],2020-04-01 07:29:51+00:00,,2020-04-03 10:20:05+00:00,Open,13295438,RATIS-836
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Client needs to maintain exception based attempt count for using Exception Dependent retry policy. Exception dependent policy helps in specifying individual policies for different exception types.

Currently policy takes number of attempts as argument. Therefore the individual policies require attempt counts for the particular exception while handling retry event. This is particularly important for using MulipleLinearRandomRetry policy which increases sleep interval based on number of attempts made by the client. Raft Client can therefore use this policy for ResourceUnavailableException and increase sleep interval for subsequent retries of the request on the same exception.",[],2020-03-27 08:20:38+00:00,2020-04-20 08:28:10+00:00,2020-04-20 08:28:10+00:00,Resolved,13294394,RATIS-835
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,,[],2020-03-27 06:26:39+00:00,2020-06-25 16:37:54+00:00,2020-06-25 16:37:54+00:00,Resolved,13294370,RATIS-833
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,,[],2020-03-27 06:20:16+00:00,2020-04-15 08:56:22+00:00,2020-04-15 08:56:22+00:00,Resolved,13294367,RATIS-832
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,The idea is to determine the rejected request count on a server bcoz of server overload.,[],2020-03-19 13:44:43+00:00,,2020-03-27 06:25:04+00:00,Open,13292708,RATIS-831
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"This metric will track failed count for all type of ratis requests-- WriteType, ReadType and WatchType.",[],2020-03-19 13:43:34+00:00,2020-09-23 05:31:44+00:00,2020-09-23 06:03:01+00:00,Resolved,13292707,RATIS-830
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, the data in the StateMachineCache is evicted as soon as the applyTransaction call is issued for a transaction in Ratis in ozone. In our testing with keys in few kbs of size, it was figured that the data is evicted from the cache before append requests can be processed in a slightly slow follower thereby making leader read the chunk data from underlying fs/disk very frequently. This leads to slowing down the leader as well as well as overall throughput of the pipeline. 

The idea here is to ensure the data is evicted from the cache only when both followers have caught up with the match index and for that, it will call into stateMachine if the data is cached in the stateMachine. 

This is required for https://issues.apache.org/jira/browse/HDDS-3227.",[],2020-03-18 11:40:04+00:00,,2021-04-20 14:49:38+00:00,Open,13292447,RATIS-829
Wish,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"Follow-up for HDDS-3148:

Ozone startup logs are cluttered by printing stack trace of AlreadyExistsException related to group addition.  Example:

{code}
2020-03-09 13:53:01,563 [grpc-default-executor-0] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - 7a07f161-9144-44b2-8baa-73f0e9299675: Failed groupAdd* GroupManagementRequest:client-27FB1A91809E->7a07f161-9144-44b2-8baa-73f0e9299675@group-E151028E3AC0, cid=2, seq=0, RW, null, Add:group-E151028E3AC0:[18f4e257-bf09-482e-b1bb-a2408a093ff7:172.17.0.2:43845, 7a07f161-9144-44b2-8baa-73f0e9299675:172.17.0.2:41551, 8a66c80e-ab55-4975-92a9-8aaf06ab418a:172.17.0.2:36921]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 7a07f161-9144-44b2-8baa-73f0e9299675: Failed to add group-E151028E3AC0:[18f4e257-bf09-482e-b1bb-a2408a093ff7:172.17.0.2:43845, 7a07f161-9144-44b2-8baa-73f0e9299675:172.17.0.2:41551, 8a66c80e-ab55-4975-92a9-8aaf06ab418a:172.17.0.2:36921] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: 7a07f161-9144-44b2-8baa-73f0e9299675: Failed to add group-E151028E3AC0:[18f4e257-bf09-482e-b1bb-a2408a093ff7:172.17.0.2:43845, 7a07f161-9144-44b2-8baa-73f0e9299675:172.17.0.2:41551, 8a66c80e-ab55-4975-92a9-8aaf06ab418a:172.17.0.2:36921] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
{code}

Since these are ""normal"", I think stack trace should be suppressed.",[],2020-03-13 18:55:35+00:00,2020-04-15 11:02:51+00:00,2020-04-15 11:02:51+00:00,Resolved,13291641,RATIS-828
Improvement,[],elek,Marton Elek,elek,Marton Elek,Critical,"ratis-tools depends on ratis-example project which means that all the projects using ratis-tools can get unexpected dependencies from the example project:

For example I see the following ozone.

{code}
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop/share/ozone/lib/ratis-examples-0.6.0-a320ae0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
{code}

I propose to move the example dependent tools implementation to the example project and make the example project depends on the tools instead of the opposite direction.",[],2020-03-13 11:01:50+00:00,2020-03-16 22:21:36+00:00,2020-03-16 22:21:36+00:00,Resolved,13291533,RATIS-827
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The size of an AppendEntriesRequestProto message can be large since it contains user data.  In such case, the leader have to send large append entry messages to followers.The large messages may increase memory load and processing time.  It is more efficient to stream large messages.",[],2020-03-09 18:09:02+00:00,,2020-03-09 18:09:02+00:00,Open,13290608,RATIS-826
Improvement,[],weichiu,Wei-Chiu Chuang,weichiu,Wei-Chiu Chuang,Major,"guava: 11.0.2 --> 28.2-jre
hadoop: 3.1.1 --> 3.1.3 (for updating transitive guava version)",[],2020-03-05 00:20:30+00:00,,2020-03-05 20:46:50+00:00,Patch Available,13289669,RATIS-825
Improvement,[],weichiu,Wei-Chiu Chuang,weichiu,Wei-Chiu Chuang,Major,"Ran an OWSAP dependency check and a number of dependencies should update:

guava: 24.1-jre --> 28.2jre
hadoop: 3.1.1 --> 3.1.3 (to update guava)
netty: 4.1.38.Final --> 4.1.46.Final
",[],2020-03-04 23:36:09+00:00,2020-03-06 22:11:09+00:00,2020-03-06 22:17:19+00:00,Resolved,13289657,RATIS-824
Bug,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Major,Add the missing links to signatures and hashes here: https://ratis.incubator.apache.org/#download,[],2020-03-04 05:01:56+00:00,,2020-03-07 06:21:11+00:00,Open,13289432,RATIS-823
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Suppose the buffer in BufferedWriteChannel has capacity n and is initially empty.  Calling write(..) with n-byte data will trigger flushInternal().  Then, the buffer becomes empty again.  If flush() is called, it won't trigger FileChannel.force(..) since the buffer is empty.",[],2020-03-04 02:05:11+00:00,2020-03-04 11:44:39+00:00,2020-03-04 11:44:39+00:00,Resolved,13289371,RATIS-822
Bug,[],yjxxtd,runzhiwang,yjxxtd,runzhiwang,Major,This jira is related to the bug of JDK8 https://bugs.openjdk.java.net/browse/JDK-8129861. ,[],2020-03-02 06:27:34+00:00,2020-03-02 12:44:46+00:00,2020-03-02 13:50:11+00:00,Resolved,13288617,RATIS-821
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"
As reported here: https://github.com/apache/incubator-ratis/pull/53",[],2020-02-28 14:52:28+00:00,2020-02-28 14:54:17+00:00,2020-02-28 14:54:38+00:00,Resolved,13288313,RATIS-820
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.ratis.statemachine.RaftSnapshotBaseTest.verifyTakeSnapshotMetric(RaftSnapshotBaseTest.java:257)
	at org.apache.ratis.statemachine.RaftSnapshotBaseTest.testBasicInstallSnapshot(RaftSnapshotBaseTest.java:236)
	...
{code}
It can be reproduced by running TestRaftSnapshotWithSimulatedRpc a few times.",[],2020-02-20 18:32:56+00:00,2020-05-01 22:16:11+00:00,2020-05-01 22:16:11+00:00,Resolved,13286541,RATIS-819
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,[https://ratis.incubator.apache.org/#download] only lists releases up to 0.3.0.  Both 0.4.0 and 0.5.0 are missing.,[],2020-02-20 12:26:45+00:00,2020-02-28 14:47:37+00:00,2020-02-28 14:55:39+00:00,Resolved,13286456,RATIS-818
Bug,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,"Update ratis notice to reflect latest timestamps i.e. to 2020. Thanks [~jmclean] for noticing this during 0.5.0 rc0 vote.

There are two NOTICE files that need to be changed:
1. under %root%/NOTICE.txt
2. under %root%/ratis-assembly/src/main/resources/NOTICE.txt
",[],2020-02-18 19:49:05+00:00,2020-02-28 14:38:32+00:00,2020-02-28 14:38:32+00:00,Resolved,13286086,RATIS-817
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"GrpcServerProtocolClient is used to send out requestVote and appendLogEntry requests.

I propose to persist raftPeerId in the constructor and use it in the error / exception message.

This is not just getting more meaningful message (it's a nice to have) but in HDDS-3023 I am modifying the byte code to mock the leader->follower communication. It's way more easier to do if the required raftPeerId is available in the class.",[],2020-02-17 13:04:10+00:00,2020-03-12 10:59:15+00:00,2020-03-12 10:59:15+00:00,Resolved,13285779,RATIS-816
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Blocker,"After writing a few large keys (128MB) with very small chunks size (64KB) in Ozone, Ratis reports log entry corruption due to checksum error:

{code}
2020-02-13 12:01:41 INFO  SegmentedRaftLogWorker:396 - e5e4fd1e-aa81-48a2-98f9-b1ba24531624@group-B85226EEE236-SegmentedRaftLogWorker: Rolling segment log-62379_62465 to index:62465
2020-02-13 12:01:41 INFO  SegmentedRaftLogWorker:541 - e5e4fd1e-aa81-48a2-98f9-b1ba24531624@group-B85226EEE236-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/f89fc072-9ee9-459b-85d1-b85226eee236/current/log_inprogress_62379 to /data/metadata/ratis/f89fc072-9ee9-459b-85d1-b85226eee236/current/log_62379-62465
2020-02-13 12:01:41 INFO  SegmentedRaftLogWorker:583 - e5e4fd1e-aa81-48a2-98f9-b1ba24531624@group-B85226EEE236-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f89fc072-9ee9-459b-85d1-b85226eee236/current/log_inprogress_62466
2020-02-13 12:01:41 ERROR LogAppender:81 - e5e4fd1e-aa81-48a2-98f9-b1ba24531624@group-B85226EEE236->ac5b3434-874b-4375-8a03-989e8c7fb692-GrpcLogAppender-AppenderDaemon failed RaftLog
org.apache.ratis.server.raftlog.RaftLogIOException: org.apache.ratis.protocol.ChecksumException: Log entry corrupted: Calculated checksum is CDFED097 but read checksum is 00000000.
	at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:311)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.get(SegmentedRaftLog.java:292)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:297)
	at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:213)
	at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:179)
	at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:122)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.ChecksumException: Log entry corrupted: Calculated checksum is CDFED097 but read checksum is 00000000.
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.decodeEntry(SegmentedRaftLogReader.java:312)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.readEntry(SegmentedRaftLogReader.java:194)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogInputStream.nextEntry(SegmentedRaftLogInputStream.java:129)
	at org.apache.ratis.server.raftlog.segmented.LogSegment.readSegmentFile(LogSegment.java:98)
	at org.apache.ratis.server.raftlog.segmented.LogSegment$LogEntryLoader.load(LogSegment.java:202)
	at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:309)
	... 7 more
{code}

Steps to reproduce:

1. Configure Ozone with 64KB chunk size and slightly higher buffer sizes:
    {code}
ozone.scm.chunk.size: 64KB
ozone.client.stream.buffer.flush.size: 256KB
ozone.client.stream.buffer.max.size: 1MB
{code}
2. Run Freon:
    {code}
ozone freon ockg -n 1 -t 1 -p warmup
ozone freon ockg -p test -t 8 -s 134217728 -n 32
{code}

Interestingly, even {{log_5106-5509}} has invalid entry (according to log dump utility):

{code}
Processing Raft Log file: /data/metadata/ratis/f89fc072-9ee9-459b-85d1-b85226eee236/current/log_5106-5509 size:1030796
...
(t:1, i:5161), STATEMACHINELOGENTRY, client-296B6A48E40D, cid=3307
Exception in thread ""main"" org.apache.ratis.protocol.ChecksumException: Log entry corrupted: Calculated checksum is 926127AE but read checksum is 00000000.
{code}",[],2020-02-13 13:18:50+00:00,2020-03-02 17:29:34+00:00,2020-03-04 02:17:55+00:00,Resolved,13285084,RATIS-815
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,TimeoutScheduler creates an instance of ScheduledThreadPoolExecutor with 0 core pool threads. There is a bug in JDK [https://bugs.openjdk.java.net/browse/JDK-8129861] which causes high CPU usage if ScheduledThreadPoolExecutor is instantiated with 0 core pool threads. The bug was fixed in Java 9.,[],2020-02-11 13:04:27+00:00,2020-03-02 12:50:43+00:00,2020-03-02 16:26:10+00:00,Resolved,13284572,RATIS-814
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This is a followup of RATIS-759.  Will add streamAsync(..) here.
{code}
 /** Send the given message using a stream. */
  CompletableFuture<RaftClientReply> streamAsync(Message message);
{code}
",[],2020-02-07 22:24:08+00:00,2020-03-11 11:29:46+00:00,2020-03-11 11:29:46+00:00,Resolved,13284026,RATIS-813
Test,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,"org.apache.ratis.grpc.TestRaftAsyncWithGrpc.testWithLoadAsync
org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc.testRetryOnExceptionDuringReplication
org.apache.ratis.grpc.TestWatchRequestWithGrpc.testWatchRequestClientTimeout
org.apache.ratis.grpc.TestRaftSnapshotWithGrpc.testBasicInstallSnapshot
org.apache.ratis.netty.TestRaftSnapshotWithNetty.testBasicInstallSnapshot

org.apache.ratis.server.simulation.TestRaftSnapshotWithSimulatedRpc.testBasicInstallSnapshot",[],2020-02-06 21:49:55+00:00,,2020-05-03 05:07:35+00:00,Open,13283786,RATIS-812
Test,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,"org.apache.ratis.logservice.server.TestMetaServer.testCloseLogOnNodeFailure
org.apache.ratis.logservice.server.TestMetaServer.testAlreadyExistLog
org.apache.ratis.logservice.server.TestMetaServer.testDeleteLog
org.apache.ratis.logservice.server.TestMetaServer.testListLogs",[],2020-02-06 21:48:14+00:00,,2020-02-06 21:48:14+00:00,Open,13283785,RATIS-811
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"WriteLog is an expensive operation and we should track its execution time in SegmentedRaftLogWorker. We should also track the time we wait on the stateMachineFuture.

 ",[],2020-02-05 11:00:44+00:00,,2020-02-06 01:45:56+00:00,Patch Available,13283443,RATIS-810
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently heartbeats and log appends update the same set of metrics. This leads to dilution of log append metrics as heartbeats are faster and larger in number. The Jira aims to separate these metrics.

The metrics need to be separated for GrpcLogAppender and RaftServerImpl#appendEntriesAsync.",[],2020-02-05 09:54:30+00:00,2020-02-27 09:55:50+00:00,2020-02-27 11:05:03+00:00,Resolved,13283425,RATIS-809
Bug,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,"As a result, the repository id does not match the maven server id specified in the ~/.m2/settings and always got HTTP 401 error returned even though the user/passwd are correct as found INFRA-19819. This ticket is opened to fix it. 

 ",[],2020-02-05 06:05:22+00:00,2020-02-06 21:46:31+00:00,2020-02-06 21:46:31+00:00,Resolved,13283378,RATIS-808
Bug,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Blocker,"Ratis-tools was introduced in RATIS-755. However, it is missing from the assembly src.xml and bin.xml. This breaks the build of bin release from src release. The ticket is opened to fix it. ",[],2020-02-04 00:15:37+00:00,2020-02-04 01:44:08+00:00,2020-02-04 01:44:09+00:00,Resolved,13283072,RATIS-807
Improvement,[],tison,Zili Chen,tison,Zili Chen,Minor,"
{code:java}
diff --git a/ratis-server/src/main/java/org/apache/ratis/server/RaftServerRpc.java b/ratis-server/src/main/java/org/apache/ratis/server/RaftServerRpc.java
index e75c3405..f2c75b86 100644
--- a/ratis-server/src/main/java/org/apache/ratis/server/RaftServerRpc.java
+++ b/ratis-server/src/main/java/org/apache/ratis/server/RaftServerRpc.java
@@ -34,7 +34,7 @@ import java.util.Objects;
  */
 public interface RaftServerRpc extends RaftServerProtocol, RpcType.Get, Closeable {
   /** To build {@link RaftServerRpc} objects. */
-  abstract class Builder<B extends Builder, RPC extends RaftServerRpc> {
+  abstract class Builder<B extends Builder<B, RPC>, RPC extends RaftServerRpc> {
     private RaftServer server;
 
     public RaftServer getServer() {
{code}
",[],2020-02-03 12:28:24+00:00,,2020-02-03 13:29:08+00:00,Patch Available,13282973,RATIS-806
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"[https://github.com/grpc-ecosystem/java-grpc-prometheus] talks about some of the grpc metrics. It will be good to explore if we can add these metrics into ratis as well.

 

PR: [https://github.com/apache/incubator-ratis/pull/159]",[],2020-01-30 14:11:39+00:00,2020-08-04 11:21:06+00:00,2020-08-04 11:21:06+00:00,Resolved,13282384,RATIS-805
Bug,[],elek,Marton Elek,elek,Marton Elek,Critical,"I am doing some kind of stress testing with Ozone. I start one Datanode in FOLLOWER mode and the load generator (Freon) behaves like a LEADER.

I am sending huge number of AppendLogEntries to the FOLLOWER without inhibitions.

As a result I got NPE:
{code:java}
2020-01-28 15:08:20 ERROR StateMachineUpdater:184 - 3fda0c39-ce3c-4540-a804-44d9ac1f4853@group-E1B13B4CA5C0-StateMachineUpdater: the StateMachineUp
dater hits Throwable
org.apache.ratis.server.raftlog.RaftLogIOException: java.lang.NullPointerException
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:320)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.get(SegmentedRaftLog.java:293)
        at org.apache.ratis.server.impl.StateMachineUpdater.applyLog(StateMachineUpdater.java:218)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:167)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
        at java.util.Objects.requireNonNull(Objects.java:203)
        at org.apache.ratis.server.raftlog.segmented.LogSegment$LogEntryLoader.load(LogSegment.java:214)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadCache(LogSegment.java:318)
        ... 4 more {code}
It seems to be a race condition between LogSegment.evictCache() and LogSegment.loadCache().
 # StateMachineUpdater tries to update the StateMachine with the next log entry
 # It can't be found in the cache, therefore the LogSegment.loadCache() is called
 # The LogSegment.LogEntryLoader.load() reads the segment files from the disk
 # After loading, it returns with the loaded entry

If the GRPC thread evicts the cache between 3 and 4. (it's possible that the log segment is already flushed, therefore can be evicted) an NPE will be thrown.",[],2020-01-28 17:01:23+00:00,2020-02-07 23:20:48+00:00,2020-02-07 23:20:48+00:00,Resolved,13281998,RATIS-804
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, there is no metric which tracks the count of how many times the resource limit on the ratis leader . It would be good indicator of system load .",[],2020-01-27 19:08:16+00:00,2020-02-04 10:29:23+00:00,2020-02-04 10:29:23+00:00,Resolved,13281785,RATIS-803
Bug,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"This Jira is to add metric for Pending append requests in GrpcLogAppender.

This will be helpful in knowing the number of outstanding append requests pending per follower in LogAppender.",[],2020-01-24 02:08:01+00:00,2020-01-28 10:28:32+00:00,2020-01-28 10:28:32+00:00,Resolved,13281321,RATIS-802
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, while triggering snapshot, snapshotUpdater#appliedIndex is taken into account to decide whether it has exceeded the snapshot threshold from the last snapshotIndex. This may lead to creating more snapshots than usual as stateMachineUpdater#appliedIndex is updated as soon as the applyTransaction call happens. Ideally, Ratis snapshot should not be triggered taking stateMachine's applied index into account.",[],2020-01-23 09:30:00+00:00,,2021-04-20 14:49:25+00:00,Open,13281148,RATIS-801
Sub-task,[],timmylicheng,Li Cheng,timmylicheng,Li Cheng,Critical,Start a Jira for suggested leader sematics. It would help Ratis performance if it can consume the leader host which its upstream user like Ozone recommends. User can choose the leader host based on load balance and rack awareness. ,[],2020-01-22 06:40:50+00:00,2020-09-01 02:22:53+00:00,2020-09-01 02:22:53+00:00,Resolved,13280904,RATIS-800
Bug,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,This Jira is to implement the exception dependent retry policy in Ratis.,[],2020-01-21 22:31:00+00:00,2020-01-31 17:21:35+00:00,2020-01-31 17:22:07+00:00,Resolved,13280850,RATIS-799
Improvement,[],tison,Zili Chen,tison,Zili Chen,Major,,[],2020-01-17 09:12:40+00:00,2020-01-17 13:00:29+00:00,2020-01-17 13:00:29+00:00,Resolved,13280087,RATIS-798
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Blocker,"While testing ozone, it was observed that ratis segment show corruptions after a server restart
{code:java}
2020-01-08 02:06:46,576 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 1 entries from segment file /metadata/hadoop-ozone/datanode/ratis/data/5e26b460-ca4e-4791-bf70-1fd535056988/current/log_inprogress_0
2020-01-08 02:06:46,576 WARN org.apache.ratis.server.raftlog.segmented.LogSegment: Segment file is corrupted: expected to have 0 entries but only 1 entries read successfully
2020-01-08 02:06:46,580 INFO org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker: 2d422fc8-f7c2-4e41-a59b-abbf76330dfe@group-1FD535056988-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2020-01-08 02:06:46,618 INFO org.eclipse.jetty.util.log: Logging initialized @1978ms
2020-01-08 02:06:46,738 INFO org.apache.ratis.server.RaftServerConfigKeys: raft.server.snaps

2020-01-16 07:51:12,268 WARN org.apache.ratis.server.raftlog.segmented.LogSegment: Segment file is corrupted: expected to have -3668 entries but only 3500 entries read successfully
{code}",[],2020-01-16 16:10:19+00:00,,2021-04-20 14:49:12+00:00,Patch Available,13279864,RATIS-797
Bug,[],bharat,Bharat Viswanadham,bharat,Bharat Viswanadham,Major,"Now in ratis, ratis.client.request.timeout is used for all kind of requests. This Jira is used to add watch time out request parameter to handle for watch requests.",[],2020-01-16 06:01:04+00:00,2020-01-23 08:57:00+00:00,2020-02-01 00:50:45+00:00,Resolved,13279746,RATIS-796
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"Presently an exception thrown during read state machine data causes a RaftLogException to be thrown but we do not notify the state machine.

Downstream in Ozone the state machine is marked unhealthy and there is no way for the follower to recover.
",[],2020-01-15 23:13:19+00:00,2020-01-23 09:02:43+00:00,2020-01-23 09:02:43+00:00,Resolved,13279697,RATIS-795
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"During Ozone testing, it was observed that a leader election happens in between the test , where a follower has caught to a certain index 313. The new leader starts sends an append request to the follower which fails with grpc Exception. This leads to leader reset the connection and start from the beginning (index 1). 
 
 
{code:java}
2020-01-13 14:56:32,995 INFO org.apache.ratis.server.impl.RaftServerImpl: 0.0.0.0:9858@group-4F125BF42C14: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
2020-01-13 14:56:32,995 INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Leader change notification received for group: group-4F125BF42C14 with new leaderId: ed90869c-317e-4303-8922-9fa83a3983cb
2020-01-13 14:56:33,042 WARN org.apache.ratis.grpc.server.GrpcLogAppender: 0.0.0.0:9858@group-4F125BF42C14->10.120.139.111:9858-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2020-01-13 14:56:33,043 DEBUG org.apache.ratis.util.PeerProxyMap: ed90869c-317e-4303-8922-9fa83a3983cb: reset proxy for b65b0b6c-b0bb-429f-a23d-467c72d4b85c
2020-01-13 14:56:33,044 DEBUG org.apache.ratis.util.LifeCycle: b65b0b6c-b0bb-429f-a23d-467c72d4b85c:10.120.139.111:9858: RUNNING -> CLOSING
2020-01-13 14:56:33,044 DEBUG org.apache.ratis.util.LifeCycle: b65b0b6c-b0bb-429f-a23d-467c72d4b85c:10.120.139.111:9858: CLOSING -> CLOSED
2020-01-13 14:56:33,044 DEBUG org.apache.ratis.util.LifeCycle: b65b0b6c-b0bb-429f-a23d-467c72d4b85c:10.120.139.111:9858: NEW
2020-01-13 14:56:33,044 DEBUG org.apache.ratis.util.TimeoutScheduler: new ScheduledThreadPoolExecutor
2020-01-13 14:56:33,044 DEBUG org.apache.ratis.util.PeerProxyMap: ed90869c-317e-4303-8922-9fa83a3983cb: Closing proxy for peer b65b0b6c-b0bb-429f-a23d-467c72d4b85c:10.120.139.111:9858
2020-01-13 14:56:33,045 DEBUG org.apache.ratis.util.TimeoutScheduler: schedule a task: timeout 6000ms, sid 1 
2020-01-13 14:56:33,047 INFO org.apache.ratis.server.impl.FollowerInfo: 0.0.0.0:9858@group-4F125BF42C14->10.120.139.111:9858: nextIndex: updateUnconditionally 314 -> 1 ---------------------> set the next index for the follower back to 1 and  starts from 1)
2020-01-13 14:56:35,840 DEBUG org.apache.ratis.grpc.server.GrpcLogAppender: 0.0.0.0:9858@group-4F125BF42C14->10.120.139.111:9858-AppendLogResponseHandler: received the first reply ed90869c-317e-4303-8922-9fa83a3983cb<-b65b0b6c-b0bb-429f-a23d-467c72d4b85c#2:OK,SUCCESS,nextIndex:314,term:5,followerCommit:313, request=AppendEntriesRequest:cid=2,entriesCount=0,lastEntry=null .  -------------------> (Receives the response from follower indficating follower is at 312)
Although the follower is at 313, the leader keeps on sending the appendRequests from index 1. 
2020-01-13 14:56:35,841 DEBUG org.apache.ratis.server.impl.FollowerInfo: 0.0.0.0:9858@group-4F125BF42C14->10.120.139.111:9858: nextIndex: updateIncreasingly 1 -> 2
2020-01-13 14:56:35,841 DEBUG org.apache.ratis.util.TimeoutScheduler: schedule a task: timeout 6000ms, sid 7
2020-01-13 14:56:35,843 DEBUG org.apache.ratis.server.impl.FollowerInfo: 0.0.0.0:9858@group-4F125BF42C14->10.120.139.111:9858: nextIndex: updateIncreasingly 2 -> 3
2020-01-13 14:56:35,843 DEBUG org.apache.ratis.util.TimeoutScheduler: schedule a task: timeout 6000ms, sid 8
{code}
 ",[],2020-01-15 16:42:42+00:00,2020-02-06 09:31:41+00:00,2020-02-06 09:31:41+00:00,Resolved,13279625,RATIS-794
Improvement,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Critical,"I think this is not an issue of intellj idea, it is caused by that we specified the output directory of grpc.

It is not friendly to new contributors, please fix it.",[],2020-01-15 02:48:06+00:00,2021-03-17 08:40:57+00:00,2021-03-17 08:40:57+00:00,Resolved,13279486,RATIS-793
Bug,[],maobaolong,Baolong Mao,maobaolong,Baolong Mao,Major,"
{code:java}
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.ratis.logservice.util.LogServiceUtils.getPeersFromQuorum(LogServiceUtils.java:43)
	at org.apache.ratis.logservice.server.LogServer.start(LogServer.java:107)
	at org.apache.ratis.logservice.server.LogServer.main(LogServer.java:165)
	Suppressed: java.lang.NullPointerException
		at org.apache.ratis.logservice.server.LogServer.close(LogServer.java:179)
		at org.apache.ratis.logservice.server.LogServer.main(LogServer.java:174)
{code}
",[],2020-01-14 13:10:08+00:00,2020-07-31 17:36:47+00:00,2020-08-03 04:32:07+00:00,Resolved,13279350,RATIS-792
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
""org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$369/802019944@2f87467e"" #152 daemon prio=5 os_prio=0 tid=0x00007f6648271000 nid=0x7aeb waiting on condition [0x00007f65d7803000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000003d82f4208> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.offer(ScheduledThreadPoolExecutor.java:1010)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.add(ScheduledThreadPoolExecutor.java:1037)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.add(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:328)
        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
        at org.apache.ratis.util.TimeoutScheduler$Scheduler.schedule(TimeoutScheduler.java:83)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:155)
        - locked <0x00000003d7ecd4e8> (a org.apache.ratis.util.TimeoutScheduler)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:138)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:191)
        at org.apache.ratis.grpc.server.GrpcLogAppender.sendRequest(GrpcLogAppender.java:203)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:194)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:121)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$369/802019944.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)


""org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$369/802019944@19778529"" #150 daemon prio=5 os_prio=0 tid=0x00007f664826f800 nid=0x7aea waiting for monitor entry [0x00007f65d7904000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:151)
        - waiting to lock <0x00000003d7ecd4e8> (a org.apache.ratis.util.TimeoutScheduler)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:138)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:191)
        at org.apache.ratis.grpc.server.GrpcLogAppender.sendRequest(GrpcLogAppender.java:203)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:194)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:121)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$369/802019944.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
{code}
The GrpcLogAppenders, one for each follower on a ratis leader seem to block to each other because both of them share same instance of TimeoutScheduler 

 

cc [~msingh]",[],2020-01-10 11:50:30+00:00,,2021-04-20 14:48:59+00:00,Open,13278697,RATIS-790
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"{code}
java.util.ConcurrentModificationException
	at java.util.ArrayList.forEach(ArrayList.java:1260)
	at org.apache.ratis.metrics.impl.MetricRegistriesImpl.lambda$create$1(MetricRegistriesImpl.java:66)
	at org.apache.ratis.metrics.impl.RefCountingMap.lambda$put$0(RefCountingMap.java:51)
	at java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1853)
	at org.apache.ratis.metrics.impl.RefCountingMap.put(RefCountingMap.java:46)
	at org.apache.ratis.metrics.impl.MetricRegistriesImpl.create(MetricRegistriesImpl.java:59)
	at org.apache.ratis.server.metrics.RatisMetrics.create(RatisMetrics.java:45)
	at org.apache.ratis.server.metrics.RatisMetrics.getMetricRegistryForLogAppender(RatisMetrics.java:82)
	at org.apache.ratis.server.metrics.LogAppenderMetrics.<init>(LogAppenderMetrics.java:32)
	at org.apache.ratis.server.impl.LeaderState.<init>(LeaderState.java:221)
	at org.apache.ratis.server.impl.RoleInfo.startLeaderState(RoleInfo.java:94)
	at org.apache.ratis.server.impl.RaftServerImpl.changeToLeader(RaftServerImpl.java:348)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:238)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:161)
{code}

(RATIS-788 has more details, if needed)",[],2020-01-10 08:56:02+00:00,2020-01-28 08:23:31+00:00,2020-01-28 08:57:05+00:00,Resolved,13278658,RATIS-789
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Major,"It seems if any exception happens while becoming leader, a single-node Ratis group can get stuck: {{in LEADER state but not ready yet}}.  Or is there some timeout that lets Ratis get out of this state?  I guess 3-node Ratis might be able to recover.

{{LeaderElection}} ignores the exception because it is already shut down after successful vote.

The {{ConcurrentModificationException}} which triggered it in this specific case is being fixed in RATIS-789.

{code}
2020-01-09 23:31:35,161 [Thread-95] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-01-09 23:31:35,165 [Thread-95] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6b60526e-eae6-4f33-854d-fa396187085c: start LeaderElection
2020-01-09 23:31:35,176 [6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1: begin an election at term 1 for -1: [6b60526e-eae6-4f33-854d-fa396187085c:localhost:9872], old=null
2020-01-09 23:31:35,177 [6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6b60526e-eae6-4f33-854d-fa396187085c: shutdown LeaderElection
2020-01-09 23:31:35,178 [6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-01-09 23:31:35,178 [6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E: change Leader from null to 6b60526e-eae6-4f33-854d-fa396187085c at term 1 for becomeLeader, leader elected after 1269ms
...
2020-01-09 23:31:35,217 [6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:run(165)) - 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E-LeaderElection1: ConcurrentModificationException is safely ignored since this is already CLOSING
java.util.ConcurrentModificationException
	at java.util.ArrayList.forEach(ArrayList.java:1260)
	at org.apache.ratis.metrics.impl.MetricRegistriesImpl.lambda$create$1(MetricRegistriesImpl.java:66)
	at org.apache.ratis.metrics.impl.RefCountingMap.lambda$put$0(RefCountingMap.java:51)
	at java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1853)
	at org.apache.ratis.metrics.impl.RefCountingMap.put(RefCountingMap.java:46)
	at org.apache.ratis.metrics.impl.MetricRegistriesImpl.create(MetricRegistriesImpl.java:59)
	at org.apache.ratis.server.metrics.RatisMetrics.create(RatisMetrics.java:45)
	at org.apache.ratis.server.metrics.RatisMetrics.getMetricRegistryForLogAppender(RatisMetrics.java:82)
	at org.apache.ratis.server.metrics.LogAppenderMetrics.<init>(LogAppenderMetrics.java:32)
	at org.apache.ratis.server.impl.LeaderState.<init>(LeaderState.java:221)
	at org.apache.ratis.server.impl.RoleInfo.startLeaderState(RoleInfo.java:94)
	at org.apache.ratis.server.impl.RaftServerImpl.changeToLeader(RaftServerImpl.java:348)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:238)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:161)
	at java.lang.Thread.run(Thread.java:748)
...
2020-01-09 23:31:48,567 ... 6b60526e-eae6-4f33-854d-fa396187085c@group-C5BA1605619E is in LEADER state but not ready yet.
{code}",[],2020-01-10 08:45:33+00:00,,2020-09-26 01:06:13+00:00,Open,13278653,RATIS-788
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,,[],2020-01-09 11:45:01+00:00,,2020-01-09 12:19:13+00:00,Patch Available,13278435,RATIS-787
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"In Ratis, the when a client submits the request, it comes with a call id . Also, when log appender sends a append request to follower , it generates a call id of its own. It seems confusing in the log messages to decipher which call id , its being referred and it would be good idea to change the id which log appender id generates to appendId.",[],2019-12-20 11:52:14+00:00,,2019-12-20 11:52:14+00:00,Open,13275718,RATIS-786
Bug,[],shashikant,Shashikant Banerjee,sammichen,Sammi Chen,Major,"{code:java}
java.lang.IllegalStateException: retry cache entry should be pending: client-7E602ACF0902:70:done
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
        at org.apache.ratis.server.impl.RetryCache.getOrCreateEntry(RetryCache.java:170)
        at org.apache.ratis.server.impl.RaftServerImpl.replyPendingRequest(RaftServerImpl.java:1242)
        at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:1303)
        at org.apache.ratis.server.impl.StateMachineUpdater.applyLog(StateMachineUpdater.java:226)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:167)
        at java.lang.Thread.run(Thread.java:748)
2019-12-20 11:27:24,343 ERROR org.apache.ratis.server.impl.StateMachineUpdater: ed90869c-317e-4303-8922-9fa83a3983cb@group-9D552F016938-StateMachineUpdater: the StateMachineUpdater hits Throwable
java.lang.IllegalStateException: retry cache entry should be pending: client-7E602ACF0902:70:done
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
        at org.apache.ratis.server.impl.RetryCache.getOrCreateEntry(RetryCache.java:170)
        at org.apache.ratis.server.impl.RaftServerImpl.replyPendingRequest(RaftServerImpl.java:1242)
        at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:1303)
        at org.apache.ratis.server.impl.StateMachineUpdater.applyLog(StateMachineUpdater.java:226)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:167)
        at java.lang.Thread.run(Thread.java:748)
{code}
The issue seems to be caused by precondition, where in the the reply future in retry cache is marked complete already where it expects to be in pending state.

 

One possible case, would be like , if the entry gets evicted from cache, we end up creating two different requests (two log entries) for same set of client and call id which is the key to retryCache. If the server now restarts and starts reapplying the transaction, the earlier index might add it to the retryCache but when the apply for the other log index happens, it might already see the future marked complete as for both of them retry cache key would be same.

FYI, the issue happens only after a restart.

cc [~msingh], [~ljain] [~szetszwo]",[],2019-12-20 11:47:44+00:00,2020-01-09 12:38:44+00:00,2020-01-09 12:38:45+00:00,Resolved,13275716,RATIS-785
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, metric for log sync batch size tracks the pendingFlushNum which is reset to 0 after every flush happens and does not define the exact batch size for each log sync. The idea here is to fix this.",[],2019-12-19 10:07:12+00:00,2019-12-20 09:21:56+00:00,2019-12-20 09:22:26+00:00,Resolved,13275458,RATIS-784
Bug,[],nanda,Nanda kumar,nanda,Nanda kumar,Major,"{{RaftServerProxy#groupAddAsync}} removes the existing group on {{AlreadyExistsException}}.
We can log WARN message, but we should not remove the existing group.",[],2019-12-17 16:04:29+00:00,2019-12-19 02:24:18+00:00,2019-12-19 02:24:18+00:00,Resolved,13275045,RATIS-783
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,,[],2019-12-16 16:11:34+00:00,2019-12-17 10:30:56+00:00,2019-12-17 10:30:56+00:00,Resolved,13274793,RATIS-782
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently ResourceSemaphore$Group supports tryAcquire api. It would be good to add an acquire api which blocks on the resources to acquire.,[],2019-12-16 14:38:26+00:00,2020-01-08 06:43:16+00:00,2020-01-08 06:43:53+00:00,Resolved,13274780,RATIS-781
Bug,[],Sammi,Sammi Chen,Sammi,Sammi Chen,Blocker,"The pipeline failed to serve write request after written a bunch of data.
There is no WARN or ERROR messags in datanode log file. 

Client log attached. 
Leader node metrids attached. 





",[],2019-12-11 14:47:25+00:00,2020-05-03 05:22:25+00:00,2020-05-03 05:22:25+00:00,Resolved,13273898,RATIS-780
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently StateMachine#truncateStateMachineData should be called in the constructor of TruncateLog. This makes sure that the function is called with RaftLog write lock held. StateMachine#writeStateMachineData is also called with RaftLog write lock held. It is important for these calls to be synchronized.,[],2019-12-11 10:20:28+00:00,2019-12-18 14:55:04+00:00,2019-12-18 14:55:04+00:00,Resolved,13273833,RATIS-779
Bug,[],Sammi,Sammi Chen,Sammi,Sammi Chen,Critical,The issue is one of the causes of https://issues.apache.org/jira/browse/HDDS-2702. ,[],2019-12-11 09:18:45+00:00,,2019-12-11 14:36:52+00:00,Open,13273808,RATIS-778
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,RATIS-765 propagates AlreadyClosedException to client. Currently the client does not retry on receiving this exception leading to failure of request.,[],2019-12-11 08:56:01+00:00,,2020-01-16 15:28:39+00:00,Open,13273806,RATIS-777
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Ratis leader while processing a client request tries to create a pending request. If it is not able to do so it fails the request with ResourceUnavailableException. But the server keeps processing the other requests from the same client. The resources can be released when the other client requests are processed, resulting in out of order processing of client requests. On failure the server should ideally fail all the client requests which need to be processed.
{code:java}
2019-12-10 19:50:31,846 [grpc-default-executor-5] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:preAppendTransaction(311)) - append seqNum:2 WriteChunk
2019-12-10 19:50:31,860 [grpc-default-executor-5] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:preAppendTransaction(311)) - append seqNum:3 WriteChunk

Caused by: org.apache.ratis.protocol.exceptions.ResourceUnavailableException: 164293f2-68e3-4851-bc46-4a828bd79ffa@group-03010B1A5718: Failed to acquire a pending write request for RaftClientRequest:client-38E7254A5AF1->164293f2-68e3-4851-bc46-4a828bd79ffa@group-03010B1A5718, cid=3, seq=4, RW, Message:000000b2080612343362...(size=182)Caused by: org.apache.ratis.protocol.exceptions.ResourceUnavailableException: 164293f2-68e3-4851-bc46-4a828bd79ffa@group-03010B1A5718: Failed to acquire a pending write request for RaftClientRequest:client-38E7254A5AF1->164293f2-68e3-4851-bc46-4a828bd79ffa@group-03010B1A5718, cid=3, seq=4, RW, Message:000000b2080612343362...(size=182) at org.apache.ratis.server.impl.RaftServerImpl.appendTransaction(RaftServerImpl.java:514) at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:589) at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:333) at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:328) at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109) at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:328) at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981) at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124) at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:327) at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:333) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:221) at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:327) at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:429) at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:421) at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:346) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:241) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168) at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251) at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309) at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292) at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:779) ... 5 more

2019-12-10 19:50:31,860 [grpc-default-executor-5] INFO ratis.ContainerStateMachine (ContainerStateMachine.java:preAppendTransaction(311)) - append seqNum:5 WriteChunk 
{code}
Further while failing the client request server does not invalidate the retry cache. Any retries from the client are therefore ignored in the server.",[],2019-12-11 06:11:49+00:00,2020-01-06 15:56:06+00:00,2020-01-06 15:57:04+00:00,Resolved,13273765,RATIS-776
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Fix checkstyle violations in ratis-netty module,[],2019-12-09 06:18:59+00:00,2020-04-01 12:13:32+00:00,2020-04-01 14:21:49+00:00,Resolved,13273257,RATIS-775
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Fix checkstyle violations in ratis-hadoop module,[],2019-12-09 06:18:36+00:00,2020-04-06 13:12:31+00:00,2020-04-07 02:38:40+00:00,Resolved,13273256,RATIS-774
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Fix checkstyle violations in ratis-server module,[],2019-12-09 06:18:11+00:00,2020-04-28 07:29:44+00:00,2020-04-29 04:14:29+00:00,Resolved,13273255,RATIS-773
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Fix checkstyle violations in ratis-grpc module.,[],2019-12-09 05:50:45+00:00,2020-04-03 17:08:54+00:00,2020-04-07 02:38:17+00:00,Resolved,13273252,RATIS-772
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Trivial,"{code}
Lines that start with ????? in the ASF License  report indicate files that do not have an Apache license header:
 !????? /testptch/ratis/ratis-grpc/src/main/java/org/apache/ratis/grpc/server/tmp
{code}",[],2019-12-05 17:06:24+00:00,2019-12-05 20:46:54+00:00,2019-12-05 21:15:44+00:00,Resolved,13272555,RATIS-771
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Add a precondition that Ratis writeBufferSize is lesser than SegmentSize in Ratis,[],2019-12-05 15:48:49+00:00,,2019-12-05 15:48:49+00:00,Open,13272534,RATIS-770
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"for log lines like 

{code}
2019-12-05 12:06:33,805 INFO impl.RaftServerImpl: ff9ad02f-a8b1-4641-8ddb-fec62ddd3a63@group-6CDAAB81725E: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
{code}

In order to make out if a raft group has 1 or 3 nodes, it will be great to have num nodes as another parameter.",[],2019-12-05 14:28:13+00:00,,2021-01-06 14:20:04+00:00,In Progress,13272516,RATIS-769
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Trivial,"With logging set to

 * trace level, log contains ""message"" and the stack trace
 * info level, log will have ""message: {}"" and the stack trace

I think the intention was to only log the exception message instead of the stack trace at info level.  Otherwise there is no difference between the levels other than the stray placeholder.

{code}
  static void infoOrTrace(Logger log, Supplier<String> message, Throwable t) {
    if (log.isTraceEnabled()) {
      log.trace(message.get(), t);
    } else {
      log.info(""{}: {}"", message.get(), t);
    }
  }
{code}",[],2019-12-05 14:24:13+00:00,2019-12-05 20:49:58+00:00,2019-12-05 21:15:55+00:00,Resolved,13272514,RATIS-768
Bug,[],msingh,Mukul Kumar Singh,rbalamohan,Rajesh Balamohan,Major,"As noticed by Rajesh, Ratis is leaking DirectByteBuffers in BufferedWriteChannel. 

As has been shared in multiple articles on the internet, it is best to allocate pool of direct byte buffers and use them from the pool. Please refer : https://www.javamex.com/tutorials/io/nio_buffer_direct.shtml

This jira introduces a BufferPool to avoid memory leaks

 !Screenshot 2019-10-25 at 12.20.05 PM.png! ",[],2019-12-04 18:09:22+00:00,2019-12-07 06:47:03+00:00,2019-12-07 06:47:03+00:00,Resolved,13272293,RATIS-767
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"TestWatchRequestWithGrpc failed with the below exception. This is a result of assertion added in RATIS-729. In ClientProtoUtils#toRaftClientReplyProto we currently do not propagate AlreadyClosedException in the RaftClientReplyProto.
{code:java}
java.lang.AssertionError: Unexpected exit.

    at org.apache.ratis.util.ExitUtils.assertNotTerminated(ExitUtils.java:109)
    at org.apache.ratis.BaseTest.assertNoFailures(BaseTest.java:75)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.util.ExitUtils$ExitException: Thread[grpc-default-executor-5,5,FailOnTimeoutGroup] has thrown an uncaught exception
    at org.apache.ratis.util.ExitUtils.terminate(ExitUtils.java:141)
    at org.apache.ratis.util.ExitUtils$States.lambda$new$0(ExitUtils.java:54)
    at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1057)
    at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052)
    at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052)
    at java.lang.Thread.dispatchUncaughtException(Thread.java:1959)
Caused by: java.lang.AssertionError: Corruption while serializing reply= RaftClientReply:client-8FD5A15E01C2->s2@group-435584180CC1, cid=6, FAILED org.apache.ratis.protocol.AlreadyClosedException: SlidingWindow$Server:2-OrderedRequestStreamObserver2 is closing: seq = 3 > nextToProcess = -1 will NEVER be processed; request = 3:null, logIndex=0, commits[] but serialized=rpcReply {
  requestorId: ""\357\216\347\031)\304Ii\200\273\217\325\241^\001\302""
  replyId: ""s2""
  raftGroupId {
    id: ""\256\245\022M\323PHF\207\220CU\204\030\f\301""
  }
  callId: 6
}
 and deserialized=RaftClientReply:client-8FD5A15E01C2->s2@group-435584180CC1, cid=6, FAILED null, logIndex=0, commits[]
    at org.apache.ratis.client.impl.ClientProtoUtils.toRaftClientReplyProto(ClientProtoUtils.java:205)
    at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.sendReply(GrpcClientProtocolService.java:355)
    at org.apache.ratis.util.SlidingWindow$RequestMap.endOfRequests(SlidingWindow.java:158)
    at org.apache.ratis.util.SlidingWindow$Server.endOfRequests(SlidingWindow.java:469)
    at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.onCompleted(GrpcClientProtocolService.java:368)
    at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onHalfClose(ServerCalls.java:262)
    at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
    at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
    at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
    at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyClosedException: SlidingWindow$Server:2-OrderedRequestStreamObserver2 is closing: seq = 3 > nextToProcess = -1 will NEVER be processed; request = 3:null
    at org.apache.ratis.util.SlidingWindow$RequestMap.endOfRequests(SlidingWindow.java:155)
    ... 10 more
{code}",[],2019-12-03 09:41:09+00:00,2019-12-05 22:05:25+00:00,2020-01-14 09:27:55+00:00,Resolved,13271902,RATIS-765
Bug,[],pifta,István Fajth,pifta,István Fajth,Major,"After restarting the cluster I have ran into the exception discussed and partly fixed by RATIS-677.
The exception:
{code}
ERROR org.apache.hadoop.ozone.container.common.statemachine.EndpointStateMachine: Unable to communicate to SCM server at <scm_host>:9861 for past X seconds.
org.apache.ratis.protocol.ChecksumException: Log entry corrupted: Calculated checksum is Y but read checksum is 00000000.
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.decodeEntry(SegmentedRaftLogReader.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.readEntry(SegmentedRaftLogReader.java:194)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogInputStream.nextEntry(SegmentedRaftLogInputStream.java:129)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.readSegmentFile(LogSegment.java:98)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadSegment(LogSegment.java:134)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.loadSegment(SegmentedRaftLogCache.java:318)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:252)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:221)
        at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:247)
        at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:191)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:121)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}

The code contains the new option about CorruptionPolicy, however HDDS DataNode does not set this property for the initialised Raft server I will create a separate JIRA for that.
After I modified the code, and specified the {{raft.server.log.corruption.policy}} as {{WARN_AND_RETURN}}, the code properly printed a warning as:

{code}
WARN org.apache.ratis.server.raftlog.segmented.LogSegment: Failed to read segment file /data/3/hadoop-ozone/datanode/ratis/data/9282c3f1-5efa-48e2-8381-af1a20ce871d/current/log_48957-49189 (start=48957, end=49189, isOpen? false): only 127 entries read successfully
org.apache.ratis.protocol.ChecksumException: Log entry corrupted: Calculated checksum is Y but read checksum is 00000000.
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.decodeEntry(SegmentedRaftLogReader.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.readEntry(SegmentedRaftLogReader.java:194)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogInputStream.nextEntry(SegmentedRaftLogInputStream.java:129)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.readSegmentFile(LogSegment.java:98)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadSegment(LogSegment.java:134)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.loadSegment(SegmentedRaftLogCache.java:318)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:252)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:221)
        at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:247)
        at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:191)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:121)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}

But about 1.6 seconds later the system throws the following exception, writing the following log lines in between the warning and the exception:
{code}
INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 127 entries from segment file /data/3/hadoop-ozone/datanode/ratis/data/9282c3f1-5efa-48e2-8381-af1a20ce871d/current/log_48957-49189
INFO org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer: Attempting to start container services.
INFO org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer: Background container scanner has been disabled.
INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Starting XceiverServerRatis ee1c9457-fb78-4a58-8b8d-1a39abee88ff at port 9858
ERROR org.apache.hadoop.ozone.container.common.statemachine.EndpointStateMachine: Unable to communicate to SCM server at <scm_host>:9861 for past X seconds.
java.io.IOException: java.lang.IllegalStateException
        at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
        at org.apache.ratis.util.IOUtils.toIOException(IOUtils.java:61)
        at org.apache.ratis.util.IOUtils.getFromFuture(IOUtils.java:70)
        at org.apache.ratis.server.impl.RaftServerProxy.getImpls(RaftServerProxy.java:284)
        at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:296)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:422)
        at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:215)
        at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:110)
        at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:36)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadSegment(LogSegment.java:156)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.loadSegment(SegmentedRaftLogCache.java:318)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:252)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:221)
        at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:247)
        at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:191)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:121)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
        ... 3 more
{code}

So changing the policy effectively just pushes the issue further down in the LogSegment.load code, where there is an assertion that we were able to read until the end, which is not true if there is a checksum error in the meantime.",[],2019-11-28 16:42:05+00:00,2019-12-16 07:44:51+00:00,2019-12-16 13:21:24+00:00,Resolved,13271265,RATIS-762
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Leader currently does not check for failure of writeStateMachineData after making an appendEntry call. StateMachine#writeStateMachineData returns a completable future which must be checked for normal execution by the leader. In case of a failure the client request must fail.,[],2019-11-26 16:39:21+00:00,,2020-09-20 06:15:03+00:00,Open,13270758,RATIS-761
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,RATIS-648 added metrics for GrpcLogAppender. It is important to track a counter for number of append entries requests that timed out.,[],2019-11-26 05:24:05+00:00,2019-11-27 09:55:06+00:00,2019-12-05 20:45:28+00:00,Resolved,13270620,RATIS-760
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"It is inefficient to send a large message using send(Message)/sendAsync(Message) in RaftClient. We already have RaftOutputStream implemented with sendAsync(..). We propose adding the following new APIs
{code:java}
  /** Create a stream to send a large message. */
  MessageOutputStream stream();

  /** Send the given message using a stream. */
  CompletableFuture<RaftClientReply> streamAsync(Message message);
{code}
Why it is inefficient? Protobuf is not designed to handle large messages; see [https://developers.google.com/protocol-buffers/docs/techniques#large-data]

Some details: Support we create a 100MB protobuf message. Protobuf and Grpc internally create multiple 100MB-buffers. These buffers won't be released until the entire message is processed. If we stream the message using one hundred 1MB-sub-messages. The buffer for the earlier sub-messages can be released when processing the later sub-messages.",[],2019-11-22 00:08:46+00:00,2020-02-07 22:22:54+00:00,2020-09-09 18:34:48+00:00,Resolved,13269975,RATIS-759
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Critical,"Observed the following illegal state transition (using Ratis 0.5.0-d6d58d0-SNAPSHOT):

{code}
2019-11-19 22:57:04,604 INFO impl.RoleInfo: 0b15f105-b523-4d80-ad5c-5dd005e74db0: start LeaderElection
2019-11-19 22:57:04,605 INFO impl.RaftServerImpl: 0b15f105-b523-4d80-ad5c-5dd005e74db0@group-3FF25090045A: changes role from CANDIDATE to FOLLOWER at term 3 for recognizeCandidate:ed65d927-a26b-4755-87c9-8340ec30b69f
2019-11-19 22:57:04,612 INFO impl.RoleInfo: 0b15f105-b523-4d80-ad5c-5dd005e74db0: shutdown LeaderElection
Exception in thread ""0b15f105-b523-4d80-ad5c-5dd005e74db0@group-3FF25090045A-LeaderElection4"" java.lang.IllegalStateException: ILLEGAL TRANSITION: In 0b15f105-b523-4d80-ad5c-5dd005e74db0@group-3FF25090045A-LeaderElection4, RUNNING -> CLOSED
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
	at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:123)
	at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:143)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:151)
{code}",['ozone'],2019-11-20 06:42:56+00:00,2019-11-22 01:06:16+00:00,2019-11-22 06:46:23+00:00,Resolved,13269515,RATIS-758
Improvement,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"[~szetszwo] recommended we remove the native library as it is no longer useful after Java 7.

https://issues.apache.org/jira/browse/RATIS-740?focusedCommentId=16976794&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16976794",[],2019-11-19 20:01:15+00:00,2020-07-21 09:24:57+00:00,2020-08-03 03:26:11+00:00,Resolved,13269382,RATIS-757
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Based on review comment from [~szetszwo], this jira aims to renames the identifiers appropriately.

https://issues.apache.org/jira/browse/RATIS-740?focusedCommentId=16968565&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16968565",[],2019-11-19 19:58:28+00:00,2019-11-26 18:26:42+00:00,2019-11-26 18:26:42+00:00,Resolved,13269381,RATIS-756
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This tool proposes to add a utility to dump the following information to the 

a) log index
b) log term
c) log entry type
d) state machine data if present",['ozone'],2019-11-19 13:36:25+00:00,2020-01-31 09:04:22+00:00,2020-01-31 09:04:22+00:00,Resolved,13269314,RATIS-755
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"If RaftCleintReply encounters an exception other than NotLeaderException, NotReplicatedException, StateMachineException or LeaderNotReady, then it sets success to false but there is no exception set. This causes a Precondition check failure in XceiverClientRatis which expects that there should be an exception if success=false.",[],2019-11-13 22:09:48+00:00,2019-11-13 22:11:33+00:00,2019-11-13 22:11:33+00:00,Resolved,13268143,RATIS-754
Improvement,[],tison,Zili Chen,tison,Zili Chen,Minor,"From the class name I used to think that it is a base class of POJOs. However, actually it works by its {{getContent}} method. It does no harm we mark it as {{@FunctionalInterface}} I think.

I'd like to provide a tiny PR to this issue if you think it is valid. Please assign the issue to me then.",[],2019-11-13 05:07:43+00:00,2019-11-14 15:06:18+00:00,2021-06-10 12:27:35+00:00,Resolved,13267910,RATIS-753
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira updates the ratis thirdparty version to 0.3.0 and also updates the protobuf.version to 3.10.0 and grpc.version to 1.24.0.,[],2019-11-12 10:06:33+00:00,2019-11-12 13:16:39+00:00,2019-11-12 13:16:39+00:00,Resolved,13267653,RATIS-752
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,TestStateMachineShutdownWithGrpc fails with assertion error. After RATIS-614 getState().getLastAppliedIndex() uses stateMachine's lastAppliedIndex. StateMachineWithConditionalWait used in the test does not update the lastAppliedTermIndex on applyTransaction call leading to test failure.,[],2019-11-11 09:39:26+00:00,2019-11-12 22:27:07+00:00,2019-11-12 22:27:07+00:00,Resolved,13267432,RATIS-751
Bug,[],clayb,Clay B.,clayb,Clay B.,Major,"In testing the current master, starting the Ratis server via {{./ratis-examples/src/main/bin/server.sh filestore server --storage $storage --id $id --peers $peers 2>&1 | \}} I end up with the following failure to start:
{code:java}
Found /home/vagrant/incubator-ratis/ratis-examples/target/ratis-examples-0.5.0-SNAPSHOT.jar
2019-11-11 03:27:52 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-11-11 03:27:52 WARN  MetricRegistriesImpl:61 - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
Exception in thread ""main"" java.lang.NoClassDefFoundError: com/codahale/metrics/jvm/GarbageCollectorMetricSet
        at org.apache.ratis.metrics.JVMMetrics.addJvmMetrics(JVMMetrics.java:42)
        at org.apache.ratis.metrics.JVMMetrics.initJvmMetrics(JVMMetrics.java:32)
        at org.apache.ratis.examples.filestore.cli.Server.run(Server.java:60)
        at org.apache.ratis.examples.common.Runner.main(Runner.java:58)
Caused by: java.lang.ClassNotFoundException: com.codahale.metrics.jvm.GarbageCollectorMetricSet
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 4 more
=== Command terminated normally (Mon Nov 11 03:27:52 2019) === {code}
 ",[],2019-11-11 03:28:22+00:00,2019-11-12 13:18:12+00:00,2019-11-12 13:18:12+00:00,Resolved,13267393,RATIS-750
Improvement,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,"{{LogAppender$AppenderDaemon#isRunning}} creates a new array for varargs of {{LifeCycle$State#isOneOf}} upon each call:

{code:title=https://github.com/apache/incubator-ratis/blob/005aa6ab0f7a9051bb4c4a47660bca29ec70aa20/ratis-server/src/main/java/org/apache/ratis/server/impl/LogAppender.java#L98-L100}
    boolean isRunning() {
      return !lifeCycle.getCurrentState().isOneOf(CLOSING, CLOSED, EXCEPTION);
    }
{code}

This is frequently called (indirectly) from the main loop:

{code:title=https://github.com/apache/incubator-ratis/blob/005aa6ab0f7a9051bb4c4a47660bca29ec70aa20/ratis-server/src/main/java/org/apache/ratis/server/impl/LogAppender.java#L450-L451}
  protected void runAppenderImpl() throws InterruptedException, IOException {
    while (isAppenderRunning()) {
{code}

There should be a constant array defined with these states to reduce GC.",['performance'],2019-11-08 21:39:06+00:00,2019-11-19 17:31:28+00:00,2019-11-19 18:42:46+00:00,Resolved,13267195,RATIS-749
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,"While updating the commit index, the follower checks whether majority index is present in the raft log. There can be cases where leader is ahead of the follower and follower does not have the entry corresponding to the majorityIndex. In such cases the follower commit index is not updated. Below is the corresponding code snippet.
{code:java}
public boolean updateLastCommitted(long majorityIndex, long currentTerm) {
  try(AutoCloseableLock writeLock = writeLock()) {
    final long oldCommittedIndex = getLastCommittedIndex();
    if (oldCommittedIndex < majorityIndex) {
      // Only update last committed index for current term. See §5.4.2 in
      // paper for details.
      final TermIndex entry = getTermIndex(majorityIndex);
      if (entry != null && entry.getTerm() == currentTerm) {
        final long newCommitIndex = Math.min(majorityIndex, getFlushIndex());
        if (newCommitIndex > oldCommittedIndex) {
          commitIndex.updateIncreasingly(newCommitIndex, traceIndexChange);
        }
        return true;
      }
    }
  }
  return false;
}{code}
This function RaftLog#updateLastCommitted is also used by follower to update its commit index. The follower does not require the check of entry.getTerm() == currentTerm and its commitIndex can be updated to min(majorityIndex, getFlushIndex()). It has already verified the entries in the appendEntriesAsync call.

This can lead to the follower commit being updated in bursts and can lead to failure of watch requests.

cc [~shashikant] [~szetszwo]",[],2019-11-08 08:29:14+00:00,2019-11-19 15:41:04+00:00,2019-11-19 15:41:04+00:00,Resolved,13267047,RATIS-748
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"This issue was observed and reported by [~hanishakoneru] while working on HDDS-2392.

Datanode restart in an integration test fails with the following exception.

{code}
Caused by: java.lang.IllegalStateException: Not started
	at org.apache.ratis.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:504)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.getPort(ServerImpl.java:176)
	at org.apache.ratis.grpc.server.GrpcService.lambda$new$2(GrpcService.java:143)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.grpc.server.GrpcService.getInetSocketAddress(GrpcService.java:182)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$new$0(RaftServerImpl.java:84)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.server.impl.RaftServerImpl.getPeer(RaftServerImpl.java:136)
	at org.apache.ratis.server.impl.RaftServerMetrics.<init>(RaftServerMetrics.java:70)
	at org.apache.ratis.server.impl.RaftServerMetrics.getRaftServerMetrics(RaftServerMetrics.java:62)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:119)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
Issue Links
{code}",['intermittent'],2019-11-07 19:01:36+00:00,2019-11-08 21:54:43+00:00,2019-11-08 21:55:31+00:00,Resolved,13266895,RATIS-747
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
2019-11-07 02:47:11,452 ERROR org.apache.ratis.server.impl.LogAppender: 61d2e0e1-f3b5-48a9-84f3-0dbef92cb5c7@group-CD36ED82D2AF->6bad43d0-7eb0-43c3-a3ae-218c7a536676-GrpcLogAppender-AppenderDaemon unexpected exception
java.lang.IllegalStateException: node61d2e0e1-f3b5-48a9-84f3-0dbef92cb5c7 is in illegal role FOLLOWER
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.handlePipelineFailure(XceiverServerRatis.java:557)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.handleNodeSlowness(XceiverServerRatis.java:621)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.notifySlowness(ContainerStateMachine.java:830)
        at org.apache.ratis.server.impl.LogAppender.checkSlowness(LogAppender.java:528)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:122)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)
        at java.lang.Thread.run(Thread.java:748)
{code}
This happens right after a leader election where the leader transitions from leader to follower while LogAppender keeps on running and does a slowness check for a follower and see one as slow and try to close the ozone ratis pipeline which assumes that the logAppender instance should be a leader and throws an exception.",[],2019-11-07 11:22:44+00:00,,2019-11-07 22:09:38+00:00,Open,13266810,RATIS-746
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
2019-11-07 02:47:23,938 ERROR org.apache.ratis.server.impl.LogAppender: 61d2e0e1-f3b5-48a9-84f3-0dbef92cb5c7@group-CD36ED82D2AF->332adcba-7bf5-4e34-aa91-20ab8839cae4-GrpcLogAppender-AppenderDaemon unexpected exceptionjava.lang.IllegalArgumentException: 61d2e0e1-f3b5-48a9-84f3-0dbef92cb5c7@group-CD36ED82D2AF-SegmentedRaftLog is expected to be opened but it is CLOSED        at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)        at org.apache.ratis.server.raftlog.RaftLog.checkLogState(RaftLog.java:102)        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:345)        at org.apache.ratis.server.raftlog.RaftLog.getNextIndex(RaftLog.java:148)        at org.apache.ratis.server.impl.LogAppender.shouldAppendEntries(LogAppender.java:544)        at org.apache.ratis.server.impl.LogAppender.shouldSendRequest(LogAppender.java:540)        at org.apache.ratis.grpc.server.GrpcLogAppender.shouldSendRequest(GrpcLogAppender.java:156)        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:103)        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)        at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 61d2e0e1-f3b5-48a9-84f3-0dbef92cb5c7@group-CD36ED82D2AF-SegmentedRaftLog        at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)        at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)        at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)        at org.apache.ratis.server.raftlog.RaftLog.close(RaftLog.java:437)        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.close(SegmentedRaftLog.java:500)        at org.apache.ratis.server.impl.ServerState.close(ServerState.java:389)        at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:275)        at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)        at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:252)        at org.apache.ratis.server.impl.RaftServerProxy.lambda$groupRemoveAsync$12(RaftServerProxy.java:406)        at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)        at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:614)        at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:1983)        at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)        at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)        at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)        at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:140)        at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)        at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:361)        at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)        at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)        at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
{code}",[],2019-11-07 11:18:48+00:00,,2019-11-07 11:18:48+00:00,Open,13266808,RATIS-745
Improvement,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,"What I would think would be an improvement is to somehow fix/remove the dependency on the hadoop-common dependency. To just use ratis-logservice adds an additional 48Mb to your application and adds a lot of potential dependency conflicts.

I believe the addition of the dependency is to get easy access to other solved solutions in hadoop, which is understandable. And hopefully this issue acts as a reminder to do something about it.

Or is the suggested solution to exclude all unwanted dependencies in the build? If so, what are those? And could that be done in Ratis?

Thank you.",[],2019-11-06 11:52:46+00:00,,2019-11-06 22:38:39+00:00,Open,13266564,RATIS-744
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As discussed in RATIS-508, we should omit the default scope so that the downstream modules can get the correct scope from other modules.",[],2019-11-04 22:05:42+00:00,2019-11-06 17:48:21+00:00,2019-11-06 17:48:21+00:00,Resolved,13266200,RATIS-743
New Feature,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,This jira aims to create a contribution.md file which documents how to contribute to Ratis.,[],2019-11-01 03:23:27+00:00,,2019-11-01 03:23:27+00:00,Open,13265680,RATIS-742
New Feature,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Create a basic PR template with following 3 sections:

1. What changes were proposed in this pull request?
2. Link to the Apache JIRA
3. How was this patch tested?

This template is adapted from Apache Hadoop Ozone: https://github.com/apache/hadoop-ozone/blob/master/.github/pull_request_template.md",[],2019-11-01 03:22:00+00:00,2020-05-25 13:29:38+00:00,2020-05-27 03:35:38+00:00,Resolved,13265679,RATIS-741
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Fix checkstyle violations in ratis-common module,[],2019-11-01 01:37:09+00:00,2019-11-19 18:05:49+00:00,2020-05-19 02:30:48+00:00,Resolved,13265665,RATIS-740
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Leader should notify state machine about log append completion events. This can be used in Ozone to control the behaviour of container state machine cache.,['ozone'],2019-10-31 13:07:48+00:00,,2019-11-20 13:18:38+00:00,Patch Available,13265530,RATIS-739
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,See https://github.com/apache/incubator-ratis/pull/41,[],2019-10-30 17:03:46+00:00,2019-10-30 17:07:08+00:00,2019-10-30 17:07:08+00:00,Resolved,13265343,RATIS-738
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,,[],2019-10-30 11:26:46+00:00,2020-04-17 08:39:43+00:00,2020-04-17 08:39:43+00:00,Resolved,13265271,RATIS-737
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In HDFS-3504, we first tried to implement exponential backoff retry policy but found that the later retries will need to wait for a very long time (since it is exponential).  We then implement a MultipleLinearRandomRetry.  We should do the same here.",[],2019-10-26 00:16:59+00:00,2019-11-20 14:41:11+00:00,2019-11-20 17:14:21+00:00,Resolved,13264573,RATIS-736
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,,[],2019-10-25 17:34:54+00:00,2019-10-31 05:00:41+00:00,2019-10-31 05:00:52+00:00,Resolved,13264509,RATIS-735
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Attached the stdout.

 

Originally seen during CI run of RATIS-694",[],2019-10-24 03:26:33+00:00,2019-10-24 18:38:08+00:00,2019-10-24 18:38:08+00:00,Resolved,13264167,RATIS-734
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Attached the stdout.

 

Originally seen during CI run of RATIS-694",[],2019-10-24 03:23:55+00:00,2019-10-24 18:11:12+00:00,2019-10-24 18:11:13+00:00,Resolved,13264166,RATIS-733
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Attached the stdout.

 

Originally seen during CI run of RATIS-694",[],2019-10-24 03:22:43+00:00,2019-10-24 18:10:07+00:00,2019-10-24 18:11:31+00:00,Resolved,13264165,RATIS-732
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Attached the stdout.

 

Originally seen during CI run of RATIS-694",[],2019-10-24 03:19:58+00:00,2019-11-18 04:51:16+00:00,2019-11-18 04:51:16+00:00,Resolved,13264164,RATIS-731
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,Jira to fix checkstyle violations in ratis-examples module,[],2019-10-24 03:10:13+00:00,2019-11-22 21:16:47+00:00,2020-04-09 04:18:30+00:00,Resolved,13264163,RATIS-730
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"In one of the runs it is seen that client receives RaftClientReply with exception as null and success flag as false. This happens because currently ClientProtoUtils#toRaftClientReplyProto only considers a few RaftException types while creating a RaftClientReplyProto. We should also add handling for other exception types.Similar changes will be required in ClientProtoUtils#toRaftClientReply.

We will also need to add handling for these exceptions in the client code.",[],2019-10-23 07:36:35+00:00,2019-11-29 00:24:16+00:00,2019-11-29 00:24:16+00:00,Resolved,13263951,RATIS-729
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"As discussed in RATIS-726, we need a similar fix for Append Request in GrpcLogAppender to remove the references to appendEntryRequest as soon as the response is received, thereby avoiding any memory pressure creation on the server.",[],2019-10-23 07:13:42+00:00,2019-10-24 10:13:51+00:00,2019-10-24 14:15:08+00:00,Resolved,13263946,RATIS-728
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,In a heap dump it could be seen that a client request retries on the same follower multiple times and every time the request is rejected with a NotLeaderException. In case of Ozone it is a WriteChunk request which leads to garbage collection of 16MB for every request. In the heap dump a client request retries multiple times leading to garbage collection of ~100MB.,[],2019-10-21 19:32:34+00:00,,2019-11-25 09:21:49+00:00,Open,13263639,RATIS-727
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"While running freon with 1 Node ratis, it was observed that the TimeoutScheduler holds on to the raftClientObject atleast for 3s(default for requestTimeoutDuration) even though the request is processed successfully and acknowledged back. This ends up creating a memory pressure causing ozone client to go OOM .

 Heapdump analysis of HDDS-2331 , it seems the timeout schduler holding onto total of 176 requests, (88 of writeChunk containing actual data and 88 putBlock requests) although data write is happening sequentially key by key in ozone.

Thanks [~adoroszlai] for helping out discovering this.

cc ~ [~ljain] [~msingh] [~szetszwo] [~jnpandey]

Similar fix may be required in GrpCLogAppender as well it uses the same TimeoutScheduler.",[],2019-10-21 15:57:54+00:00,2019-10-23 11:52:29+00:00,2019-10-24 18:12:01+00:00,Resolved,13263590,RATIS-726
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,RaftServerImpl#appendEntriesAsync(AppendEntriesRequestProto r) currently converts the LogEntryProto list to an array. We can avoid the array conversion and use the original list itself.,[],2019-10-21 13:42:43+00:00,,2019-10-22 05:01:36+00:00,Open,13263553,RATIS-725
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Blocker,"{code:java}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e9477db3-627c-447b-9726-7a0202331e44@group-284D2F681BFD is not in [RUNNING]: current state is NEWjava.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e9477db3-627c-447b-9726-7a0202331e44@group-284D2F681BFD is not in [RUNNING]: current state is NEW at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259) at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197) at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e9477db3-627c-447b-9726-7a0202331e44@group-284D2F681BFD is not in [RUNNING]: current state is NEW at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139) at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265) at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99) at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204) at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 more2019-10-21 17:40:18,702 [4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1 got exception when requesting votes: {}java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998885738ns at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259) at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197) at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998885738ns at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139) at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265) at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99) at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204) at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 more2019-10-21 17:40:18,705 [4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1: Election REJECTED; received 0 response(s) [] and 2 exception(s); 4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD:t1, leader=null, voted=4ed74939-427d-455d-852a-df3499c9dbb2, raftlog=4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [4ed74939-427d-455d-852a-df3499c9dbb2:192.168.29.38:50945, 31cc45f0-16ea-48bc-b870-9e866f150589:192.168.29.38:50943, e9477db3-627c-447b-9726-7a0202331e44:192.168.29.38:50944], old=null2019-10-21 17:40:18,705 [4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e9477db3-627c-447b-9726-7a0202331e44@group-284D2F681BFD is not in [RUNNING]: current state is NEW at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259) at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197) at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e9477db3-627c-447b-9726-7a0202331e44@group-284D2F681BFD is not in [RUNNING]: current state is NEW at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139) at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265) at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99) at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204) at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 more2019-10-21 17:40:18,705 [4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998885738ns at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259) at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197) at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998885738ns at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139) at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265) at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99) at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204) at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 more2019-10-21 17:40:18,708 [4ed74939-427d-455d-852a-df3499c9dbb2@group-284D2F681BFD-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4ed74939-427d-455d-85
{code}
This was observed while running ozone with ratis snapshot",[],2019-10-21 13:12:51+00:00,2019-10-23 07:12:39+00:00,2019-10-23 07:12:39+00:00,Resolved,13263537,RATIS-724
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RATIS-702 has changed metrics to be pluggable.  Metrics related tests are failing.,[],2019-10-19 08:21:26+00:00,2019-10-21 14:41:03+00:00,2019-10-22 05:59:38+00:00,Resolved,13263312,RATIS-723
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
2019-10-16 23:28:21,517 WARN org.apache.ratis.server.impl.LogAppender: 7cd8590b-b724-4d53-8888-a565ab6706c7@group-398C6C673F7A->5949f017-d0b5-47ad-90c9-26b0b1981551: Failed to get (t:59, i:1569), STATEMACHINELOGENTRY, client-17EF628BF6BC, cid=191 in 2499999948ns: {}
java.util.concurrent.TimeoutException
        at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
        at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
        at org.apache.ratis.server.raftlog.RaftLog$EntryWithData.getEntry(RaftLog.java:472)
        at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:134)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:220)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:175)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:119)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)
        at java.lang.Thread.run(Thread.java:748)
2019-10-16 23:28:21,542 INFO org.apache.ratis.grpc.client.GrpcClientProtocolService: Failed RaftClientRequest:client-DBF59FE01BBD->7cd8590b-b724-4d53-8888-a565ab6706c7@group-398C6C673F7A, cid=219, seq=0, Watch-ALL_COMMITTED(1262), Message:<EMPTY>, reply=RaftClientReply:client-DBF59FE01BBD->7cd8590b-b724-4d53-8888-a565ab6706c7@group-398C6C673F7A, cid=219, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 219 and log index 1262 is not yet replicated to ALL_COMMITTED, logIndex=1262, commits[7cd8590b-b724-4d53-8888-a565ab6706c7:c1702, 3b9b7dee-f9c7-48e0-af14-5c043e050b84:c1641, 5949f017-d0b5-47ad-90c9-26b0b1981551:c269]
{code}",[],2019-10-17 19:19:24+00:00,,2021-04-20 14:47:24+00:00,Open,13262934,RATIS-722
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major," 
{code:java}
Exception in thread ""org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$343/1887343319@7c2935ab"" java.lang.IllegalStateException: ILLEGAL TRANSITION: In 7cd8590b-b724-4d53-8888-a565ab6706c7@group-E476037E5613->3b9b7dee-f9c7-48e0-af14-5c043e050b84-GrpcLogAppender-AppenderDaemon, CLOSING -> EXCEPTION
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
	at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:123)
	at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:143)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:81)
	at java.lang.Thread.run(Thread.java:748)

{code}
 ",[],2019-10-17 10:15:18+00:00,,2019-10-18 05:45:29+00:00,Open,13262826,RATIS-721
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major," 
{code:java}
Oct 16, 2019 1:42:50 PM org.apache.ratis.thirdparty.io.grpc.netty.NettyServerHandler onStreamError
WARNING: Stream Error
org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception$StreamException: Received DATA frame for an unknown stream 3
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:129)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.shouldIgnoreHeadersOrDataFrame(DefaultHttp2ConnectionDecoder.java:531)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onDataRead(DefaultHttp2ConnectionDecoder.java:183)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onDataRead(Http2InboundFrameLogger.java:48)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readDataFrame(DefaultHttp2FrameReader.java:421)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:251)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:390)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:450)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441)
	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

{code}
 ",[],2019-10-17 10:13:50+00:00,,2019-10-18 05:46:53+00:00,Open,13262825,RATIS-720
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major," 
{code:java}
Exception in thread ""org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$343/1887343319@5d317807"" java.lang.IllegalArgumentException: 7cd8590b-b724-4d53-8888-a565ab6706c7@group-E476037E5613-SegmentedRaftLog is expected to be opened but it is CLOSED
	at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
	at org.apache.ratis.server.raftlog.RaftLog.checkLogState(RaftLog.java:102)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:345)
	at org.apache.ratis.server.raftlog.RaftLog.getNextIndex(RaftLog.java:148)
	at org.apache.ratis.server.impl.LeaderState.addAndStartSenders(LeaderState.java:384)
	at org.apache.ratis.server.impl.LeaderState.restartSender(LeaderState.java:410)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:93)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 7cd8590b-b724-4d53-8888-a565ab6706c7@group-E476037E5613-SegmentedRaftLog
	at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
	at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
	at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
	at org.apache.ratis.server.raftlog.RaftLog.close(RaftLog.java:437)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.close(SegmentedRaftLog.java:500)
	at org.apache.ratis.server.impl.ServerState.close(ServerState.java:389)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:275)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:252)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$groupRemoveAsync$12(RaftServerProxy.java:406)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:614)
	at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:1983)
	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:140)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:361)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

{code}
 ",[],2019-10-17 10:11:43+00:00,,2019-10-18 05:49:03+00:00,Open,13262820,RATIS-719
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Blocker,"{code:java}
Shashikant Banerjee 10:38 AM2019-10-16 11:45:43,150 ERROR [java.util.concurrent.ThreadPoolExecutor$Worker@5d45ac64[State = -1, empty queue]] org.apache.ratis.client.impl.OrderedAsync: Failed* to retry RaftClientRequest:client-A67D4B37A25B->afda84a7-3b53-4b20-bd3b-5400b60a5014@group-DC6EDD5625BC, cid=9, seq=3*, RW, ...
java.lang.IllegalStateException
    at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:36)
    at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:124)
    at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:110)
    at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:180)
    at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.onNext(GrpcClientProtocolClient.java:318)
    at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:68)
    at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
    at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
    at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
    at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
    at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
    at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
    at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
    at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
    at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
{code}",[],2019-10-17 06:47:36+00:00,2019-10-22 07:44:02+00:00,2019-10-22 07:44:37+00:00,Resolved,13262779,RATIS-718
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"Error thrown while running Teragen on Ozone cluster.

{code}
Error getting metrics from source ratis_core.ratis_leader.3b9b7dee-f9c7-48e0-af14-5c043e050b84@group-C1E270F4213F
java.lang.NullPointerException
    at org.apache.ratis.server.impl.RaftLeaderMetrics.lambda$null$2(RaftLeaderMetrics.java:86)
    at com.github.joshelser.dropwizard.metrics.hadoop.HadoopMetrics2Reporter.snapshotAllMetrics(HadoopMetrics2Reporter.java:239)
    at com.github.joshelser.dropwizard.metrics.hadoop.HadoopMetrics2Reporter.getMetrics(HadoopMetrics2Reporter.java:219)
    at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:200)
    at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotMetrics(MetricsSystemImpl.java:419)
    at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.sampleMetrics(MetricsSystemImpl.java:406)
    at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.onTimerEvent(MetricsSystemImpl.java:381)
    at org.apache.hadoop.metrics2.impl.MetricsSystemImpl$4.run(MetricsSystemImpl.java:368)
    at java.util.TimerThread.mainLoop(Timer.java:555)
    at java.util.TimerThread.run(Timer.java:505)
{code}",[],2019-10-17 05:48:10+00:00,2019-10-18 10:16:35+00:00,2019-10-18 10:16:36+00:00,Resolved,13262771,RATIS-717
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,RetryCache$CacheEntry$replyFuture holds onto RaftClientRequest until eviction. Multiple cache entries can hold a lot of memory thus leading to GC pauses.,[],2019-10-15 17:42:36+00:00,2019-10-17 02:59:26+00:00,2019-10-17 02:59:27+00:00,Resolved,13262420,RATIS-716
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,The pendingRequestsMap currently maintains all the AppendEntryRequests sent to a follower until they timeout. These contain LogEntryProto and hence contain references to the state machine data. Only the metadata of the request should be stored in the log appender map.,[],2019-10-14 13:30:19+00:00,2019-10-24 14:12:23+00:00,2019-10-24 14:12:23+00:00,Resolved,13262159,RATIS-715
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In PendingRequests, the number of outstanding requests is limited but the byte size is not.   The byte size should also be limited in order to avoid out of memory.",[],2019-10-14 09:55:03+00:00,2019-10-28 22:23:16+00:00,2019-10-28 22:23:16+00:00,Resolved,13262123,RATIS-714
Bug,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,"[ERROR] TestInstallSnapshotNotificationWithGrpc>InstallSnapshotNotificationTests.testRestartFollower:193->InstallSnapshotNotificationTests.testRestartFollower:204 » TestTimedOut
[ERROR] TestRaftAsyncWithGrpc>RaftAsyncTests.testWithLoadAsync:258->RaftAsyncTests.lambda$testWithLoadAsync$7:259 » TestTimedOut
[ERROR] TestWatchRequestWithGrpc>WatchRequestTests.testWatchRequestAsyncChangeLeader:295->WatchRequestTests.lambda$testWatchRequestAsyncChangeLeader$6:296->WatchRequestTests.runTest:124->WatchRequestTests.runTestWatchRequestAsyncChangeLeader:330->WatchRequestTests.checkAll:263 » Timeout

 ",[],2019-10-12 22:17:34+00:00,,2019-10-12 22:17:34+00:00,Open,13261970,RATIS-713
Bug,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,"[ERROR] TestRaftStateMachineExceptionWithSimulatedRpc>RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication:145->RaftStateMachineExceptionTests.runTestRetryOnExceptionDuringReplication:170 » NullPointer
[INFO]",[],2019-10-12 22:13:38+00:00,,2019-10-12 22:13:38+00:00,Open,13261969,RATIS-712
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently , a watch request from raft client times out by default in 3 sec . In certain conditions, it may be required to have a higher watch request timeout value.

This will require having a separate timeout for the watch request.",[],2019-10-11 17:37:54+00:00,,2019-11-25 23:58:29+00:00,Open,13261854,RATIS-711
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Critical,"In ozone perf testing, it was observed that once leader goes through gc pause cycle and wakes up, it just times out all append requests , but the follower seems to be processing the append requests fine. It goes in a loop and ends up failing the watch requests on the leader.",[],2019-10-11 17:21:56+00:00,2019-10-31 13:21:10+00:00,2019-10-31 13:21:10+00:00,Resolved,13261845,RATIS-710
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Blocker,"Currently, when a watch request times out with a NotReplicatedException on the leader raft client starts retrying the request on different server and starts failing with NotLeaderException and it goes in a loop. Ideally , when a watch request times out , it should not be retried automatically by raft client given the timeout value in the leader is sufficiently reasonable.",[],2019-10-11 17:17:30+00:00,2020-04-08 14:17:59+00:00,2020-04-08 14:17:59+00:00,Resolved,13261843,RATIS-709
Test,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Minor,ClientProtoUtils#toRaftClientRequestProto in the profiling is taking a lot of time to process.,[],2019-10-11 06:20:40+00:00,2019-10-24 21:49:53+00:00,2019-10-24 21:49:53+00:00,Resolved,13261704,RATIS-708
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"TestRaftAsyncWithGrpc#testBasicAppendEntriesAsync and other tests fail if the initial minTimeout is 0 then the server can trigger a leader election much more frequently because the heartbeat interval is still at minTimeoutMs/2

{code}
2019-10-11 00:45:47,813 INFO  impl.FollowerState (FollowerState.java:run(108)) - s0@group-C51B0F2AC202-FollowerState: change to CANDIDATE, lastRpcTime:21ms, electionTimeout:17ms
2019-10-11 00:45:47,870 INFO  impl.FollowerState (FollowerState.java:run(108)) - s0@group-C51B0F2AC202-FollowerState: change to CANDIDATE, lastRpcTime:35ms, electionTimeout:31ms
2019-10-11 00:45:47,933 INFO  impl.FollowerState (FollowerState.java:run(108)) - s0@group-C51B0F2AC202-FollowerState: change to CANDIDATE, lastRpcTime:51ms, electionTimeout:51ms
2019-10-11 00:45:47,969 INFO  impl.FollowerState (FollowerState.java:run(108)) - s0@group-C51B0F2AC202-FollowerState: change to CANDIDATE, lastRpcTime:22ms, electionTimeout:21ms
{code}",[],2019-10-10 20:05:43+00:00,2019-10-15 09:21:20+00:00,2019-10-23 11:13:35+00:00,Resolved,13261641,RATIS-707
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"I started an Ozone cluster on Kubernetes and started a freon test (ozone freon ockg -n10000)

After a while I found that the one freon instance is not creating keys any more. I checked the om RPC endpoint with ozone insight and no RPC messages has been arrived.

Based on the jstack output we have a deadlock between PeerProxyMap.handleException and GrpcClientRpc.sendRequestAsync.

I am not sure (yet) what is the exact problem, but based on the stack traces It seems to be Ratis related.

{code}
Found one Java-level deadlock:
=============================
""pool-2-thread-6"":
  waiting to lock monitor 0x00007f80356c8800 (object 0x000000033eb70a00, a java.lang.Object),
  which is held by ""java.util.concurrent.ThreadPoolExecutor$Worker@77329f41[State = -1, empty queue]""
""java.util.concurrent.ThreadPoolExecutor$Worker@77329f41[State = -1, empty queue]"":
  waiting to lock monitor 0x0000000001170980 (object 0x000000033eb99b10, a org.apache.ratis.util.SlidingWindow$Client),
  which is held by ""java.util.concurrent.ThreadPoolExecutor$Worker@df368f8[State = -1, empty queue]""
""java.util.concurrent.ThreadPoolExecutor$Worker@df368f8[State = -1, empty queue]"":
  waiting to lock monitor 0x00007f80356c8800 (object 0x000000033eb70a00, a java.lang.Object),
  which is held by ""java.util.concurrent.ThreadPoolExecutor$Worker@77329f41[State = -1, empty queue]""

Java stack information for the threads listed above:
===================================================
""pool-2-thread-6"":
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:103)
	- waiting to lock <0x000000033eb70a00> (a java.lang.Object)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsyncUnordered(GrpcClientRpc.java:78)
	at org.apache.ratis.client.impl.UnorderedAsync.sendRequestWithRetry(UnorderedAsync.java:75)
	at org.apache.ratis.client.impl.UnorderedAsync.send(UnorderedAsync.java:59)
	at org.apache.ratis.client.impl.RaftClientImpl.sendWatchAsync(RaftClientImpl.java:139)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:282)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
	- locked <0x00000003f2ba4240> (a org.apache.hadoop.ozone.client.io.OzoneOutputStream)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.createKey(RandomKeyGenerator.java:710)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.access$1100(RandomKeyGenerator.java:88)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator$ObjectCreator.run(RandomKeyGenerator.java:615)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.3/Executors.java:515)
	at java.util.concurrent.FutureTask.run(java.base@11.0.3/FutureTask.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.3/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.3/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@11.0.3/Thread.java:834)
""java.util.concurrent.ThreadPoolExecutor$Worker@77329f41[State = -1, empty queue]"":
	at org.apache.ratis.util.SlidingWindow$Client.resetFirstSeqNum(SlidingWindow.java:348)
	- waiting to lock <0x000000033eb99b10> (a org.apache.ratis.util.SlidingWindow$Client)
	at org.apache.ratis.client.impl.OrderedAsync.resetSlidingWindow(OrderedAsync.java:121)
	at org.apache.ratis.client.impl.OrderedAsync$$Lambda$496/0x0000000840498440.accept(Unknown Source)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$handleIOException$6(RaftClientImpl.java:349)
	at org.apache.ratis.client.impl.RaftClientImpl$$Lambda$427/0x00000008402e1840.accept(Unknown Source)
	at java.util.Optional.ifPresent(java.base@11.0.3/Optional.java:183)
	at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:349)
	at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequest$10(OrderedAsync.java:236)
	at org.apache.ratis.client.impl.OrderedAsync$$Lambda$358/0x00000008402d7040.apply(Unknown Source)
	at java.util.concurrent.CompletableFuture.uniExceptionally(java.base@11.0.3/CompletableFuture.java:986)
	at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(java.base@11.0.3/CompletableFuture.java:970)
	at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.3/CompletableFuture.java:506)
	at java.util.concurrent.CompletableFuture.completeExceptionally(java.base@11.0.3/CompletableFuture.java:2088)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:345)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.close(GrpcClientProtocolClient.java:334)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$400(GrpcClientProtocolClient.java:261)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$close$1(GrpcClientProtocolClient.java:141)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$$Lambda$435/0x00000008402d1c40.accept(Unknown Source)
	at java.util.Optional.ifPresent(java.base@11.0.3/Optional.java:183)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.close(GrpcClientProtocolClient.java:141)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$close$1(PeerProxyMap.java:74)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy$$Lambda$430/0x00000008402e1440.run(Unknown Source)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle$$Lambda$433/0x00000008402d1040.get(Unknown Source)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.close(PeerProxyMap.java:70)
	- locked <0x000000008c1ba0e8> (a org.apache.ratis.util.PeerProxyMap$PeerAndProxy)
	at org.apache.ratis.util.PeerProxyMap.resetProxy(PeerProxyMap.java:127)
	- locked <0x000000033eb70a00> (a java.lang.Object)
	at org.apache.ratis.util.PeerProxyMap.handleException(PeerProxyMap.java:136)
	at org.apache.ratis.client.impl.RaftClientRpcWithProxy.handleException(RaftClientRpcWithProxy.java:47)
	at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:372)
	at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequest$10(OrderedAsync.java:236)
	at org.apache.ratis.client.impl.OrderedAsync$$Lambda$358/0x00000008402d7040.apply(Unknown Source)
	at java.util.concurrent.CompletableFuture.uniExceptionally(java.base@11.0.3/CompletableFuture.java:986)
	at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(java.base@11.0.3/CompletableFuture.java:970)
	at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.3/CompletableFuture.java:506)
	at java.util.concurrent.CompletableFuture.completeExceptionally(java.base@11.0.3/CompletableFuture.java:2088)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$3(GrpcClientProtocolClient.java:324)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$$Lambda$490/0x000000084049f040.accept(Unknown Source)
	at java.util.Optional.ifPresent(java.base@11.0.3/Optional.java:183)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:329)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:324)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:318)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$$Lambda$336/0x00000008403b2040.run(Unknown Source)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
	at org.apache.ratis.util.TimeoutScheduler$$Lambda$345/0x00000008403ac440.accept(Unknown Source)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
	at org.apache.ratis.util.TimeoutScheduler$$Lambda$349/0x00000008403a1440.run(Unknown Source)
	at org.apache.ratis.util.LogUtils$1$$Lambda$448/0x00000008402d6840.run(Unknown Source)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.3/Executors.java:515)
	at java.util.concurrent.FutureTask.run(java.base@11.0.3/FutureTask.java:264)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(java.base@11.0.3/ScheduledThreadPoolExecutor.java:304)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.3/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.3/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@11.0.3/Thread.java:834)
""java.util.concurrent.ThreadPoolExecutor$Worker@df368f8[State = -1, empty queue]"":
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:103)
	- waiting to lock <0x000000033eb70a00> (a java.lang.Object)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:208)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:169)
	at org.apache.ratis.client.impl.OrderedAsync$$Lambda$449/0x00000008402d6c40.accept(Unknown Source)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
	at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:294)
	- locked <0x000000033eb99b10> (a org.apache.ratis.util.SlidingWindow$Client)
	at org.apache.ratis.client.impl.OrderedAsync.lambda$scheduleWithTimeout$7(OrderedAsync.java:195)
	at org.apache.ratis.client.impl.OrderedAsync$$Lambda$444/0x00000008402d4840.run(Unknown Source)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
	at org.apache.ratis.util.TimeoutScheduler$$Lambda$345/0x00000008403ac440.accept(Unknown Source)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
	at org.apache.ratis.util.TimeoutScheduler$$Lambda$349/0x00000008403a1440.run(Unknown Source)
	at org.apache.ratis.util.LogUtils$1$$Lambda$448/0x00000008402d6840.run(Unknown Source)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.3/Executors.java:515)
	at java.util.concurrent.FutureTask.run(java.base@11.0.3/FutureTask.java:264)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(java.base@11.0.3/ScheduledThreadPoolExecutor.java:304)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.3/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.3/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@11.0.3/Thread.java:834)

Found 1 deadlock.
{code}",[],2019-10-10 14:40:24+00:00,2019-10-17 18:29:46+00:00,2019-10-17 18:29:46+00:00,Resolved,13261582,RATIS-706
Bug,[],ljain,Lokesh Jain,nilotpalnandi,Nilotpal Nandi,Major,"GrpcClientProtocolClient#close throws InterruptedException. This happens when GrpcClientProtocolClient#close is called from a TimeoutScheduler thread. GrpcClientProtocolClient#close calls scheduler.close() which interrupts all the timeout scheduler threads including the thread executing the close routine. This leads to InterruptedException when channel.awaitTermination is called.

 
{code:java}
19/10/09 07:40:33 ERROR client.GrpcClientProtocolClient: Unexpected exception while waiting for channel termination
java.lang.InterruptedException
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)
        at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImpl.awaitTermination(ManagedChannelImpl.java:763)
        at org.apache.ratis.thirdparty.io.grpc.internal.ForwardingManagedChannel.awaitTermination(ForwardingManagedChannel.java:57)
        at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.awaitTermination(ManagedChannelOrphanWrapper.java:70)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient.close(GrpcClientProtocolClient.java:146)
        at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$close$1(PeerProxyMap.java:74)
        at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
        at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.close(PeerProxyMap.java:70)
        at org.apache.ratis.util.PeerProxyMap.resetProxy(PeerProxyMap.java:127)
        at org.apache.ratis.util.PeerProxyMap.handleException(PeerProxyMap.java:136)
        at org.apache.ratis.client.impl.RaftClientRpcWithProxy.handleException(RaftClientRpcWithProxy.java:47)
        at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:372)
        at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequest$10(OrderedAsync.java:236)
        at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870)
        at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852)
        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$3(GrpcClientProtocolClient.java:324)
        at java.util.Optional.ifPresent(Optional.java:159)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:329)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:324)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:318)
        at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113)
        at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133)
        at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
        at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}
 

 ",[],2019-10-10 06:25:17+00:00,2019-10-11 08:38:05+00:00,2019-10-11 08:38:19+00:00,Resolved,13261496,RATIS-705
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In OrderedAsync, the messages are sent asynchronously except for the first message.  The first message is used to establish the connection.  OrderedAsync will wait for the first message to complete before sending the following messages.

Note that, when sending only two messages, the performance of sending the messages asynchronously is degenerated to sending them sequentially 

[~msingh] has discovered a case that can be optimized: an application may send two or more messages and the first message may take a long time to process.  In this case, we may send a dummy lightweighted message establish the connection, and then send real messages.",['ozone'],2019-10-09 10:00:49+00:00,2019-10-24 07:18:59+00:00,2019-10-24 16:40:35+00:00,Resolved,13261280,RATIS-704
Bug,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,"I'm getting intermittent ambiguous method reference compilation errors. It seems like it's a real bug since the method is ambigious when the referenced generic types have been ereased. Though I'm not sure why this is not always failing, it should, but it's probably a bug in Javac. I'm running Eclipse and it consistently complains about it.

Output from Maven:

[ERROR] testRevertConfigurationChange(org.apache.ratis.server.simulation.TestRaftReconfigurationWithSimulatedRpc) Time elapsed: 0.108 s <<< ERROR!
 java.lang.Error: 
 Unresolved compilation problems: 
 The method attempt(CheckedSupplier<Boolean,RuntimeException>, int, TimeDuration, String, Logger) is ambiguous for the type JavaUtils
 The method attempt(CheckedSupplier<Boolean,RuntimeException>, int, TimeDuration, String, Logger) is ambiguous for the type JavaUtils

[INFO] Running org.apache.ratis.server.simulation.TestServerRestartWithSimulatedRpc
 [ERROR] Tests run: 5, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 4.013 s <<< FAILURE! - in org.apache.ratis.server.simulation.TestServerRestartWithSimulatedRpc
 [ERROR] testRestartCommitIndex(org.apache.ratis.server.simulation.TestServerRestartWithSimulatedRpc) Time elapsed: 0.081 s <<< ERROR!
 java.lang.Error: 
 Unresolved compilation problems: 
 The method attempt(CheckedSupplier<Boolean,RuntimeException>, int, TimeDuration, String, Logger) is ambiguous for the type JavaUtils
 The method attempt(CheckedSupplier<Boolean,RuntimeException>, int, TimeDuration, String, Logger) is ambiguous for the type JavaUtils

[ERROR] testRestartFollower(org.apache.ratis.server.simulation.TestServerRestartWithSimulatedRpc) Time elapsed: 0.074 s <<< ERROR!
 java.lang.Error: 
 Unresolved compilation problem: 
 The method attempt(CheckedSupplier<Boolean,RuntimeException>, int, TimeDuration, String, Logger) is ambiguous for the type JavaUtils

A fix (but ugly) would just to be to re arrange the arguments.

 ",[],2019-10-05 19:40:44+00:00,2019-10-15 22:58:13+00:00,2019-10-15 22:58:13+00:00,Resolved,13260731,RATIS-703
Wish,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,It would be really nice if the metrics functionality also was pluggable so one could choose how to report metrics.,[],2019-10-05 00:18:01+00:00,2019-10-21 14:41:22+00:00,2020-02-28 14:57:11+00:00,Resolved,13260679,RATIS-702
Bug,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Major,"I have attached the below failing tests' output from the surefire run:

[INFO] Results:
 [INFO] 
 [ERROR] Failures: 
 [ERROR] org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc.testHandleStateMachineException(org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithGrpc>RaftStateMachineExceptionTests.testHandleStateMachineException:81 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithGrpc>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc.testRetryOnExceptionDuringReplication(org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithGrpc>RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication:145 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithGrpc>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc.testRetryOnStateMachineException(org.apache.ratis.grpc.TestRaftStateMachineExceptionWithGrpc)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithGrpc>RaftStateMachineExceptionTests.testRetryOnStateMachineException:99 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithGrpc>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty.testHandleStateMachineException(org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithNetty>RaftStateMachineExceptionTests.testHandleStateMachineException:81 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithNetty>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty.testRetryOnExceptionDuringReplication(org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithNetty>RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication:145 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithNetty>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty.testRetryOnStateMachineException(org.apache.ratis.netty.TestRaftStateMachineExceptionWithNetty)
 [ERROR] Run 1: TestRaftStateMachineExceptionWithNetty>RaftStateMachineExceptionTests.testRetryOnStateMachineException:99 Unexpected exit.
 [ERROR] Run 2: TestRaftStateMachineExceptionWithNetty>BaseTest.assertNotTerminated:61 Unexpected exit.
 [INFO] 
 [ERROR] Errors: 
 [ERROR] Tests run: 261, Failures: 13, Errors: 4, Skipped: 4

 

 ",[],2019-10-05 00:12:23+00:00,,2019-10-12 21:51:33+00:00,Open,13260678,RATIS-701
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"Fix flaky unit test failing with the following error:
{code}
s2:  RUNNING  FOLLOWER s2@group-9F6C12DCC257:t0, leader=null, voted=null, raftlog=s2@group-9F6C12DCC257-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [s3:0.0.0.0:49315, s4:0.0.0.0:49316, s0:0.0.0.0:49312, s1:0.0.0.0:49313, s2:0.0.0.0:49314], old=null RUNNING
	at org.apache.ratis.MiniRaftCluster.newIllegalStateExceptionForNoLeaders(MiniRaftCluster.java:506)
	at org.apache.ratis.RaftTestUtil.lambda$waitForLeader$1(RaftTestUtil.java:90)
	at org.apache.ratis.MiniRaftCluster.getLeader(MiniRaftCluster.java:539)
	at org.apache.ratis.MiniRaftCluster.getLeader(MiniRaftCluster.java:532)
	at org.apache.ratis.RaftTestUtil.lambda$waitForLeader$3(RaftTestUtil.java:98)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:152)
	at org.apache.ratis.RaftTestUtil.waitForLeader(RaftTestUtil.java:97)
	at org.apache.ratis.RaftTestUtil.waitForLeader(RaftTestUtil.java:77)
	at org.apache.ratis.RaftTestUtil.waitForLeader(RaftTestUtil.java:72)
	at org.apache.ratis.RaftBasicTests.runTestOldLeaderCommit(RaftBasicTests.java:176)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
	at org.apache.ratis.RaftBasicTests.testOldLeaderCommit(RaftBasicTests.java:172)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{code}",[],2019-10-04 05:06:37+00:00,2019-10-15 02:55:49+00:00,2019-10-15 02:55:49+00:00,Resolved,13260496,RATIS-700
Bug,[],hheg,Henrik Hegardt,hheg,Henrik Hegardt,Minor,"Ratis-Metric is depending on the dependency com.github.joshelser:dropwizard-metrics-hadoop-metrics2-reporter: 0.1.2. This in turn depends on the org.apache.hadoop:hadoop-common:2.6.0. This in turn depends on org.apache.hadoop:hadoop-annotations:2.6.0 which have an dependency on a system scoped dependency named jdk.tools:1.6. I'm running java 11 and this dependency doesn't exist in my environment so I can't compile with ratis included in my project because it fails trying to resolve that dependency.

However, the project ratis-hadoop depends on the the dependency org.apache.hadoop:hadoop-common:3.1.1 (which should be upgraded to 3.1.2 because the sources are missing in 3.1.1) which doesn't have the jdk.tools:1.6 dependency. So if I depend on this I can build the project because the faulty 2.6.0 dependency is shadowed transitively by the 3.1.1 dependency and everything is compiling.

The simple fix would be updating so ratis-metric is depending directly on the 3.1.2 dependency instead since it effectively will be the 3.1.1 code you are going run with anyway when running with the ratis-hadoop dependency.",[],2019-10-01 21:35:06+00:00,2019-10-17 03:49:14+00:00,2019-10-24 04:44:26+00:00,Resolved,13260002,RATIS-699
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"Followers always wait for (minTimeoutMillis + randomWait), before initiating leader election. This penalizes the first time the ratis ring is created or when server restarts by enforcing a wait for leader election term.",[],2019-10-01 17:49:57+00:00,2019-10-09 09:12:22+00:00,2019-10-10 20:16:26+00:00,Resolved,13259970,RATIS-698
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"In Ozone we started to use simple shell scripts to check the quality of the code. (dev-support/check/checkstyle.sh). They help us to execute local maven commands quickly and collect all of the results.

They also help us to use github-actions or other highly parallel CI in the future.",[],2019-09-30 13:37:22+00:00,2020-04-24 09:00:11+00:00,2020-04-24 09:00:11+00:00,Resolved,13259672,RATIS-697
Sub-task,[],clayb,Clay B.,clayb,Clay B.,Major,"In {{RaftStorageDirectory.getLogSegmentFiles()}} one can hang while creating a {{Files.newDirectoryStream}}. If one gets an {{IOException}} the server will simply hang at this point.


{code:java}
Exception in thread ""main"" java.nio.file.FileSystemException: /home/vagrant/test_data/data2_slowed/64656d6f-5261-6674-4772-6f7570313233/current: Input/output error
        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
        at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:427)
        at java.nio.file.Files.newDirectoryStream(Files.java:457)
        at org.apache.ratis.server.storage.RaftStorageDirectory.getLogSegmentFiles(RaftStorageDirectory.java:200)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:223)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:204)
        at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:247)
        at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:191)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:121)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:110)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748) {code}",[],2019-09-28 14:27:05+00:00,,2019-12-18 06:49:14+00:00,Patch Available,13259438,RATIS-696
Improvement,[],clayb,Clay B.,clayb,Clay B.,Minor,In testing with [Namazu|https://github.com/apache/incubator-ratis/blob/35838f032a4096d78843130fa1435bcddf5ce961/dev-support/vagrant/README.md#ratis-hdd-slowdown-vm] disk paths which fail in the face of {{IOException}}s are found. This umbrella-JIRA is to track the code paths found that need hardening. These code paths seem to be fatal to the Ratis server performing actions but does not cause the server to abort out.,['namazu'],2019-09-28 14:20:59+00:00,,2019-11-13 05:47:04+00:00,Patch Available,13259437,RATIS-695
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Minor,"Checkstyle found 78 item(s) in 30 file(s)

BaseStateMachine.java : 5 item(s)
Variable 'server' must be private and have accessor methods. (49:49) [VisibilityModifierCheck]
Variable 'groupId' must be private and have accessor methods. (50:34) [VisibilityModifierCheck]
Variable 'lifeCycle' must be private and have accessor methods. (51:29) [VisibilityModifierCheck]
'server' hides a field. (67:37) [HiddenFieldCheck]
'groupId' hides a field. (67:57) [HiddenFieldCheck]

BufferedChannelBase.java : 1 item(s)
Variable 'fileChannel' must be private and have accessor methods. (25:31) [VisibilityModifierCheck]

LeaderElection.java : 3 item(s)
Variable 'result' must be private and have accessor methods. (70:18) [VisibilityModifierCheck]
Variable 'term' must be private and have accessor methods. (71:16) [VisibilityModifierCheck]
switch without ""default"" clause. (208:0) [MissingSwitchDefaultCheck]

LeaderState.java : 9 item(s)
Variable 'type' must be private and have accessor methods. (70:16) [VisibilityModifierCheck]
Variable 'newTerm' must be private and have accessor methods. (71:16) [VisibilityModifierCheck]
Variable 'handler' must be private and have accessor methods. (72:20) [VisibilityModifierCheck]
Definition of 'equals()' without corresponding definition of 'hashCode()'. (84:5) [EqualsHashCodeCheck]
'for' construct must use '{}'s. (129:0) [NeedBracesCheck]
Empty statement. (129:52) [EmptyStatementCheck]
Name 'UPDATE_COMMIT_EVENT' must match pattern '^[a-z][a-zA-Z0-9]*$'. (178:34) [MemberNameCheck]
Name 'CHECK_STAGING_EVENT' must match pattern '^[a-z][a-zA-Z0-9]*$'. (180:34) [MemberNameCheck]
'stagingState' hides a field. (296:31) [HiddenFieldCheck]

LogAppender.java : 5 item(s)
Variable 'server' must be private and have accessor methods. (122:34) [VisibilityModifierCheck]
Variable 'raftLog' must be private and have accessor methods. (124:27) [VisibilityModifierCheck]
Variable 'follower' must be private and have accessor methods. (125:32) [VisibilityModifierCheck]
Variable 'halfMinTimeoutMs' must be private and have accessor methods. (129:24) [VisibilityModifierCheck]
switch without ""default"" clause. (483:0) [MissingSwitchDefaultCheck]

LogSegment.java : 1 item(s)
Class LogSegment should be declared as final. (53:0) [FinalClassCheck]

MemoryRaftLog.java : 1 item(s)
'entries' hides a field. (161:68) [HiddenFieldCheck]

MetaFile.java : 2 item(s)
'term' hides a field. (88:23) [HiddenFieldCheck]
'votedFor' hides a field. (88:36) [HiddenFieldCheck]

PendingRequests.java : 2 item(s)
Line is longer than 120 characters (found 123). (112:0) [LineLengthCheck]
Line is longer than 120 characters (found 122). (201:0) [LineLengthCheck]

RaftConfiguration.java : 2 item(s)
Class RaftConfiguration should be declared as final. (36:0) [FinalClassCheck]
Class Builder should be declared as final. (43:0) [FinalClassCheck]

RaftLog.java : 1 item(s)
Line is longer than 120 characters (found 131). (321:0) [LineLengthCheck]

RaftServer.java : 1 item(s)
Line is longer than 120 characters (found 128). (79:0) [LineLengthCheck]

RaftServerConstants.java : 1 item(s)
interfaces should describe a type and hence have methods. (22:0) [InterfaceIsTypeCheck]

RaftServerImpl.java : 5 item(s)
Line is longer than 120 characters (found 136). (82:0) [LineLengthCheck]
'state' hides a field. (124:19) [HiddenFieldCheck]
'stateMachine' hides a field. (545:24) [HiddenFieldCheck]
More than 7 parameters (found 8). (885:54) [ParameterNumberCheck]
'stateMachine' hides a field. (1,250:24) [HiddenFieldCheck]

RaftServerProxy.java : 2 item(s)
Name '_1' must match pattern '^[a-z][a-zA-Z0-9]*$'. (385:24) [ParameterNameCheck]
Line is longer than 120 characters (found 123). (397:0) [LineLengthCheck]

RaftServerRpc.java : 1 item(s)
'server' hides a field. (45:35) [HiddenFieldCheck]

RaftStorage.java : 1 item(s)
'metaFile' hides a field. (89:14) [HiddenFieldCheck]

RaftStorageDirectory.java : 3 item(s)
Variable 'startIndex' must be private and have accessor methods. (66:23) [VisibilityModifierCheck]
Variable 'endIndex' must be private and have accessor methods. (67:23) [VisibilityModifierCheck]
'if' construct must use '{}'s. (355:0) [NeedBracesCheck]

RatisMetrics.java : 5 item(s)
Utility classes should not have a public or default constructor. (30:1) [HideUtilityClassConstructorCheck]
'static' modifier out of order with the JLS suggestions. (31:16) [ModifierOrderCheck]
'static' modifier out of order with the JLS suggestions. (32:16) [ModifierOrderCheck]
'static' modifier out of order with the JLS suggestions. (33:16) [ModifierOrderCheck]
Variable 'metricsReporting' must be private and have accessor methods. (41:27) [VisibilityModifierCheck]

SegmentedRaftLogCache.java : 9 item(s)
Variable 'startIndex' must be private and have accessor methods. (58:16) [VisibilityModifierCheck]
Variable 'endIndex' must be private and have accessor methods. (59:16) [VisibilityModifierCheck]
Variable 'isOpen' must be private and have accessor methods. (60:19) [VisibilityModifierCheck]
Variable 'targetLength' must be private and have accessor methods. (61:16) [VisibilityModifierCheck]
Variable 'newEndIndex' must be private and have accessor methods. (62:16) [VisibilityModifierCheck]
Variable 'toTruncate' must be private and have accessor methods. (81:27) [VisibilityModifierCheck]
Variable 'toDelete' must be private and have accessor methods. (82:29) [VisibilityModifierCheck]
Variable 'arrayIndex' must be private and have accessor methods. (490:15) [VisibilityModifierCheck]
Variable 'truncateIndex' must be private and have accessor methods. (491:16) [VisibilityModifierCheck]

SegmentedRaftLogOutputStream.java : 1 item(s)
Name 'fill' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'. (40:35) [ConstantNameCheck]

SegmentedRaftLogReader.java : 4 item(s)
'if' construct must use '{}'s. (68:0) [NeedBracesCheck]
'if' construct must use '{}'s. (76:0) [NeedBracesCheck]
'if' construct must use '{}'s. (84:0) [NeedBracesCheck]
Name 'maxOpSize' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'. (129:28) [ConstantNameCheck]

ServerImplUtils.java : 1 item(s)
Utility classes should not have a public or default constructor. (34:1) [HideUtilityClassConstructorCheck]

ServerProtoUtils.java : 2 item(s)
More than 7 parameters (found 9). (356:38) [ParameterNumberCheck]
More than 7 parameters (found 9). (403:36) [ParameterNumberCheck]

ServerState.java : 3 item(s)
'leaderId' hides a field. (291:38) [HiddenFieldCheck]
'currentTerm' hides a field. (367:55) [HiddenFieldCheck]
'currentTerm' hides a field. (375:58) [HiddenFieldCheck]

SimpleStateMachineStorage.java : 1 item(s)
'raftStorage' hides a field. (63:32) [HiddenFieldCheck]

StateMachine.java : 1 item(s)
Unused import - org.apache.ratis.server.RaftServerConfigKeys. (25:8) [UnusedImportsCheck]

StateMachineUpdater.java : 1 item(s)
'appliedIndex' hides a field. (256:18) [HiddenFieldCheck]

TransactionContext.java : 1 item(s)
Unused import - java.util.Collection. (30:8) [UnusedImportsCheck]

TransactionContextImpl.java : 3 item(s)
'stateMachineContext' hides a field. (123:59) [HiddenFieldCheck]
'smLogEntryProto' hides a field. (142:84) [HiddenFieldCheck]
'shouldCommit' hides a field. (159:53) [HiddenFieldCheck]",[],2019-09-27 20:58:31+00:00,2019-10-24 16:01:18+00:00,2019-10-24 16:04:44+00:00,Resolved,13259358,RATIS-694
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"RATIS-678 introcuded _notifyLeaderChanged_ API on the StateMachine interface which will be called to notify the statemachine when the leaderId changes on leader as well as the follower.

Downstream services like Ozone utilize this functionality to decide when the Raft group is ready to accept writes and do open the write pipeline.

Purpose of this jira is to combine notifyLeader and notifyLeaderChanged into a single API.",[],2019-09-27 20:08:05+00:00,2019-10-03 04:02:52+00:00,2019-10-03 04:02:52+00:00,Resolved,13259339,RATIS-693
Sub-task,[],clayb,Clay B.,clayb,Clay B.,Major,"Working with our Namazu infrastructure, the first issue I hit when dialing up the faulty I/O injection rate is as follows:
{code}
2019-09-27 14:13:45 ERROR RaftStorageDirectory:336 - Failed to acquire lock on /home/vagrant/test_data/data0_slowed/64656d6f-5261-6674-4772-6f7570313233/in_use.lock. If this storage directory is mounted via NFS, ensure that the appropriate nfs lock services are running.
java.io.IOException: Input/output error
        at java.io.RandomAccessFile.writeBytes(Native Method)
        at java.io.RandomAccessFile.write(RandomAccessFile.java:512)
        at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:327)
        at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:291)
        at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
        at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
        at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:110)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Exception in thread ""main"" java.io.IOException: Input/output error
        at java.io.RandomAccessFile.writeBytes(Native Method)
        at java.io.RandomAccessFile.write(RandomAccessFile.java:512)
        at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:327)
        at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:291)
        at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
        at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
        at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:110)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}

It looks like the call chain does not re-try anywhere however.",['namazu'],2019-09-27 16:22:07+00:00,2019-10-24 15:54:57+00:00,2019-10-24 15:54:57+00:00,Resolved,13259312,RATIS-692
Sub-task,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Minor,"Checkstyle found 83 item(s) in 22 file(s)
 * ArchiveHdfsLogReader.java : 3 item(s)
 ** Unused import - java.io.File. (21:8) [UnusedImportsCheck]
 ** Unused import - java.nio.Buffer. (24:8) [UnusedImportsCheck]
 ** Unused import - org.apache.ratis.logservice.api.LogName. (39:8) [UnusedImportsCheck]
 * ArchiveHdfsLogWriter.java : 1 item(s)
 ** Unused import - org.apache.ratis.util.LogUtils. (32:8) [UnusedImportsCheck]
 * ArchivedLogStreamImpl.java : 3 item(s)
 ** Variable 'name' must be private and have accessor methods. (45:11) [VisibilityModifierCheck]
 ** Variable 'config' must be private and have accessor methods. (49:27) [VisibilityModifierCheck]
 ** Variable 'state' must be private and have accessor methods. (53:9) [VisibilityModifierCheck]
 * CommandFactory.java : 1 item(s)
 ** Class CommandFactory should be declared as final. (35:0) [FinalClassCheck]
 * Constants.java : 1 item(s)
 ** Utility classes should not have a public or default constructor. (25:1) [HideUtilityClassConstructorCheck]
 * LogMessage.java : 1 item(s)
 ** Variable 'logName' must be private and have accessor methods. (27:21) [VisibilityModifierCheck]
 * LogName.java : 1 item(s)
 ** Class LogName should be declared as final. (31:0) [FinalClassCheck]
 * LogReaderImpl.java : 2 item(s)
 ** Variable 'currentRecordId' must be private and have accessor methods. (61:8) [VisibilityModifierCheck]
 ** File contains tab characters (this is the first instance). (126:1) [FileTabCharacterCheck]
 * LogServer.java : 2 item(s)
 ** Variable 'peer' must be private and have accessor methods. (192:18) [VisibilityModifierCheck]
 ** Redundant 'public' modifier. (193:9) [RedundantModifierCheck]
 * LogServiceClient.java : 3 item(s)
 ** 'private' modifier out of order with the JLS suggestions. (57:11) [ModifierOrderCheck]
 ** 'private' modifier out of order with the JLS suggestions. (58:11) [ModifierOrderCheck]
 ** 'config' hides a field. (269:68) [HiddenFieldCheck]
 * LogServiceMetricsRegistry.java : 2 item(s)
 ** Utility classes should not have a public or default constructor. (28:1) [HideUtilityClassConstructorCheck]
 ** Variable 'metricsReporting' must be private and have accessor methods. (35:27) [VisibilityModifierCheck]
 * LogServiceShell.java : 1 item(s)
 ** Name 'LOG' must match pattern '^[a-z][a-zA-Z0-9]*$'. (46:25) [StaticVariableNameCheck]
 * LogServiceShellOpts.java : 1 item(s)
 ** Variable 'metaQuorum' must be private and have accessor methods. (24:17) [VisibilityModifierCheck]
 * LogServiceUtils.java : 1 item(s)
 ** Utility classes should not have a public or default constructor. (32:1) [HideUtilityClassConstructorCheck]
 * LogStateMachine.java : 13 item(s)
 ** 'state' hides a field. (185:19) [HiddenFieldCheck]
 ** Redundant 'final' modifier. (199:9) [RedundantModifierCheck]
 ** Redundant 'final' modifier. (206:9) [RedundantModifierCheck]
 ** Redundant 'final' modifier. (207:9) [RedundantModifierCheck]
 ** Redundant 'final' modifier. (236:9) [RedundantModifierCheck]
 ** Redundant 'final' modifier. (237:9) [RedundantModifierCheck]
 ** 'archivalInfo' hides a field. (334:9) [HiddenFieldCheck]
 ** '{' at column 3 should be on the previous line. (347:3) [LeftCurlyCheck]
 ** '{' at column 3 should be on the previous line. (362:3) [LeftCurlyCheck]
 ** Redundant 'final' modifier. (464:12) [RedundantModifierCheck]
 ** switch without ""default"" clause. (538:0) [MissingSwitchDefaultCheck]
 ** 'state' hides a field. (576:16) [HiddenFieldCheck]
 ** 'state' hides a field. (747:45) [HiddenFieldCheck]
 * LogStream.java : 1 item(s)
 ** Redundant 'public' modifier. (33:3) [RedundantModifierCheck]
 * LogStreamImpl.java : 6 item(s)
 ** Variable 'listeners' must be private and have accessor methods. (51:24) [VisibilityModifierCheck]
 ** Variable 'name' must be private and have accessor methods. (55:11) [VisibilityModifierCheck]
 ** Variable 'raftClient' must be private and have accessor methods. (59:14) [VisibilityModifierCheck]
 ** Variable 'config' must be private and have accessor methods. (63:27) [VisibilityModifierCheck]
 ** Variable 'state' must be private and have accessor methods. (67:19) [VisibilityModifierCheck]
 ** Variable 'length' must be private and have accessor methods. (72:8) [VisibilityModifierCheck]
 * MetaServiceProtoUtil.java : 3 item(s)
 ** Unused import - org.apache.ratis.proto.RaftProtos. (27:8) [UnusedImportsCheck]
 ** Utility classes should not have a public or default constructor. (40:1) [HideUtilityClassConstructorCheck]
 ** Variable 'i' must be private and have accessor methods. (192:38) [VisibilityModifierCheck]
 * MetaStateMachine.java : 18 item(s)
 ** Unused import - org.apache.ratis.metrics.impl.RatisMetricRegistryImpl. (53:8) [UnusedImportsCheck]
 ** Name 'LOG' must match pattern '^[a-z][a-zA-Z0-9]*$'. (78:12) [MemberNameCheck]
 ** Variable 'LOG' must be private and have accessor methods. (78:12) [VisibilityModifierCheck]
 ** Must have at least one statement. (163:43) [EmptyBlockCheck]
 ** 'properties' hides a field. (218:28) [HiddenFieldCheck]
 ** 'peers' hides a field. (260:34) [HiddenFieldCheck]
 ** Line is longer than 120 characters (found 124). (294:0) [LineLengthCheck]
 ** Redundant 'final' modifier. (315:14) [RedundantModifierCheck]
 ** Line is longer than 120 characters (found 124). (331:0) [LineLengthCheck]
 ** 'peers' hides a field. (332:32) [HiddenFieldCheck]
 ** Variable 'peer' must be private and have accessor methods. (402:18) [VisibilityModifierCheck]
 ** Variable 'groups' must be private and have accessor methods. (403:24) [VisibilityModifierCheck]
 ** Redundant 'public' modifier. (405:9) [RedundantModifierCheck]
 ** Line is longer than 120 characters (found 123). (437:0) [LineLengthCheck]
 ** Line is longer than 120 characters (found 130). (456:0) [LineLengthCheck]
 ** 'if' construct must use '{}'s. (496:0) [NeedBracesCheck]
 ** 'if' construct must use '{}'s. (497:0) [NeedBracesCheck]
 ** 'if' construct must use '{}'s. (502:0) [NeedBracesCheck]
 * MetadataServer.java : 1 item(s)
 ** Variable 'metaStateMachine' must be private and have accessor methods. (54:18) [VisibilityModifierCheck]
 * RaftLogReader.java : 7 item(s)
 ** Unused import - org.apache.ratis.server.raftlog.RaftLogIOException. (22:8) [UnusedImportsCheck]
 ** Unused import - org.apache.ratis.thirdparty.com.google.protobuf.ByteString. (23:8) [UnusedImportsCheck]
 ** Unused import - org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException. (24:8) [UnusedImportsCheck]
 ** Redundant 'public' modifier. (32:3) [RedundantModifierCheck]
 ** Redundant 'public' modifier. (37:3) [RedundantModifierCheck]
 ** Redundant 'public' modifier. (43:3) [RedundantModifierCheck]
 ** Redundant 'public' modifier. (49:3) [RedundantModifierCheck]
 * VerificationTool.java : 11 item(s)
 ** Line is longer than 120 characters (found 121). (71:0) [LineLengthCheck]
 ** Line is longer than 120 characters (found 144). (73:0) [LineLengthCheck]
 ** Line is longer than 120 characters (found 142). (79:0) [LineLengthCheck]
 ** Line is longer than 120 characters (found 162). (85:0) [LineLengthCheck]
 ** Line has trailing spaces. (96:0) [RegexpSinglelineCheck]
 ** 'abstract' modifier out of order with the JLS suggestions. (178:12) [ModifierOrderCheck]
 ** Variable 'logName' must be private and have accessor methods. (180:21) [VisibilityModifierCheck]
 ** Variable 'client' must be private and have accessor methods. (181:30) [VisibilityModifierCheck]
 ** Variable 'numRecords' must be private and have accessor methods. (182:17) [VisibilityModifierCheck]
 ** Variable 'logFreq' must be private and have accessor methods. (183:17) [VisibilityModifierCheck]
 ** Variable 'valueSize' must be private and have accessor methods. (184:17) [VisibilityModifierCheck]",[],2019-09-27 03:48:03+00:00,2019-10-17 11:32:47+00:00,2019-10-18 02:29:58+00:00,Resolved,13259178,RATIS-691
Bug,[],ljain,Lokesh Jain,nilotpalnandi,Nilotpal Nandi,Major,"RaftClient does not change leaderId and does not refresh the streamObserver for the old leaderId in case of TimeoutIOException. For AlreadyClosedException also the raft client should retry to a different leader.

For TimeoutIOException leader change is good to have if the server has false notion of being the leader. Similarly for AlreadyClosedException I guess it will be good to try sending request to a different server since the existing stream might be closed by server.
{code:java}
19/09/25 18:09:42 DEBUG client.RaftClient: client-E5E9D444D128: suggested new leader: null. Failed RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4 with {}

19/09/25 18:09:42 DEBUG client.RaftClient: client-E5E9D444D128: suggested new leader: null. Failed RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4 with {}org.apache.ratis.protocol.TimeoutIOException: Request timeout 3000ms: RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4 at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$3(GrpcClientProtocolClient.java:319) at java.util.Optional.ifPresent(Optional.java:159) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:323) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:318) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:312) at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:113) at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:133) at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50) at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)

19/09/25 18:09:42 DEBUG client.RaftClient: client-E5E9D444D128: oldLeader=46001d60-9ca0-4042-a521-69cb38b96882,  curLeader=46001d60-9ca0-4042-a521-69cb38b96882, newLeader=394810ca-48fe-47bd-a0c8-eeaaec380bc319/09/25 18:09:42 DEBUG impl.OrderedAsync: schedule* attempt #171 with policy RetryLimited(maxAttempts=180, sleepTime=1000ms) for RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4

19/09/25 18:09:43 DEBUG impl.OrderedAsync: client-E5E9D444D128: send* RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4

19/09/25 18:09:43 DEBUG client.RaftClient: client-E5E9D444D128: suggested new leader: null. Failed RaftClientRequest:client-E5E9D444D128->46001d60-9ca0-4042-a521-69cb38b96882@group-0B8E59E48142, cid=34, seq=11*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$72/2083154356@108d55c4 with {}java.io.IOException: java.lang.IllegalStateException: Entry already exists for key 11 in map SlidingWindow$Server:257-OrderedRequestStreamObserver257:requests at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54) at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:106) at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75) at org.apache.ratis.grpc.GrpcUtil.unwrapIOException(GrpcUtil.java:128) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onError(GrpcClientProtocolClient.java:283) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434) at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678) at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584) at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.IllegalStateException: Entry already exists for key 11 in map SlidingWindow$Server:257-OrderedRequestStreamObserver257:requests at sun.reflect.GeneratedConstructorAccessor22.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.apache.ratis.util.ReflectionUtils.instantiateException(ReflectionUtils.java:222) at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:104) ... 22 more
{code}",[],2019-09-26 16:52:29+00:00,2019-09-30 03:09:38+00:00,2019-10-10 09:48:21+00:00,Resolved,13259100,RATIS-690
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"If raft servers are in CLOSED state then client should fail fast. Currently the client retries upto max number of retries before failing the request. We should fail the request faster in such cases.
{code:java}
19/09/26 11:26:55 DEBUG impl.OrderedAsync: schedule* attempt #178 with policy RetryLimited(maxAttempts=180, sleepTime=1000ms) for RaftClientRequest:client-90F3DF988698->044832b2-4f44-46e0-9702-e6a0a7542763@group-93F633896F08, cid=0, seq=1*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$74/1538849250@4905c46b

19/09/26 11:23:39 DEBUG impl.OrderedAsync: client-90F3DF988698: Failed* RaftClientRequest:client-90F3DF988698->664c4e90-08f3-46c9-a073-c93ef2a55da3@group-93F633896F08, cid=0, seq=1*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$74/1538849250@4905c46b with {}19/09/26 11:23:39 DEBUG impl.OrderedAsync: client-90F3DF988698: Failed* RaftClientRequest:client-90F3DF988698->664c4e90-08f3-46c9-a073-c93ef2a55da3@group-93F633896F08, cid=0, seq=1*, RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$74/1538849250@4905c46b with {}java.util.concurrent.CompletionException: org.apache.ratis.protocol.ServerNotReadyException: 664c4e90-08f3-46c9-a073-c93ef2a55da3@group-93F633896F08 is not in [RUNNING]: current state is CLOSED at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308) at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577) at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:339) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$000(GrpcClientProtocolClient.java:255) at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onError(GrpcClientProtocolClient.java:284) at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434) at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678) at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467) at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584) at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.ratis.protocol.ServerNotReadyException: 664c4e90-08f3-46c9-a073-c93ef2a55da3@group-93F633896F08 is not in [RUNNING]: current state is CLOSED at org.apache.ratis.server.impl.RaftServerImpl.lambda$assertLifeCycleState$9(RaftServerImpl.java:472) at org.apache.ratis.util.LifeCycle.assertCurrentState(LifeCycle.java:185) at org.apache.ratis.server.impl.RaftServerImpl.assertLifeCycleState(RaftServerImpl.java:471) at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:536) at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:333) at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:328) at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109) at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:328) at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981) at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124) at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:327) at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:333) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:220) at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:326) at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:429) at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:421) at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:345) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:240) at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168) at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248) at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263) at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:686) ... 5 more
{code}",[],2019-09-26 15:54:16+00:00,,2019-09-27 09:57:17+00:00,Open,13259094,RATIS-689
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"LifeCycle#checkStateAndClose does not run closeMethod when there is a transition from NEW to CLOSED state. In case of RaftServerImpl this leads to leak of resources as the SegmentedRaftLogWorker#workerThread is never closed.

 The below log shows that the group creation failed because the group was removed before the server could be started and transition to RUNNING state. Therefore the group was removed while the server was still in NEW state and the state transitioned from NEW to CLOSED without shutting down the server threads.
{code:java}
2019-09-19 12:57:18,936 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - dbb1763a-ad27-40d5-a907-326b490ac078: addNew group-B983B2DCF085:[8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed:10.200.5.17:50422, dbb1763a-ad27-40d5-a907-326b490ac078:10.200.5.17:50421, 6f0a09de-30ac-4af3-bd09-c1d256eeede3:10.200.5.17:50423] returns group-B983B2DCF085:java.util.concurrent.CompletableFuture@69914d62[Not completed]
2019-09-19 12:57:27,953 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - dbb1763a-ad27-40d5-a907-326b490ac078: remove group-B983B2DCF085:java.util.concurrent.CompletableFuture@69914d62[Not completed, 1 dependents]
2019-09-19 12:59:04,846 [pool-48-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed: Failed groupAdd* GroupManagementRequest:client-256726B37980->8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085, cid=2, seq=0, RW, null, Add:group-B983B2DCF085:[8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed:10.200.5.17:50422, dbb1763a-ad27-40d5-a907-326b490ac078:10.200.5.17:50421, 6f0a09de-30ac-4af3-bd09-c1d256eeede3:10.200.5.17:50423]2019-09-19 12:59:04,846 [pool-48-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed: Failed groupAdd* GroupManagementRequest:client-256726B37980->8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085, cid=2, seq=0, RW, null, Add:group-B983B2DCF085:[8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed:10.200.5.17:50422, dbb1763a-ad27-40d5-a907-326b490ac078:10.200.5.17:50421, 6f0a09de-30ac-4af3-bd09-c1d256eeede3:10.200.5.17:50423]java.util.concurrent.CompletionException: java.lang.IllegalStateException: 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed: failed to start a new impl:      null 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085:t0, leader=null, voted=null, raftlog=8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed:10.200.5.17:50422, dbb1763a-ad27-40d5-a907-326b490ac078:10.200.5.17:50421, 6f0a09de-30ac-4af3-bd09-c1d256eeede3:10.200.5.17:50423], old=null CLOSED at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280) at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577) at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.IllegalStateException: 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed: failed to start a new impl:      null 8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085:t0, leader=null, voted=null, raftlog=8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed:10.200.5.17:50422, dbb1763a-ad27-40d5-a907-326b490ac078:10.200.5.17:50421, 6f0a09de-30ac-4af3-bd09-c1d256eeede3:10.200.5.17:50423], old=null CLOSED at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:75) at org.apache.ratis.server.impl.RaftServerProxy.lambda$groupAddAsync$10(RaftServerProxy.java:382) at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602) ... 5 more
Timestamp: 2019-09-19 01:12:35,583
""8e6c3d3c-fdb0-4da3-8339-a4c04a7595ed@group-B983B2DCF085-SegmentedRaftLogWorker""  prio=5 tid=703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:283)
        at java.lang.Thread.run(Thread.java:748)
{code}
 ",[],2019-09-20 11:46:51+00:00,,2019-09-20 15:04:24+00:00,Patch Available,13257927,RATIS-687
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In the conf keys, some getter/setter methods are missing.  Some of the method names are not using the standard naming convention.",[],2019-09-19 20:02:14+00:00,2020-03-11 11:59:45+00:00,2020-03-11 11:59:45+00:00,Resolved,13257770,RATIS-686
Improvement,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"Findbugs has been marked deprecated and all future work is now happening under SpotBugs project.

This Jira is to investigate and possibly transition to Spotbugs.

 

Ref1 - [https://mailman.cs.umd.edu/pipermail/findbugs-discuss/2017-September/004383.html]

Ref2 - [https://spotbugs.github.io/]

 

A turn off for developers is that IntelliJ does not yet have a plugin for Spotbugs - [https://youtrack.jetbrains.com/issue/IDEA-201846]",[],2019-09-18 21:19:57+00:00,,2020-04-10 05:55:51+00:00,Patch Available,13257513,RATIS-685
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Yetus QA build fails currently due to unreachable maven url. We can change the url in Dockerfile to point to maven version 3.6.2.,[],2019-09-18 11:21:26+00:00,2019-09-18 18:07:30+00:00,2019-09-18 18:08:09+00:00,Resolved,13257353,RATIS-684
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Since the Ratis metrics work is going on in parallel from multiple folks, it will be a good idea to have a final sanity check and cleanup tasks to bring the task to closure. These are the tasks aimed in this JIRA. 

* Organize RatisMetrics and RatisMetricNames into a single class
(It would be good to organize RatisMetrics and RatisMetricNames into a single class. The metrics can be organized like RaftServerConfigKeys and RaftClientConfigKeys so that metrics corresponding to a particular component like Log, Appender can be tracked in a sub class)
* Investigate whether we can move the groupId and followerId in metric names to attributes. This will make aggregation from a metrics system easier.
* Deploy a cluster and do sanity check of all metrics. ",[],2019-09-18 09:58:24+00:00,2020-01-30 16:55:46+00:00,2020-01-30 16:55:46+00:00,Resolved,13257337,RATIS-683
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"LogAppender maintains nextIndex, matchIndex and rpc response time for a follower to whom append entries are sent. The Jira aims to add metrics to track these fields for a follower log appender.",[],2019-09-18 09:51:38+00:00,2019-11-05 13:54:48+00:00,2019-11-05 15:30:44+00:00,Resolved,13257334,RATIS-682
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The following fields found in conf were not following the naming convention:
- GrpcConfigKeys.TLS.TLS_ROOT_PREFIX
- RaftServerConfigKeys.SLEEP_DEVIATION_THRESHOLD
- RaftServerConfigKeys.Snapshot.RETENTION_POLICY_KEY
",[],2019-09-17 20:53:34+00:00,2019-09-19 18:42:15+00:00,2019-09-19 18:42:15+00:00,Resolved,13257211,RATIS-681
Bug,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Blocker,"Fix Ratis LICENSE file issues raised by Justin here:

https://mail-archives.apache.org/mod_mbox/incubator-general/201909.mbox/%3C573A4F4D-8303-418D-8133-03AAC8085708%40me.com%3E

",[],2019-09-17 17:36:59+00:00,2019-10-28 16:54:40+00:00,2019-10-28 16:54:40+00:00,Resolved,13257180,RATIS-680
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,We need a counter for number of times append entries are received in the raft log. We can also add counter for number of times log is flushed. This would be useful in determining flush frequency for raft log.,[],2019-09-17 14:13:35+00:00,2019-09-30 11:11:11+00:00,2019-10-08 12:19:03+00:00,Resolved,13257128,RATIS-679
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"org.apache.ratis.statemachine.StateMachine#notifyLeader

does not provide the group id for which leader election is complete.",[],2019-09-13 22:05:48+00:00,2019-09-27 09:56:08+00:00,2019-09-27 20:08:55+00:00,Resolved,13256626,RATIS-678
Bug,[],Sammi,Sammi Chen,Sammi,Sammi Chen,Blocker,"Steps:
1.  Run Teragen and generated a few GB data in a 4 datanodes cluster.  
2.  Stoped the datanodes through ./stop-ozone.sh.
3.  Changed the ozone binaries
4.  Start the cluster through ./start-ozone.sh.
5.  Two datanode regisisterd to SCM. Two datanode fail to appear at SCM side.  
Checked these two failed node, datanode process is still running. In the logfile, I found a lot of following errors. 

2019-09-12 21:06:45,255 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis ba17ad5e-714e-4d82-85d8-ff2e0737fcf9 at port 9858
2019-09-12 21:06:47,255 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
2019-09-12 21:06:47,255 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
2019-09-12 21:06:47,255 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis ba17ad5e-714e-4d82-85d8-ff2e0737fcf9 at port 9858
2019-09-12 21:06:47,255 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at 10.120.110.183:9861 for past 2100 seconds.
org.apache.ratis.protocol.ChecksumException: LogEntry is corrupt. Calculated checksum is -134141393 but read checksum 0
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.decodeEntry(SegmentedRaftLogReader.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogReader.readEntry(SegmentedRaftLogReader.java:185)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogInputStream.nextEntry(SegmentedRaftLogInputStream.java:121)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.readSegmentFile(LogSegment.java:94)
        at org.apache.ratis.server.raftlog.segmented.LogSegment.loadSegment(LogSegment.java:117)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogCache.loadSegment(SegmentedRaftLogCache.java:310)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:234)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.openImpl(SegmentedRaftLog.java:204)
        at org.apache.ratis.server.raftlog.RaftLog.open(RaftLog.java:247)
        at org.apache.ratis.server.impl.ServerState.initRaftLog(ServerState.java:190)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:120)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:110)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
",[],2019-09-12 13:10:22+00:00,2019-09-23 21:00:51+00:00,2019-12-09 16:01:54+00:00,Resolved,13256343,RATIS-677
Sub-task,[],sdeka,Supratim Deka,sdeka,Supratim Deka,Major,"RATIS-650 tracks the commit indexes of each peer in a RaftGroup - tracking is done as metrics on the RAFT group leader.

This jira however tracks the RaftLog commit index as a metric of the local RaftServer. This metric will be reported by all nodes running a raft server irrespective of their role (Leader or Follower).
",[],2019-09-11 02:33:13+00:00,2019-10-18 10:29:27+00:00,2019-10-26 00:07:46+00:00,Resolved,13256015,RATIS-676
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently GroupInfoReply does not provide information regarding the lifecycle state of RaftServerImpl corresponding to a group. This should be part of the GroupInfoReply so that client can know the current lifecycle state of group in the server.,[],2019-09-09 09:13:06+00:00,,2019-09-09 09:13:06+00:00,Open,13255580,RATIS-675
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,{{ratis-metrics/src/main/resources/META-INF/services/org.apache.hadoop.hbase.metrics.MetricRegistries}} should be {{ratis-metrics/src/main/resources/META-INF/services/org.apache.ratis.metrics.MetricRegistries}},[],2019-09-06 21:46:39+00:00,2019-09-09 03:58:42+00:00,2019-09-09 14:09:58+00:00,Resolved,13255375,RATIS-674
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{noformat}
2019-09-04 16:32:21,638 WARN  server.LogStateMachine (LogStateMachine.java:processArchiveLog(686)) - Exception while processing archival request for LogName['testLogExport']
java.lang.NullPointerException
        at org.apache.ratis.logservice.server.LogStateMachine.processArchiveLog(LogStateMachine.java:619)
        at org.apache.ratis.logservice.server.LogStateMachine.access$6(LogStateMachine.java:599)
        at org.apache.ratis.logservice.server.LogStateMachine$7.run(LogStateMachine.java:310)
        at org.apache.ratis.statemachine.impl.BaseStateMachine.recordTime(BaseStateMachine.java:210)
        at org.apache.ratis.logservice.server.LogStateMachine.query(LogStateMachine.java:308)
        at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:553)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:333)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:328)
        at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:328)
        at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981)
        at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124)
        at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:327)
        at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:333)
        at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:220)
        at org.apache.ratis.grpc.client.GrpcClientProtocolService$UnorderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:276)
        at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:240)
        at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168)
        at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:686)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748) {noformat}
Saw this in {{TestMetaServer-output.txt}}.

Problem seems to be [https://github.com/apache/incubator-ratis/blob/c2a6a24a9ff85cc24132f5d5db40391bd36fbe70/ratis-logservice/src/main/java/org/apache/ratis/logservice/server/LogStateMachine.java#L612-L613]

The {{putIfAbsent}} call would return {{null}}. Interestingly, the test cases still pass somehow :)

FYI [~ankit.singhal]",[],2019-09-04 20:40:04+00:00,,2019-09-05 01:43:47+00:00,Open,13254860,RATIS-673
Improvement,[],clayb,Clay B.,clayb,Clay B.,Trivial,"The Vagrant tests are [pointing|https://github.com/apache/incubator-ratis/blob/35838f032a4096d78843130fa1435bcddf5ce961/dev-support/vagrant/Vagrantfile#L92] to a specific mirror and a URL which broke with the new Maven 3.6.x release.

We should point to an {{archive.apache.org}} URL if I understand correctly.",[],2019-09-03 23:17:30+00:00,,2021-04-20 14:54:43+00:00,Patch Available,13254507,RATIS-672
Improvement,[],Sammi,Sammi Chen,Sammi,Sammi Chen,Major,"If this log means there is no concern, I would suggest to lower its log level to debug.

2019-09-03 19:37:31,931 WARN org.apache.ratis.grpc.server.GrpcLogAppender: org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler@7dfaa82c: Request not found, ignoring reply: ba17ad5e-714e-4d82-85d8-ff2e0737fcf9<-1c08cf06-4612-4e97-b159-babbd3747bc8#3199:FAIL,NOT_LEADER,nextIndex:1486,term:6,followerCommit:1480
",[],2019-09-03 11:42:28+00:00,,2019-09-03 15:42:17+00:00,Open,13254375,RATIS-671
Sub-task,[],sdeka,Supratim Deka,sdeka,Supratim Deka,Major,"Plotting the Log apply index (log index applied on the StateMachine) against the RaftLog commit index, is useful in monitoring the performance of the statemachine.
This jira adds a metric/gauge which tracks the current value of log apply index.",[],2019-09-01 08:23:03+00:00,2019-09-16 10:02:59+00:00,2019-09-16 10:02:59+00:00,Resolved,13254107,RATIS-670
Improvement,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,"This is needed for TLS client that does not have its own local persistence of cert file.

CA cert will be decoded from block token for client external to ozone cluser (non SCM/OM/DN).",[],2019-08-28 00:07:45+00:00,2019-08-29 02:40:50+00:00,2019-08-29 02:40:50+00:00,Resolved,13253363,RATIS-669
Bug,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Blocker,"NOTICE file needs to be updated based on Justin's comments here:

 

[https://mail-archives.apache.org/mod_mbox/incubator-general/201908.mbox/%3C8EA21F57-A972-4CBE-AC2F-D3830FE6BDB4%40classsoftware.com%3E]

 

 ",[],2019-08-27 18:26:16+00:00,2019-09-12 17:19:07+00:00,2019-09-12 17:19:07+00:00,Resolved,13253318,RATIS-668
Improvement,[],clayb,Clay B.,clayb,Clay B.,Trivial,"The LogService lifecycle documentation provided in RATIS-637 is very helpful. To aid one's understanding, it would be useful to have a visual of the states.",[],2019-08-23 00:06:26+00:00,2019-08-30 21:45:47+00:00,2019-08-31 01:52:09+00:00,Resolved,13252553,RATIS-667
Improvement,[],timmylicheng,Li Cheng,timmylicheng,Li Cheng,Major,"I'm using this issue to discuss the coalesced heartbeat plan in multi-raft. We are looking at incorporating multi-raft feature in ratis into Hadoop Ozone. So in ozone, every datanode would be in multiple raft groups or say pipelines with multi-raft, which brings:
 # Is there any plan for coalesced heartbeat on single node? 
 # Are we going to use gRPC to achieve coalesced heartbeat like what cockroach does? Shall we assume only Java APIs are required?
 # Either we have coalesced heartbeat, every node would have chances to be selected as leader in each raft group. So to the extreme extend, one node, say node A, would be the leader to all raft groups. If we implement coalesced heartbeat, there would more easily push node A to be the bottleneck for future stumbling in performance. Any idea on how to avoid this extremity? Maybe do a candidate scrub?
 # How do we plan to test the 'single node, multi raft groups' scenario? Furthermore, if we allow coalesced heartbeat configurable, how to determine when and whether to use it?

 

[~szetszwo] [~Sammi] [~xyao] [~waterlx]",[],2019-08-22 12:05:08+00:00,,2019-08-29 21:52:49+00:00,Open,13252369,RATIS-666
Improvement,[],clayb,Clay B.,clayb,Clay B.,Trivial,"To be able to interrogate the good metrics work going on in Ratis, I would like an easier way to view the metrics available from the Ratis daemons (and clients).",[],2019-08-19 22:09:54+00:00,,2019-08-31 00:43:25+00:00,Patch Available,13251714,RATIS-665
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Over in RATIS-637, we were trying to document the lifecycle of a Log in the LogService.

Our [~ankit@apache.org] mentioned that, upon reaching the ARCHIVED state, a log is not automatically deleted or truncated. We could provided some functionality such that, when this state is reached, we automatically clean up this Log in the LogService.

Normally, an ""archive"" of something would imply that it is removed - deleting the log automatically would make the most sense to me, as long as we can be sure it exists in the archival location.",[],2019-08-19 21:33:59+00:00,,2019-08-19 21:33:59+00:00,Open,13251704,RATIS-664
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently watch requests use follower's match index. Match index signifies the log index till which follower has accepted append entries. Watch requests should rather use follower's log flush index which signifies the log index till which the log entries have been synced to the disk.,[],2019-08-19 11:51:14+00:00,,2019-08-19 11:51:46+00:00,Open,13251563,RATIS-663
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"For any commit index c1 there is a corresponding metadata entry which is added to the log. This metadata entry signifies that c1 has been replicated by majority nodes in the quorum. 

Currently watch requests watch on the log entry itself. It should rather watch the metadata entry corresponding to the commit.

Let us take a majority commit c1 with servers s1(leader) and s2 in the majority. s1 and s2 were able to commit c1 in the log. Now s1 fails and s2 may not have received metadata entry for c1. In such a scenario if s2 restarts it will not be able to apply c1 on the state machine.",[],2019-08-19 11:47:22+00:00,,2019-08-20 06:07:43+00:00,Open,13251561,RATIS-662
New Feature,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently during RaftServerProxy#groupRemoveAsync there is no way for stateMachine to know that the RaftGroup will be removed. This Jira aims to add a call in the stateMachine to handle group removal.

It also changes the logic of groupRemoval api to remove the RaftServerImpl from the RaftServerProxy#impls map after the shutdown is complete. This is required to synchronize the removal with the corresponding api of RaftServer#getGroupIds. RaftServer#getGroupIds uses the RaftServerProxy#impls map to get the groupIds.",[],2019-08-19 10:55:54+00:00,2019-08-30 21:11:49+00:00,2019-09-03 18:07:27+00:00,Resolved,13251554,RATIS-661
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"While taking a ratis snapshot, it just applied all the transactions from the commitIndex to the applied index. In case, it needs to take a snapshot, on applyTransaction failure, it closes the raftServerImpl. In case, snapshot is not required while applying the current set of transactions and if any of these transactions fail, these will be ignored. Ideally, every applyTransaction failures should be caught and stateMachine updater should not take any further snapshot once a failure is detected.",[],2019-08-19 10:29:02+00:00,,2021-04-20 14:54:03+00:00,Open,13251544,RATIS-660
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,StateMachineUpdater might not take snapshot during close. This might happen if the StateMachineUpdater#stopAndJoin is called right after the snapshot check in StateMachineUpdater:156-162.,[],2019-08-19 06:06:05+00:00,2019-08-30 21:11:16+00:00,2019-09-03 08:00:37+00:00,Resolved,13251510,RATIS-659
Bug,[],msingh,Mukul Kumar Singh,arp,Arpit Agarwal,Major,"ratis-assembly does not include ratis-resource-bundle, this results in a compilation failure in the created bundle.",[],2019-08-16 11:10:47+00:00,2019-08-16 18:00:21+00:00,2019-08-16 18:00:21+00:00,Resolved,13251222,RATIS-658
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"GrpcClientProtocolClient logging is too verbose, there are multiple instances of logging as following.

{code}
19/08/14 12:08:47 INFO client.GrpcClientProtocolClient: client-9D2DF1304552->e89f9c37-e0e1-4026-b0cc-c6393c8e4777: receive RaftClientReply:client-9D2DF1304552->e89f9c37-e0e1-4026-b0cc-c6393c8e4777@group-533C90750B00, cid=1783, SUCCESS, logIndex=350, commits[e89f9c37-e0e1-4026-b0cc-c6393c8e4777:c350, 0fcf00d5-f7bd-4c92-841d-05627de071c9:c348, 23ee46ae-bf29-4654-895c-3481eb1249d6:c347]
{code}",['ozone'],2019-08-15 01:50:15+00:00,2019-09-11 05:26:20+00:00,2019-09-11 05:26:20+00:00,Resolved,13250920,RATIS-657
Task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,[~szetszwo] suggested that we can avoid bundling hadoop dependencies in ratis-examples.jar on https://issues.apache.org/jira/browse/RATIS-654?focusedCommentId=16902474&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16902474,[],2019-08-08 17:46:28+00:00,,2019-08-08 17:46:28+00:00,Open,13249716,RATIS-656
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This is the last JIRA split from the huge patch in RATIS-605.,[],2019-08-07 17:58:05+00:00,2019-09-17 19:44:10+00:00,2019-09-17 19:44:10+00:00,Resolved,13249500,RATIS-655
Bug,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,"Details on licenses, what can be bundled and what can't be as per apache:-
http://www.apache.org/legal/resolved.html

Below is the guide on how a dev should be assembling LICENSE and NOTICE:
http://www.apache.org/dev/licensing-howto.html

We need to include LICENSE and NOTICE for transitive dependencies as well
http://www.apache.org/dev/licensing-howto.html#deps-of-deps

The supplemental model[s1] of maven can help in supplementing missing information of LICENSE and NOTICE in the third-party dependencies in our bundled LICENSE and NOTICE

[1] https://maven.apache.org/plugins/maven-remote-resources-plugin/supplemental-models.html

Here, I have copied the resource-bundle created by HBase , so that we don't need to re-write whole logic of generating LICENSE and NOTICE in apache way.

",[],2019-08-06 18:22:06+00:00,2019-08-12 20:43:51+00:00,2019-08-12 21:20:00+00:00,Resolved,13249188,RATIS-654
Bug,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-08-04 18:06:19+00:00,2019-08-12 21:20:00+00:00,2019-08-12 21:20:00+00:00,Resolved,13248773,RATIS-653
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Following metrics would be good to determine overall snapshot and log purge behaviour of a ratis pipeline:

 
|takeSnapshotLatency|Time taken to take a ratis snapshot.|
|numSnapshots|Number of snapshots taken |
|purgeLogRecordLatency|Time taken to purge logRecords.|
|numPurgeLogCalls|Number of Purge log calls|
|numInstallSnapshotOps|Number of install snapshot calls|",[],2019-08-01 19:33:36+00:00,2019-11-18 11:16:55+00:00,2019-11-18 11:17:37+00:00,Resolved,13248417,RATIS-652
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Critical,"Following metrics would be helpful to determine the leader election events and timeouts:

 
|numLeaderElections|Number of leader elections since the creation of ratis pipeline|
|numLeaderElectionTimeouts|Number of leader election timeouts or failures|
|LeaderElectionCompletionLatency|Time required to complete a leader election|
|MaxNoLeaderInterval|Max time where there has been no elected leader in the raft ring|
|heartBeatMissCount|No of times heartBeat response is missed from a server |",[],2019-08-01 19:30:55+00:00,2019-08-28 05:11:20+00:00,2019-08-30 16:55:25+00:00,Resolved,13248415,RATIS-651
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Tracking the RaftLog commit index on each peer in a RaftGroup is useful to monitor the performance of the group.

Simply as an illustrative example : whenever a specific peer starts to lag behind the majority, the problem becomes visible to the monitoring agent even before the slow follower detection mechanism on the Leader kicks in.


 ",[],2019-08-01 19:24:21+00:00,2019-10-04 17:59:25+00:00,2019-10-04 17:59:25+00:00,Resolved,13248413,RATIS-650
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Following metrics would be good to have to measure the load and the processing time of client requests:

 
|numReadRequestCount|Number of read type requests received on the leader|
|numWriteRequestCount|Number of write type requests received on the leader|
|numWatchForMajorityRequestCount|Number of Watch for Majority type requests received on the leader. 
 |
|numWatchForAllRequestCount|Number of Watch for All type requests received on the leader.|
|raftClientReadRequestLatency|Time required to process read type requests |
|raftClientWriteRequestLatency|Time required to process write type requests|
|raftClientWatchForMajority|Time required to process WatchForMajority requests|
|raftClientWatchForAllRequests|Time required to process WatchForAll requests|
|requestQueueLimitHitCount|Number of times the no of pending requests in the leader hit the configured limit.|
|numRequestRetryCacheHitCount|No of of Request Retry Cache hits. This gives an idea of retries via Raft clients because of request timeouts or exceptions.|",[],2019-08-01 19:16:22+00:00,2019-10-18 10:56:32+00:00,2019-11-07 19:05:11+00:00,Resolved,13248412,RATIS-649
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Following metrics would be useful related to GrpcLogAppends for performance and health monitoring and tuning:
|GrpcLogAppenderLatency|Time taken to append a log entry to each follower and get acknowledgement|
|logAppendRetryCount|Total no of retried logAppends requests|
|logAppendRequestCount|Total no of logAppendRequest|
|appendEntryProcessingLatency|Time required to process an append entry request on each follower|",[],2019-08-01 19:01:35+00:00,2019-10-23 22:35:15+00:00,2019-11-26 05:24:39+00:00,Resolved,13248410,RATIS-648
Sub-task,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"We need the following metrics related to RaftLog and RaftLogWorker:
|raftLogSyncLatency|Time taken to sync raft log|
|numRaftLogSyncOps|Number of Raft log sync calls with respect to time(equals no of FlushStateMacine Calls)|
|raftLogSynBatchSize|No of raft log entries synced with each flush call|
|raftLogReadLatency|Time required to read a raft log entry from actual raft log file and create a raft log entry (Raft log read latency)|
|raftLogAppendLatency|Total time taken to append a raft log entry (this also includes writeStateMachineData which will vary depending upon the size of the data to be written as well as external factors)|
|raftLogEnqueuedTime|Time of RaftLogEntry in the Raft Log Worker Queue|
|raftLogQueueingDelay|Time required to enqueue a raft Log entry in raft log worker queue|
|raftLogSegmentLoadLatency|Time required to load and process raft log segments during restart|
|raftLogWorkerQueueSize|Raft log worker queue size which at any time gives the no of pending log entries to be committed to the raft log.|
|raftLogCacheMissCount|Number of RaftLogCacheMisses |",[],2019-08-01 18:57:47+00:00,2019-09-27 15:38:14+00:00,2019-09-27 15:38:14+00:00,Resolved,13248408,RATIS-647
New Feature,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"For performance measurements and ratis pipeline health diagnostics, certain metrics need to be incorporated inside ratis. This Jira aims to encompass all the required metrices.",['ozone'],2019-08-01 17:28:26+00:00,,2021-04-20 14:53:30+00:00,Reopened,13248390,RATIS-646
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication has failed in Jenkins with NullPointerException; for example https://builds.apache.org/job/PreCommit-RATIS-Build/915/testReport/org.apache.ratis.server.simulation/TestRaftStateMachineExceptionWithSimulatedRpc/testRetryOnExceptionDuringReplication/

Just able to reproduce it:
{code}
java.lang.NullPointerException
	at org.apache.ratis.server.impl.RaftStateMachineExceptionTests.testRetryOnExceptionDuringReplication(RaftStateMachineExceptionTests.java:172)
{code}
",[],2019-07-31 18:18:15+00:00,,2019-08-08 17:08:05+00:00,Reopened,13248182,RATIS-645
Bug,[],sdeka,Supratim Deka,sdeka,Supratim Deka,Major,"This is related to HDDS-1739 which detects and reports IO failures during applyTransaction.

Currently, the StateMachineUpdater in response to a failed applyLog/applyTransaction operation triggers a shutdown of the Ratis server.

Instead, the desired behaviour is to stop accepting new append requests on the group. For the case of Ozone, the state machine will initiate destruction/closing of the Ratis group - this is implemented as a part of HDDS-1739.

 ",[],2019-07-31 11:38:45+00:00,2019-08-06 11:11:57+00:00,2019-08-06 11:11:57+00:00,Resolved,13248086,RATIS-644
Improvement,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"It will be a useful feature for Ratis to provide a Snapshot retention policy which clients can configure. As a starting point, we can have the number of recent snapshot files to retain be configurable.

The motivation is from HDDS-1786. ",['ozone'],2019-07-30 17:36:37+00:00,2019-07-31 09:11:52+00:00,2019-07-31 09:13:04+00:00,Resolved,13247902,RATIS-643
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Update ratis notice to reflect latest timestamps i.e. to 2019.

Thanks [~jghoman] for noticing this during 0.4.0 rc0 vote.",[],2019-07-29 04:52:05+00:00,2019-08-03 13:48:53+00:00,2019-08-03 13:48:53+00:00,Resolved,13247569,RATIS-642
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,RaftPeerId currently does not extend RaftId so that it is not consistent with ClientId and RaftGroupId.,[],2019-07-26 22:07:40+00:00,,2019-08-05 23:47:47+00:00,Patch Available,13247423,RATIS-641
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Leader election after the initialization should happen immediately to ensure that data pipeline accept incoming IO soon after it is started.,['ozone'],2019-07-26 15:28:26+00:00,,2021-04-20 14:52:56+00:00,Open,13247346,RATIS-640
Bug,[],adoroszlai,Attila Doroszlai,adoroszlai,Attila Doroszlai,Minor,"Numbers are allowed in variable names, but such variables cannot be used in expressions:

{noformat}
$ client.sh arithmetic assign --name v1 --value 1
$ client.sh arithmetic assign --name v2 --value 2
$ client.sh arithmetic assign --name v3 --value ""v1+v2""
...
Exception in thread ""main"" java.lang.IllegalArgumentException: Invalid expression v1 Try something like: 'a+b' or '2'
	at org.apache.ratis.examples.arithmetic.cli.Assign.createExpression(Assign.java:73)
	at org.apache.ratis.examples.arithmetic.cli.Assign.createBinaryExpression(Assign.java:87)
	at org.apache.ratis.examples.arithmetic.cli.Assign.createExpression(Assign.java:69)
	at org.apache.ratis.examples.arithmetic.cli.Assign.operation(Assign.java:53)
	at org.apache.ratis.examples.arithmetic.cli.Client.run(Client.java:51)
	at org.apache.ratis.examples.common.Runner.main(Runner.java:67)
{noformat}

Similarly, values like {{0}} and {{0.1}} cannot be used in expressions:

{noformat}
$ client.sh arithmetic assign --name b --value '0.1+1'
... IllegalArgumentException: Invalid expression 0.1+1 Try something like: 'a+b' or '2'
$ client.sh arithmetic assign --name b --value '0+1'
... 'IllegalArgumentException: Invalid expression 0+1 Try something like: 'a+b' or '2'
{noformat}

Also, negative values result in exception:

{noformat}
$ client.sh arithmetic assign --name a --value '-5'
Exception in thread ""main"" java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at java.lang.Double.valueOf(Double.java:502)
	at org.apache.ratis.examples.arithmetic.cli.Assign.createExpression(Assign.java:61)
	at org.apache.ratis.examples.arithmetic.cli.Assign.createBinaryExpression(Assign.java:87)
	at org.apache.ratis.examples.arithmetic.cli.Assign.createExpression(Assign.java:69)
	at org.apache.ratis.examples.arithmetic.cli.Assign.operation(Assign.java:53)
	at org.apache.ratis.examples.arithmetic.cli.Client.run(Client.java:51)
	at org.apache.ratis.examples.common.Runner.main(Runner.java:67)
{noformat}",[],2019-07-25 19:08:55+00:00,2020-05-14 09:22:47+00:00,2020-05-16 07:33:11+00:00,Resolved,13247135,RATIS-639
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,"While building source created using ratis-assembly following error is seen.
{code:java}
$ mvn clean install

[ERROR] Child module /Users/ljain/Downloads/apache-ratis-incubating-0.4.0-rc0/ratis-metrics of /Users/ljain/Downloads/apache-ratis-incubating-0.4.0-rc0/pom.xml does not exist @
@
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]
[ERROR]   The project org.apache.ratis:ratis:0.4.0-rc0 (/Users/ljain/Downloads/apache-ratis-incubating-0.4.0-rc0/pom.xml) has 1 error
[ERROR]     Child module /Users/ljain/Downloads/apache-ratis-incubating-0.4.0-rc0/ratis-metrics of /Users/ljain/Downloads/apache-ratis-incubating-0.4.0-rc0/pom.xml does not exist
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException

{code}",[],2019-07-25 17:41:32+00:00,2019-07-25 20:17:07+00:00,2019-07-25 20:17:07+00:00,Resolved,13247121,RATIS-638
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"With Ankit's changes around archiving and exporting logs, it would be good to get a diagram on the lifecycle of a log on the website.",[],2019-07-25 16:19:36+00:00,2019-08-19 21:39:59+00:00,2019-08-22 19:42:05+00:00,Resolved,13247109,RATIS-637
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Ratis already has the ability to set up gRPC with TLS. Document this pieces of how this works, and how it might work for folks downstream.",[],2019-07-25 16:04:45+00:00,2019-08-19 23:24:10+00:00,2019-08-19 23:24:10+00:00,Resolved,13247102,RATIS-636
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,This feature is required by Ozone(HDDS-1753) to figure the min replicated index across all servers of a RaftGroup.,['ozone'],2019-07-24 04:14:55+00:00,2019-08-20 09:37:31+00:00,2019-08-20 09:37:31+00:00,Resolved,13246716,RATIS-635
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,After determining pipeline slowness leader should propagate slowness information to the followers. Leader and followers should notify their respective state machines about pipeline slowness.,['ozone'],2019-07-22 17:53:48+00:00,,2019-07-26 15:47:32+00:00,Open,13246377,RATIS-634
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"RATIS-631 adds capability in leader to determine pipeline slowness. Leader should use this information for handling client requests. For instance if one of the follower is slow, then client requests demanding commit in all the nodes can be rejected by the leader. If both the followers are slow then all the client requests can be rejected by the leader.",['ozone'],2019-07-22 17:44:42+00:00,,2019-07-26 15:47:50+00:00,Open,13246375,RATIS-633
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"This Jira aims to determine pipeline slowness in leader using follower indexes (commit index and state machine last applied index). As part of Jira, configurations and algorithm would be defined for determining slowness.",['ozone'],2019-07-22 17:33:19+00:00,,2020-01-23 10:25:15+00:00,Patch Available,13246372,RATIS-632
Sub-task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,State Machine's last applied index denotes the index till which the transactions have been successfully applied by the state machine. This index needs to be propagated from the follower to leader in order for leader to determine by how many transactions follower's state machine is lagging behind.,['ozone'],2019-07-22 17:15:53+00:00,,2020-01-23 10:27:37+00:00,Patch Available,13246369,RATIS-631
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"The aim of the Jira is to add flow control in Ratis in order to handle slowness of LogWorker, LogAppender and StateMachine. The idea is to propagate indexes like commit index(LogAppender) and lastAppliedIndex(StateMachine) from followers to leader. The leader can use these indices to determine slowness of a follower and handle client requests accordingly. For instance if one of the follower is lagging behind then client requests demanding commit by all nodes can be rejected by leader.",['ozone'],2019-07-22 17:07:15+00:00,,2019-07-29 11:27:33+00:00,Open,13246367,RATIS-630
Bug,[],clayb,Clay B.,clayb,Clay B.,Trivial,"The [vagrant|https://github.com/apache/incubator-ratis/commit/35838f032a4096d78843130fa1435bcddf5ce961] test-harness bits are broken as the load generator does not launch. It fails with the following output:
{code:java}
Found /home/vagrant/incubator-ratis/ratis-examples/target/ratis-examples-0.4.0-SNAPSHOT.jar
2019-07-20 21:02:13 INFO  LogUtils:41 - Set org.apache.ratis.server.impl.RaftServerImpl log level to DEBUG
2019-07-20 21:02:13 INFO  LogUtils:41 - Set org.apache.ratis.client.RaftClient log level to DEBUG
Wrong parameters: Can only specify option --peers once.
Usage: <main class&gt; [command] [command options]
  Commands:
    server      Start an filestore server
      Usage: server [options]
        Options:
        * --id, -i
            Raft id of this server
        * --peers, -r
            Raft peers (format: name:host:port,name:host:port)
          --raftGroup, -g
            Raft group identifier
            Default: demoRaftGroup123
        * --storage, -s
            Storage dir

    loadgen      Load Generator for FileStore
      Usage: loadgen [options]
        Options:
        * --numFiles
            Number of files
        * --peers, -r
            Raft peers (format: name:host:port,name:host:port)
          --raftGroup, -g
            Raft group identifier
            Default: demoRaftGroup123
        * --size
            Size of each file


Verification of all Ratis file server logs have the same checksum across all storage directories:
find: ‘/home/vagrant/test_data/data?’: No such file or directory
=== Command terminated normally (Sat Jul 20 21:02:13 2019) ===
{code}
Further, it appears that the servers are no longer logging to the {{screen}} session or the {{server_n*.log}} files.",[],2019-07-21 22:10:42+00:00,2019-08-26 23:48:07+00:00,2019-08-26 23:48:07+00:00,Resolved,13246210,RATIS-629
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"This is a followup on RATIS-625.  This JIRE is to simplify the code in LogSegment:
- LogRecordWithEntry can be removed.
- hasEntryCache can be removed.
- appendToOpenSegment should take only a single LogEntryProto parameter.
",[],2019-07-19 18:15:34+00:00,2019-07-26 12:26:10+00:00,2019-07-26 12:26:19+00:00,Resolved,13246056,RATIS-628
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently, for a leader election to complete, timeouts are decided by min and max values given by rpc.timeout.min and rpc.timeout.max. But, there is a separate config for leader timeout given by ""leader.election.timeout"" after which the statemachine of the server is notified
about leader election pending for a long time. The naming of the configs seem confusing at times.",['ozone'],2019-07-19 10:16:54+00:00,2019-08-01 12:41:25+00:00,2019-08-01 12:41:25+00:00,Resolved,13245960,RATIS-627
Bug,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-07-18 22:12:59+00:00,2019-07-19 21:29:50+00:00,2019-07-19 21:29:50+00:00,Resolved,13245883,RATIS-626
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"LogSegment#append leaks the entryCache when a RaftServerImpl is restarted.
On restart, the entries are loaded from the raft Logs and then added in the entryCache, however after adding the entry in the cache, hasEntryCache is not set to true.

cc: [~ljain] [~szetszwo]",[],2019-07-18 16:43:50+00:00,2019-07-18 21:12:23+00:00,2019-07-19 18:16:24+00:00,Resolved,13245828,RATIS-625
Task,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"This Jira aims to add support to RaftServer to support pause and unpause to its state. When paused, the RaftServer should not accept any incoming append log entries.",['ozone'],2019-07-17 22:18:19+00:00,,2021-04-20 14:52:25+00:00,In Progress,13245630,RATIS-624
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Leader election after groupAdd should be triggered instantaneously to make sure that a new leader is chosen soon in a newly created pipeline.,['ozone'],2019-07-16 10:28:48+00:00,,2019-07-16 10:28:48+00:00,Open,13245183,RATIS-623
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Critical,"I've seen this bug a few times, but finally got to the bottom of it. The VerificationTool will get to the end, but not exit. The reason is that at least one log has still not yet been created.

* The client will be blocked asking the metadataquorum to create a log
* The metadata leader will have tons of threads blocked on the writeLock

What I just found today was an exception, logged to stderr (not stdout), that was thrown when the group create failed.

However, we don't catch and re-throw this exception on group create failure, but proceed then to try to send a message to the group which failed to be created.

We must catch this failure, try to clean up, and propagate the original createLog exception back to the client.",[],2019-07-12 20:46:48+00:00,2020-04-16 02:03:33+00:00,2020-04-16 02:03:33+00:00,Resolved,13244698,RATIS-622
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,The new ratis-metrics project should be added to the src assembly manually to include it in the final src tar file.,[],2019-07-11 13:11:35+00:00,2019-07-26 01:50:45+00:00,2019-07-26 01:50:45+00:00,Resolved,13244317,RATIS-621
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Even after taking a snapshot, the raft log loads all the segment in the log
{code}
2019-07-01 23:22:47,481 [pool-18-thread-1] INFO       - Setting the last applied index to (t:2, i:15237039)
{code}

{code}
2019-07-01 23:22:47,516 INFO org.apache.ratis.server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-07-01 23:22:47,531 INFO org.apache.ratis.server.impl.RaftServerImpl: 62941ca3-f244-4298-8497-f4c0bd57430a:group-4D230AB58084 set configuration 0: [1f3d7936-cb4e-4b68-86ed-578070472dea:1
0.17.213.36:9858, 62941ca3-f244-4298-8497-f4c0bd57430a:10.17.213.35:9858, f07c1f87-b377-40d9-8c56-4f1440c4fa77:10.17.213.37:9858], old=null at 0
2019-07-01 23:22:47,578 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9882
2019-07-01 23:22:47,579 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T10:11:56-07:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-01 23:22:47,601 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7461 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_0-7460
2019-07-01 23:22:47,608 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6ce90bc5{/logs,file:///var/log/ozone/,AVAILABLE}
2019-07-01 23:22:47,608 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b1c0397{/static,jar:file:/var/lib/hadoop-ozone/ozone-0.5.0-SNAPSHOT/share
/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-07-01 23:22:47,635 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7386 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_7461-14846
2019-07-01 23:22:47,663 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7440 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_14847-22286
2019-07-01 23:22:47,664 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@8a62297{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-7539213566265642568.di
r/webapp/,AVAILABLE}{/hddsDatanode}
2019-07-01 23:22:47,681 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7353 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_22287-29639
2019-07-01 23:22:47,695 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5116ac09{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
2019-07-01 23:22:47,695 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7291 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_29640-36930
2019-07-01 23:22:47,695 INFO org.eclipse.jetty.server.Server: Started @56648ms
2019-07-01 23:22:47,695 INFO org.apache.hadoop.hdds.server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
2019-07-01 23:22:47,709 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7049 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_36931-43979
2019-07-01 23:22:47,732 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7141 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230
ab58084/current/log_43980-51120
2019-07-01 23:22:47,747 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7321 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230ab58084/current/log_51121-58441
2019-07-01 23:22:47,768 INFO org.apache.ratis.server.raftlog.segmented.LogSegment: Successfully read 7081 entries from segment file /data/1/ozone-0701/ratis/log/f7ddda32-45e0-4bec-a3e7-4d230ab58084/current/log_58442-65522
{code}",['ozone'],2019-07-10 06:05:24+00:00,2019-10-15 18:42:44+00:00,2019-10-15 18:42:44+00:00,Resolved,13244018,RATIS-619
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,Ratis leader should request if the commit index gap between leader and follower is high,['ozone'],2019-07-09 14:04:16+00:00,,2019-07-15 18:24:42+00:00,Open,13243895,RATIS-618
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"StateMachine#takeSnapshot should pass the log index at which the snapshot should be taken,
this will avoid the need to maintaining lastAppliedCommitIndex in the stateMachine.",[],2019-07-09 14:02:40+00:00,2019-07-14 15:21:20+00:00,2019-07-14 15:21:20+00:00,Resolved,13243894,RATIS-617
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"StateMachineUpdater#takeSnapshot blocks the StateMachineUpdater thread, this takeSnapshot call should be moved to a different thread.",['ozone'],2019-07-09 14:00:44+00:00,2021-04-20 14:52:04+00:00,2021-04-20 14:52:04+00:00,Resolved,13243893,RATIS-616
Bug,[],nanda,Nanda kumar,nanda,Nanda kumar,Blocker,When all the nodes in the raft ring are isolated (network partition) {{StateMachine#notifyExtendedNoLeader}} is not getting called.,"['blockade', 'ozone']",2019-07-08 11:15:30+00:00,2019-08-01 10:28:58+00:00,2019-08-01 10:28:58+00:00,Resolved,13243644,RATIS-615
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,"Currently Raft leader uses the StateMachineUpdater's lastAppliedIndex to determine if leader is ready to take requests. It should rather use StateMachine's lastAppliedTermIndex because it denotes the index till which the transactions have already been completed whereas StateMachineUpdater's lastAppliedIndex denotes the index till which the applyTransaction call has been made to the StateMachine.

Currently the new leader might not have applied all the transactions of the old term. Any reads served on the new leader can be stale.",['ozone'],2019-07-05 16:52:37+00:00,2019-11-05 09:24:25+00:00,2019-11-11 09:41:35+00:00,Resolved,13243420,RATIS-614
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently StateMachineUpdater applies all the transactions until the committed index. In cases where there is a huge difference between applied and committed index, all these transactions would be pending in the state machine and can take a lot of heap space. Such a scenario was seen in the Ozone cluster where a large amount of heap was taken by unapplied transactions leading to frequent GC pauses.",['ozone'],2019-07-05 16:13:28+00:00,2019-07-22 17:57:58+00:00,2019-07-22 18:25:03+00:00,Resolved,13243413,RATIS-613
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, we use bytes for RaftPeerId.  It is better to create a protobuf message for it as suggested by [~msingh].",['ozone'],2019-07-05 08:20:48+00:00,,2019-07-26 22:18:18+00:00,Open,13243307,RATIS-612
Test,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Add a test for the InstallSnapshotNotification with follower restart.  The test is to see if the leader could set the nextIndex correct for the follower; see also RATIS-608.,['ozone'],2019-07-04 14:25:03+00:00,2019-07-18 18:00:50+00:00,2019-07-18 18:00:50+00:00,Resolved,13243225,RATIS-611
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,RaftClientReply has quite a few constructors with many parameters.  We should employ the builder pattern to build RaftClientReply objects.,['ozone'],2019-07-04 01:44:19+00:00,2020-11-18 03:46:15+00:00,2020-11-18 03:46:18+00:00,Resolved,13243110,RATIS-610
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,This an effort to reduce the patch size in RATIS-605.  The RaftLog related change for RaftGroupMemberId will be done here.,['ozone'],2019-07-03 06:26:34+00:00,2019-08-07 18:00:13+00:00,2019-08-07 18:00:13+00:00,Resolved,13242912,RATIS-609
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,"GrpcLogAppender sets the next Index erroneously when the follower is not accessible.

{code}
2019-06-30 15:46:29,779 INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4819fbc0-e361-4926-932c-842627c9ffaa:group-4122452CF032 set configuration 2171: [e89e0844-d98e-4b11-8ead-64a6d2f9e2b
0:192.168.0.2:63501, 4819fbc0-e361-4926-932c-842627c9ffaa:192.168.0.2:63513, 3956fe0f-e48d-4616-a867-993d92dc33fe:192.168.0.2:63525], old=null at 2171

2019-06-30 15:46:29,779 WARN  server.GrpcLogAppender (LogUtils.java:warn(136)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: Failed appendEntries1: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception 2:org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.0.2:63501

2019-06-30 15:46:29,780 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 4819fbc0-e361-4926-932c-842627c9ffaa-SegmentedRaftLogWorker:Storage Directory /Users/msingh/code/apache/ozone/github/git_oz1/hadoop-ozone/integration-test/target/test/data/MiniOzoneClusterImpl-28640af6-bc0a-4f80-bc2d-d6d7c2cb932f/datanode-3/data/ratis/a6a7f1ed-bbde-445c-814d-4122452cf032: Rolled log segment from /Users/msingh/code/apache/ozone/github/git_oz1/hadoop-ozone/integration-test/target/test/data/MiniOzoneClusterImpl-28640af6-bc0a-4f80-bc2d-d6d7c2cb932f/datanode-3/data/ratis/a6a7f1ed-bbde-445c-814d-4122452cf032/current/log_inprogress_0 to /Users/msingh/code/apache/ozone/github/git_oz1/hadoop-ozone/integration-test/target/test/data/MiniOzoneClusterImpl-28640af6-bc0a-4f80-bc2d-d6d7c2cb932f/datanode-3/data/ratis/a6a7f1ed-bbde-445c-814d-4122452cf032/current/log_0-2170

2019-06-30 15:46:29,780 INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: nextIndex: updateUnconditionally 2171 -> 1


2019-06-30 15:46:29,812 WARN  server.GrpcLogAppender (LogUtils.java:warn(136)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: Failed appendEntries1: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception 2:org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.0.2:63501

2019-06-30 15:46:29,812 INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: nextIndex: updateUnconditionally 2 -> 1
2019-06-30 15:46:30,091 INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(176)) - Moving container #9 to CLOSED state, datanode 823473d3-96da-4854-8688-9db0117c54d8{ip: 192.168.0.2, host: 192.168.0.2, networkLocation: /default-rack, certSerialId: null} reported CLOSED replica.

2019-06-30 15:46:30,321 WARN  server.GrpcLogAppender (LogUtils.java:warn(136)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: Failed appendEntries1: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception 2:org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.0.2:63501

2019-06-30 15:46:30,322 INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - g:group-4122452CF0324819fbc0-e361-4926-932c-842627c9ffaa->e89e0844-d98e-4b11-8ead-64a6d2f9e2b0: nextIndex: updateUnconditionally 1 -> 0
{code}",['ozone'],2019-07-01 13:27:35+00:00,,2019-07-15 11:35:31+00:00,Open,13242508,RATIS-608
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"a) When a node shutdowns or transitions from a follower to candidate, it does not shuts down the streamobservers to its leader.
b) similarly when a leader transitions to a follower, it does not close the appenders to the followers cleanly.",['ozone'],2019-07-01 04:02:04+00:00,,2019-07-14 15:24:14+00:00,Patch Available,13242410,RATIS-607
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,GrpcService should use SO_REUSEADDR flag to allow the port to be re-used,['ozone'],2019-06-28 09:22:30+00:00,2019-07-26 15:54:53+00:00,2019-07-26 15:54:53+00:00,Resolved,13242124,RATIS-606
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In multi-raft, a server may belong to more than one groups so that the RaftPeerId is not enough to identity a particular group that the server belong to.",[],2019-06-27 11:44:28+00:00,2019-07-05 08:14:59+00:00,2019-08-07 18:00:34+00:00,Resolved,13241919,RATIS-605
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently orderedRequestStreamObserver does not cleanup the sliding window and the orderedStreamObservers map when responding error.,[],2019-06-27 08:11:07+00:00,2019-06-28 08:43:14+00:00,2019-06-28 08:43:27+00:00,Resolved,13241878,RATIS-604
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira proposes to add a SmLogEntryProto to toString converter so that logEntry information can be printed on errors/exceptions.,['ozone'],2019-06-21 16:48:13+00:00,2019-10-24 17:57:00+00:00,2019-10-24 17:57:00+00:00,Resolved,13240913,RATIS-603
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,GrpcClientProtocolClient should return raft client reply for NLE in place of exception,['ozone'],2019-06-21 10:44:34+00:00,,2019-07-14 15:25:37+00:00,Open,13240836,RATIS-602
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"There are 3 issues with leader election

a) OrderedAsync#sendRequest doesn't handle NotLeaderException
b) RaftServerImpl#generateNotLeaderException should not guess current leader when it does not has information about it. This leads to client retrying aggressively which leads into RetryException.
c) RaftClient right now changes leader for AlreadyClosedException and TimeoutIOException, these events do not trigger leader election and hence the leader should not be changed.",[],2019-06-20 14:30:11+00:00,2019-06-27 15:55:35+00:00,2019-09-27 05:19:22+00:00,Resolved,13240661,RATIS-601
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Since installSnapshot is not a frequent operations, we should just print the log messages in info as well as add more log messages.",[],2019-06-19 22:47:18+00:00,2019-07-03 05:12:22+00:00,2019-07-03 05:12:22+00:00,Resolved,13240526,RATIS-600
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to Underscores in Numeric Literals in Java (see https://docs.oracle.com/javase/8/docs/technotes/guides/language/underscores-literals.html), RaftProperties should support underscores in numeric literals.

For simplicity, we could just replace all the underscores with empty strings.",[],2019-06-19 22:20:11+00:00,,2019-11-06 18:38:57+00:00,Patch Available,13240522,RATIS-599
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-06-19 21:25:00+00:00,,2019-06-19 21:25:00+00:00,Open,13240511,RATIS-598
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,We need to get notified whenever the leader changes so that we can reschedule the Archiving on it.,[],2019-06-19 21:18:09+00:00,2019-06-20 20:11:50+00:00,2019-06-20 20:11:50+00:00,Resolved,13240508,RATIS-597
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The conf raft.server.leader.election.timeout is actually for extended no leader but not leader election.  It should be renamed to avoid confusion.,[],2019-06-19 21:07:18+00:00,2019-07-22 21:08:36+00:00,2019-08-01 12:41:25+00:00,Resolved,13240505,RATIS-596
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This was discovered by [~msingh].  Currently, the appendEntry future complete after the WriteLog task is executed.  However, the entry may not be flushed.",[],2019-06-19 02:10:42+00:00,2019-06-26 08:36:18+00:00,2019-06-26 08:36:18+00:00,Resolved,13240335,RATIS-595
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-06-17 22:26:59+00:00,2019-07-09 19:18:12+00:00,2019-07-10 05:16:09+00:00,Resolved,13240071,RATIS-594
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-06-17 22:26:27+00:00,2019-07-09 19:18:26+00:00,2019-07-09 19:18:26+00:00,Resolved,13240070,RATIS-593
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Critical,"RATIS-571, modified the GrpcClientProtocolClient to not set the AsyncStreamObserver reference to null on an exception, however, the ReplyMap reference is set to null. This results in the client getting an AlredyClosedException on the stream on a retry for a NotLeader or a LeadrNotReady exception and never recovers. This is common in a unit test scenario where a request is sent immediately after the cluster is up.

There is nothing special here about one node Ratis however, the HDDS unit tests that fail are all one node Ratis and the most probable cause is that with client retrying a different node each time, increases the chance of success on a three-node ring.



",[],2019-06-17 18:26:34+00:00,2019-06-28 08:37:29+00:00,2019-06-28 08:57:26+00:00,Resolved,13240024,RATIS-592
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"I was trying out Rajeshbabu's new changes in RATIS-541 using the docker automation, but gave invalid options the first time which caused the workers to exit (divide by zero).

When I tried to rerun the VerificationTool, I found that the tool got stuck waiting for logs to be created. Getting a thread dump from the active leader of the metadata quorum showed 150+ threads all stuck waiting to get a write lock. However, there are no threads holding the lock that everyone is waiting on which seems to me like a deadlock.

It seems like we have some kind of bug where we orphan a lock that's still held. This doesn't happen normally - makes me wonder if it can happen when the leader changes? I'll attach the log of the metadata quorum nodes from my local test. However, I bet this could be reproduced with some adequate load.

Can you take a look into this, Vlad?",[],2019-06-17 14:07:56+00:00,,2019-06-17 14:08:58+00:00,Open,13239948,RATIS-591
Bug,[],rakeshr,Rakesh Radhakrishnan,rakeshr,Rakesh Radhakrishnan,Major,"Ran Freon benchmark in a three node cluster with 100 writer threads. After some time the client got hanged due to deadlock issue.

+Freon with the args:-+
--numOfBuckets=10 --numOfKeys=8 --keySize=67108864 --numOfVolumes=100 --numOfThreads=100

3 BLOCKED threads. Attached whole threaddump.

{code}
Found one Java-level deadlock:
=============================
""grpc-default-executor-6"":
  waiting for ownable synchronizer 0x000000021546bd00, (a java.util.concurrent.locks.ReentrantReadWriteLock$FairSync),
  which is held by ""ForkJoinPool.commonPool-worker-7""
""ForkJoinPool.commonPool-worker-7"":
  waiting to lock monitor 0x00007f48fc99c448 (object 0x000000021546be30, a org.apache.ratis.util.SlidingWindow$Client),
  which is held by ""grpc-default-executor-6""
{code}

{code}
ForkJoinPool.commonPool-worker-7
priority:5 - threadId:0x00007f48d834b000 - nativeId:0x9ffb - nativeId (decimal):40955 - state:BLOCKED
stackTrace:
java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.ratis.util.SlidingWindow$Client.resetFirstSeqNum(SlidingWindow.java:348)
- waiting to lock <0x000000021546be30> (a org.apache.ratis.util.SlidingWindow$Client)
at org.apache.ratis.client.impl.OrderedAsync.resetSlidingWindow(OrderedAsync.java:122)
at org.apache.ratis.client.impl.OrderedAsync$$Lambda$943/1670264164.accept(Unknown Source)
at org.apache.ratis.client.impl.RaftClientImpl.lambda$handleIOException$6(RaftClientImpl.java:352)
at org.apache.ratis.client.impl.RaftClientImpl$$Lambda$944/769363367.accept(Unknown Source)
at java.util.Optional.ifPresent(Optional.java:159)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:352)
at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequest$10(OrderedAsync.java:235)
at org.apache.ratis.client.impl.OrderedAsync$$Lambda$776/1213731951.apply(Unknown Source)
at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870)
at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852)
at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:324)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.close(GrpcClientProtocolClient.java:313)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$400(GrpcClientProtocolClient.java:245)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$close$1(GrpcClientProtocolClient.java:131)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$$Lambda$950/1948156329.accept(Unknown Source)
at java.util.Optional.ifPresent(Optional.java:159)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient.close(GrpcClientProtocolClient.java:131)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$close$1(PeerProxyMap.java:73)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy$$Lambda$948/427065222.run(Unknown Source)
at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
at org.apache.ratis.util.LifeCycle$$Lambda$949/1311526821.get(Unknown Source)
at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.close(PeerProxyMap.java:70)
- locked <0x00000003e793ef48> (a org.apache.ratis.util.PeerProxyMap$PeerAndProxy)
at org.apache.ratis.util.PeerProxyMap.resetProxy(PeerProxyMap.java:126)
- locked <0x0000000215453400> (a java.lang.Object)
at org.apache.ratis.util.PeerProxyMap.handleException(PeerProxyMap.java:135)
at org.apache.ratis.client.impl.RaftClientRpcWithProxy.handleException(RaftClientRpcWithProxy.java:47)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:375)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:341)
at org.apache.ratis.client.impl.UnorderedAsync.lambda$sendRequestWithRetry$4(UnorderedAsync.java:108)
at org.apache.ratis.client.impl.UnorderedAsync$$Lambda$976/655038759.accept(Unknown Source)
at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
at java.util.concurrent.CompletableFuture$Completion.exec(CompletableFuture.java:443)
at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
{code}

{code}
orkJoinPool.commonPool-worker-25
priority:5 - threadId:0x00007f48d8349000 - nativeId:0x9ff4 - nativeId (decimal):40948 - state:BLOCKED
stackTrace:
java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.ratis.util.SlidingWindow$Client.resetFirstSeqNum(SlidingWindow.java:348)
- waiting to lock <0x0000000083738128> (a org.apache.ratis.util.SlidingWindow$Client)
at org.apache.ratis.client.impl.OrderedAsync.resetSlidingWindow(OrderedAsync.java:122)
at org.apache.ratis.client.impl.OrderedAsync$$Lambda$943/1670264164.accept(Unknown Source)
at org.apache.ratis.client.impl.RaftClientImpl.lambda$handleIOException$6(RaftClientImpl.java:352)
at org.apache.ratis.client.impl.RaftClientImpl$$Lambda$944/769363367.accept(Unknown Source)
at java.util.Optional.ifPresent(Optional.java:159)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:352)
at org.apache.ratis.client.impl.OrderedAsync.lambda$sendRequest$10(OrderedAsync.java:235)
at org.apache.ratis.client.impl.OrderedAsync$$Lambda$776/1213731951.apply(Unknown Source)
at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870)
at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852)
at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:324)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.close(GrpcClientProtocolClient.java:313)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$400(GrpcClientProtocolClient.java:245)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$close$1(GrpcClientProtocolClient.java:131)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$$Lambda$950/1948156329.accept(Unknown Source)
at java.util.Optional.ifPresent(Optional.java:159)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient.close(GrpcClientProtocolClient.java:131)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$close$1(PeerProxyMap.java:73)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy$$Lambda$948/427065222.run(Unknown Source)
at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
at org.apache.ratis.util.LifeCycle$$Lambda$949/1311526821.get(Unknown Source)
at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.close(PeerProxyMap.java:70)
- locked <0x00000001fced7120> (a org.apache.ratis.util.PeerProxyMap$PeerAndProxy)
at org.apache.ratis.util.PeerProxyMap.resetProxy(PeerProxyMap.java:126)
- locked <0x0000000083743b10> (a java.lang.Object)
at org.apache.ratis.util.PeerProxyMap.handleException(PeerProxyMap.java:135)
at org.apache.ratis.client.impl.RaftClientRpcWithProxy.handleException(RaftClientRpcWithProxy.java:47)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:375)
at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:341)
at org.apache.ratis.client.impl.UnorderedAsync.lambda$sendRequestWithRetry$4(UnorderedAsync.java:108)
at org.apache.ratis.client.impl.UnorderedAsync$$Lambda$976/655038759.accept(Unknown Source)
at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
at java.util.concurrent.CompletableFuture$Completion.exec(CompletableFuture.java:443)
at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
{code}

{code}
pool-2-thread-20
priority:5 - threadId:0x00007f48fd02d000 - nativeId:0x9e26 - nativeId (decimal):40486 - state:BLOCKED
stackTrace:
java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:242)
- waiting to lock <0x0000000083738128> (a org.apache.ratis.util.SlidingWindow$Client)
at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:156)
at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:148)
at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:128)
at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:224)
at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:301)
at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:609)
at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:466)
at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.write(BlockOutputStream.java:248)
at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:129)
at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:211)
at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
at org.apache.hadoop.ozone.freon.RandomKeyGenerator$OfflineProcessor.run(RandomKeyGenerator.java:650)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
{code}",[],2019-06-14 08:19:27+00:00,2019-06-24 06:27:12+00:00,2019-06-24 06:27:12+00:00,Resolved,13239476,RATIS-590
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In SegmentedRaftLogOutputStream.write(LogEntryProto entry), the entry is first converted to a byte array and then write to BufferedWriteChannel.  In BufferedWriteChannel, it copies the byte array to a ByteBuffer.  The copying should be eliminated.",[],2019-06-14 00:57:08+00:00,,2019-06-19 01:36:26+00:00,Patch Available,13239407,RATIS-589
Bug,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,"It is desirable to export data out of the StateMachine itself to ensure that RAFT quorums remain well-performing. After new data stops flowing into the LogService, we can export the log out of the LogService and to a distributed filesystem that would have more ideal storage facilities. Moving these logs out of the LogService helps avoid local disk capacity issues at the Ratis level. Ideally, this would be another extension point for each storage systems which would provide common LogService API, easing adoption by downstream applications 

* Work Breakdown
* Configure MetadataStateMachine with some “remote storage” location (e.g. hdfs://localhost:8020/ratis-logs). This is “cold” storage where we can place a log in after we disallow writes to it (when it moves to the state “CLOSED”)
* When the MetadataStateMachine moves a log to the CLOSED state, it must queue it to be uploaded to the remote storage location. This can be accompanied with some new state, e.g. “ARCHIVED”
* When clients try to read a log which is “ARCHIVED”, they must know to read from this location in remote storage, instead of from the LogStateMachine as before.
* Implement a LogStream implementation that gives the same API to clients to read from the LogStateMachine (as it does today) or from the remote storage location.
* Optional: rewrite the RAFT log into a more optimal form upon writing it to the remote storage location. E.g we don’t need to maintain Ratis-internal log messages.

Thanks [~elserj] for the above write-up.",[],2019-06-12 17:57:28+00:00,2019-07-18 00:20:02+00:00,2019-07-25 16:27:34+00:00,Resolved,13239099,RATIS-588
Bug,[],sdeka,Supratim Deka,sdeka,Supratim Deka,Major,"SegmentedRaftLog uses a BufferedWriteChannel for writing the log.
FinalizeLogSegment task is enqueued when a segment fills up. This task closes the channel and does cleanup.

SegmentedRaftLogOutputStream.close() internally invokes BufferedWriteChannel.flush(false)
the false passed to flush indicates not to flush the buffer cache.

This means that the contents of the log file are not persisted on disk. An abrupt power failure could result in loss of committed log entries. ",[],2019-06-11 09:11:43+00:00,2019-06-17 18:28:48+00:00,2019-06-17 18:28:48+00:00,Resolved,13238712,RATIS-587
Bug,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"On receiving install snapshot notification and installing a snapshot, the follower should only return the installed snapshot index. Currently the return type is termIndex but snapshots do not have a term.",['ozone'],2019-06-07 23:53:10+00:00,,2019-08-16 21:10:58+00:00,Open,13238327,RATIS-586
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,LogMetadata call on receiving a quorum does not wait for the file IO to complete before acknowledging the watch requests. This can lead to problems on restart where a watch request acknowledged back to the client is not persisted.,[],2019-06-05 05:01:11+00:00,,2019-06-12 23:49:01+00:00,Open,13237643,RATIS-585
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis currently triggers commit entry for every log entry which has been replicated. Each of these commit entries is in turn a file IO to the raft log.

For Ozone, this commit entries in the log are only needed for PutBlock requests, and this should be configurable in Ratis too.",['ozone'],2019-06-05 04:57:47+00:00,,2019-07-14 15:26:50+00:00,Open,13237642,RATIS-584
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-539, we have directly updated asf-site without asf-site-source.  This JIRA is to sync asf-site-source with asf-site.",[],2019-06-04 07:51:52+00:00,2019-06-05 03:45:27+00:00,2019-06-05 03:45:27+00:00,Resolved,13237419,RATIS-583
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Looks like folks have been modifying the contents of the generated website instead of using `hugo` on the asf-site-source branch to generate new HTML for them.

Figure out what all has been changed in the generated website, and make sure that is captured in asf-site-source, too.",[],2019-06-03 21:18:09+00:00,2019-06-07 18:45:08+00:00,2019-06-07 18:45:08+00:00,Resolved,13237333,RATIS-582
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Update the website with some info about the logservice.

cc/ [~clayb].",[],2019-06-02 01:33:08+00:00,2019-06-07 19:44:56+00:00,2019-06-07 19:44:56+00:00,Resolved,13237077,RATIS-581
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"Follow-up from RATIS-574. Similar to request based customization, the RetryPolicy interface should allow for customized sleepTime based on the exception.",['ozone'],2019-05-31 20:41:04+00:00,2019-11-06 09:42:19+00:00,2019-11-06 09:49:33+00:00,Resolved,13236966,RATIS-580
Bug,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"ExitUtils.terminate is called for several different scenarios. In a multi-raft scenario, this would result in JVM shutdown and renders all groups unusable.

Stacktrace:
{code}
2019-05-21 23:26:52,692 ERROR org.apache.ratis.util.ExitUtils: Terminating with exit status -1: Thread[64008f18-c6d8-4c99-a116-9b772e8c4953:group-D6E12D98D556:LeaderElection
2450,5,main] has thrown an uncaught exception
java.lang.IllegalStateException: ILLEGAL TRANSITION: In 64008f18-c6d8-4c99-a116-9b772e8c4953:group-D6E12D98D556:LeaderElection2450, RUNNING -> CLOSED
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
        at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:123)
        at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:143)
        at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:154)
        at java.lang.Thread.run(Thread.java:748)
{code}",[],2019-05-30 22:14:07+00:00,2019-06-14 22:01:37+00:00,2019-06-14 22:01:37+00:00,Resolved,13236711,RATIS-579
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Illegal State transition in LeaderElection

{code}
java.lang.IllegalStateException: ILLEGAL TRANSITION: In 3d75e29e-ff2a-47a6-82c4-6408d200876d:2019group--CB73AD2587F6:LeaderElection13, STARTING -> CLOSED

java.lang.IllegalStateException: ILLEGAL TRANSITION: In 3d75e29e-ff2a-47a6-82c4-6408d200876d:group-CB73AD2587F6:LeaderElection13, CLOSED -> RUNNING

java.lang.IllegalStateException: ILLEGAL TRANSITION: In 37da83b0-33ff-44cf-aeb9-67a102e13468:group-9FC4313E1696:LeaderElection217, RUNNING -> CLOSED

java.lang.IllegalStateException: IL2LEGAL TRANSITION: I0n 95ef0599-6d8a-40f8-a69c-7ba0c956dc6c:group-21734B88A322:LeaderElection265, RUNNING -> CLOSED
{code}",['ozone'],2019-05-30 13:23:12+00:00,2019-08-02 19:57:54+00:00,2019-11-20 06:45:05+00:00,Resolved,13236486,RATIS-578
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Found the following NPE in the LogAppender while creating a new request.

{code}
2019-05-30 08:10:44,275 ERROR impl.LogAppender (LogAppender.java:run(90)) - org.apache.ratis.server.impl.LogAppender$AppenderDaemon@5e4b44cc unexpected exception
java.lang.NullPointerException
        at java.util.Objects.requireNonNull(Objects.java:203)
        at java.util.Optional.<init>(Optional.java:96)
        at java.util.Optional.of(Optional.java:108)
        at org.apache.ratis.server.impl.ServerProtoUtils.getStateMachineEntry(ServerProtoUtils.java:197)
        at org.apache.ratis.server.impl.ServerProtoUtils.getStateMachineData(ServerProtoUtils.java:205)
        at org.apache.ratis.server.impl.ServerProtoUtils.shouldReadStateMachineData(ServerProtoUtils.java:210)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:206)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:209)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:169)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:113)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:80)
        at java.lang.Thread.run(Thread.java:748)
{code}",['MiniOzoneChaosCluster'],2019-05-30 09:54:48+00:00,2019-06-13 20:45:33+00:00,2019-06-13 20:45:33+00:00,Resolved,13236445,RATIS-577
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,"TestWatchRequestWithGrpc#testWatchRequestTimeout fails with the below exception.
{code:java}
java.util.concurrent.ExecutionException: org.apache.ratis.protocol.NotReplicatedException: Request with call Id 2221 and log index 1 is not yet replicated to ALL

at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
at org.apache.ratis.WatchRequestTests$WatchReplies.get(WatchRequestTests.java:165)
at org.apache.ratis.WatchRequestTests$WatchReplies.getAll(WatchRequestTests.java:155)
at org.apache.ratis.WatchRequestTests.checkTimeout(WatchRequestTests.java:401)
at org.apache.ratis.WatchRequestTests.runTestWatchRequestTimeout(WatchRequestTests.java:384)
at org.apache.ratis.WatchRequestTests.runTest(WatchRequestTests.java:122)
at org.apache.ratis.WatchRequestTests.lambda$testWatchRequestTimeout$8(WatchRequestTests.java:338)
at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:125)
at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:113)
at org.apache.ratis.WatchRequestTests.testWatchRequestTimeout(WatchRequestTests.java:337)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.NotReplicatedException: Request with call Id 2221 and log index 1 is not yet replicated to ALL
at org.apache.ratis.client.impl.ClientProtoUtils.toRaftClientReply(ClientProtoUtils.java:236)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onNext(GrpcClientProtocolClient.java:253)
at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onNext(GrpcClientProtocolClient.java:248)
at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
... 1 more

{code}",[],2019-05-29 08:55:17+00:00,2019-06-28 07:47:08+00:00,2019-06-28 07:47:24+00:00,Resolved,13236191,RATIS-575
Improvement,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Major,"While doing performance tests with Ozone, it was observed that the client always waits for retry timeout when a NotLeaderException is logged. This bears a performance penalty for the client who cannot try the next Ratis server in the ring.",[],2019-05-28 17:41:56+00:00,2019-06-05 03:33:46+00:00,2019-10-22 11:36:31+00:00,Resolved,13236056,RATIS-574
Improvement,[],sdeka,Supratim Deka,sdeka,Supratim Deka,Major,"As part of Handling IO Failures, HDDS-1595.

The scope of this jira is to handle failure in RAFT log append by:
1. notify the error to the state machine for consumer specific handling
2. propagate the error to the initiator (to the client from leader, to the leader from follower).
",[],2019-05-28 01:12:20+00:00,2019-06-24 05:21:16+00:00,2019-06-24 05:21:16+00:00,Resolved,13235889,RATIS-573
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently the raft server does not process a request until the first request for the sliding window is received. This is non-optimal in cases where the server is not a leader or where the requests can fail fast as the server waits for the first request before processing. Ideally there should be a preprocessing phase which can fail requests in such cases.,['ozone'],2019-05-27 10:34:57+00:00,,2019-07-14 15:29:08+00:00,Open,13235784,RATIS-572
Bug,[],rakeshr,Rakesh Radhakrishnan,rakeshr,Rakesh Radhakrishnan,Blocker,"Hits NPE during Freon benchmark test run. Below is the exception logged at the client side output log message. 

{code}
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@6c585536
java.lang.NullPointerException
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.completeReplyExceptionally(GrpcClientProtocolClient.java:320)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.access$000(GrpcClientProtocolClient.java:245)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers$1.onError(GrpcClientProtocolClient.java:269)
        at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
        at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
        at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

{code}",['ozone'],2019-05-27 10:01:19+00:00,2020-05-03 05:23:03+00:00,2020-05-03 05:23:03+00:00,Resolved,13235774,RATIS-576
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"It is possible for the client to send first request in sliding window with firstFlag as false.

In the below example, request with sequence number 73 is accepted in the sliding window when the first request is 70. Therefore its first flag is false. After that the request with sequence 72 gets a reply from the stream observer dc40cfe3. When request 73 is sent to stream observer 87103303 the first flag as false and is therefore never processed in the new stream observer. It leads to all requests in the server sliding window to be blocked.

 
{code:java}
2019-05-26 11:07:50,532 INFO util.SlidingWindow (SlidingWindow.java:sendOrDelayRequest(243)) - uid=4272f0d0-95e7-461a-9201-82ddfb218847 request seqNum=73 requestsFirst=70 firstSeqNum=-1 request=RaftClien
tRequest:client-DBC1276EA2C1->s0@group-6920A8550E5D, cid=952, seq=73, RW, 3-72
2019-05-26 11:07:50,622 INFO util.SlidingWindow (SlidingWindow.java:sendRepliesFromHead(439)) - dc40cfe3-a06a-43db-893e-e86b0cd41a8b server send reply seq=72 request=RaftClientRequest:client-DBC1276EA2C1
->s1@group-6920A8550E5D, cid=938, seq=72*, RW, Message:332d3731:RaftClientReply:client-DBC1276EA2C1->s1@group-6920A8550E5D, cid=938, SUCCESS, logIndex=842, commits[s1:c914, s0:c914, s2:c717]
2019-05-26 11:07:50,628 DEBUG client.RaftClient (RaftClientImpl.java:sendRequestAsync(364)) - client-DBC1276EA2C1: send* RaftClientRequest:client-DBC1276EA2C1->s2@group-6920A8550E5D, cid=952, seq=73, RW, 3-72
2019-05-26 11:07:50,633 INFO  util.SlidingWindow (SlidingWindow.java:receivedRequest(398)) - uid=87103303-ba73-45bf-b2ee-e6c8debf7a25 server received request=RaftClientRequest:client-DBC1276EA2C1->s2@group-6920A8550E5D, cid=952, seq=73, RW, Message:332d3732:null 13-OrderedRequestStreamObserver13: got seq=73 in 13-OrderedRequestStreamObserver13: requests[], nextToProcess=-1
{code}
 ",[],2019-05-27 09:00:53+00:00,2019-06-04 09:04:29+00:00,2019-06-24 06:10:45+00:00,Resolved,13235759,RATIS-571
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,"a) A NotleaderException received by the client causes the client to reset the streamObserver. This can be avoided

b) The close of the current channel can happen offline in another thread managing the connection pool.",['ozone'],2019-05-24 18:30:03+00:00,,2019-07-15 11:32:14+00:00,Open,13235506,RATIS-570
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,"Running TestDataValidate in Ozone leads to StatusRuntimeException on the datanode frequently.
This causes an unclean shutdown on the stream on the datanode.

In GrpcClientProtocolClient, shutdownNow should be followed by a awaitTermination to wait for a clean shutdown.",['ozone'],2019-05-24 18:26:51+00:00,2019-09-14 04:51:30+00:00,2019-09-14 04:51:30+00:00,Resolved,13235504,RATIS-569
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently SlidingWindow does not fail the out of order requests on close. The out of order requests are not processed and are therefore never removed from the queue leading to memory leak. Further OrderedRequestStreamObserver should be removed from the orderedStreamObservers map on error or completion.,[],2019-05-24 06:51:01+00:00,2019-05-29 04:50:41+00:00,2019-06-27 05:35:05+00:00,Resolved,13235300,RATIS-568
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,RaftServerImpl#getID should return a groupID and peerID suffixed value to help with debugging.,[],2019-05-23 17:33:53+00:00,2019-07-15 05:03:58+00:00,2019-07-15 05:03:58+00:00,Resolved,13235191,RATIS-567
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,OrderedStreamObservers#closeAllExisting currently closes all the stream observers on notifyNotLeader. However this can lead to stream observers for a different groups to be closed. This can cause the client to retry unnecessarily. Not leader should only close the stream observers for a certain groupid.,[],2019-05-23 17:31:31+00:00,2019-05-29 08:40:04+00:00,2019-05-30 04:31:13+00:00,Resolved,13235189,RATIS-566
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"The ordered async client code currently is in RaftClientImpl so that it is mixed with the sync'ed client code, while the unordered async code is in UnorderedAsync.  This JIRA is to move the ordered async code to OrderedAsync so that it is easier for debugging and testing.",[],2019-05-23 08:29:54+00:00,2019-05-29 08:59:05+00:00,2019-05-29 08:59:05+00:00,Resolved,13235074,RATIS-565
Improvement,[],swagle,Siddharth Wagle,swagle,Siddharth Wagle,Major,"The current API: org.apache.ratis.statemachine.StateMachine#notifyInstallSnapshotFromLeader, only provides the term index and does not provide the raft group information to the follower.",[],2019-05-22 23:16:12+00:00,2019-06-05 07:29:46+00:00,2019-06-12 05:33:41+00:00,Resolved,13235014,RATIS-564
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Leader will purge the snapshot after applying a transaction. A transaction is applied after a majority has been reached. This means that a slow follower will request for a transaction which has already been purged and for this transaction to catchup the leader has to transfer the snapshot. This can be detrimental for the performance while replicating.,[],2019-05-21 06:02:07+00:00,2019-05-28 18:21:59+00:00,2019-05-28 18:21:59+00:00,Resolved,13234487,RATIS-563
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,Different StateMachine might need to add a new configurable purging policy inside Ratis.,['ozone'],2019-05-21 05:57:54+00:00,,2020-09-20 05:57:38+00:00,Open,13234486,RATIS-562
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently StateMachineUpdater only takes snapshots based on number of transaction. StateMachine should be able to control taking snapshots for following cases
a) time elapsed
b) once certain conditions are met, these conditions will be specified in the implementing statemachine.
",[],2019-05-20 07:40:56+00:00,2019-07-15 05:06:10+00:00,2019-07-15 05:06:10+00:00,Resolved,13234221,RATIS-561
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Minor,While debugging Ratis issues it is important to also print the SM log entry proto objects. This jira will add a callback to Ratis to print the SMLogEntryProto objects.,['ozone'],2019-05-20 07:34:42+00:00,2019-07-15 05:02:20+00:00,2019-07-15 05:02:20+00:00,Resolved,13234219,RATIS-560
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"GrpcLogAppender#createRequest throws IllegalStateException

{code}
2019-05-19 13:29:29,879 ERROR impl.LogAppender (LogAppender.java:run(90)) - org.apache.ratis.server.impl.LogAppender$AppenderDaemon@f7cf7bd unexpected exception
java.lang.IllegalStateException: GrpcLogAppender(c04faabb-66d4-4cd0-85c2-412d28ae70e1->bd0ce7cf-56a1-44e8-bf84-3cf5d431c1cf): follower's nextIndex = 1 != logStartIndex = 9995
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
        at org.apache.ratis.server.impl.LogAppender.getPrevious(LogAppender.java:179)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:186)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:169)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:113)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:80)
        at java.lang.Thread.run(Thread.java:748)

{code}",[],2019-05-19 08:18:20+00:00,2019-05-24 06:08:24+00:00,2019-05-24 06:08:24+00:00,Resolved,13234157,RATIS-559
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Follower stuck in inconsistent state after node restart 
{code}
2019-05-19 12:02:24,377 INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(983)) - e143b976-ab35-4555-a800-7f05a2b1b738: Failed appendEntries as latest snapshot (5128) already h
as the append entries (first index: 0)
2019-05-19 12:02:24,378 INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(965)) - e143b976-ab35-4555-a800-7f05a2b1b738: inconsistency entries. Reply:ad136ce5-92e0-4bd6-a302-cdd
4f8b7775b<-e143b976-ab35-4555-a800-7f05a2b1b738#34:FAIL,INCONSISTENCY,nextIndex:5129,term:4,followerCommit:5128
2019-05-19 12:02:24,383 INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(983)) - e143b976-ab35-4555-a800-7f05a2b1b738: Failed appendEntries as latest snapshot (5128) already h
as the append entries (first index: 1)
2019-05-19 12:02:24,387 INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(965)) - e143b976-ab35-4555-a800-7f05a2b1b738: inconsistency entries. Reply:ad136ce5-92e0-4bd6-a302-cdd4f8b7775b<-e143b976-ab35-4555-a800-7f05a2b1b738#35:FAIL,INCONSISTENCY,nextIndex:5129,term:4,followerCommit:5128
2019-05-19 12:02:24,387 ERROR server.GrpcLogAppender (GrpcLogAppender.java:onNext(236)) - Failed onNext request=ad136ce5-92e0-4bd6-a302-cdd4f8b7775b->e143b976-ab35-4555-a800-7f05a2b1b738#34-t4, previous=(t:0, i:0), leaderCommit=5182, initializing? false, entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY, reply=ad136ce5-92e0-4bd6-a302-cdd4f8b7775b<-e143b976-ab35-4555-a800-7f05a2b1b738#34:FAIL,INCONSISTENCY,nextIndex:5129,term:4,followerCommit:5128
java.lang.IllegalStateException
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:36)
        at org.apache.ratis.grpc.server.GrpcLogAppender.checkAndUpdateNextIndex(GrpcLogAppender.java:304)
        at org.apache.ratis.grpc.server.GrpcLogAppender.access$900(GrpcLogAppender.java:47)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNextImpl(GrpcLogAppender.java:267)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:234)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:214)
        at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}",['MiniOzoneChaosCluster'],2019-05-19 07:16:28+00:00,2019-05-23 06:42:51+00:00,2019-05-23 06:43:22+00:00,Resolved,13234153,RATIS-558
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis leader is throwing illegalStateException for the while responding to Inconsistency entries in raft log.

{code}
2019-05-19 12:02:24,387 ERROR server.GrpcLogAppender (GrpcLogAppender.java:onNext(236)) - Failed onNext request=ad136ce5-92e0-4bd6-a302-cdd4f8b7775b->e143b976-ab35-4555-a800-7f05a2b1b738#34-t4, previous=(t:0, i:0), leaderCommit=5182, initializing? false, entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY, reply=ad136ce5-92e0-4bd6-a302-cdd4f8b7775b<-e143b976-ab35-4555-a800-7f05a2b1b738#34:FAIL,INCONSISTENCY,nextIndex:5129,term:4,followerCommit:5128
java.lang.IllegalStateException
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:36)
        at org.apache.ratis.grpc.server.GrpcLogAppender.checkAndUpdateNextIndex(GrpcLogAppender.java:304)
        at org.apache.ratis.grpc.server.GrpcLogAppender.access$900(GrpcLogAppender.java:47)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNextImpl(GrpcLogAppender.java:267)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:234)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:214)
        at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}",['MiniOzoneChaosCluster'],2019-05-19 06:50:10+00:00,2019-05-23 06:43:58+00:00,2019-05-23 06:43:58+00:00,Resolved,13234151,RATIS-557
Improvement,[],rajeshbabu,Rajeshbabu Chintaguntla,rajeshbabu,Rajeshbabu Chintaguntla,Major,Currently there is no way to detect the node failures at master log servers and add new nodes to the group serving the log. We need to analyze how Ozone is working in this case.,[],2019-05-15 14:36:59+00:00,2019-09-05 05:04:49+00:00,2019-09-05 10:54:30+00:00,Resolved,13233502,RATIS-556
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The are quite a many classes in org.apache.ratis.server.storage are RaftLog related -- the general interface, the segmented RaftLog implementation and the memory RaftLog implementation.  Let's move them to separated packages.",[],2019-05-14 02:06:13+00:00,2019-05-15 23:19:53+00:00,2019-05-15 23:19:53+00:00,Resolved,13233114,RATIS-555
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Blocker,,['ozone'],2019-05-14 01:14:02+00:00,2019-08-22 20:48:26+00:00,2019-08-22 20:48:26+00:00,Resolved,13233109,RATIS-554
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-05-14 01:08:23+00:00,2019-05-29 16:04:00+00:00,2019-05-29 16:04:00+00:00,Resolved,13233108,RATIS-553
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,"Basic metric implemented through timer to get :-
* No. of requests
* Histogram for the time taken by the request
* Request rate etc

Metrics collected at server for LogStream
||MetricName||Metric description||
| readNextQueryTime | Read request from reader on next() call|
|startIndexTime| Request to get start index of the log|
|sizeRequestTime|request to get size of the log|
|getStateTime| request to get state of log(currently managed at client so may be 0 all the time)|
|lastIndexQueryTime| request to get last index of the log|
|lengthQuery|request to get length of the log|

Metric collected at Metadata service
||MetricName||Metric description||
|CREATELOG|request to create log|
|DELETELOG|request to delete log|
|LISTLOG|request to list log|
|GETLOG|request to get log|
|ARCHIVELOG|request to archive log|

",[],2019-05-14 00:29:27+00:00,2019-05-29 16:03:49+00:00,2019-05-29 16:03:49+00:00,Resolved,13233105,RATIS-552
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-05-14 00:28:24+00:00,2019-07-09 19:18:40+00:00,2019-07-09 19:18:40+00:00,Resolved,13233104,RATIS-551
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-05-14 00:25:55+00:00,2019-05-29 16:03:38+00:00,2019-05-29 16:03:38+00:00,Resolved,13233103,RATIS-550
Sub-task,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-05-14 00:24:33+00:00,2019-05-29 16:03:12+00:00,2019-05-29 16:03:12+00:00,Resolved,13233102,RATIS-549
New Feature,[],ankit@apache.org,Ankit Singhal,ankit@apache.org,Ankit Singhal,Major,,[],2019-05-14 00:16:35+00:00,2019-07-24 18:51:17+00:00,2019-07-24 18:51:17+00:00,Resolved,13233100,RATIS-548
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In RaftLogCache, there are quite a few inner classes which are used in quite many places.  Let move some of them out.",[],2019-05-13 23:42:58+00:00,,2019-05-27 11:03:02+00:00,Patch Available,13233087,RATIS-547
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"To simulate ""real-world"" situations, it would be nice for the VerificationTool to be capable of padding out the values it writes to generate non-trivial ""logs"". Presently, it's difficult to get the LogService to roll into a new Raft log segment.

To try to retain the verification of the value, we can implement this by keeping the original value as a prefix, but then generate random data as the suffix of the entry.

cc/ [~chrajeshbabu32@gmail.com]",[],2019-05-13 23:32:46+00:00,2019-05-16 13:20:40+00:00,2019-05-16 13:20:40+00:00,Resolved,13233084,RATIS-546
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,It is possible for a follower to turn itself to a candidate after a JVM pause. The timeout in follower should consider the JVM pause interval before triggering leader re-election.,[],2019-05-09 08:46:41+00:00,2019-06-03 06:45:32+00:00,2019-06-03 06:45:46+00:00,Resolved,13232404,RATIS-545
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Apart from taking snapshots at a certain frequency, there should also be ability to trigger snapshot creation based on timing or on any other external trigger from the implementing statemachine.",['ozone'],2019-05-08 09:30:08+00:00,,2019-07-15 05:06:11+00:00,Open,13232185,RATIS-544
Bug,[],avijayan,Aravindan Vijayan,avijayan,Aravindan Vijayan,Blocker,"{code}
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1352, SUCCESS, logIndex=15195,
 commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15201, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15189, aaf673a3-95ac-43aa-8614-b1a324142430:c15186]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1355, SUCCESS, logIndex=15196,
 commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15201, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15189, aaf673a3-95ac-43aa-8614-b1a324142430:c15186]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1357, SUCCESS, logIndex=15197,
 commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15201, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15189, aaf673a3-95ac-43aa-8614-b1a324142430:c15186]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-C46A037579AA->5a076d87-abf9-4ade-ae37-adab741d99a6: receive RaftClientReply:client-C46A037579AA->5a076d87-abf9-4ade-ae37-adab741d99a6@group-AE803AF42C5D, cid=1370, SUCCESS, logIndex=0, com
mits[5a076d87-abf9-4ade-ae37-adab741d99a6:c16423, 6e21905d-9796-4248-834e-ed97ea6763ef:c16422, 34e8d6e5-456f-4e2a-99a5-4f21fd9c4a7e:c16423]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-EBF618C3F968->a5729949-67f1-496e-a0d3-1bfc0e139836: receive RaftClientReply:client-EBF618C3F968->a5729949-67f1-496e-a0d3-1bfc0e139836@group-4E41299EA191, cid=1376, SUCCESS, logIndex=0, com
mits[a5729949-67f1-496e-a0d3-1bfc0e139836:c4764, 111d4c23-756f-4c8a-a48d-aa2a327a5179:c4764, 287eccfb-8461-419a-8732-529d042380b3:c4764]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-4D5E3CDC8889->0bb45975-b0d2-499e-85cc-22ea22c57ecb: receive RaftClientReply:client-4D5E3CDC8889->0bb45975-b0d2-499e-85cc-22ea22c57ecb@group-D1BB7F32F754, cid=1382, FAILED org.apache.ratis.
protocol.NotLeaderException: Server 0bb45975-b0d2-499e-85cc-22ea22c57ecb is not the leader (f1a756c3-6b42-4ece-8093-dbcdac5f8d5b:10.17.200.18:9858). Request must be sent to leader., logIndex=0, commits[0bb45975-b0d2-499e-85cc-22ea22c57ecb:c15358, 6c7a
780f-5474-49da-b880-3eaf69d9d83d:c15358, f1a756c3-6b42-4ece-8093-dbcdac5f8d5b:c15358]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1359, SUCCESS, logIndex=15208, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15210, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1362, SUCCESS, logIndex=15209, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15210, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
19/05/03 10:23:31 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1363, SUCCESS, logIndex=15210, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15210, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
19/05/03 10:23:32 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1371, SUCCESS, logIndex=15211, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15211, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
19/05/03 10:23:32 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1372, SUCCESS, logIndex=15212, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15214, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
19/05/03 10:23:32 INFO client.GrpcClientProtocolClient: client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da: receive RaftClientReply:client-FD23551CACEE->51711703-9f9d-4c79-bfb1-38726f0059da@group-1EADCA052664, cid=1373, SUCCESS, logIndex=15213, commits[51711703-9f9d-4c79-bfb1-38726f0059da:c15214, 0beac0f1-af74-43ac-ba73-0a92ecb9f0ae:c15201, aaf673a3-95ac-43aa-8614-b1a324142430:c15189]
{code}",['ozone'],2019-05-06 17:06:42+00:00,2019-09-10 09:07:14+00:00,2019-09-11 21:00:17+00:00,Resolved,13231827,RATIS-543
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"IllegalStateException stating ""Unexpected gap in segments: binarySearch(-1) returns -1, segments=[log-0_0]"" when ozone datanode is restarted.
{code:java}
2019-05-05 06:26:47,217 INFO org.apache.ratis.server.impl.RaftServerProxy: bf6fd9c4-100a-4035-98db-abe8e0a25fb9: remove LEADER group-AC345A757F02 bf6fd9c4-100a-4035-98db-abe8e0a25fb9:t2, leader=bf6fd9c4-100a-4035-98db-abe8e0a25fb9, voted=bf6fd9c4-100a-4035-98db-abe8e0a25fb9, raftlog=bf6fd9c4-100a-4035-98db-abe8e0a25fb9-SegmentedRaftLog:OPENED:c2,f2,i2, conf=1: [bf6fd9c4-100a-4035-98db-abe8e0a25fb9:172.27.76.77:9858], old=null RUNNING
2019-05-05 06:26:47,230 INFO org.apache.ratis.server.impl.RaftServerImpl: bf6fd9c4-100a-4035-98db-abe8e0a25fb9: shutdown group-AC345A757F02
2019-05-05 06:26:47,230 INFO org.apache.ratis.util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC345A757F02,id=bf6fd9c4-100a-4035-98db-abe8e0a25fb9
2019-05-05 06:26:47,231 INFO org.apache.ratis.server.impl.RoleInfo: bf6fd9c4-100a-4035-98db-abe8e0a25fb9: shutdown LeaderState
2019-05-05 06:26:47,231 INFO org.apache.ratis.server.impl.PendingRequests: bf6fd9c4-100a-4035-98db-abe8e0a25fb9-PendingRequests: sendNotLeaderResponses
2019-05-05 06:26:47,236 INFO org.apache.ratis.server.impl.StateMachineUpdater: StateMachineUpdater-bf6fd9c4-100a-4035-98db-abe8e0a25fb9-group-AC345A757F02: set stopIndex = 2
2019-05-05 06:26:47,239 ERROR org.apache.ratis.server.impl.StateMachineUpdater: Terminating with exit status 2: StateMachineUpdater-bf6fd9c4-100a-4035-98db-abe8e0a25fb9-group-AC345A757F02: the StateMachineUpdater hits Throwable
java.lang.IllegalStateException: Unexpected gap in segments: binarySearch(-1) returns -1, segments=[log-0_0]
at org.apache.ratis.server.storage.RaftLogCache$LogSegmentList.purge(RaftLogCache.java:259)
at org.apache.ratis.server.storage.RaftLogCache.purge(RaftLogCache.java:461)
at org.apache.ratis.server.storage.SegmentedRaftLog.purgeImpl(SegmentedRaftLog.java:273)
at org.apache.ratis.server.storage.RaftLog.purge(RaftLog.java:325)
at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
at java.lang.Thread.run(Thread.java:748)
2019-05-05 06:26:47,249 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Thread Interrupted waiting to refresh disk information: sleep interrupted
{code}",[],2019-05-05 06:33:30+00:00,2019-05-16 22:23:35+00:00,2019-05-16 22:23:35+00:00,Resolved,13231631,RATIS-542
Improvement,[],rajeshbabu,Rajeshbabu Chintaguntla,rajeshbabu,Rajeshbabu Chintaguntla,Major,"Currently, in the verification tool, we are verifying single updates correctness in verification but the same can do for batch and mix of batch and single updates.",[],2019-05-03 08:28:34+00:00,2019-07-17 12:14:21+00:00,2019-07-17 23:38:27+00:00,Resolved,13231410,RATIS-541
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,LeaderElection#shutdown does not stop the daemon. This leads to multiple leader election threads accumulating in the JVM as a daemon is added in every leader election. It ultimately leads to JVM shutdown.,[],2019-05-02 10:42:31+00:00,2019-05-14 13:44:32+00:00,2019-05-14 13:44:32+00:00,Resolved,13231228,RATIS-540
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Ratis 0.3.0 is released.  We should add an announcement on the web site.,[],2019-04-29 21:22:43+00:00,2019-05-03 19:22:59+00:00,2019-05-03 19:22:59+00:00,Resolved,13230774,RATIS-539
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"For Ozone, the client watches for the commit indexes to catch up.

However after the leader commits an index in its log, it takes the next heartbeat to update the index on the follower.

This introduces an unnecessary delay in the protocol as watch for commit catch up takes time.

This can be optimized by forcing a heartbeat soon after the commit index is updated.",[],2019-04-26 13:07:07+00:00,2019-04-29 05:59:29+00:00,2019-04-29 05:59:29+00:00,Resolved,13230303,RATIS-537
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,RaftServerImpl#appendEntriesAsync receives both metadata and smdata entries from the leader. A follower should never append Metadata entry to its log.,[],2019-04-26 12:57:55+00:00,2019-04-30 07:28:08+00:00,2019-04-30 07:28:08+00:00,Resolved,13230301,RATIS-536
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{code:java}
2019-04-25 20:36:27,456 ERROR server.LogStateMachine (VerificationTool.java:waitForCompletion(129)) - Got exception
java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.ratis.logservice.common.LogAlreadyExistException: testlog2
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.ratis.logservice.tool.VerificationTool.waitForCompletion(VerificationTool.java:123)
at org.apache.ratis.logservice.tool.VerificationTool.main(VerificationTool.java:101)
Caused by: java.lang.RuntimeException: org.apache.ratis.logservice.common.LogAlreadyExistException: testlog2
at org.apache.ratis.logservice.tool.VerificationTool$BulkWriter.run(VerificationTool.java:170)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.logservice.common.LogAlreadyExistException: testlog2
at org.apache.ratis.logservice.server.MetaStateMachine.processCreateLogRequest(MetaStateMachine.java:291)
at org.apache.ratis.logservice.server.MetaStateMachine.query(MetaStateMachine.java:198)
at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:530)
at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:333)
at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:328)
at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109)
at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:328)
at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981)
at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124)
at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:327)
at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:333)
at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:206)
at org.apache.ratis.grpc.client.GrpcClientProtocolService$UnorderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:262)
at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:226)
at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:154)
at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248)
at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263)
at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:686)
at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
... 3 more
{code}
When running the verification tool, I occasionally see the above error message. However, when running the tool, the log definitely did not exist prior:
{noformat}
2019-04-25 20:35:44,278 INFO server.LogStateMachine (VerificationTool.java:main(83)) - Executing parallel writes
2019-04-25 20:35:44,919 INFO server.LogStateMachine (VerificationTool.java:main(91)) - Observed logs already in system: []
2019-04-25 20:35:44,921 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog0']
2019-04-25 20:35:44,932 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog1']
2019-04-25 20:35:44,935 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog3']
2019-04-25 20:35:44,932 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog2']
2019-04-25 20:35:44,941 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog5']
2019-04-25 20:35:44,942 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog4']
2019-04-25 20:35:44,950 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog8']
2019-04-25 20:35:44,948 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog7']
2019-04-25 20:35:44,948 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog6']
2019-04-25 20:35:44,953 INFO server.LogStateMachine (VerificationTool.java:run(157)) - Creating LogName['testlog9']{noformat}
I don't have a grasp on why this sometimes happens. If I had to guess, I'd start looking around what happens when the leader changes for the metadata quorum.",[],2019-04-25 19:47:03+00:00,,2019-04-25 19:47:03+00:00,Open,13230164,RATIS-535
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,"Due to JVM GC pauses a follower is not able to process the append entries and as a result turns into a candidate. This leads to leader reelection. Below are the logs illustrating the scenario.

Below are the leader ratis logs. The leader sends heartbeat to follower after every 500ms.
{code:java}
2019-04-23 18:34:46,360 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) appendRequest=leaderTerm=2, previousLog=term: 2
index: 211601
, leaderCommit=211601, commits: [5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:46,360 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) wait 500ms
2019-04-23 18:34:46,862 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) appendRequest=leaderTerm=2, previousLog=term: 2
index: 211601
, leaderCommit=211601, commits: [5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:46,862 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) wait 500ms
2019-04-23 18:34:47,362 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) appendRequest=leaderTerm=2, previousLog=term: 2
index: 211601
, leaderCommit=211601, commits: [5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:47,362 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) wait 500ms
2019-04-23 18:34:47,862 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) appendRequest=leaderTerm=2, previousLog=term: 2
index: 211601
, leaderCommit=211601, commits: [5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:47,863 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) wait 500ms
2019-04-23 18:34:48,363 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) appendRequest=leaderTerm=2, previousLog=term: 2
index: 211601
, leaderCommit=211601, commits: [5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:48,363 INFO org.apache.ratis.grpc.server.GrpcLogAppender: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:group-80F1E6232C38 APPENDER GrpcLogAppender(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16 -> eaa2a877-0e7f-44f3-a514-12243ce2b925) wait 500ms
{code}
Below are the follower logs showing a GC pause.
{code:java}
2019-04-23 18:34:46,361 INFO org.apache.ratis.server.impl.RaftServerImpl: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 HEARTBEAT: eaa2a877-0e7f-44f3-a514-12243ce2b925: receive appendEntries(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16, 2, (t:2, i:211601), 211601, false, commits[5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:46,362 INFO org.apache.ratis.server.impl.RaftServerImpl: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 HEARTBEAT: eaa2a877-0e7f-44f3-a514-12243ce2b925: succeeded to handle AppendEntries. Reply: 5c400f35-d7ba-4911-8cd3-7ceb48e2ef16->eaa2a877-0e7f-44f3-a514-12243ce2b925,true,SUCCESS,nextIndex:211602,term:2,followerCommit:211601
2019-04-23 18:34:48,583 INFO org.apache.ratis.server.impl.FollowerState: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 changes to CANDIDATE, lastRpcTime:2221, electionTimeout:1124ms
2019-04-23 18:34:48,583 INFO org.apache.ratis.server.impl.RoleInfo: eaa2a877-0e7f-44f3-a514-12243ce2b925: shutdown FollowerState
2019-04-23 18:34:48,583 INFO org.apache.ratis.server.impl.RaftServerImpl: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 changes role from FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-04-23 18:34:48,583 INFO org.apache.ratis.server.impl.RaftServerImpl: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 HEARTBEAT: eaa2a877-0e7f-44f3-a514-12243ce2b925: receive appendEntries(5c400f35-d7ba-4911-8cd3-7ceb48e2ef16, 2, (t:2, i:211601), 211601, false, commits[5c400f35-d7ba-4911-8cd3-7ceb48e2ef16:c211601, 187c2006-dc9e-40c7-b3e7-ca32b0c3ef45:c211601, eaa2a877-0e7f-44f3-a514-12243ce2b925:c211601], entries: []
2019-04-23 18:34:48,583 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1774ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1359ms
GC pool 'PS Scavenge' had collection(s): count=1 time=532ms
2019-04-23 18:34:48,583 INFO org.apache.ratis.server.impl.RoleInfo: eaa2a877-0e7f-44f3-a514-12243ce2b925: start LeaderElection
2019-04-23 18:34:48,598 INFO org.apache.ratis.server.impl.RaftServerImpl: eaa2a877-0e7f-44f3-a514-12243ce2b925:group-80F1E6232C38 changes role from CANDIDATE to FOLLOWER at term 2 for appendEntries
2019-04-23 18:34:48,598 INFO org.apache.ratis.server.impl.RoleInfo: eaa2a877-0e7f-44f3-a514-12243ce2b925: shutdown LeaderElection
{code}
There is a GC pause of approx. 2 seconds which causes the leader election to start in the follower.",[],2019-04-24 20:30:19+00:00,2019-05-16 21:01:08+00:00,2021-01-12 02:57:10+00:00,Resolved,13229968,RATIS-534
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Mukul was kind enough to link to [https://github.com/apache/hadoop/blob/d31c86892e0ceec5d642f76fc9123fac4fd80db8/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/transport/server/ratis/XceiverServerRatis.java] in Ozone which lists a bunch of RatisServer configuration keys that Ozone sets.

We should go through this list and set the ones that make sense for the LogService too. For example, initial testing with a longer leader election timeout helps significantly.",[],2019-04-23 22:20:46+00:00,2019-05-03 18:09:17+00:00,2019-05-03 18:09:17+00:00,Resolved,13229724,RATIS-533
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"UnorderedAsync#sendRequestWithRetry
{code:java}
if (e instanceof IOException) {
  if (e instanceof NotLeaderException) {
    client.handleNotLeaderException(request, (NotLeaderException) e, false);
  } else if (!(e instanceof GroupMismatchException)) {
    client.handleIOException(request, (IOException) e, null, false);
  }
} else {
  if (!client.getClientRpc().handleException(request.getServerId(), e, false)) {
    f.completeExceptionally(e);
    return;
  }
}

LOG.info(""schedule retry for attempt #{}, policy={}, request={}"", attemptCount, retryPolicy, request);
client.getScheduler().onTimeout(retryPolicy.getSleepTime(), () -> sendRequestWithRetry(pending, client),
    LOG, () -> clientId + "": Failed~ to retry "" + request);
{code}
Currently, in case of GroupMismatchException, it is ignored and retried as per the retry policy.In case as such, it should just mark the reply future to complete exceptionally.",[],2019-04-22 11:33:10+00:00,2019-04-29 14:01:44+00:00,2019-04-29 14:01:44+00:00,Resolved,13229360,RATIS-532
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Following exception can be seen in MiniOzoneChaosCluster after Datanode restarts.

{code}
java.io.IOException: Failed to lock storage /Users/msingh/code/apache/ozone/oz_new1/hadoop-ozone/integration-test/target/test/data/MiniOzoneClusterImpl-6e7bf33e-55b8-4437-8a0d-0da730510c70/datanode-4/data/ratis/49740cb4-b1cf-418a-af8e-1b28e0bf6cbc. The directory is already locked
        at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
        at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:291)
        at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
        at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:91)
        at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:59)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:106)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:101)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
        at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
        at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
        at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1108)
        at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
        at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
{code}","['MiniOzoneChaosCluster', 'ozone']",2019-04-17 04:47:38+00:00,,2019-07-14 15:32:03+00:00,Open,13228492,RATIS-538
Bug,[],andywu,Andy Wu,andywu,Andy Wu,Major," 

Repeatly run the *TestServerRestartWithGrpc.runTestRestartCommitIndex,* and it will fail after couple of runs. 

For the detailed log, please refer to the attachment. [^runTestRestartCommitIndex.log]
{code:java}
java.lang.AssertionError: 
Expected :136
Actual :138
 <Click to see difference>

 at org.junit.Assert.fail(Assert.java:88)
 at org.junit.Assert.failNotEquals(Assert.java:834)
 at org.junit.Assert.assertEquals(Assert.java:645)
 at org.junit.Assert.assertEquals(Assert.java:631)
 at org.apache.ratis.server.ServerRestartTests.runTestRestartCommitIndex(ServerRestartTests.java:276)
 at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:119)
 at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:107)
 at org.apache.ratis.server.ServerRestartTests.testRestartCommitIndex(ServerRestartTests.java:221)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
 at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
 at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.lang.Thread.run(Thread.java:745)
{code}
 ",[],2019-04-16 18:31:12+00:00,,2019-04-16 18:31:12+00:00,Open,13228400,RATIS-531
Improvement,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Major,"After enabling thread context in Ozone log messages, we see some Ratis operations being executed in common fork join pool. E.g.

{code}
2019-04-11 14:25:54,583 ForkJoinPool.commonPool-worker-3 INFO  storage.RaftLogWorker (RaftLogWorker.java:rollLogSegment(303)) - 3e59bcbc-e6f0-4681-b8a6-76e163e9ff19-RaftLogWorker: Rolling segment log-0_70 to index:70
{code}

and

{code}
2019-04-11 14:25:56,715 ForkJoinPool.commonPool-worker-1 INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(264)) - Failed RaftClientRequest:client-B5832CAE4B89->8a182bb4-96a8-42e8-a7da-549c9663fc30@group-7136CD304607, cid=333, seq=0, Watch-ALL_COMMITTED(79), Message:<EMPTY>, reply=RaftClientReply:client-B5832CAE4B89->8a182bb4-96a8-42e8-a7da-549c9663fc30@group-7136CD304607, cid=333, FAILED org.apache.ratis.protocol.NotLeaderException: Server 8a182bb4-96a8-42e8-a7da-549c9663fc30 is not the leader (beff1b4d-05f9-4f7d-a6f2-1405b0950e8c:10.22.8.149:57253). Request must be sent to leader., logIndex=0, commits[8a182bb4-96a8-42e8-a7da-549c9663fc30:c129, 48a1cbdc-86a2-40d3-9831-13e044923ee4:c72, beff1b4d-05f9-4f7d-a6f2-1405b0950e8c:c129]
{code}

It's better to use a dedicated ExecutorService or ForkJoinPool instead.",[],2019-04-11 23:26:37+00:00,,2019-04-11 23:27:19+00:00,Open,13227578,RATIS-530
Improvement,[],msingh,Mukul Kumar Singh,nilotpalnandi,Nilotpal Nandi,Major,A leader with slow followers can cause the leader to keep accumulating lots of pending requests in its queue. The jira proposes to rate limit incoming requests based on the maximum number of pending requests in the queue.,[],2019-04-11 16:18:34+00:00,2019-05-09 19:29:13+00:00,2019-05-09 19:29:13+00:00,Resolved,13227499,RATIS-529
Bug,[],msingh,Mukul Kumar Singh,nilotpalnandi,Nilotpal Nandi,Major,"In cases of errors, the leader might not be able to replicate a certain requets to majority of the nodes, this will cause the request to remain in the leader and will not timeout ever.

This jira proposes to adds a timeout in Ratis server to let the timeout remove the request for the pending queue and free up memory.",[],2019-04-11 16:16:10+00:00,2019-07-14 15:33:37+00:00,2019-07-14 15:33:37+00:00,Resolved,13227496,RATIS-528
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Minor,We can create a {{shell}} and {{load-tool}} (for VerificationTool) to make invoking them easier.,[],2019-04-11 00:56:12+00:00,2019-05-03 18:08:43+00:00,2019-05-03 18:08:43+00:00,Resolved,13227364,RATIS-527
Task,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,Can make automation around building the ratis-logservice image better.,[],2019-04-10 23:28:16+00:00,2019-05-03 18:08:17+00:00,2019-05-03 18:08:23+00:00,Resolved,13227352,RATIS-526
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"* Delete the logs we're about to create if they already exist
 * Reduce the frequency of the VerificationTool logging the record written (e.g. every 50th record, log a message)
 * Allow just write portion
 * Allow just read portion
 * Options to specify number of logs
 * Options to specify number of records per log
 * Use the correct {{LOG}} instead of {{Log}}.",[],2019-04-10 19:38:02+00:00,2019-05-03 18:07:50+00:00,2019-05-03 18:07:50+00:00,Resolved,13227303,RATIS-525
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"VerificationTool and the LogServiceShell both use JCommander to implement a required argument provided by the user (the metadata quorum string), but don't mark the option as required. This lets the user omit providing it which results in a NPE.",[],2019-04-10 19:13:15+00:00,2019-05-03 18:07:45+00:00,2019-05-03 18:07:45+00:00,Resolved,13227298,RATIS-524
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Minor,"While working on the DML path, seems like we put a lot of log messages at DEBUG for things that are now just ""routine"".

Back them off to TRACE.",[],2019-04-10 19:00:00+00:00,2019-05-03 18:07:37+00:00,2019-05-03 18:09:40+00:00,Resolved,13227295,RATIS-523
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{code:java}
2019-04-09 18:32:17,016 ERROR server.LogStateMachine (VerificationTool.java:waitForCompletion(85)) - Got exception
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: java.lang.NullPointerException
    at java.util.concurrent.FutureTask.report(FutureTask.java:122)
    at java.util.concurrent.FutureTask.get(FutureTask.java:192)
    at org.apache.ratis.logservice.tool.VerificationTool.waitForCompletion(VerificationTool.java:79)
    at org.apache.ratis.logservice.tool.VerificationTool.main(VerificationTool.java:72)
Caused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: java.lang.NullPointerException
    at org.apache.ratis.logservice.tool.VerificationTool$BulkReader.run(VerificationTool.java:155)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.io.IOException: java.lang.NullPointerException
    at org.apache.ratis.logservice.impl.LogReaderImpl.readNext(LogReaderImpl.java:98)
    at org.apache.ratis.logservice.tool.VerificationTool$BulkReader.run(VerificationTool.java:142)
... 5 more
Caused by: java.io.IOException: java.lang.NullPointerException
    at org.apache.ratis.logservice.impl.LogReaderImpl.readNext(LogReaderImpl.java:86)
... 6 more
{code}
Saw this in the verification step of the VerificationTool. Seems like there is a situation where we don't get an Exception thrown back from the Ratis server.
{code:java}
      ReadLogReplyProto proto = ReadLogReplyProto.parseFrom(reply.getMessage().getContent());
      if (proto.hasException()) {
        LogServiceException e = proto.getException();
        throw new IOException(e.getErrorMsg());
      }
{code}
LogReaderImpl.java:86 is on the above new {{IOException}} creation, seeming to indicate that the {{LogServiceException}} is null.",[],2019-04-10 18:59:04+00:00,,2019-04-10 18:59:04+00:00,Open,13227293,RATIS-522
Bug,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,"The example README specifies storage directory as /tmp/data. While running multiple peers on the same node, a separate storage directory needs to be specified for each peer. This should be clarified in the documentation.",[],2019-04-10 17:09:28+00:00,2019-04-16 04:48:56+00:00,2019-04-16 04:48:56+00:00,Resolved,13227257,RATIS-521
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,"Configuration of implementation specific details inside of Ratis itself need to be created as they presently are static. The ability to configure them on the fly for administration of the system is a must.
Work breakdown:
RATIS-477 has some implementation of LogStateMachine configuration.
Need a method to configure the MetadataStateMachine and LogStateMachine(s) with LogService-level configuration. For example:
Command-line arguments to specify configuration key=values
Configuration file which can be specified
Something else… (with justification why chosen)
Potentially, can the system be dynamically reconfigured.
Method of configuring the system must be clearly documented",[],2019-04-10 00:10:55+00:00,2019-05-31 15:51:31+00:00,2019-05-31 15:51:31+00:00,Resolved,13227069,RATIS-520
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"- Add links to ratis web site and the raft paper web site.
- Break long lines so that the source is more readable.
- Add missing argument descriptions.
- Replace xx.xx.xx.xx which 127.0.0.1 in the command examples so that it can be copy & paste.",[],2019-04-09 04:59:40+00:00,2019-04-16 05:06:54+00:00,2019-04-16 05:06:54+00:00,Resolved,13226849,RATIS-519
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Currently , the retry policy is enforced on a raft client which handles multiple requests. The idea here is to add support for request specific retry policy in Raft client.",[],2019-04-08 06:31:24+00:00,2019-05-06 18:51:38+00:00,2019-05-06 18:51:38+00:00,Resolved,13226622,RATIS-518
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Blocker,"Thanks [~ljain] for discovering the following problems:

- While executing in the binary I got the following error.
{code}
no main manifest attribute, in apache-ratis-incubating-0.3.0/examples/bin/../lib/ratis-examples-0.3.0.jar
{code}
- For the source after doing ""maven clean package” I got the following error.
{code}
ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0-shaded.jar ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0.jar
Jar file is missing. Please do a full build (mvn clean package) first.
{code}",[],2019-04-08 03:45:27+00:00,2019-04-09 02:48:06+00:00,2019-04-09 11:00:35+00:00,Resolved,13226608,RATIS-517
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"The following error is observed on Ozone Dataodes while running IO.
{code}
2019-04-05 11:12:46,081 ERROR server.GrpcLogAppender (GrpcLogAppender.java:onNext(226)) - Failed onNext serverReply {
  requestorId: ""ba438b75-8549-4cbe-ab0d-7de0e1ed173d""
  replyId: ""1cede484-3dc6-4518-9587-1c6f8e7747e7""
  raftGroupId {
    id: ""\\\201\033c\350\373B9\263\335\214\357\274`\315\215""
  }
  callId: 1305
  success: true
}
term: 2
nextIndex: 3171
followerCommit: 3165

java.lang.IllegalStateException: reply's next index is 3171, request's previous is term: 2
index: 3169

        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
        at org.apache.ratis.grpc.server.GrpcLogAppender.onSuccess(GrpcLogAppender.java:294)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNextImpl(GrpcLogAppender.java:239)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:224)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:206)
        at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}",['MiniOzoneChaosCluster'],2019-04-07 01:58:06+00:00,2019-07-14 15:31:21+00:00,2019-07-14 15:31:22+00:00,Resolved,13226540,RATIS-516
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Critical,"Match index is not updated increasingly as noted in the following stack trace.

{code}
java.lang.IllegalStateException: Failed to updateIncreasingly for matchIndex: 393 -> 0
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:72)
        at org.apache.ratis.server.storage.RaftLogIndex.updateIncreasingly(RaftLogIndex.java:60)
        at org.apache.ratis.server.impl.FollowerInfo.updateMatchIndex(FollowerInfo.java:66)
        at org.apache.ratis.grpc.server.GrpcLogAppender.onSuccess(GrpcLogAppender.java:309)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNextImpl(GrpcLogAppender.java:239)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:224)
        at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:206)
        at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
        at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}",['MiniOzoneChaosCluster'],2019-04-03 18:39:33+00:00,2019-05-14 14:01:38+00:00,2019-07-14 15:31:22+00:00,Resolved,13225930,RATIS-515
Improvement,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"It is possible that the installSnapshot setting is different between leader and follower. In such cases, we should log an error.
Also, before processing the request, we should check whether this setting is same between the leader and follower.",[],2019-04-03 00:27:53+00:00,2019-04-10 08:53:08+00:00,2019-04-10 08:53:08+00:00,Resolved,13225668,RATIS-514
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Blocker,"The modules ratis-proto, ratis-test and ratis-logservice are missing from assembly src.xml and bin.xml,
",[],2019-04-02 03:50:12+00:00,2019-04-04 05:08:50+00:00,2019-04-04 05:08:50+00:00,Resolved,13225417,RATIS-513
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"{code}
2019-03-30 04:33:50,166 ERROR ratis.MiniRaftCluster (MiniRaftCluster.java:runWithNewCluster(122)) - Failed org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:107)
java.lang.NullPointerException
	at org.apache.ratis.MiniRaftCluster.toRaftPeer(MiniRaftCluster.java:384)
	at org.apache.ratis.MiniRaftCluster.removePeers(MiniRaftCluster.java:431)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.runTestAddRemovePeers(RaftReconfigurationBaseTest.java:128)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.lambda$testLeaderStepDown$3(RaftReconfigurationBaseTest.java:121)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:119)
	at org.apache.ratis.MiniRaftCluster$Factory$Get.runWithNewCluster(MiniRaftCluster.java:107)
	at org.apache.ratis.server.impl.RaftReconfigurationBaseTest.testLeaderStepDown(RaftReconfigurationBaseTest.java:121)
	...
{code}
",[],2019-03-30 06:12:00+00:00,2019-04-01 05:47:12+00:00,2019-04-01 06:32:12+00:00,Resolved,13224959,RATIS-512
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"When a raft request fails with GroupMismatchException, all the pending requests in the sliding window should be marked failed.",[],2019-03-29 05:26:21+00:00,2019-04-01 05:46:18+00:00,2019-04-01 06:31:48+00:00,Resolved,13224753,RATIS-511
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Blocker,"https://builds.apache.org/job/PreCommit-RATIS-Build/712/artifact/out/patch-asflicense-problems.txt
{code}
Lines that start with ????? in the ASF License  report indicate files that do not have an Apache license header:
 !????? /testptch/ratis/ratis-logservice/src/main/java/org/apache/ratis/logservice/tool/VerificationTool.java
{code}
",[],2019-03-28 10:13:31+00:00,2019-03-28 11:24:02+00:00,2019-03-28 11:24:02+00:00,Resolved,13224553,RATIS-510
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Major,"Here is the exception seen in ozone.log

-------------------------------------------------------

 
{noformat}
2019-03-25 22:31:21,288 INFO org.apache.ratis.server.storage.RaftLogWorker: 3f7e8187-f253-4efe-a6e8-41b4c1c85f9d-RaftLogWorker: Rolling segment log-86786_86807 to index:86807
2019-03-25 22:31:21,289 INFO org.apache.ratis.server.storage.RaftLogWorker: 3f7e8187-f253-4efe-a6e8-41b4c1c85f9d-RaftLogWorker: Rolled log segment from /data/disk1/ozone/meta/ratis/891d2bbb-4c39-4714-944c-8f2d7503c052/current/log_inprogress_86786 to /data/disk1/ozone/meta/ratis/891d2bbb-4c39-4714-944c-8f2d7503c052/current/log_86786-86807
2019-03-25 22:31:21,290 INFO org.apache.ratis.server.impl.RaftServerImpl: 3f7e8187-f253-4efe-a6e8-41b4c1c85f9d: set configuration 86808: [3f7e8187-f253-4efe-a6e8-41b4c1c85f9d:172.27.21.202:9858, 48f8862a-1cc1-45a6-9a5c-d8a5ffe1b29a:172.27.38.206:9858, 9c360a3a-2671-4ad7-81ee-452f54bdcdab:172.27.87.142:9858], old=null at 86808
2019-03-25 22:31:21,389 INFO org.apache.ratis.server.storage.RaftLogWorker: 3f7e8187-f253-4efe-a6e8-41b4c1c85f9d-RaftLogWorker: created new log segment /data/disk1/ozone/meta/ratis/891d2bbb-4c39-4714-944c-8f2d7503c052/current/log_inprogress_86808
2019-03-25 22:31:22,302 INFO org.apache.ratis.grpc.server.GrpcServerProtocolService: 3f7e8187-f253-4efe-a6e8-41b4c1c85f9d: appendEntries completed
2019-03-25 22:31:22,377 ERROR org.apache.ratis.grpc.server.GrpcLogAppender: Failed onNext serverReply {
 requestorId: ""3f7e8187-f253-4efe-a6e8-41b4c1c85f9d""
 replyId: ""9c360a3a-2671-4ad7-81ee-452f54bdcdab""
 raftGroupId {
 id: ""\211\035+\273L9G\024\224L\217-u\003\300R""
 }
 success: true
}
term: 2
nextIndex: 86810
followerCommit: 86807
java.lang.IllegalStateException: reply's next index is 86810, request's previous is term: 1
index: 86807
at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.grpc.server.GrpcLogAppender.onSuccess(GrpcLogAppender.java:294)
 at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNextImpl(GrpcLogAppender.java:239)
 at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:224)
 at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onNext(GrpcLogAppender.java:206)
 at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onMessage(ClientCalls.java:421)
 at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
 at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onMessage(ForwardingClientCallListener.java:33)
 at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:519)
 at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
 at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
2019-03-25 22:31:24,207 WARN org.apache.ratis.grpc.client.GrpcClientProtocolService: 8576-UnorderedRequestStreamObserver8576: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
{noformat}
 ",[],2019-03-26 10:03:41+00:00,,2019-03-26 10:03:41+00:00,Open,13223995,RATIS-509
Improvement,[],yew1eb,Hai Zhou,yew1eb,Hai Zhou,Major,"Improve the request to raise the abstraction level of our logging framework so that logging is done through slf4j instead of directly through log4j. 
This will allow users to swap-out the underlying logging framework, giving a choice of log4j, logback-classic, and log4j2.

eg.
In my project, I use logback, which conflicts with log4j.",[],2019-03-23 08:48:39+00:00,2019-10-30 16:48:29+00:00,2019-11-04 22:06:11+00:00,Resolved,13223477,RATIS-508
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently RaftServerProxy#newRaftServerImpl uses common thread pool for creating an instance of RaftServerImpl. We should use a separate executor for this purpose.,[],2019-03-20 08:38:00+00:00,2019-03-21 16:47:25+00:00,2019-03-22 05:27:42+00:00,Resolved,13222765,RATIS-507
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"{code}
java.lang.AssertionError: 
Expected :101
Actual   :111
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.ratis.server.ServerRestartTests.runTestRestartCommitIndex(ServerRestartTests.java:276)
{code}
It seems that the test runs too fast so that the last metadata entry is not yet written.",[],2019-03-20 01:51:51+00:00,2019-03-28 06:11:18+00:00,2019-03-28 06:11:18+00:00,Resolved,13222712,RATIS-506
New Feature,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"This Jira aims to make the install snapshot command from leader to follower configurable. By default, install snapshot should be enabled. ",[],2019-03-19 18:38:21+00:00,2019-03-20 07:35:19+00:00,2019-03-20 07:35:19+00:00,Resolved,13222654,RATIS-505
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a server is a follower, clients can still send requests to it.  The server will response NotLeaderException.  It is possible that the server may later become a leader.  As a result, the server may replies NotLeaderException for some earlier requests when it is not yet the leader, and then processes some later requests after it becomes the leader.  It violates the ordering guarantee.",[],2019-03-19 07:25:16+00:00,,2019-03-19 07:26:04+00:00,Open,13222511,RATIS-504
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Minor,"IllegalArgumentException: SegmentedRaftLog is expected to be opened but it is CLOSED
{code}
Exception in thread ""Thread-429"" java.lang.IllegalArgumentException: a790aa85-94ee-4627-a474-37d60022f180-SegmentedRaftLog is expected to be opened but it is CLOSED
        at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
        at org.apache.ratis.server.storage.RaftLog.checkLogState(RaftLog.java:88)
        at org.apache.ratis.server.storage.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:246)
        at org.apache.ratis.server.storage.RaftLog.getNextIndex(RaftLog.java:137)
        at org.apache.ratis.server.impl.LeaderState.<init>(LeaderState.java:208)
        at org.apache.ratis.server.impl.RoleInfo.startLeaderState(RoleInfo.java:90)
        at org.apache.ratis.server.impl.RaftServerImpl.changeToLeader(RaftServerImpl.java:324)
        at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:162)
        at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:102)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close a790aa85-94ee-4627-a474-37d60022f180-SegmentedRaftLog
        at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
        at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
        at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
        at org.apache.ratis.server.storage.RaftLog.close(RaftLog.java:398)
        at org.apache.ratis.server.storage.SegmentedRaftLog.close(SegmentedRaftLog.java:406)
        at org.apache.ratis.server.impl.ServerState.close(ServerState.java:389)
        at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:256)
        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:220)
        at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:233)
        at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.lambda$close$0(RaftServerProxy.java:110)
        ...
        at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.close(RaftServerProxy.java:110)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$close$4(RaftServerProxy.java:307)
        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:220)
        at org.apache.ratis.server.impl.RaftServerProxy.close(RaftServerProxy.java:305)
        ...
{code}
",[],2019-03-19 04:45:26+00:00,2019-03-28 10:25:32+00:00,2019-03-28 10:25:32+00:00,Resolved,13222487,RATIS-503
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This problem was seen with Ozone in datanodes state machine.

Before restart of the datanode, a snapshot was taken at log index 6. Please note that the commit entry for this will be after this log index in the Raft Log.
{code}
2019-03-19 08:56:30,225 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-4c165953-147b-48fb-89e1-951579e828eb: set stopIndex = 6
2019-03-19 08:56:30,225 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:1, i:6)
2019-03-19 08:56:30,226 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /Users/msingh/code/apache/ozone/oz_new1/hadoop-ozone/integration-test/t
arget/test-dir/MiniOzoneClusterImpl-0fa66624-f533-44bc-8f6f-99cf251fe4c3/datanode-0/data/ratis/34393916-e10d-4b3c-b212-5c910eea4935/sm/snapshot.1_6
2019-03-19 08:56:30,231 INFO  impl.RaftServerImpl (ServerState.java:close(386)) - 4c165953-147b-48fb-89e1-951579e828eb closes. The last applied log index is 6
{code}

After restart, the state machine register 6 as the log index in the snapshot.

{code}
2019-03-19 08:56:33,351 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(209)) - Setting the last applied index to (t:1, i:6)
{code}

Now, after applying all the transactions after the snapshot, the state machine will encounter a commit entry for this log index (5). this hits the assert in the state machine.

{code}
java.io.IOException: java.lang.IllegalStateException: Failed to updateIncreasingly for commitIndex: 6 -> 5
        at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:54)
        at org.apache.ratis.util.IOUtils.toIOException(IOUtils.java:61)
        at org.apache.ratis.util.IOUtils.getFromFuture(IOUtils.java:70)
        at org.apache.ratis.server.impl.RaftServerProxy.getImpls(RaftServerProxy.java:283)
        at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:295)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:417)
        at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:182)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:165)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:334)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to updateIncreasingly for commitIndex: 6 -> 5
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:72)
        at org.apache.ratis.server.storage.RaftLogIndex.updateIncreasingly(RaftLogIndex.java:60)
        at org.apache.ratis.server.storage.RaftLog.lambda$open$7(RaftLog.java:245)
        at java.util.Optional.ifPresent(Optional.java:159)
        at org.apache.ratis.server.storage.RaftLog.open(RaftLog.java:244)
        at org.apache.ratis.server.impl.ServerState.initLog(ServerState.java:191)
        at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:114)
        at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:103)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:207)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582)
        at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
        at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
{code}",[],2019-03-19 04:22:25+00:00,2019-03-19 18:38:35+00:00,2019-03-22 05:27:34+00:00,Resolved,13222477,RATIS-502
Bug,[],arp,Arpit Agarwal,arp,Arpit Agarwal,Major,"The source code is now hosted on gitbox, so the website needs to be updated.

https://ratis.incubator.apache.org/#source
",[],2019-03-19 03:45:16+00:00,,2019-03-19 03:45:16+00:00,Open,13222474,RATIS-501
Improvement,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Minor,"It is too much for every ozone sh key put.

{code}

bash-4.2$ ozone sh key put /vol1/bucket1/key1 LICENSE.txt
2019-03-14 16:35:03 INFO GrpcClientProtocolClient:302 - schedule 3000ms timeout check for RaftClientRequest:client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b@group-D2B35873B94E, cid=0, seq=0 RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$64/878991463@3e6fd0b9
2019-03-14 16:35:04 INFO GrpcClientProtocolClient:256 - client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b: receive RaftClientReply:client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b@group-D2B35873B94E, cid=0, SUCCESS, logIndex=1, commits[45e6a76d-7c48-4e3d-b18e-fee47055793b:c2]
2019-03-14 16:35:04 INFO GrpcClientProtocolClient:302 - schedule 3000ms timeout check for RaftClientRequest:client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b@group-D2B35873B94E, cid=1, seq=1 RW, org.apache.hadoop.hdds.scm.XceiverClientRatis$$Lambda$64/878991463@25211d10
2019-03-14 16:35:04 INFO GrpcClientProtocolClient:256 - client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b: receive RaftClientReply:client-D48F06A03AF5->45e6a76d-7c48-4e3d-b18e-fee47055793b@group-D2B35873B94E, cid=1, SUCCESS, logIndex=3, commits[45e6a76d-7c48-4e3d-b18e-fee47055793b:c4]

{code}",[],2019-03-14 19:43:21+00:00,2019-03-18 06:50:24+00:00,2019-03-18 06:50:24+00:00,Resolved,13221745,RATIS-500
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The situation described in RATIS-459 is still possible if a server is not restarted.  A simple solution is to close the sliding window if there is a NotLeaderException.  indeed, we should close all client connections when a leader steps down.",[],2019-03-14 18:54:05+00:00,2019-03-19 07:18:31+00:00,2019-03-19 07:26:04+00:00,Resolved,13221741,RATIS-499
New Feature,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"When a lagging Follower wants to catch up with the Leader, and the Leader only has logs with start index greater than the Followers's last log index, then the leader sends an InstallSnapshotRequest to the the Follower. 

The aim of this Jira is to allow State Machine to decouple snapshot installation from the Ratis server. When Leader does not have the logs to get the Follower up to speed, it should notify the Follower to install a snapshot (if install snapshot through Log Appender is disabled). The Follower in turn notifies its state machine that a snapshot is required to catch up with the leader.",[],2019-03-14 02:00:39+00:00,2019-04-03 13:17:24+00:00,2019-04-03 13:17:24+00:00,Resolved,13221573,RATIS-498
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"This bug happens when a LogAppender is started (startAppender()) and then immediately stopped (stopAppender()).

This bug is not a problem in real application, since an uncaught exception with no harm will be thrown, but it will fail unit tests.",[],2019-03-12 00:22:03+00:00,2019-05-06 10:20:15+00:00,2019-05-06 10:20:15+00:00,Resolved,13220971,RATIS-497
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently notifyIndexUpdate notifies the state machine with only the log index, however the term of the log entry should be notified as well.",[],2019-03-08 19:00:48+00:00,2019-03-09 04:06:16+00:00,2019-03-22 05:27:43+00:00,Resolved,13220526,RATIS-496
Bug,[],andywu,Andy Wu,andywu,Andy Wu,Major,"When two servers are (mis)configured with the same id, thread running LeaderElection#waitForResults might crash. 

{code:java}
try {
if (conf.hasMajority(votedPeers, server.getId())) {
}
} catch(ExecutionException e) {}
 
boolean hasMajority(Collection<RaftPeerId> others, RaftPeerId selfId) { 
Preconditions.assertTrue(!others.contains(selfId)); 
return conf.hasMajority(others, selfId) && (oldConf == null || oldConf.hasMajority(others, selfId));
}
{code}
Preconditions.assertTrue(!others.contains(selfId)); statement inside RaftConfiguration#hasMajority() might throw IllegalStateException. This RunTimeException will kill thread running LeaderElection#waitForResults code.

stacktrace:
{code:java}
Exception in thread ""Thread-13"" java.lang.IllegalStateException
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:33)
 at org.apache.ratis.server.impl.RaftConfiguration.hasMajority(RaftConfiguration.java:211)
 at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:225)
 at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:146)
 at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:102){code}
",[],2019-03-07 00:19:31+00:00,2019-04-23 12:48:40+00:00,2019-04-23 18:31:19+00:00,Resolved,13220066,RATIS-495
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In some (unlucky) cases, tests may fail to change leader which leads to a failure.  Testing leader change is not an objective of the particular tests.  When leader change fails, these tests becomes meaningless.

We may throw AssumptionViolatedException (new in junit 4.12) so that failing to change leader won't generate a test case failure.",[],2019-03-05 21:01:31+00:00,2019-03-07 22:29:59+00:00,2019-03-07 22:29:59+00:00,Resolved,13219657,RATIS-494
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In PeerProxyMap, when a peer is in CLOSING or CLOSED states, it throws IOException.  It should throw AlreadyClosedException so that the client will try reconnecting.",[],2019-03-04 22:48:01+00:00,2019-03-05 22:06:15+00:00,2019-03-05 22:06:15+00:00,Resolved,13219417,RATIS-493
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently leader adds both transaction context as well as RaftClientRequest in the PendingRequest. Both of these contain a reference to state machine data which should not be maintained as this data is maintained by state machine if state machine caching is enabled and by log segment cache if not enabled.,['ozone'],2019-03-01 18:40:12+00:00,,2019-07-14 15:34:06+00:00,Open,13218974,RATIS-492
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Raft Storage directory creation can fail because of a FileException as noted in log below.
In case the command fails, the error should be propagated back to the client.


{code}
2019-02-28 08:21:52,589 INFO org.apache.ratis.server.storage.RaftStorageDirectory: The storage directory /data/disk2/scm/ratis/5c880577-edec-461e-8d0f-af1417ba7add does not exist. Creating ...
2019-02-28 08:21:52,589 WARN org.apache.ratis.util.FileUtils: Failed to Files.createDirectories /data/disk2/scm/ratis/5c880577-edec-461e-8d0f-af1417ba7add: java.nio.file.AccessDeniedException: /data/disk2/scm
{code}",[],2019-02-28 09:19:30+00:00,2019-03-07 10:38:36+00:00,2019-03-07 10:38:36+00:00,Resolved,13218576,RATIS-491
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"With MultiRaft feature in Ratis, same server can be in different role in different raft groups. That's why it becomes essential to log the RaftGroupId along with other information to figure out precisely for which group particular steps are executed.",[],2019-02-27 06:00:08+00:00,2019-03-27 15:51:10+00:00,2019-03-28 06:13:16+00:00,Resolved,13218258,RATIS-490
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, the RetryCache is created with a size-based eviction policy.  When the number of requests is larger than maximum size, entires will be evicted even they are not expired.",[],2019-02-22 23:42:48+00:00,2019-02-25 19:35:18+00:00,2019-02-27 23:48:19+00:00,Resolved,13217545,RATIS-489
Sub-task,[],fpih,Fredrik Pihlqvist,fpih,Fredrik Pihlqvist,Major,,[],2019-02-20 11:36:28+00:00,,2019-02-20 11:36:28+00:00,Open,13216889,RATIS-488
Improvement,[],fpih,Fredrik Pihlqvist,fpih,Fredrik Pihlqvist,Minor,Too many lines of code in single class.,[],2019-02-20 11:36:27+00:00,,2019-02-20 11:36:28+00:00,Open,13216888,RATIS-487
Sub-task,[],ritesh.kapoor,Ritesh,ritesh.kapoor,Ritesh,Major,,['pull-request-available'],2019-02-17 14:36:07+00:00,,2019-03-13 00:32:08+00:00,Patch Available,13216237,RATIS-486
Bug,[],clayb,Clay B.,clayb,Clay B.,Major,"Running the load generator without a Ratis cluster (e.g. spurious node IPs) results in an OOM.

If one has a single Ratis server it tries seemingly indefinitely:
{code:java}
vagrant@ratis-server:~/incubator-ratis$ ./ratis-examples/src/main/bin/client.sh filestore loadgen --size 1048576 --numFiles 100 --peers n0:127.0.0.1:1{code}
If one has two Ratis servers it OOMs:
{code:java}
vagrant@ratis-server:~/incubator-ratis$ ./ratis-examples/src/main/bin/client.sh filestore loadgen --size 1048576 --numFiles 100 --peers n0:127.0.0.1:1,n1:127.0.0.1:2
[...]
1/787867107@5e5792a0 with java.util.concurrent.CompletionException: java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-02-14 07:47:22 DEBUG RaftClient:417 - client-272A2E13A5DD: suggested new leader: null. Failed RaftClientRequest:client-272A2E13A5DD->n1@group-6F7570313233, cid=0, seq=0 RW, org.apache.ratis.examples.filestore.FileStoreClient$$Lambda$41/787867107@5e5792a0 with java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-02-14 07:47:22 DEBUG RaftClient:437 - client-272A2E13A5DD: change Leader from n1 to n0
2019-02-14 07:47:22 DEBUG RaftClient:291 - schedule attempt #10740 with policy RetryForeverNoSleep for RaftClientRequest:client-272A2E13A5DD->n1@group-6F7570313233, cid=0, seq=0 RW, org.apache.ratis.examples.filestore.FileStoreClient$$Lambda$41/787867107@5e5792a0
2019-02-14 07:47:22 DEBUG RaftClient:323 - client-272A2E13A5DD: send* RaftClientRequest:client-272A2E13A5DD->n0@group-6F7570313233, cid=0, seq=0 RW, org.apache.ratis.examples.filestore.FileStoreClient$$Lambda$41/787867107@5e5792a0
2019-02-14 07:47:22 DEBUG RaftClient:338 - client-272A2E13A5DD: Failed RaftClientRequest:client-272A2E13A5DD->n0@group-6F7570313233, cid=0, seq=0 RW, org.apache.ratis.examples.filestore.FileStoreClient$$Lambda$41/787867107@5e5792a0 with java.util.concurrent.CompletionException: java.lang.OutOfMemoryError: unable to create new native thread
Exception in thread ""main"" java.util.concurrent.CompletionException: java.lang.OutOfMemoryError: unable to create new native thread
        at org.apache.ratis.client.impl.RaftClientImpl.lambda$sendRequestAsync$14(RaftClientImpl.java:349)
        at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870)
        at java.util.concurrent.CompletableFuture.uniExceptionallyStage(CompletableFuture.java:884)
        at java.util.concurrent.CompletableFuture.exceptionally(CompletableFuture.java:2196)
        at org.apache.ratis.client.impl.RaftClientImpl.sendRequestAsync(RaftClientImpl.java:334)
        at org.apache.ratis.client.impl.RaftClientImpl.sendRequestWithRetryAsync(RaftClientImpl.java:286)
        at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:243)
        at org.apache.ratis.util.SlidingWindow$Client.retry(SlidingWindow.java:259)
        at org.apache.ratis.client.impl.RaftClientImpl.lambda$null$10(RaftClientImpl.java:293)
        at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:85)
        at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:104)
        at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
        at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:717)
        at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)
        at java.util.concurrent.ThreadPoolExecutor.ensurePrestart(ThreadPoolExecutor.java:1603)
        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:334)
        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
        at org.apache.ratis.util.TimeoutScheduler.schedule(TimeoutScheduler.java:117)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:104)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:82)
        at org.apache.ratis.util.TimeoutScheduler.onTimeout(TimeoutScheduler.java:134)
        at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.onNext(GrpcClientProtocolClient.java:234)
        at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:71)
        at org.apache.ratis.client.impl.RaftClientImpl.sendRequestAsync(RaftClientImpl.java:324)
        ... 15 more
{code}",[],2019-02-14 07:49:01+00:00,2019-08-30 21:24:38+00:00,2019-10-17 08:02:14+00:00,Resolved,13215693,RATIS-485
Improvement,[],ritesh.kapoor,Ritesh,ritesh.kapoor,Ritesh,Minor,Too many lines of code in single class.,[],2019-02-12 02:42:37+00:00,,2019-02-20 11:36:28+00:00,Open,13215138,RATIS-484
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Major,"steps taken :

--------------------
 # created 12 datanode cluster.
 # started put key operation with size 100GB.

 

Seeing following exceptions  frequently in datanode logs

--------------------------------------------------------------------------------
{noformat}
2019-02-11 09:43:54,759 INFO org.apache.ratis.server.storage.RaftLogWorker: 541f579c-790a-44b0-9989-80415e119cf4-RaftLogWorker: created new log segment /data/disk1/ozone/meta/ratis/d0c1bf83-bfe5-4646-af49-d735ee312392/current/log_inprogress_3286
2019-02-11 09:44:17,443 WARN org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(541f579c-790a-44b0-9989-80415e119cf4 -> 64b7e2c8-4663-42a4-a145-1bafefbccd4c): Failed get (t:1, i:3288), STATEMACHINELOGENTRY, client-3D1F07BD7204, cid=6942 in 11999532ns
java.util.concurrent.TimeoutException
 at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
 at org.apache.ratis.server.storage.RaftLog$EntryWithData.getEntry(RaftLog.java:433)
 at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:133)
 at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:171)
 at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)
 at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)
 at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:101)
 at java.lang.Thread.run(Thread.java:748)
2019-02-11 09:44:18,073 INFO org.apache.ratis.server.storage.RaftLogWorker: 541f579c-790a-44b0-9989-80415e119cf4-RaftLogWorker: Rolling segment log-3286_3295 to index:3295{noformat}
 
{noformat}
2019-02-11 09:42:58,533 INFO org.apache.ratis.server.storage.RaftLogWorker: 541f579c-790a-44b0-9989-80415e119cf4-RaftLogWorker: created new log segment /data/disk1/ozone/meta/ratis/d0c1bf83-bfe5-4646-af49-d735ee312392/current/log_inprogress_3190
2019-02-11 09:43:20,620 WARN org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(541f579c-790a-44b0-9989-80415e119cf4 -> 4e4626c5-f542-410a-a117-96386cd4e3b5): Failed get (t:1, i:3192), STATEMACHINELOGENTRY, client-AA54864AC41C, cid=6742 in 999326ns
java.util.concurrent.TimeoutException
 at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
 at org.apache.ratis.server.storage.RaftLog$EntryWithData.getEntry(RaftLog.java:433)
 at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:133)
 at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:171)
 at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)
 at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)
 at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:101)
 at java.lang.Thread.run(Thread.java:748)
2019-02-11 09:43:21,505 INFO org.apache.ratis.server.storage.RaftLogWorker: 541f579c-790a-44b0-9989-80415e119cf4-RaftLogWorker: Rolling segment log-3190_3199 to index:3199{noformat}
 

 
{noformat}
2019-02-11 09:45:13,622 INFO org.apache.ratis.server.storage.RaftLogWorker: 6233367a-34c2-495b-ade4-6f7e11f5eb9e-RaftLogWorker: created new log segment /data/disk1/ozone/meta/ratis/390e6f99-716f-4708-8425-c1cdb4ef4cde/current/log_inprogress_3397
2019-02-11 09:45:13,637 WARN org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(6233367a-34c2-495b-ade4-6f7e11f5eb9e -> 4c976a84-5271-474c-b297-ec9119617da9): Failed get (t:1, i:3397), STATEMACHINELOGENTRY, client-311AFF4454D6, cid=7135 in 74999474ns
java.util.concurrent.TimeoutException
 at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
 at org.apache.ratis.server.storage.RaftLog$EntryWithData.getEntry(RaftLog.java:433)
 at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:133)
 at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:171)
 at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)
 at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)
 at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:101)
 at java.lang.Thread.run(Thread.java:748)
2019-02-11 09:45:13,637 WARN org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(6233367a-34c2-495b-ade4-6f7e11f5eb9e -> e7825b0a-b777-49cb-91e9-8a0b230a44ce): Failed get (t:1, i:3397), STATEMACHINELOGENTRY, client-311AFF4454D6, cid=7135 in 74999312ns
java.util.concurrent.TimeoutException
 at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
 at org.apache.ratis.server.storage.RaftLog$EntryWithData.getEntry(RaftLog.java:433)
 at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:133)
 at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:171)
 at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)
 at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)
 at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:101)
 at java.lang.Thread.run(Thread.java:748){noformat}",[],2019-02-11 09:50:36+00:00,,2019-02-11 09:50:36+00:00,Open,13214955,RATIS-483
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently while transferring ratis snapshots, the snapshot data transferred is the entire snapshot.

This should be supplemented with a method to transfer the diff between the a snapshot which exists on the source.",[],2019-02-11 09:05:45+00:00,,2019-02-11 09:05:45+00:00,Open,13214947,RATIS-482
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Should help make RATIS-477 easier to handle. LogStateMachine's ""query"" RPC was getting pretty unruly. Having ""log reading"" being a standalone class will hopefully make further work much easier to handle.",[],2019-02-09 00:45:12+00:00,2019-02-11 23:28:44+00:00,2019-02-11 23:28:59+00:00,Resolved,13214758,RATIS-481
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"After the loadgen tool was added/updated, the README was updated with the new usage, but not the website. Let's get that too.",[],2019-02-05 16:00:27+00:00,2019-06-03 21:06:04+00:00,2019-06-03 21:06:04+00:00,Resolved,13213954,RATIS-480
Bug,[],clayb,Clay B.,clayb,Clay B.,Minor,"Hi Josh, as mentioned in RATIS-463, it seems like RATIS-456 was working when applied as a patch during its merge but now breaks for my testing with the following perhaps due to the move to thirdparty?

Server processes are started via:
{code:java}
vagrant@ratis-server:~$ cat incubator-ratis/dev-support/vagrant/bin/start_ratis_server.sh |tail -3 | head -n2
cd /home/vagrant/incubator-ratis/
java -jar `find ./ -name 'ratis-examples*-SNAPSHOT.jar'` filestore server --storage $storage --id $id --peers $peers 2>&1 | tee ~/server_${id}.log

vagrant@ratis-server:~$ grep 'Exception in thread' server*.log
server_n0.log:Exception in thread ""StateMachineUpdater-n0"" java.lang.NoClassDefFoundError: org/apache/ratis/util/ExitUtils
server_n1.log:Exception in thread ""n1-RaftLogWorker"" Exception in thread ""StateMachineUpdater-n1"" java.lang.NoClassDefFoundError: org/apache/ratis/util/ExitUtils
server_n2.log:Exception in thread ""org.apache.ratis.server.impl.LogAppender$$Lambda$155/1659649329@438afb89"" java.lang.NoClassDefFoundError: org/apache/log4j/spi/ThrowableInformatio{code}
The loadgen is started via:
{code:java}
vagrant@ratis-server:~$ cat incubator-ratis/dev-support/vagrant/bin/start_ratis_load_gen.sh |tail -3 | head -n2
cd /home/vagrant/incubator-ratis
./ratis-examples/src/main/bin/client.sh filestore loadgen --size 1048576 --numFiles 100 --peers $peers 2>&1 | tee ~/loadgen.log

vagrant@ratis-server:~$ grep 'Exception in thread' load*.log
loadgen.log:Exception in thread ""main"" java.util.concurrent.CompletionException: java.lang.NoClassDefFoundError: org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$9
server_n0.log:Exception in thread ""StateMachineUpdater-n0"" java.lang.NoClassDefFoundError: org/apache/ratis/util/ExitUtils
server_n1.log:Exception in thread ""n1-RaftLogWorker"" Exception in thread ""StateMachineUpdater-n1"" java.lang.NoClassDefFoundError: org/apache/ratis/util/ExitUtils
server_n2.log:Exception in thread ""org.apache.ratis.server.impl.LogAppender$$Lambda$155/1659649329@438afb89"" java.lang.NoClassDefFoundError: org/apache/log4j/spi/ThrowableInformation
{code}
I do see that these classes are present though:
 {{ExitUtils}}:
{code:java}
incubator-ratis/ -name ""*.jar"" -a -exec jar -tf \{\} \; -a -print | egrep '.jar|org/apache/ratis/util/ExitUtils' | grep -B1 ExitUtils
/data/incubator-ratis/ratis-common/target/ratis-common-0.4.0-SNAPSHOT-tests.jar
org/apache/ratis/util/ExitUtils.class
org/apache/ratis/util/ExitUtils$States.class
org/apache/ratis/util/ExitUtils$ExitException.class
--
/data/incubator-ratis/ratis-proto/target/ratis-proto-0.4.0-SNAPSHOT-sources.jar
org/apache/ratis/util/ExitUtils.class
org/apache/ratis/util/ExitUtils$States.class
org/apache/ratis/util/ExitUtils$ExitException.class{code}
And {{DelayedStream}}:
{code:java}
incubator-ratis/ -name ""*.jar"" -a -exec jar -tf \{\} \; -a -print | egrep '.jar|org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream' | grep -B1 DelayedStream
/data/incubator-ratis/ratis-proto/target/ratis-proto-0.4.0-SNAPSHOT-sources.jar
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$12.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$5.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener$2.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener$3.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$4.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$2.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$9.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$3.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$10.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$7.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener$1.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener$4.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$1.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$14.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$DelayedStreamListener$5.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$13.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$6.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$11.class
org/apache/ratis/thirdparty/io/grpc/internal/DelayedStream$8.class
{code}
 ",[],2019-01-31 23:22:26+00:00,2019-02-05 15:58:17+00:00,2019-02-05 20:37:51+00:00,Resolved,13213205,RATIS-479
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"While Ratis already has opencencus dependencies the current Ozone tries to use opentracing. (See HDDS-1017). 

To support opentracing (or any other tracing utility) we need an extension point to add any grpc server/client interceptor. With the interceptor it would be possible to propagate existing tracing context over the wire.

This patch is a very small modification: if the classname is the interceptor is defined, the interceptor will be added to the client/server side. ",[],2019-01-31 10:06:58+00:00,2020-06-23 15:10:12+00:00,2021-06-10 12:23:27+00:00,Resolved,13213031,RATIS-478
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"[~vrodionov] and [~rajeshbabu] were asking about this in RATIS-470. Can we improve the logic that reads through the ""head"" of the RaftLog to find the ""LogService offset""?

Vlad suggested:

{quote}
Josh, can we simplify this a little bit? Client gets Raft log ID one every append, for multi-get calls we can use this LogID (RAFT) as our start log ID to avoid iterating through all logs, then you can unwind log entries by using new logic, see above:
 int numRecordsInAppend = append.getDataCount();

There is no need to iterate from the very beginning
{quote}",[],2019-01-30 23:33:03+00:00,,2019-06-05 03:38:18+00:00,Patch Available,13212936,RATIS-477
Bug,[],dineshchitlangia,Dinesh Chitlangia,dineshchitlangia,Dinesh Chitlangia,Major,"The checkstyle file cannot be imported as-is when using a Checkstyle Plugin in an IDE.
 It fails to load with following error:
{code:java}
org.infernus.idea.checkstyle.exception.CheckStylePluginException: <html><b>The Checkstyle rules file could not be parsed.</b><br>SuppressionCommentFilter is not allowed as a child in Checker<br>The file has been blacklisted for 60s.</html>
{code}

This jira aims to fix this so developers can setup checkstyle plugin easily to work on Ratis.",[],2019-01-25 01:31:05+00:00,2019-01-25 21:51:54+00:00,2019-03-22 05:27:51+00:00,Resolved,13211703,RATIS-476
Bug,[],rajeshbabu,Rajeshbabu Chintaguntla,rajeshbabu,Rajeshbabu Chintaguntla,Major,"Written an app to create multiple logs and write data to the logs. At some point of time writing to log failing with following error.
{noformat}
2019-01-24 22:09:04 ERROR RaftServerImpl:1119 - localhost_9951: applyTransaction failed for index:1 proto:(t:1, i:1), STATEMACHINELOGENTRY, client-DE592625D102, cid=11
2019-01-24 22:09:04 ERROR StateMachineUpdater:133 - Terminating with exit status 2: StateMachineUpdater-localhost_9951: the StateMachineUpdater hits Throwable
java.lang.IllegalStateException: localhost_9951: Failed updateLastAppliedTermIndex: newTI = (t:1, i:1) < oldTI = (t:1, i:7)
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:72)
	at org.apache.ratis.statemachine.impl.BaseStateMachine.updateLastAppliedTermIndex(BaseStateMachine.java:116)
	at org.apache.ratis.logservice.server.LogStateMachine.processAppendRequest(LogStateMachine.java:324)
	at org.apache.ratis.logservice.server.LogStateMachine.applyTransaction(LogStateMachine.java:356)
	at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:1116)
	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

Getting this error just after writing few entries.",[],2019-01-24 16:36:16+00:00,2019-03-27 20:11:29+00:00,2019-03-28 14:22:53+00:00,Resolved,13211610,RATIS-475
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Apache Ratis git repository location is incorrect on Apache Ratis website.

https://ratis.incubator.apache.org/#source
",[],2019-01-16 08:27:18+00:00,,2019-01-16 08:27:18+00:00,Open,13209823,RATIS-474
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,I want to be able to know the size of a log (in terms of bytes on disk) as well as the length of a log (number of records).,[],2019-01-09 20:10:10+00:00,2019-01-28 21:09:20+00:00,2019-03-22 05:27:51+00:00,Resolved,13208628,RATIS-473
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"In the {{read}} shell command, I tried to include the index of each record in the log, like:
{noformat}
[0:a, 1:b, 2:c, ...]
{noformat}

But this comes across as confusing, I think. Undo it.",[],2019-01-09 19:57:16+00:00,2019-01-28 19:34:43+00:00,2019-03-22 05:27:48+00:00,Resolved,13208627,RATIS-472
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{code:java}
    @Test
    public void testReadOffEndOfLog() throws Exception {
      try (LogServiceClient client = new LogServiceClient(cluster.getMetaIdentity())) {
        LogStream stream = client.createLog(LogName.of(""testReadWrite""));
        LogWriter writer = stream.createWriter();
        String message = ""Hello world!"";
        ByteBuffer testMessage =  ByteBuffer.wrap(message.getBytes());
        writer.write(testMessage);
        LogReader reader = stream.createReader();
        ByteBuffer res = reader.readNext();
        assertEquals(message, ByteBufferUtils.toStringUtf8(res));
        // readNext() should return `null` when there is no remaining record
        res = reader.readNext();
        assertNull(res);
      }
    }
{code}

The above test test should either pass (or throw an exception on the second {{readNext()}} call), but hangs indefinitely. We should be able to catch this.

FYI [~vrodionov], [~rajeshbabu]",[],2019-01-09 16:18:25+00:00,,2019-06-05 03:38:37+00:00,Open,13208576,RATIS-471
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Digging into LogServiceReadWriteBase, I'm noticing that the validation clause for the data we wrote to the state machine is lacking.

The test writes 10 ""records"" into the log, but because we write these in a single message to the state machine, we only get one ""record"" in the Raft log.

Need to figure out how to take the one client-protobuf message containing N ""logservice records"" but make sure we have N ""raft messages"" in the log (or something equivalent).

fyi [~chrajeshbabu32@gmail.com], [~vrodionov].",[],2019-01-08 21:44:20+00:00,2019-01-30 18:39:43+00:00,2019-03-22 05:27:38+00:00,Resolved,13208410,RATIS-470
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,Noticed that I missed a bunch of license headers in committing 387. Go back and fix.,[],2019-01-03 20:08:51+00:00,2019-01-07 23:44:29+00:00,2019-03-22 05:27:51+00:00,Resolved,13207540,RATIS-469
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We should make a tarball which can be the logservice's installation: scripts, configuration, and jar files.

This will help RATIS-372, [~rajeshbabu].",[],2018-12-31 21:08:35+00:00,2019-01-03 20:43:51+00:00,2019-03-22 05:27:41+00:00,Resolved,13207083,RATIS-468
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We have a base test class for the LogStateMachine class, but nothing for the MetaStateMachine or the combination of MetaStateMachine and LogStateMachine.

We should have something that sets up an environment for us that we can simply write a test using the LogServiceClient class.

[~rajeshbabu], [~vrodionov].",[],2018-12-31 20:33:39+00:00,,2018-12-31 20:33:50+00:00,Open,13207082,RATIS-467
Bug,[],gsbiju,Biju Nair,gsbiju,Biju Nair,Minor,"By following the instructions to run the arithmetic example on the project page on Apache, the example fails to run. This is due to the changes made in RATIS-456. The instructions needs to be updated. Even better it would be good to make the starter shell scripts for the examples to be a bit more user friendly.  ",[],2018-12-27 20:36:28+00:00,,2019-01-31 16:53:42+00:00,Patch Available,13206682,RATIS-466
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira proposes to add dockerfile for creating the docker images and also provides the docker-compose files to create a 3 node ratis cluster.,['docker'],2018-12-27 12:58:29+00:00,2019-06-30 04:33:16+00:00,2019-06-30 04:33:16+00:00,Resolved,13206606,RATIS-465
Bug,[],msingh,Mukul Kumar Singh,clayb,Clay B.,Major,"The filestore client readme point to

bq. bin/client.sh filestore loadgen --value <file_size> --files <num_files>

However these command line options should be --size and --numFiles respectively.

Thanks [~clayb] for catching this.",[],2018-12-21 01:54:31+00:00,2018-12-28 05:28:20+00:00,2019-03-22 05:27:44+00:00,Resolved,13205860,RATIS-464
Improvement,[],clayb,Clay B.,clayb,Clay B.,Trivial,We now have a load generator in RATIS-456 which can exercise Ratis. It would be good to have a basic known way to spin-up a distributed Ratis cluster and hammer it to ensure that basic performance and reliability can be achieved.,[],2018-12-21 01:31:15+00:00,2019-03-11 18:08:45+00:00,2019-03-11 18:08:45+00:00,Resolved,13205859,RATIS-463
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently, if the data is not cached in the raft log segment, Filestore example will not be able to read data from the leader to append data to follower. This jira adds a readStateMachineData api to FileStore example.",[],2018-12-20 07:29:50+00:00,2018-12-28 05:22:11+00:00,2019-03-22 05:27:36+00:00,Resolved,13205632,RATIS-462
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This jira proposes to track the movement to Ratis repositories to gitbox and the required changes needed in Ratis infra to facilitate a smooth transition.

Will add new tasks as we will discover them.",[],2018-12-20 06:30:24+00:00,2019-01-11 06:12:19+00:00,2019-01-11 06:12:19+00:00,Resolved,13205626,RATIS-461
Bug,[],alanwu1009,Alan Wu,alanwu1009,Alan Wu,Major,"I don't know if this is a bug, I looked at the changeset of ...ratis/server/impl/ConfigurationManager.java, in line 52-56, I found an assertion statement is added by Tsz-Wo to check whether the last entry index is less than current entry index if so, will throw an exception, but when I enable snapshot function, this kind of exception will always be thrown.",[],2018-12-20 04:18:38+00:00,2019-01-30 09:01:34+00:00,2019-03-22 05:27:48+00:00,Resolved,13205619,RATIS-460
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"With some discussion with [~ljain] (thanks!), the following (highly unlikely) hypothetical scenario may lead to the async requests out-of-order.
# Requests r1-r5 success, 
# Request r6 fails with NotLeader, 
# Request r7 fails with some other IOException
# r6 is still keeping retrying and a retry of r7 succeeds with s1.

Below are the suggested fix:
- In SlidingWindow.Client, resetFirstSeqNum() should, but currently does not, clear the request map.  
- If a request is replied with NotLeaderException, it should not be removed from the request map until resetFirstSeqNum() above.",['ozone'],2018-12-19 03:33:05+00:00,2019-03-14 19:08:09+00:00,2019-03-14 22:29:53+00:00,Resolved,13205275,RATIS-459
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"In GrpcLogAppender when an append entry times out we remove the entry from the pendingRequests. This decreases the size of pendingRequests which affects the logic in GrpcLogAppender#shouldWait. Further we also consider heartbeats in shouldWait because heartbeats are tracked in pendingRequests. It should actually wait on the number of log entries which are appended to follower but have not yet been processed by it.

GrpcConfigKeys.Server.leaderOutstandingAppendsMax should also be a fraction of RaftServerConfigKeys.Log.queueSize. This brings flow control for leader's append entries to follower because then number of outstanding append entries in leader would be limited by maximum number of operations in raft log worker.",['ozone'],2018-12-18 11:36:24+00:00,2020-01-10 13:14:59+00:00,2020-01-10 13:14:59+00:00,Resolved,13205105,RATIS-458
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Critical,Currently all the timed out append entry replies are ignored by the leader. These replies have information like match index which can be updated by leader.,['ozone'],2018-12-18 11:07:17+00:00,2019-10-30 15:30:40+00:00,2019-10-30 15:31:07+00:00,Resolved,13205099,RATIS-457
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,This jira proposes to add a load generator to Ratis. This will be used to test the FileStoreStateMachine.,[],2018-12-17 18:05:31+00:00,2018-12-20 07:01:37+00:00,2019-03-22 05:27:38+00:00,Resolved,13204955,RATIS-456
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"There are more than 10 exception classes defined in org.apache.ratis.protocol.  Let move them to a new package, say org.apache.ratis.protocol.exception.",[],2018-12-14 02:34:56+00:00,2020-09-16 20:33:35+00:00,2020-09-16 20:33:35+00:00,Resolved,13204391,RATIS-455
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,RATIS-445 is done which got ratis-thirdparty-0.2.0 released. Use it.,[],2018-12-13 21:27:21+00:00,2018-12-20 21:27:17+00:00,2018-12-24 03:32:14+00:00,Resolved,13204356,RATIS-454
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Suppose client has made more than one async calls and then waits for the replies.  Suppose the leader is not ready or some other transient problem.  The retries on the first async call may fail, the code will set RaftRetryFailureException in the reply.  However, the retries of the following async calls may succeed.  In such case, the call ordering is not guaranteed -- a later call succeeds without delivered an earlier call.",[],2018-12-08 01:07:35+00:00,2018-12-11 21:23:05+00:00,2019-03-22 05:27:43+00:00,Resolved,13203182,RATIS-453
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"- RaftExceptionBaseTest expects the NotLeaderException contains the correct suggested leader.  However, the server could possibly have not yet learned the correct leader yet.
- RaftReconfigurationBaseTest does not count the log index correctly due to metadata entries.",[],2018-12-07 00:38:03+00:00,2018-12-14 01:57:33+00:00,2019-03-22 05:27:47+00:00,Resolved,13202940,RATIS-452
Task,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,"{quote}
Hi,

> Are we looking at different things, Justin? The NOTICE file in the directory you mention only has copyright information for bundled software (and text to help us know to what product that copyright statement applies).

That is not the purpose of NOTICE.

> Are you expecting a more verbatim inclusion of the full NOTICE content and not the relevant ""spirit""?

See [1]

>
> For LICENSE, gRPC is ALv2 (no mention required), protobuf-java is 3-clause BSD (which is included), netty is ALv2 (no mention required), and gson is also ALv2. What do you see that's missing?

It's not required but recommend that all licenses be listed in LICENSE. [2]

Thanks,
Justin


1. http://www.apache.org/dev/licensing-howto.html#mod-notice
2. http://www.apache.org/dev/licensing-howto.html#alv2-dep
{quote}

From thirdparty 0.2.0 rc0 on general@incubator from JustinM.

tl;dr remove copyright notices from NOTICE and include all license text into LICENSE for bundled dependencies.",['newbie'],2018-12-07 00:16:33+00:00,,2018-12-07 00:16:52+00:00,Open,13202938,RATIS-451
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,Timestamp and TimeDuration are ideal candidates for value-based classes; see https://docs.oracle.com/javase/8/docs/api/java/lang/doc-files/ValueBased.html,[],2018-12-05 23:32:27+00:00,2018-12-06 19:51:31+00:00,2019-03-22 05:27:45+00:00,Resolved,13202660,RATIS-450
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"There are quite a few functional interfaces in org.apache.ratis.util.  Let's move them to a new package, say org.apache.ratis.util.function.  It would be an analogy to java.util.function.",[],2018-12-05 22:21:58+00:00,2018-12-06 19:33:16+00:00,2019-03-22 05:27:39+00:00,Resolved,13202652,RATIS-449
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Critical,"exception seen  in datanode.log

---------------------------------------------
{noformat}
java.lang.IllegalStateException: File /data/disk1/ozone/meta/ratis/5689db14-7ca4-4198-8826-a21df55a3ae0/current/log_2466-2484 to be truncated does not exist
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.server.storage.RaftLogWorker$TruncateLog.execute(RaftLogWorker.java:459)
 at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:216)
 at java.lang.Thread.run(Thread.java:748){noformat}
 

 
{noformat}
[root@ctr-e139-1542663976389-22144-01-000007 current]# ls -lhart /data/disk1/ozone/meta/ratis/5689db14-7ca4-4198-8826-a21df55a3ae0/current
total 2.7M
-rw-r--r-- 1 root root 16K Dec 4 10:15 log_0-41
-rw-r--r-- 1 root root 9.1K Dec 4 10:15 log_42-52
-rw-r--r-- 1 root root 12K Dec 4 10:15 log_53-62
-rw-r--r-- 1 root root 15K Dec 4 10:15 log_63-70
-rw-r--r-- 1 root root 16K Dec 4 10:15 log_71-91
-rw-r--r-- 1 root root 12K Dec 4 10:15 log_92-101
-rw-r--r-- 1 root root 15K Dec 4 10:16 log_102-109
..
..
..
..
-rw-r--r-- 1 root root 1.9K Dec 4 10:48 log_2438-2441
-rw-r--r-- 1 root root 187 Dec 4 10:48 raft-meta.conf
-rw-r--r-- 1 root root 14K Dec 4 10:48 log_2442-2457
-rw-r--r-- 1 root root 15K Dec 4 10:48 log_2458-2465
-rw-r--r-- 1 root root 49 Dec 4 10:48 raft-meta
-rw-r--r-- 1 root root 16K Dec 4 10:48 log_2466-2483
drwxr-xr-x 2 root root 12K Dec 4 10:48 .
-rw-r--r-- 1 root root 7.9K Dec 4 10:48 log_inprogress_2485
drwxr-xr-x 4 root root 4.0K Dec 4 10:48 ..
 
 
{noformat}
 

 ",[],2018-12-04 11:35:59+00:00,2018-12-05 22:14:33+00:00,2019-03-22 05:27:37+00:00,Resolved,13202244,RATIS-448
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When readStateMachineData takes a long time, LogAppender will wait indefinitely until it returns.  In such case, the leader may not able to send heartbeat to the followers in time so that  the followers may start a leader election.

Thanks [~msingh] and [~ljain] to discover this bug.",[],2018-12-03 21:43:23+00:00,2018-12-06 18:39:47+00:00,2019-03-22 05:27:36+00:00,Resolved,13202112,RATIS-447
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"[https://www.apache.org/dev/release-distribution#sigs-and-sums]

Per the above, SHA checksums should be name according to the algorithm: e.g. SHA512 xsum should be in a file with a suffix .sha512.",[],2018-11-30 20:02:54+00:00,2018-11-30 20:35:14+00:00,2018-11-30 20:35:14+00:00,Resolved,13201701,RATIS-446
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,,[],2018-11-30 17:05:22+00:00,2018-12-13 21:25:20+00:00,2018-12-13 21:25:20+00:00,Resolved,13201674,RATIS-445
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,"The Jira aims to add more logs for start, rolling and truncate of log segments. Currently these operations are not logged.",[],2018-11-30 14:46:29+00:00,2018-12-04 19:09:04+00:00,2019-03-22 05:27:41+00:00,Resolved,13201640,RATIS-444
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"FollowerState.inLogSync is to indicate that the follower is writing log/statemachine data. So that it should not time out to start a leader election. However, it is not working correctly in the async case: suppose there are two or more outstanding appendEntriesAsync calls, the first completed call will clear inLogSync even if the other calls are still in progress.",[],2018-11-29 23:34:59+00:00,2018-12-03 01:28:38+00:00,2019-03-22 05:27:37+00:00,Resolved,13201478,RATIS-443
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The ReplicationLevel parameter in send(..) and sendAsync(..) methods is to wait until the specified ReplicationLevel satisfied.  Currently, it only supports MAJORITY and ALL.

The Watch API, which supports all ReplicationLevel(s), provides the same functionality and the implementation is more light-weighted since Watch requests are readonly.  Therefore, we propose to remove the ReplicationLevel parameter from send(..) and sendAsync(..) methods in order to simplify the code.",[],2018-11-29 22:21:57+00:00,2018-11-30 22:18:31+00:00,2019-03-22 05:27:48+00:00,Resolved,13201459,RATIS-442
Test,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,This is a follow up of RATIS-383 to add unit test.,[],2018-11-29 22:21:27+00:00,2019-01-02 23:21:44+00:00,2019-01-02 23:21:44+00:00,Resolved,13201458,RATIS-441
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"RATIS-383 (re)included the Netty tcnative native libraries to use TLS in Netty. We should try to add a unit test in Ratis Thirdparty so that we know that we have properly packaged the Netty java and native code.

Xiaoyu mentioned that HDDS-115 may have some code to copy when that has finished.",[],2018-11-29 21:57:36+00:00,2018-11-29 22:29:21+00:00,2018-11-30 17:07:24+00:00,Resolved,13201452,RATIS-440
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"TestSegmentedRaftLog.testAppendEntriesWithInconsistency() is failing due to RATIS-430 -- it misses a ""break"" statement.

Also, some tests will fail with NullPointerException if SegmentedRaftLog.LOG is set to Level.TRACE since server is null.",[],2018-11-28 23:12:03+00:00,2018-11-30 22:05:21+00:00,2019-03-22 05:27:52+00:00,Resolved,13201206,RATIS-439
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In RaftBasicTests.testWithLoad, it asserts if
- each server contains ALL the message and the number of such servers must be in majority.  

It is over strict.  It should assert if
- each message is contained in a majority of servers.",[],2018-11-27 22:22:26+00:00,2018-12-01 20:50:45+00:00,2019-03-22 05:27:37+00:00,Resolved,13200966,RATIS-438
New Feature,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We should come up with a ""standard"" test for the LogService. Some desirable features:

* Capable of scaling out to many nodes (clients and servers)
* Validation of data written
* Can report performance
* Can inject ""chaos""
* Execution platforms (how will folks run this test -- will it require any specific tools or other packages?)

We should come up with a high-level design for how we want to build such a test for the LogService, and figure out what to implement first (obviously, building some inject-able chaos would be premature at this point).",[],2018-11-27 21:51:39+00:00,,2018-12-05 08:02:13+00:00,Open,13200958,RATIS-437
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently heartbeats are sent in the same channel as append entries. It might happen that append entries are blocked due to StateMachine#readStateMachineData. In such a case the heartbeats can be missed. There are two possible solutions -
 # Create a separate channel for heartbeats
 # Separate heartbeat logic from append entries in LogAppender. In this case the heartbeats should not be blocked by append entries. One way to do it is to send heartbeats periodically via another thread.",[],2018-11-27 08:50:02+00:00,2018-12-07 10:46:40+00:00,2018-12-07 10:47:24+00:00,Resolved,13200800,RATIS-436
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently RaftLogWorker uses a blocking queue which blocks the append entries if the queue is full. We should rather fail the operation if the queue is full.,['ozone'],2018-11-27 08:40:41+00:00,,2019-05-23 06:09:39+00:00,Open,13200794,RATIS-435
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"We use ManagedChannel#shutdownNow which cancels all the active streams and throws StatusRuntimeException. 
{code:java}
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
 at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:272)
 at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
 at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:738)
 at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
 at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)

{code}
We should use ManagedChannel#shutdown and ManagedChannel#awaitTermination in order to close the channel properly.",[],2018-11-27 08:12:17+00:00,,2018-11-27 08:12:17+00:00,Open,13200786,RATIS-434
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"With the Watch API, the ReplicationLevel from writeRequestType RaftClientRequest becomes redundant.  Let remove it and the implementation so that we can simplify the code.",[],2018-11-21 23:47:41+00:00,2018-11-30 23:12:23+00:00,2018-11-30 23:12:23+00:00,Resolved,13199957,RATIS-433
Bug,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Blocker,"4.1.29.Final include several SSL related fix such as below required Ozone security (authn only SSL without encryption, NPE without this fix) and Ratis security.

[https://github.com/netty/netty/pull/8171/commits/0f0d7a2c7eda04cceace93d1682aeac1c24efe8a]

 

cc: [~jnp]",[],2018-11-19 19:07:44+00:00,2018-11-20 16:46:18+00:00,2018-11-20 16:46:19+00:00,Resolved,13199410,RATIS-432
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"{code:java}
2018-11-16 09:54:42,949 INFO org.apache.ratis.server.impl.RoleInfo: 0813f1a9-61be-4cab-aa05-d5640f4a8341: start FollowerState

2018-11-16 09:54:43,005 INFO org.apache.ratis.server.impl.RaftServerImpl: 0813f1a9-61be-4cab-aa05-d5640f4a8341: change Leader from null to e3e9a703-55bb-482b-a0a1-ce8000474ac2 at term 4 for appendEntries, leader elected after 61ms

2018-11-16 09:54:43,006 INFO org.apache.ratis.server.impl.RaftServerImpl: 0813f1a9-61be-4cab-aa05-d5640f4a8341: set configuration 3917: [e3e9a703-55bb-482b-a0a1-ce8000474ac2:172.26.32.230:9858, c6ad906f-7e71-4bac-bde3-d22bc1aa8c7d:172.26.32.231:9858, 0813f1a9-61be-4cab-aa05-d5640f4a8341:172.26.32.228:9858], old=null at 3917

2018-11-16 09:54:43,391 WARN org.apache.ratis.util.FileUtils: Failed to Files.delete /data/disk2/scm/ratis/a85fce1a-2aef-49cf-899e-894b9c74e7f6/current/log_3930-3930: java.nio.file.NoSuchFileException: /data/disk2/scm/ratis/a85fce1a-2aef-49cf-899e-894b9c74e7f6/current/log_3930-3930

2018-11-16 09:54:43,393 ERROR org.apache.ratis.server.storage.RaftLogWorker: Terminating with exit status 1: 0813f1a9-61be-4cab-aa05-d5640f4a8341-RaftLogWorker failed.

java.nio.file.NoSuchFileException: /data/disk2/scm/ratis/a85fce1a-2aef-49cf-899e-894b9c74e7f6/current/log_3930-3930

        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)

        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)

        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)

        at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:244)

        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)

        at java.nio.file.Files.delete(Files.java:1126)

        at org.apache.ratis.util.FileUtils.lambda$delete$8(FileUtils.java:82)

        at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:52)

        at org.apache.ratis.util.FileUtils.delete(FileUtils.java:81)

        at org.apache.ratis.util.FileUtils.deleteFile(FileUtils.java:72)

        at org.apache.ratis.server.storage.RaftLogWorker$TruncateLog.execute(RaftLogWorker.java:477)

        at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:216)

        at java.lang.Thread.run(Thread.java:745)
{code}",[],2018-11-19 09:39:59+00:00,2018-12-07 10:50:49+00:00,2018-12-07 10:51:03+00:00,Resolved,13199274,RATIS-431
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"While running performance runs with Ozone, it hits ConcurrentModificationException while loading the cached Raft Segment
{code:java}
2018-11-16 14:55:56,329 WARN org.apache.ratis.grpc.server.GrpcLogAppender: e3e9a703-55bb-482b-a0a1-ce8000474ac2: Failed appendEntries to 0813f1a9-61be-4cab-aa05-d5640f4a8341:172.26.32.228:9858: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception

2018-11-16 14:55:56,588 WARN org.apache.ratis.grpc.server.GrpcLogAppender: e3e9a703-55bb-482b-a0a1-ce8000474ac2: Failed appendEntries to 0813f1a9-61be-4cab-aa05-d5640f4a8341:172.26.32.228:9858: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception

2018-11-16 14:55:56,778 INFO org.apache.ratis.server.storage.RaftLogWorker: Rolling segment:e3e9a703-55bb-482b-a0a1-ce8000474ac2-RaftLogWorker index to:3962

2018-11-16 14:55:56,870 INFO org.apache.ratis.server.storage.RaftLogWorker: Rolling segment:e3e9a703-55bb-482b-a0a1-ce8000474ac2-RaftLogWorker index to:3963

2018-11-16 14:55:56,895 WARN org.apache.ratis.grpc.server.GrpcLogAppender: e3e9a703-55bb-482b-a0a1-ce8000474ac2: Failed appendEntries to 0813f1a9-61be-4cab-aa05-d5640f4a8341:172.26.32.228:9858: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception

2018-11-16 14:55:56,896 INFO org.apache.ratis.server.storage.RaftLogWorker: Rolling segment:e3e9a703-55bb-482b-a0a1-ce8000474ac2-RaftLogWorker index to:3964

2018-11-16 14:55:56,898 INFO org.apache.ratis.server.storage.RaftLogWorker: Rolling segment:e3e9a703-55bb-482b-a0a1-ce8000474ac2-RaftLogWorker index to:3965

2018-11-16 14:55:56,899 ERROR org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(e3e9a703-55bb-482b-a0a1-ce8000474ac2 -> 0813f1a9-61be-4cab-aa05-d5640f4a8341) unexpected exception

java.util.ConcurrentModificationException

        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380)

        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)

        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)

        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)

        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)

        at java.util.stream.LongPipeline.reduce(LongPipeline.java:438)

        at java.util.stream.LongPipeline.sum(LongPipeline.java:396)

        at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526)

        at org.apache.ratis.server.storage.RaftLogCache.getCachedSegmentNum(RaftLogCache.java:118)

        at org.apache.ratis.server.storage.RaftLogCache.shouldEvict(RaftLogCache.java:122)

        at org.apache.ratis.server.storage.SegmentedRaftLog.checkAndEvictCache(SegmentedRaftLog.java:215)

        at org.apache.ratis.server.storage.SegmentedRaftLog.get(SegmentedRaftLog.java:193)

        at org.apache.ratis.server.storage.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:199)

        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:207)

        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)

        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)

        at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:100)

        at java.lang.Thread.run(Thread.java:745)
{code}",[],2018-11-19 09:35:03+00:00,2018-11-22 19:44:46+00:00,2019-03-22 05:27:46+00:00,Resolved,13199271,RATIS-430
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Some cases are:
- https://builds.apache.org/job/PreCommit-RATIS-Build/538/testReport/junit/org.apache.ratis.grpc/TestRaftReconfigurationWithGrpc/testKillLeaderDuringReconf/
- https://builds.apache.org/job/PreCommit-RATIS-Build/539/testReport/junit/org.apache.ratis.netty/TestRaftReconfigurationWithNetty/testAddPeers/",[],2018-11-19 00:52:58+00:00,2018-11-20 01:29:27+00:00,2018-11-20 01:29:27+00:00,Resolved,13199210,RATIS-429
Improvement,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,"Failure detectors are an important piece in designing robust distributed systems. Components must be expected to fail, and the rest of the system should either continue functioning properly (ideal) or at the very least degrade gracefully instead of crashing or becoming corrupted. Because of the unreliable nature of communication over networks, however, detecting that a node has failed is a nontrivial task. The *phi accrual failure detector* is a popular choice for solving this problem, as it provides a good balance of flexibility and adaptability to different network conditions. It is used successfully in several real-world distributed systems, such as Apache Cassandra and Akka clusters, and also has a Node.js implementation.

[Original paper|http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.7427&rep=rep1&type=pdf]",[],2018-11-16 22:13:54+00:00,,2018-11-16 22:17:32+00:00,Open,13199049,RATIS-428
Improvement,[],nanda,Nanda kumar,nanda,Nanda kumar,Major,"It would be very helpful to have a better API as part of RaftServer, this will help us in knowing whether the RaftServer is part of the given group or not.",[],2018-11-16 11:50:01+00:00,2018-11-27 00:34:31+00:00,2019-03-22 05:27:45+00:00,Resolved,13198884,RATIS-427
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"In Ratis, 2 types of log entries exists, it can either of type StateMachineLogEntryProto or RaftConfigurationProto. Only StateMachineLogEntryProto is processed by the state machine, however RaftConfigurationProto is processed internally. In certain cases, state machine might like to maintain the sequence of events being processed by it i.e. ContainerStateMachine for Ozone. In such cases State machine should be notified of index updates while processing RaftConfigurationProto.

{code}
  oneof LogEntryBody {
    StateMachineLogEntryProto stateMachineLogEntry = 3;
    RaftConfigurationProto configurationEntry = 4;
  }
{code}",[],2018-11-16 04:09:17+00:00,2019-02-11 09:51:19+00:00,2019-02-11 09:51:19+00:00,Resolved,13198817,RATIS-426
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,"Presently, you can ask the LogReader for {{0}} records via the method {{#readBulk(int)}}. That's pretty silly.

We should validate that the user is strictly asking for one or more records from the LogReader.

Same goes for the {{LogReader#readBulk(List)}} variant -- we should require that the provided list be at least size one.",['newbie'],2018-11-15 22:51:18+00:00,2019-01-29 23:26:56+00:00,2019-01-29 23:26:56+00:00,Resolved,13198774,RATIS-425
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{noformat}
0:2


josha
{noformat}

When I read the record from a log where I wrote the value {{a}}, I get the above data back. Seems like we might be sending too much data back from the StateMachine?

FYI [~vrodionov].",['newbie'],2018-11-15 22:36:05+00:00,2019-03-26 20:52:36+00:00,2019-03-26 20:52:36+00:00,Resolved,13198766,RATIS-424
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"{noformat}
logservice> create josh
Created log 'josh'
logservice> put josh a
logservice> read josh
First=0, lastId=1
[]
logservice> put josh b
logservice> read josh
First=0, lastId=2
[0:2


josha]
logservice> put josh c
logservice> read josh
First=0, lastId=3
[0:2


josha, 0:2


joshb]
{noformat}

pardon the crappy formatting on the log data, but it seems like we always read up to the n-1'th record instead of all n records as the shell should do.

",[],2018-11-15 22:33:20+00:00,2018-12-31 19:27:19+00:00,2018-12-31 19:27:19+00:00,Resolved,13198763,RATIS-423
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,Small refactoring. LogStateMachine is going to be moved to the server sub-package.,[],2018-11-15 21:26:16+00:00,2018-11-15 22:31:03+00:00,2018-11-15 22:31:03+00:00,Resolved,13198744,RATIS-422
Task,[],elserj,Josh Elser,elserj,Josh Elser,Blocker,Switch over ratis to use the new thirdparty release.,[],2018-11-15 18:37:18+00:00,2018-11-17 21:58:21+00:00,2018-11-17 21:58:21+00:00,Resolved,13198700,RATIS-421
Bug,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Had some logservice quorums running locally, and this prevent TestMetaServer from passing.

Need to make sure we're grabbing some unique ports, and not some ports that may already be occupied.",['newbie'],2018-11-15 18:17:52+00:00,,2018-11-15 18:17:52+00:00,Open,13198694,RATIS-420
Bug,[],szetszwo,Tsz-wo Sze,gsbiju,Biju Nair,Major,Run the {{start-all.sh}} script in {{ratis-examples/src/main/bin}}.  The servers come up but shutdown immediately.,[],2018-11-15 18:05:04+00:00,2018-11-15 18:32:24+00:00,2018-11-15 18:33:00+00:00,Resolved,13198690,RATIS-419
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"The following tests seem to be failing intermittently  as shown here :https://builds.apache.org/job/PreCommit-RATIS-Build/523/testReport/
 # TestWatchRequestWithGrpc#testWatchRequestAsync
 # TestWatchRequestWithGrpc#testWatchRequestAsync
 # TestRaftAsyncWithGrpc#testWithLoadAsync

These tests need to fixed.",[],2018-11-15 10:48:42+00:00,,2019-06-05 03:39:15+00:00,Open,13198586,RATIS-418
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"* PureJavaCrc32C.java:[17] (regexp) RegexpSingleline: Line has trailing spaces.
- PureJavaCrc32C.java:[40,3] (design) DesignForExtension: Method 'getValue' is not designed for extension - needs to be abstract, final or empty.
- PureJavaCrc32C.java:[46,3] (design) DesignForExtension: Method 'reset' is not designed for extension - needs to be abstract, final or empty.
- PureJavaCrc32C.java:[51,3] (design) DesignForExtension: Method 'update' is not designed for extension - needs to be abstract, final or empty.
- PureJavaCrc32C.java:[87] (regexp) RegexpSingleline: Line has trailing spaces.
- PureJavaCrc32C.java:[93,9] (modifier) ModifierOrder: 'public' modifier out of order with the JLS suggestions.
- PureJavaCrc32C.java:[96] (regexp) RegexpSingleline: Line has trailing spaces.
- PureJavaCrc32C.java:[101,28] (naming) ConstantName: Name 'T8_0_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[102,28] (naming) ConstantName: Name 'T8_1_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[103,28] (naming) ConstantName: Name 'T8_2_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[104,28] (naming) ConstantName: Name 'T8_3_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[105,28] (naming) ConstantName: Name 'T8_4_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[106,28] (naming) ConstantName: Name 'T8_5_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[107,28] (naming) ConstantName: Name 'T8_6_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[108,28] (naming) ConstantName: Name 'T8_7_start' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- PureJavaCrc32C.java:[112 - 630] (regexp) RegexpSingleline: Line has trailing spaces.
",['newbie'],2018-11-15 02:08:27+00:00,2019-01-25 22:39:02+00:00,2019-03-22 05:27:44+00:00,Resolved,13198496,RATIS-417
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- ClientImplUtils.java:[24,8] (imports) UnusedImports: Unused import - org.apache.ratis.retry.RetryPolicies.
- ClientImplUtils.java:[26,8] (imports) UnusedImports: Unused import - org.apache.ratis.util.TimeDuration.
- ClientImplUtils.java:[31,1] (design) HideUtilityClassConstructor: Utility classes should not have a public or default constructor.

 ",['newbie'],2018-11-15 02:05:17+00:00,2019-01-25 22:33:38+00:00,2019-03-22 05:27:40+00:00,Resolved,13198495,RATIS-416
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The DesignForExtension rule only useful in public API but not implementations.  Let's disable it for now.,[],2018-11-15 02:04:21+00:00,2018-11-16 21:39:23+00:00,2018-11-16 21:39:23+00:00,Resolved,13198494,RATIS-415
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- RaftClient.java:[155,43] (coding) HiddenField: 'group' hides a field.

- RaftClientImpl.java:[23,8] (imports) UnusedImports: Unused import - org.apache.ratis.retry.RetryPolicies.
- RaftClientImpl.java:[45,35] (naming) ConstantName: Name 'callIdCounter' must match pattern '^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$'.
- RaftClientImpl.java:[237] (sizes) LineLength: Line is longer than 120 characters (found 122).
- RaftClientImpl.java:[237,50] (coding) HiddenField: 'groupId' hides a field.

",['newbie'],2018-11-15 02:03:21+00:00,2019-01-25 22:11:28+00:00,2019-03-22 05:27:39+00:00,Resolved,13198493,RATIS-414
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After RATIS-131, we should fix the legitimate checkstyle warnings. ",[],2018-11-15 01:55:33+00:00,2020-05-18 02:48:49+00:00,2020-05-18 02:48:49+00:00,Resolved,13198491,RATIS-413
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"lastCommitted is only used once outside RaftLog.  The usage is in a SegmentedRaftLog constructor.  We should change lastCommitted to private.

Then, SegmentedRaftLog could initialize lastCommitted using a RaftLog constructor (needs to add a parameter.)

BTW, let's also rename lastCommitted to commitIndex so that it is consistent with other code.",['newbie'],2018-11-13 23:26:16+00:00,2019-01-24 20:49:02+00:00,2019-01-24 20:49:02+00:00,Resolved,13198189,RATIS-412
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Trivial,"ServerProtoUtils is an interface so that everything is automatically public.  We should remove the unnecessary keyword ""public"".",['newbie'],2018-11-13 23:16:46+00:00,2019-02-16 17:10:47+00:00,2019-03-22 05:27:42+00:00,Resolved,13198186,RATIS-411
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"With Ozone, each of raft log segments are of 1GB in size. Also each of the writeChunk request will have 16MB worth of payload. So this can result in multiple writeChunk requests to be part of one log segment.

Because the caching policy in ratis works on eviction of log segments, these results in segments holding onto memory which is part of stateMachine.",[],2018-11-13 13:41:28+00:00,2018-11-21 18:26:02+00:00,2019-03-22 05:27:42+00:00,Resolved,13198061,RATIS-410
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When there is commitIndex changed, the watchRequests is updated with the indices in SenderList.  However, when there is a conf change, SenderList includes all servers in both old and new confs.  As a result, the computed indices may be incorrect.",[],2018-11-12 23:53:56+00:00,2018-11-17 23:53:41+00:00,2018-11-17 23:53:41+00:00,Resolved,13197928,RATIS-409
Bug,[],nanda,Nanda kumar,nanda,Nanda kumar,Major,"When we restart one of the node in the raft ring and in meantime if we have processed few transactions, the restarted node fails on {{RaftLogWorker$WriteLog#execute}}

{code}
2018-11-12 20:09:13,299 ERROR storage.RaftLogWorker (ExitUtils.java:terminate(86)) - Terminating with exit status 1: 866cb1cc-2d3e-44a7-977f-8510870b42ef-RaftLogWorker failed.
java.lang.IllegalStateException: lastWrittenIndex == 0, entry == term: 2
configurationEntry {
  peers {
    id: ""2552aca0-7b51-416e-8e52-1370fdcd5fd7""
    address: ""xxx.xxx.xxx.xxx:61142""
  }
  peers {
    id: ""542ec0a9-2bc5-4ac8-ad82-ba5d0fe2c2ae""
    address: ""xxx.xxx.xxx.xxx:61145""
  }
  peers {
    id: ""866cb1cc-2d3e-44a7-977f-8510870b42ef""
    address: ""xxx.xxx.xxx.xxx:61154""
  }
}

  at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
  at org.apache.ratis.server.storage.RaftLogWorker$WriteLog.execute(RaftLogWorker.java:351)
  at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:216)
  at java.lang.Thread.run(Thread.java:748)
{code}


At this time:
lastWrittenIndex: 0
entry.getIndex(): 0
entry.getTerm(): 2",[],2018-11-12 14:48:40+00:00,,2018-11-12 14:48:40+00:00,Open,13197826,RATIS-408
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis currently uses Grpc version 1.14.0. This can be updated to 1.16.0.

Along with this protobuf version can be updated to 3.5.1 and Netty to 4.1.30.Final.",[],2018-11-12 04:19:25+00:00,2019-10-29 18:17:21+00:00,2019-10-29 18:17:21+00:00,Resolved,13197697,RATIS-407
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RaftServerImpl, the appendEntriesAsync(..) calls must be sequential (although the actual log I/O is async).  Otherwise, the entries appended may be out of order.

As a result, RaftLog.append(entries) needs not to hold the RaftServerImpl lock.",[],2018-11-09 21:09:28+00:00,2018-11-15 01:29:50+00:00,2018-11-15 01:29:50+00:00,Resolved,13197509,RATIS-406
Improvement,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Critical,Recently all the unit tests are failing. This is caused by the latest Java 8 issue reported at SUREFIRE-1588 and fixed in Maven Surefire plugin 3.0.0-M1. We need to update the plugin.,[],2018-11-09 18:03:17+00:00,2018-11-09 18:47:43+00:00,2018-11-21 22:29:22+00:00,Resolved,13197471,RATIS-405
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"The deadlock happens when the RaftLogWorker queue is completely full.  This happens when the following thread is trying to enqueue holding onto the RaftServerImpl lock.

{code}
""grpc-default-executor-18"" #459 daemon prio=5 os_prio=0 tid=0x00007f8cd4a4a000 nid=0x5f6 waiting on condition [0x00007f8c31df2000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x0000000098dd53d0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.ratis.server.storage.RaftLogWorker.addIOTask(RaftLogWorker.java:186)
        at org.apache.ratis.server.storage.RaftLogWorker.writeLogEntry(RaftLogWorker.java:300)
        at org.apache.ratis.server.storage.SegmentedRaftLog.appendEntry(SegmentedRaftLog.java:302)
        at org.apache.ratis.server.storage.SegmentedRaftLog.append(SegmentedRaftLog.java:379)
        at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:914)
        - locked <0x000000009893b638> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:821)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$appendEntriesAsync$18(RaftServerProxy.java:434)
        at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$310/1439556067.apply(Unknown Source)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:309)
        at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$176/355487796.get(Unknown Source)
        at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:82)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:309)
        at org.apache.ratis.server.impl.RaftServerProxy$$Lambda$175/1025132044.apply(Unknown Source)
        at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981)
        at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124)
        at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:308)
        at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:434)
        at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.onNext(GrpcServerProtocolService.java:76)
        at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.onNext(GrpcServerProtocolService.java:66)
        at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:683)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}


The RaftLogWorker thread is in turn blocked on locking the RaftServerImpl lock as in the following trace.

{code}
""c5a4d441-cb73-47a2-94b5-fc8233061955-RaftLogWorker"" #440 daemon prio=5 os_prio=0 tid=0x00000000026a2000 nid=0x5e3 waiting for monitor entry [0x00007f8c884aa000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.ratis.server.impl.RaftServerImpl.lambda$appendEntriesAsync$21(RaftServerImpl.java:925)
        - waiting to lock <0x000000009893b638> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.impl.RaftServerImpl$$Lambda$316/47202155.apply(Unknown Source)
        at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
        at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
        at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)
        at org.apache.ratis.server.storage.SegmentedRaftLog$Task.done(SegmentedRaftLog.java:83)
        at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:220)
        at java.lang.Thread.run(Thread.java:748)
{code}",[],2018-11-09 07:53:13+00:00,2018-11-09 21:02:38+00:00,2018-11-09 21:10:58+00:00,Resolved,13197338,RATIS-404
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Starting build #478, all builds failed with ""VM crash or System.exit"" at ratis-common; https://builds.apache.org/job/PreCommit-RATIS-Build/478/artifact/out/patch-unit-root.txt

Build #477 did not have such problem; see https://builds.apache.org/job/PreCommit-RATIS-Build/477/artifact/out/patch-unit-root.txt",[],2018-11-09 00:38:34+00:00,2018-11-21 22:29:22+00:00,2018-11-21 22:29:22+00:00,Resolved,13197280,RATIS-403
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, RaftLogWorker queue is limited in the number of entries.  It should also limit the data size in order to avoid OutOfMemoryError.",[],2018-11-08 22:28:54+00:00,2018-12-07 00:59:26+00:00,2019-03-22 05:27:34+00:00,Resolved,13197256,RATIS-402
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"If all retries have failed, RaftLogWorker.StateMachineDataPolicy.getFromFuture(..) will return successfully.  It should throw an exception.

Thanks [~msingh] for pointing it out.",[],2018-11-08 22:17:25+00:00,2018-11-09 01:01:11+00:00,2018-11-09 01:01:11+00:00,Resolved,13197250,RATIS-401
Sub-task,[],rajeshbabu,Rajeshbabu Chintaguntla,rajeshbabu,Rajeshbabu Chintaguntla,Major,As part of this wanted to prepare shell scripts to start masters and workers for log service meta data daemons. These will be used in implementation docker images for testing.,[],2018-11-08 14:10:44+00:00,,2018-11-19 23:23:13+00:00,Open,13197132,RATIS-400
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When there is a test failed in an earlier module, all the tests in the depended modules won't be run (even with mvn -fae).  The JIRA propose moving all the tests to a new module as a workaround.",[],2018-11-08 00:20:29+00:00,2018-11-13 23:39:59+00:00,2018-11-13 23:39:59+00:00,Resolved,13196962,RATIS-399
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In dev-support/docker/Dockerfile, the protobuf version is still 3.1.0 but not 3.5.0 used in pom.xml.

Let's also update the maven version.",[],2018-11-07 23:32:00+00:00,2018-11-09 00:09:39+00:00,2018-11-09 00:09:39+00:00,Resolved,13196953,RATIS-398
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,MiniRaftCluster.getMaxTimeout() method was deprecated by RATIS-381.  Let's remove it.,[],2018-11-07 02:30:18+00:00,2019-02-02 22:43:43+00:00,2019-03-22 05:27:50+00:00,Resolved,13196724,RATIS-397
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"If the future from writeStateMachineData throws TimeoutIOException, the RaftLogWorker will terminate Java VM. In some cases, such behavior is undesirable. For example, the application may want to just shut down Ratis server but not the entire application.

In this JIRA, we allow retrying on TimeoutIOException. Then, application could detect no progression if TimeoutIOException happens again and again.

Note that RaftLogWorker has a BlockingQueue with capacity of 4096. If TimeoutIOException happens again and again, it won't accept further appendEntry and block the callers.",[],2018-11-07 02:16:17+00:00,2018-11-07 19:35:14+00:00,2018-11-08 00:18:14+00:00,Resolved,13196723,RATIS-396
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Following HADOOP-14671, let's upgrade Apache Yetus to 0.8.0.",[],2018-11-06 23:47:51+00:00,2018-11-07 00:06:34+00:00,2018-11-07 00:06:34+00:00,Resolved,13196714,RATIS-395
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"In the below code in TransactionContextImpl,
{code:java}
@Override
public TransactionContext setException(Exception ioe) {
  assert exception != null;
  this.exception = ioe;
  return this;
}
{code}
While setting the exception it asserts based on the exception maintained in the object is not null or not. While setting the exception first time, it will be null always and hence asserts. We should relax the check here.",[],2018-11-06 14:16:46+00:00,2018-11-06 22:30:50+00:00,2018-11-06 22:30:50+00:00,Resolved,13196564,RATIS-394
Bug,[],Sandeep Nemuri,Sandeep Nemuri,Sandeep Nemuri,Sandeep Nemuri,Minor," !Screen Shot 2018-11-06 at 1.34.15 PM.png|align=center,|height=750%,width=750&! 

This is because of below error.   
!Screen Shot 2018-11-06 at 1.39.02 PM.png!",[],2018-11-06 08:12:31+00:00,2018-11-15 14:28:06+00:00,2018-11-15 14:28:06+00:00,Resolved,13196429,RATIS-393
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Currently Ratis servers exit on a TimeoutIO exception as noticed in HDDS-799. Ratis Server should handle exceptions and retry the operations if needed.,[],2018-11-05 18:24:03+00:00,2018-11-08 00:18:14+00:00,2018-11-08 00:18:14+00:00,Resolved,13196315,RATIS-392
Task,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,Need to create a README for the logservice,['newbie'],2018-11-02 22:29:28+00:00,2018-11-29 16:35:19+00:00,2018-11-29 16:35:19+00:00,Resolved,13195994,RATIS-391
Task,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,"LogStateMachine is contained in the ""api"" package which makes no sense.

LogServiceClient would be considered client api, but doesn't exist in the ""api"" package.","['newbie', 'pull-request-available']",2018-11-02 20:43:39+00:00,2019-10-21 16:55:42+00:00,2019-10-21 18:26:56+00:00,Resolved,13195973,RATIS-390
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"After shutting down the leaderState, the Log Appender throws the following exception.

{code}
2018-11-02 06:00:11,500 INFO org.apache.ratis.server.impl.RaftServerImpl: 2dd779ad-06e5-4dfa-9228-664511cc2d18 closes. The last applied log index is 57969
2018-11-02 06:00:11,500 ERROR org.apache.ratis.server.impl.LogAppender: GrpcLogAppender(2dd779ad-06e5-4dfa-9228-664511cc2d18 -> 30150210-575a-4bd8-b6f2-62a56d2d0a8b) unexpected exception
java.lang.IllegalArgumentException: 2dd779ad-06e5-4dfa-9228-664511cc2d18-SegmentedRaftLog is expected to be opened but it is CLOSED
        at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
        at org.apache.ratis.server.storage.RaftLog.checkLogState(RaftLog.java:80)
        at org.apache.ratis.server.storage.SegmentedRaftLog.get(SegmentedRaftLog.java:175)
        at org.apache.ratis.server.storage.SegmentedRaftLog.getEntryWithData(SegmentedRaftLog.java:200)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:207)
        at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:152)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:96)
        at org.apache.ratis.server.impl.LogAppender.runAppender(LogAppender.java:100)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 2dd779ad-06e5-4dfa-9228-664511cc2d18-SegmentedRaftLog
        at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
        at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
        at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
        at org.apache.ratis.server.storage.RaftLog.close(RaftLog.java:336)
        at org.apache.ratis.server.storage.SegmentedRaftLog.close(SegmentedRaftLog.java:425)
        at org.apache.ratis.server.impl.ServerState.close(ServerState.java:388)
        at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:260)
        at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:219)
        at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:237)
        at org.apache.ratis.server.impl.RaftServerProxy.lambda$groupRemoveAsync$12(RaftServerProxy.java:387)
        at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
        at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:614)
        at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:1983)
        at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:385)
        at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:348)
        at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
        at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:115)
        at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
        at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:361)
        at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)
        at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:707)
        at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        ... 1 more
{code}",[],2018-11-02 06:42:03+00:00,,2018-11-30 23:17:30+00:00,Open,13195831,RATIS-389
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,The attempt(..) methods with long sleepMs parameter were deprecated by RATIS-381.  Let's remove them and use the ones with TimeDuration sleepTime parameter.,[],2018-11-02 02:09:24+00:00,,2018-11-02 02:09:24+00:00,Open,13195803,RATIS-388
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"I've been thinking about how to give a ""compelling"" demo for the LogService. I keep coming back to a simple shell that could be used to do simple things like create, read, and write to a log.

I am thinking something like:
{code}
> create 'log1'
> put 'log1' 'a'
> put 'log1' 'b'
> put 'log1' 'c'
> read 'log1'
['a', 'b', 'c']
> delete 'log'
{code}

Users would provide the location of the MetaData service to this shell. Everything else should be auto-magic (in the final version, anyways).

I think this compliments the docker infra work that [~rajeshbabu] is working on.",[],2018-11-01 15:31:36+00:00,2018-12-31 21:42:40+00:00,2019-03-22 05:27:44+00:00,Resolved,13195680,RATIS-387
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"Raft client sync Api has support for retry policies. Similarly, for Async API's including watch Api, support for Retry Policy is required.",[],2018-11-01 10:48:54+00:00,2018-11-16 21:12:50+00:00,2018-11-16 21:13:06+00:00,Resolved,13195628,RATIS-386
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Minor,We should have a nice README at https://github.com/apache/incubator-ratis/tree/master/ratis-logservice to help guide people to the project and encourage contributions/involvement.,['newbie'],2018-10-31 21:46:21+00:00,,2018-10-31 21:46:21+00:00,Open,13195503,RATIS-385
Bug,[],xyao,Xiaoyu Yao,msingh,Mukul Kumar Singh,Major,"RATIS-246 discusses making GRPC endpoint secure with mTLS. This jira is needed as GRPC/netty has dependency on tcnative jar/libraries that need to be shaded in Ratis-Thirdparty.

We also need to ensure gRPC, Netty, and netty-tcnative have compatible versions (will have to bump them).",['ozone'],2018-10-31 18:46:15+00:00,2018-11-29 21:56:02+00:00,2021-03-19 07:37:19+00:00,Resolved,13195456,RATIS-383
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Some tests may fail with NullPointerException since RaftTestUtil.waitForLeader(..) may return null (and the tests do not check for null) when leader elections take a long time.

It seems RaftTestUtil.waitForLeader(..) better waits for a longer period and, if there is a no leader, throw an exception with some descriptive error message, instead of returning null.",[],2018-10-30 17:33:18+00:00,2018-11-03 12:32:54+00:00,2018-11-03 12:32:54+00:00,Resolved,13195172,RATIS-381
Improvement,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Minor,"Currently RaftGroup#hashCode produces hash code only based on groupId.

This is unsymmetrical with {{equals}} where peers is also considered.",[],2018-10-29 21:04:13+00:00,,2019-07-26 18:32:53+00:00,Open,13194972,RATIS-380
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, writing state machine data and writing raft log are both asynchronous so that they can be completed in any order.  In some applications such as Ozone, it is hard to handle the case that writing raft log has succeeded but state machine data has failed.

In this JIRA, we provide an option to allow writing state machine data to be synchronized with writing raft log.",[],2018-10-29 11:47:14+00:00,2018-10-30 05:12:54+00:00,2018-10-30 05:12:54+00:00,Resolved,13194811,RATIS-379
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"There should be a large overlap of the ""arguments"" used to launch a MetaService SM and a LogService SM.

It would be nice to consolidate MasterServer and LogServiceWorker into a single class. Each can specify an extra arguments that they need to add (in addition to the common) arguments.

FYI [~vrodionov], [~sergey.soldatov]",['newbie'],2018-10-26 19:24:44+00:00,2018-12-05 03:03:24+00:00,2018-12-05 03:03:24+00:00,Resolved,13194496,RATIS-378
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Blocker,"steps taken :

------------------
 # wrote 5GB files through ozonefs
 # stopped datanodes, scm , om.
 # started all services.
 # Tried to read the file.

One of the datanodes failed to start. Throwing ""java.lang.IllegalStateException: Corrupted log header"" 

 
{noformat}
2018-10-26 10:26:01,317 ERROR org.apache.ratis.server.storage.LogInputStream: caught exception initializing log_inprogress_293
java.lang.IllegalStateException: Corrupted log header: ^@^@^@^@^@^@^@^@
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.server.storage.LogInputStream.init(LogInputStream.java:93)
 at org.apache.ratis.server.storage.LogInputStream.nextEntry(LogInputStream.java:120)
 at org.apache.ratis.server.storage.LogSegment.readSegmentFile(LogSegment.java:111)
 at org.apache.ratis.server.storage.LogSegment.loadSegment(LogSegment.java:133)
 at org.apache.ratis.server.storage.RaftLogCache.loadSegment(RaftLogCache.java:110)
 at org.apache.ratis.server.storage.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:151)
 at org.apache.ratis.server.storage.SegmentedRaftLog.open(SegmentedRaftLog.java:120)
 at org.apache.ratis.server.impl.ServerState.initLog(ServerState.java:191)
 at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:114)
 at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:106)
 at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:196)
 at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
 at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582)
 at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
 at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
 at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
 at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
2018-10-26 10:26:03,671 INFO org.apache.hadoop.ozone.web.netty.ObjectStoreRestHttpServer: Listening HDDS REST traffic on /0.0.0.0:9880
2018-10-26 10:26:03,672 INFO org.apache.hadoop.ozone.HddsDatanodeService: Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@1e411d81
2018-10-26 10:26:03,676 INFO org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer: Attempting to start container services.
2018-10-26 10:26:03,676 INFO org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis: Starting XceiverServerRatis 0d7f5327-df16-40fe-ac88-7ed06e76a20f at port 9858
2018-10-26 10:26:03,702 ERROR org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine: Unable to start the DatanodeState Machine
java.io.IOException: java.lang.IllegalStateException: Corrupted log header: ^@^@^@^@^@^@^@^@
 at org.apache.ratis.util.IOUtils.asIOException(IOUtils.java:51)
 at org.apache.ratis.server.storage.LogInputStream.nextEntry(LogInputStream.java:123)
 at org.apache.ratis.server.storage.LogSegment.readSegmentFile(LogSegment.java:111)
 at org.apache.ratis.server.storage.LogSegment.loadSegment(LogSegment.java:133)
 at org.apache.ratis.server.storage.RaftLogCache.loadSegment(RaftLogCache.java:110)
 at org.apache.ratis.server.storage.SegmentedRaftLog.loadLogSegments(SegmentedRaftLog.java:151)
 at org.apache.ratis.server.storage.SegmentedRaftLog.open(SegmentedRaftLog.java:120)
 at org.apache.ratis.server.impl.ServerState.initLog(ServerState.java:191)
 at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:114)
 at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:106)
 at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:196)
 at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
 at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582)
 at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
 at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
 at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
 at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: java.lang.IllegalStateException: Corrupted log header: ^@^@^@^@^@^@^@^@
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.server.storage.LogInputStream.init(LogInputStream.java:93)
 at org.apache.ratis.server.storage.LogInputStream.nextEntry(LogInputStream.java:120)
 ... 15 more
2018-10-26 10:26:03,703 ERROR org.apache.hadoop.ozone.HddsDatanodeService: Exception in HddsDatanodeService.
java.lang.NullPointerException
 at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.join(DatanodeStateMachine.java:331)
 at org.apache.hadoop.ozone.HddsDatanodeService.join(HddsDatanodeService.java:191)
 at org.apache.hadoop.ozone.HddsDatanodeService.main(HddsDatanodeService.java:250)
2018-10-26 10:26:03,706 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.lang.NullPointerException
2018-10-26 10:26:03,714 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Thread Interrupted waiting to refresh disk information: sleep interrupted
2018-10-26 10:26:03,715 INFO org.apache.hadoop.ozone.HddsDatanodeService: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down HddsDatanodeService at ctr-e138-1518143905142-541661-01-000005.hwx.site/172.27.68.
{noformat}
 ",[],2018-10-26 10:51:34+00:00,2018-10-29 05:47:44+00:00,2018-10-30 15:10:20+00:00,Resolved,13194382,RATIS-377
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,"The problem statement:

Raft server logs not only log data but ALL DML (Create/Delete etc) commands as well. When reading data from Raft log file using Log Service read API we need to filter these command out.

See LogServiceStateMachine class.",[],2018-10-25 22:59:21+00:00,,2018-10-26 02:43:38+00:00,Open,13194265,RATIS-376
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,"I assigned this ticket to [~sergey.soldatov] to work on TestMetaServer first. When its done, he can reassign this back to me.",[],2018-10-25 22:53:47+00:00,2018-11-13 21:45:14+00:00,2018-11-13 21:45:14+00:00,Resolved,13194263,RATIS-375
Sub-task,[],sergey.soldatov,Sergey Soldatov,sergey.soldatov,Sergey Soldatov,Major,"There are several problems:
1. Masters have fixed data dir and tests don't clean it up, so every next run it reads previous data.  
2. testReadWritetoLog has incorrect assert for the list of the logs.
3. Some of the operations take longer than 3 seconds, so rpc timeout happens and client resends the query.  For bulk operations such as delete all logs that may lead to unpredictable behavior.
TODO: 
1. make mini cluster using test dir instead of tmp
2. filter the list for the particular log name
3. disable cleanUp test until the new retry policy or proper handling for retries is implemented.  ",[],2018-10-25 14:12:15+00:00,2018-10-26 15:31:07+00:00,2018-10-27 07:33:16+00:00,Resolved,13194149,RATIS-374
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a server is killed, the last log entry may be partially written.  RaftLog will then consider the log as corrupted and the server will fail to start up.

In such case, since the last entry is never successfully written, it can be safely ignored.  RaftLog should tolerate it.",[],2018-10-25 05:37:25+00:00,2018-10-26 09:43:30+00:00,2018-10-26 09:43:30+00:00,Resolved,13194053,RATIS-373
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We should have something that can stand up a logservice in a pseudo-distributed manner.

Docker is all the rage right now, and would make it easy to deploy onto something like k8s in the future.

Using [docker-compose|https://docs.docker.com/compose/] would provide us a nice way to have one docker image for the metadata service daemons, another for logservice daemons (if needed), and then create a network that connects them all together. The final docker-compose yaml would be something like:

It would be nice to provide a ""client"" container in which we show a basic create/write/read/delete example to give folks a starting point.

* 1 network
* 3 instances of metadata service statemachines
* 3 instances of log service statemachines
* 1 image with the example client.

[~chrajeshbabu32@gmail.com], make sense to you?",[],2018-10-25 00:17:23+00:00,2019-01-03 20:43:47+00:00,2019-03-22 05:27:40+00:00,Resolved,13194015,RATIS-372
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"RATIS-352 tries to add metadata entries to the raft log.  However, there are tests expecting consecutive log indices so that they fail intermittently.  This JIRA is to fix the (most of) tests so that they won't depends on consecutive log indices.",[],2018-10-24 14:32:33+00:00,2018-10-24 22:59:14+00:00,2018-10-24 22:59:14+00:00,Resolved,13193890,RATIS-371
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"TestRaftServerSlownessDetection failure keep showing up in QA reports.  In my machine, it also fails every few runs.

BTW, TestRaftServerSlownessDetection only check simulated rpc.  The gRPC implementation is never tested.",['ozone'],2018-10-24 12:16:15+00:00,,2020-09-15 21:55:27+00:00,Reopened,13193854,RATIS-370
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,"Polish implementation, implement some missing features, add more UTs",[],2018-10-23 22:33:38+00:00,2018-10-26 19:42:34+00:00,2018-12-14 17:24:32+00:00,Resolved,13193700,RATIS-369
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"TestRaftSnapshotWithSimulatedRpc.testRestartPeer and some other tests are failing.
{code}
Caused by: java.lang.IllegalStateException
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:33)
	at org.apache.ratis.server.impl.ConfigurationManager.addConfiguration(ConfigurationManager.java:47)
	at org.apache.ratis.server.impl.ServerState.setRaftConf(ServerState.java:351)
{code}
ConfigurationManager may already have added a conf from the conf metadata file.  Then, it fails when adding it again from the log.",[],2018-10-23 16:34:53+00:00,2018-10-24 04:13:11+00:00,2018-10-24 04:13:11+00:00,Resolved,13193615,RATIS-368
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Bump current protobuf version to 3.5.1,[],2018-10-23 09:29:37+00:00,,2019-01-31 19:00:10+00:00,Open,13193504,RATIS-367
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"stopIndex is better to use Long since raftLog.getLastCommittedIndex() may return -1. In such case, updater.join() may not return since the updater thread is stuck in wait().

Some tests are failing; e.g. [https://builds.apache.org/job/PreCommit-RATIS-Build/434/testReport/org.apache.ratis/TestRaftServerLeaderElectionTimeout/testLeaderElectionDetection/]",[],2018-10-22 16:36:11+00:00,2018-10-22 18:27:54+00:00,2018-10-24 04:13:55+00:00,Resolved,13193296,RATIS-366
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code:java}
//RaftServerProxy
  public Iterable<RaftGroupId> getGroupIds() throws IOException {
    return getImpls().stream().map(RaftServerImpl::getGroupId).collect(Collectors.toList());
  }
{code}
getGroupIds() above unnecessarily calls getImpls() and then map RaftServerImpl to RaftGroupId.  We may get RaftGroupId(s) directly from ImplMap.",[],2018-10-22 16:27:55+00:00,2018-11-17 04:33:34+00:00,2018-11-17 04:33:34+00:00,Resolved,13193295,RATIS-365
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"The responsibility of storing the raft configuration currently is state Machine's responsibility.
This jira proposes to add a mechanism for Raft Server to persist the configuration to its own metafile
",[],2018-10-22 14:39:42+00:00,2018-10-23 07:58:15+00:00,2018-10-24 04:13:11+00:00,Resolved,13193281,RATIS-364
Improvement,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Blocker,"StateMachineUpdater should apply all the committed transactions before shutdown, otherwise committed data can be lost.",[],2018-10-19 23:12:18+00:00,2018-10-22 10:01:58+00:00,2018-10-24 04:13:55+00:00,Resolved,13192990,RATIS-363
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, we use TransactionContextImpl constructors to create TransactionContext objects.  Howerver, TransactionContextImpl is supposed to be internal but not a public API.  It is better to add a Builder for TransactionContext.  The Builder is a public API.",[],2018-10-19 10:41:28+00:00,2018-11-05 10:07:48+00:00,2018-11-05 10:07:48+00:00,Resolved,13192815,RATIS-362
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As stated in the TODO in TestStateMachine.testTransactionContextIsPassedBack(), MemoryRaftLog may throw NPE.
{code}
    // TODO: fix and run with in-memory log. It fails with NPE
    // TODO: if change setUseMemory to true
    RaftServerConfigKeys.Log.setUseMemory(properties, false);
{code}",[],2018-10-19 10:33:48+00:00,2018-10-22 14:45:31+00:00,2018-10-22 15:00:33+00:00,Resolved,13192814,RATIS-361
Bug,[],sergey.soldatov,Sergey Soldatov,sergey.soldatov,Sergey Soldatov,Major,RaftLog has some technical messages in the log related to changes in the configuration. We should skip them during read operations. ,[],2018-10-19 09:34:06+00:00,2019-01-11 20:45:46+00:00,2019-01-11 20:45:46+00:00,Resolved,13192790,RATIS-360
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After a watch request is added to a server, it will stay there until the watch condition is satisfied.  In this JIRA, we propose adding timeout support so that a watch request will be failed and removed from the server when it times out.",[],2018-10-19 04:28:47+00:00,2018-12-05 01:21:05+00:00,2019-03-22 05:27:40+00:00,Resolved,13192744,RATIS-359
Task,[],elserj,Josh Elser,elserj,Josh Elser,Minor,"If I have my /etc/hosts misconfigured so that my machine has an IP address set other than my actual IP address, the tests will fail to form a quorum because my computer can't talk to itself.

Two ""nice"" things we could do:
 * Make sure we use localhost/127.0.0.1 for everything in tests to avoid this problem entirely
 * If we do use the hostname for a node (instead of localhost), we can detect when the networking is messed up and fail the test immediately (and obviously).

For context, the new LogService test failed when my /etc/hosts was messed up. Starting from there and seeing how things fail and coming up with the proper fix would be best.",['newbie'],2018-10-18 19:32:58+00:00,,2018-10-19 10:11:08+00:00,Open,13192671,RATIS-358
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This is a second code refactoring of RATIS-353:
- Remove ProtoUtils.isConfigurationLogEntry(..)
-* Use LogEntryProto.hasConfigurationLogEntry() instead.
- Move the LogEntryProto related methods from ProtoUtils to ServerProtoUtils
-* These methods are only used in server.
",[],2018-10-18 04:49:59+00:00,2018-10-20 02:33:08+00:00,2018-10-20 02:33:08+00:00,Resolved,13192423,RATIS-357
Improvement,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,"This Jira adds replication level majority-committed, in the watch api, for clients who want to wait for transaction to be committed at majority of the peers.",['ozone'],2018-10-17 07:20:45+00:00,2018-10-19 04:20:11+00:00,2018-10-19 04:20:20+00:00,Resolved,13192147,RATIS-356
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,All these tests are failing in trunk.,[],2018-10-17 07:03:53+00:00,2018-10-18 22:56:29+00:00,2018-10-18 22:56:29+00:00,Resolved,13192145,RATIS-355
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"- Remove LeaderNoOp – it is not used.
- Rename SMLogEntryProto to StateMachineLogEntryProto.
-* As well rename the 'data' field to 'logData'.",[],2018-10-16 08:18:30+00:00,2018-10-18 01:27:00+00:00,2018-10-18 01:27:00+00:00,Resolved,13191825,RATIS-354
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We propose some refactoring on LogEntryProto:
- Remove LeaderNoOp -- it is not used.
- Rename SMLogEntryProto to StateMachineLogEntryProto.
- Move clientId and callId from LogEntryProto to StateMachineLogEntryProto.
- Adds StateMachineEntryProto for stateMachineData.",[],2018-10-16 03:00:18+00:00,2018-10-21 07:33:02+00:00,2018-10-21 07:33:02+00:00,Resolved,13191781,RATIS-353
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Current the commit index is not persisted in the Raft log.  When a server restarts, it cannot apply its log until it has joined a Raft group.  There is no problem if there is a Raft group.  

However, a server cannot recover its data when formatting a Raft group is impossible (e.g. a majority of servers are dead).  Ideally, a server can safely apply the log up to the commit index.  The JIRA is to persist the commit index so that such recovery is possible.",[],2018-10-15 10:24:37+00:00,2018-11-21 19:16:58+00:00,2019-03-22 05:27:46+00:00,Resolved,13191545,RATIS-352
Bug,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Trivial,"Here is related code:
{code}
      Preconditions.assertTrue(!request.hasPreviousLog() ||
              lastIndex == request.getPreviousLog().getIndex(),
          ""reply's next index is %s, request's previous is %s"",
          replyNextIndex, request.getPreviousLog());
{code}
The '%s' seems to be wrong.",[],2018-10-12 20:50:39+00:00,,2018-10-12 20:50:39+00:00,Open,13191296,RATIS-351
Improvement,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Minor,"The following example comes from GrpcLogAppender#mayWait :
{code}
      } catch(InterruptedException ie) {
        LOG.warn(this + "": Wait interrupted by "" + ie);
      }
{code}
The interrupt status should be restored before returning.",[],2018-10-12 20:42:27+00:00,,2018-10-12 20:42:27+00:00,Open,13191295,RATIS-350
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Feedback from 0.1.0 rc1: need to get ""incubating"" in the artifact name somewhere.

Will also include a rename of the modules to be a little more concise (remove the ""ratis-thirdparty-parent"") as that shows up in the final name.",[],2018-10-11 18:35:57+00:00,2018-10-31 16:48:33+00:00,2018-10-31 16:48:33+00:00,Resolved,13191022,RATIS-349
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In HDDS-625, we found that the Ozone client does not terminate.  The SlidingWindow (debug) thread and the TimeoutScheduler threads are holding up process termination.",[],2018-10-11 15:56:14+00:00,2018-10-11 21:04:55+00:00,2018-10-12 02:37:23+00:00,Resolved,13190964,RATIS-348
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"There were a few suggestions from [~jnp] and [~msingh] in RATIS-234.
- rename LeaderState.computeCommittedIndices(..).
- add a watch request test with leader changes.",[],2018-10-11 13:11:24+00:00,2018-10-12 03:17:37+00:00,2018-10-12 03:17:37+00:00,Resolved,13190898,RATIS-347
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"On restart on a Ratis server, it may be desirable to not allow the node to rejoin the raft ring. This jira proposes to add a config parameter to let the server do this.",[],2018-10-10 07:37:23+00:00,2019-10-23 11:38:46+00:00,2019-10-23 11:38:46+00:00,Resolved,13190575,RATIS-346
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Watch requests are special read-only requests.  Once the watch condition is satisfied, it should be returned immediately.  It should not wait for the earlier requests, if there are any.

Currently, the watch requests are put in the sliding window so that it won't return until all earlier requests have been returned.",[],2018-10-10 04:02:19+00:00,2019-03-11 22:34:06+00:00,2019-03-11 22:34:06+00:00,Resolved,13190554,RATIS-345
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,Create a release of the thirdparty artifact.,[],2018-10-08 20:23:59+00:00,2018-11-15 18:35:26+00:00,2018-11-15 18:35:26+00:00,Resolved,13190202,RATIS-344
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"I've noticed a convention in the tests which does something like:
{noformat}
public class TestRaftAsyncWithGrpc extends RaftAsyncTests<MiniRaftClusterWithGrpc>
    implements MiniRaftClusterWithGrpc.FactoryGet {
}{noformat}
In other words, the details that we are running against a gRPC are captured in the class hierarchy and the class definition itself is empty.

It would be nice if we could define the transport implementation dynamically instead of requiring these extra ""empty"" classes. The JUnit parameterization feature, [https://github.com/junit-team/junit4/wiki/parameterized-tests,] is pretty nice and would clean this up.",['newbie'],2018-10-08 16:39:23+00:00,,2018-10-15 16:01:55+00:00,Open,13190138,RATIS-343
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Let's try to keep all of the logservice ""code"" in one place, thus keeping everything in one jar.

We should be able to copy the relevant maven plugin configuration from ratis-proto into ratis-logservice to compile the protobuf spec files into java code.",['newbie'],2018-10-05 23:01:11+00:00,2018-11-02 20:39:22+00:00,2018-11-02 20:39:22+00:00,Resolved,13189834,RATIS-342
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"In follower, RaftServerImpl#appendEntriesAsync, entries should only be applied to state machine
only after writing the log to the state machine.",[],2018-10-05 11:11:45+00:00,2018-10-06 21:37:04+00:00,2018-10-17 07:08:40+00:00,Resolved,13189690,RATIS-341
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"It should be shaded to org.apache.ratis.thirdparty.*.

Also, ratis-thridparty needs a README.",[],2018-10-05 07:56:12+00:00,2018-10-06 00:36:00+00:00,2018-10-06 00:36:00+00:00,Resolved,13189657,RATIS-340
Improvement,[],sergey.soldatov,Sergey Soldatov,sergey.soldatov,Sergey Soldatov,Minor,At the moment all ServerState messages such as Leader changed don't have any information about the group id and when several quorums are working on the same nodes the log looks quite confusing and it's not clear for which group the node was elected as a leader. ,[],2018-10-04 18:28:08+00:00,,2018-11-30 23:24:50+00:00,Open,13189518,RATIS-339
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,ServerInformationReply currently only returns information of a particular group.  It should return informations of all the groups.,[],2018-10-03 19:46:56+00:00,2018-10-22 15:19:37+00:00,2018-10-22 15:19:37+00:00,Resolved,13189287,RATIS-338
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"leaderState/heartbeatMonitor is declared as volatile. Some code like below won't work since leaderState may be set to null in between.
{code:java}
//RaftServerImpl.checkLeaderState(..)
    } else if (leaderState == null || !leaderState.isReady()) {
{code}",[],2018-10-02 00:58:10+00:00,2018-10-08 06:50:07+00:00,2018-10-09 14:40:17+00:00,Resolved,13188741,RATIS-337
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
//LeaderState
  boolean isBootStrappingPeer(RaftPeerId peerId) {
    return inStagingState() && getStagingState().contains(peerId);
  }

  boolean inStagingState() {
    return stagingState != null;
  }
 
  ConfigurationStagingState getStagingState() {
    return stagingState;
  }
{code}
Since stagingState is volatile, it could be set to null between inStagingState() and contains(..).",[],2018-09-27 21:14:29+00:00,2018-10-05 07:03:47+00:00,2018-10-09 14:40:17+00:00,Resolved,13188034,RATIS-336
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"[~vrodionov] pointed out that ratis-hadoop-shaded still shows errors in the IDE. This is due to the same reason that ratis-proto showed errors.

Let me lift this over to ratis-thirdparty too.",[],2018-09-27 02:09:24+00:00,2018-10-04 18:28:34+00:00,2018-10-04 18:28:34+00:00,Resolved,13187775,RATIS-335
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Half of the Metadata Service for managing LogStreams.

RATIS-279 is handling the ""DDL"" operations, and Rajesh suggested that we spin out management of the servers which are available to back these LogStreams in a second task. This is it.",[],2018-09-26 20:41:08+00:00,2018-10-24 23:20:33+00:00,2018-10-24 23:20:34+00:00,Resolved,13187721,RATIS-334
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"ReplicationLevel.ALL means that
 - a client request is returned success when all the servers (instead of a majority of servers) have received the request.

We propose to add a new ReplicationLevel.ALL_COMMITTED. It means
 - a client request is returned success when all the servers have *committed* the request.",[],2018-09-25 18:32:25+00:00,2018-11-30 23:20:59+00:00,2018-11-30 23:20:59+00:00,Resolved,13187401,RATIS-333
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Currently RaftServer.Builder could only set StateMachine but not StateMachine.Registry.  We should allow both cases.,[],2018-09-25 18:26:10+00:00,2018-09-27 17:51:11+00:00,2018-10-17 07:08:40+00:00,Resolved,13187399,RATIS-332
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis client should provide a method to wait for commit from all the peers.

Also it will be great is supplier method can be provided to take an action on this event.",[],2018-09-25 08:21:54+00:00,2018-10-22 10:25:26+00:00,2018-10-22 10:25:26+00:00,Resolved,13187207,RATIS-331
Task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Need to vet the stuff included in ratis-thirdparty to make sure we're using it all and that we have appropriate LICENSE and NOTICE files included for it.

Also, need to make some steps for releasing it.",[],2018-09-24 20:22:19+00:00,2018-09-28 12:19:46+00:00,2018-09-28 12:19:46+00:00,Resolved,13187128,RATIS-330
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently while running Ratis with Ozone, Frequent leader elections can be noticed in the datanode logs. This is happening because of missing heartbeats from the leader to follower.",['ozone'],2018-09-24 16:10:12+00:00,2019-06-17 07:40:50+00:00,2019-06-17 07:40:50+00:00,Resolved,13187077,RATIS-329
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently for a follower, statemachine is updated right after appending the entries in the in-memory log. This complicates the state machine implementation. This can be simplified by updating the state machine after applying the log completely.

{code}
RaftServerImpl.java#appendEntriesAsync

state.updateStatemachine(leaderCommit, currentTerm);
{code}
",['ozone'],2018-09-23 15:06:47+00:00,2019-07-01 09:15:37+00:00,2019-07-01 09:15:37+00:00,Resolved,13186890,RATIS-328
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"- slownessInfo and leaderElectionTimeoutInfo should be volatile.
- blockingSemaphore is shared by various methods.  It may not work as expected.",[],2018-09-20 21:53:07+00:00,2018-10-02 10:30:26+00:00,2018-10-02 10:30:26+00:00,Resolved,13186479,RATIS-327
Improvement,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"When a follower truncates its log entry in case there is a mismatch between the received log entry and its own stored entry, we should also remove the stateMachine data written as a part of appending the stored log entry on the follower.",[],2018-09-19 18:36:32+00:00,2018-12-14 02:15:30+00:00,2019-03-22 05:27:35+00:00,Resolved,13186127,RATIS-326
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,It should import the shaded class instead.,[],2018-09-18 21:00:45+00:00,2018-09-19 09:27:58+00:00,2018-09-19 09:27:58+00:00,Resolved,13185904,RATIS-325
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The grpc class names are inconsistent:
- Inconsistent capitalization: GRpc vs Grpc
- Some name are confusing such as RaftClientProtocolProxy and AppendStreamer.

Also, RaftGRpcService should be moved to the server package.",[],2018-09-17 23:16:44+00:00,2018-09-20 05:02:22+00:00,2018-09-20 05:02:22+00:00,Resolved,13185666,RATIS-324
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,There are some deprecated API usage after updated the grpc version.,[],2018-09-17 21:06:21+00:00,2018-09-18 10:00:53+00:00,2018-09-18 10:18:26+00:00,Resolved,13185637,RATIS-323
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should
- Add valueOf methods to RaftGroup and change the constructors to private.
- Add hashCode and equals",[],2018-09-17 20:20:17+00:00,2018-09-18 10:01:32+00:00,2018-09-18 21:27:44+00:00,Resolved,13185628,RATIS-322
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,Currently raft log does not make sure that any appendEntry has a term greater than or equal to the last applied entry's term in the log. This Jira aims to add that check.,[],2018-09-17 11:09:17+00:00,2018-09-25 20:37:32+00:00,2018-09-25 20:37:33+00:00,Resolved,13185478,RATIS-321
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"HBase has a use-case where, in certain situations, we need to prevent a RegionServer from continuing to write more edits into a Log. Specifically, if a RS loses its ZooKeeper lock, we want to prevent that RS from being allowed to write anything more into any WALs.

For the ""current"" Log, this is easy for us to handle as we can call {{LogService#closeLog(LogName)}} to prevent anyone from writing from writing to that LogStream. However, we don't have any mechanism to prevent that RS from creating a new Log and starting to write to it.

We need to come up with a solution inside of the LogService which can be used to prevent a specific client from creating new Logs.",[],2018-09-14 15:58:11+00:00,,2018-09-14 15:58:11+00:00,Open,13185179,RATIS-320
Task,[],elserj,Josh Elser,elserj,Josh Elser,Trivial,"TestRaftServerJmx has a timeout of 10s which I frequently run into on my daily-use laptop.
{code:java}
[INFO] Running org.apache.ratis.server.impl.TestRaftServerJmx
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.872 s - in org.apache.ratis.server.impl.TestRaftServerJmx{code}
Typically, I see a failure in shutting down the cluster. Let's kick out this timeout a little more.",[],2018-09-13 19:14:03+00:00,2018-09-18 15:23:06+00:00,2018-09-18 15:26:39+00:00,Resolved,13184983,RATIS-319
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"TestDataValidate in Ozone throws the following exception.

{code}
java.lang.RuntimeException: ManagedChannel allocation site
        at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
        at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
        at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
        at org.apache.ratis.shaded.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:410)
        at org.apache.ratis.grpc.client.RaftClientProtocolClient.<init>(RaftClientProtocolClient.java:80)
        at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:56)
        at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:55)
        at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:182)
        at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:54)
        at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:101)
        at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:78)
        at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:313)
        at org.apache.ratis.client.impl.RaftClientImpl.sendRequestWithRetry(RaftClientImpl.java:268)
        at org.apache.ratis.client.impl.RaftClientImpl.send(RaftClientImpl.java:197)
        at org.apache.ratis.client.impl.RaftClientImpl.send(RaftClientImpl.java:178)
        at org.apache.ratis.client.RaftClient.send(RaftClient.java:82)
        at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequest(XceiverClientRatis.java:193)
        at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommand(XceiverClientRatis.java:210)
        at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.createContainer(ContainerProtocolCalls.java:297)
        at org.apache.hadoop.ozone.client.io.ChunkGroupOutputStream.checkKeyLocationInfo(ChunkGroupOutputStream.java:197)
        at org.apache.hadoop.ozone.client.io.ChunkGroupOutputStream.addPreallocateBlocks(ChunkGroupOutputStream.java:180)
        at org.apache.hadoop.ozone.client.rpc.RpcClient.createKey(RpcClient.java:472)
        at org.apache.hadoop.ozone.client.OzoneBucket.createKey(OzoneBucket.java:245)
        at org.apache.hadoop.ozone.freon.RandomKeyGenerator$OfflineProcessor.run(RandomKeyGenerator.java:601)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}",[],2018-09-13 11:25:27+00:00,2018-09-26 16:36:57+00:00,2018-09-26 16:36:57+00:00,Resolved,13184868,RATIS-318
Sub-task,[],vrodionov,Vladimir Rodionov,vrodionov,Vladimir Rodionov,Major,,[],2018-09-13 02:58:56+00:00,2018-09-20 17:43:27+00:00,2018-09-26 16:05:51+00:00,Resolved,13184777,RATIS-317
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"After the changes in RATIS-288, developers may find that their IDEs are complaining about dependencies that we bundle in ratis-proto-shaded as not being ""found"".

This is understandable because IDEs typically aren't smart enough to follow the maven-shade-plugin and unravel the relocation that's happening.

The easiest solution for this is to make an artifact for our ""thirdparty"" dependencies that has its own release schedule. The ""core"" of Ratis can then depend on this artifact and the relocated dependencies in the well-known location (fix the IDE errors). Additionally, this will give us a bit more flexibility in upgrading to newer versions of these dependencies without having to re-release Ratis (e.g. if there is a CVE on Netty, we can make a new release of ratis-thirdparty without re-releasing Ratis just for that change).

We could move this to a separate git repo, but it's easy enough to just leave this is a sub-directory of ratis.git. I don't have strong feelings either way.",[],2018-09-12 21:24:57+00:00,2018-09-24 19:57:34+00:00,2018-09-24 20:22:41+00:00,Resolved,13184729,RATIS-316
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"groupRemove currently only remove the group from the map but does not delete the group storage directory.  We should add an option to clean up the directory.

Also, when a server restarts, it should check if there are existing group directories.  If there are any, add them to the map.","['acadia', 'ozone']",2018-09-12 21:05:17+00:00,2018-09-17 17:43:50+00:00,2018-09-17 20:06:19+00:00,Resolved,13184723,RATIS-315
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"ConfUtils logs a message for each value read from a conf.  This is a desire behavior for servers.  However, it is undesired for the clients.","['acadia', 'ozone']",2018-09-10 17:56:41+00:00,2018-09-11 21:01:22+00:00,2018-09-18 18:21:03+00:00,Resolved,13184114,RATIS-314
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"This was found in Ozone testing.

Three nodes in the pipeline.
{code:java}
group-2041ABBEE452:[bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9:172.27.12.96:9858, faa888b7-92bb-4e35-a38c-711bd1c28948:172.27.80.23:9858, ff544de8-96ea-4097-8cdc-460ac1c60db7:172.27.23.161:9858]
{code}
On two servers, the reinitialization request succeeds, 
{code:java}
2018-09-09 10:49:40,938 INFO org.apache.ratis.server.impl.RaftServerProxy: faa888b7-92bb-4e35-a38c-711bd1c28948: reinitializeAsync ReinitializeRequest(client-682DF1D0F737->faa888b7-92bb-4e35-a38c-711bd1c28948) in group-7347726F7570, cid=4, seq=0 RW, null, group-2041ABBEE452:[bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9:172.27.12.96:9858, faa888b7-92bb-4e35-a38c-711bd1c28948:172.27.80.23:9858, ff544de8-96ea-4097-8cdc-460ac1c60db7:172.27.23.161:9858

2018-09-09 10:49:40,209 INFO org.apache.ratis.server.impl.RaftServerProxy: bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9: reinitializeAsync ReinitializeRequest(client-DFE3ACF394F9->bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9) in group-7347726F7570, cid=3, seq=0 RW, null, group-2041ABBEE452:[bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9:172.27.12.96:9858, faa888b7-92bb-4e35-a38c-711bd1c28948:172.27.80.23:9858, ff544de8-96ea-4097-8cdc-460ac1c60db7:172.27.23.161:9858]
{code}
But around the same time, the third server is not ready
{code:java}
2018-09-09 10:49:41,414 WARN org.apache.ratis.grpc.server.RaftServerProtocolService: ff544de8-96ea-4097-8cdc-460ac1c60db7: Failed requestVote bfe9c5f2-da9b-4a8f-9013-7540cbbed1c9->ff544de8-96ea-4097-8cdc-460ac1c60db7#0: org.apache.ratis.protocol.ServerNotReadyException: Server ff544de8-96ea-4097-8cdc-460ac1c60db7 is not [RUNNING]: current state is STARTING
{code}
Though the reinitialization request never got processed on this server, the exception is ignored in RaftClientImpl. This needs to be addressed",[],2018-09-10 17:02:51+00:00,2018-09-11 13:18:37+00:00,2018-09-11 13:18:37+00:00,Resolved,13184096,RATIS-313
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Major,"steps taken :

-------------------
 # created 6 node ozone cluster.
 # copied a file from local through ozoneFS interface :  ozone fs -copyFromLocal /etc/passwd /
 # created a copy of the passwd file - ozone fs -cp /passwd /passwd2
 # Now , tried to overwrite the key 'passwd2' with  different content -  ./ozone oz -putKey /fs-volume/fs-bucket/passwd2 -file /etc/services

Observations :

------------------------

PutKey ozone client request hang indefinitely  because ratis client keeps re-trying.

datanode log :

---------------------- 
{noformat}
2018-09-06 13:32:53,506 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858: change Leader from null to 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858 at term 11 for appendEntries, leader elected after 286ms
 2018-09-06 13:32:53,510 INFO org.apache.ratis.server.storage.RaftLogWorker: Rolling segment:d9654353-6240-4ac6-b561-04e0498ba522_9858-RaftLogWorker index to:423
 2018-09-06 13:32:53,518 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858-org.apache.ratis.server.impl.RoleInfo@6e79224c: Withhold vote from candidate 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858 with term 11. State: leader=071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858, term=11, lastRpcElapsed=8ms
 2018-09-06 13:32:53,518 INFO org.apache.ratis.server.impl.LogAppender: d9654353-6240-4ac6-b561-04e0498ba522_9858 stops appending log entries to follower 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858(next=423, match=422, attendVote=true, lastRpcSendTime=299, lastRpcResponseTime=297)
 2018-09-06 13:32:56,217 WARN org.apache.ratis.server.impl.LogAppender: GRpcLogAppender(d9654353-6240-4ac6-b561-04e0498ba522_9858 > d00d2193-4f96-4ee2-bd52-9d245a90e51f_9858): appendEntries Timeout, request=d9654353-6240-4ac6-b561-04e0498ba522_9858>d00d2193-4f96-4ee2-bd52-9d245a90e51f_9858#1675
 2018-09-06 13:32:56,220 WARN org.apache.ratis.server.impl.LogAppender: GRpcLogAppender(d9654353-6240-4ac6-b561-04e0498ba522_9858 > 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858): appendEntries Timeout, request=d9654353-6240-4ac6-b561-04e0498ba522_9858>071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858#1687
 2018-09-06 17:20:14,788 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858: change Leader from 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858 to null at term 12 for updateCurrentTerm
 2018-09-06 17:20:14,800 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858: change Leader from null to d00d2193-4f96-4ee2-bd52-9d245a90e51f_9858 at term 12 for appendEntries, leader elected after 11ms
 2018-09-06 17:20:19,116 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858: change Leader from d00d2193-4f96-4ee2-bd52-9d245a90e51f_9858 to null at term 13 for updateCurrentTerm
 2018-09-06 17:20:19,123 INFO org.apache.ratis.server.impl.RaftServerImpl: d9654353-6240-4ac6-b561-04e0498ba522_9858: change Leader from null to 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858 at term 13 for appendEntries, leader elected after 7ms
 2018-09-06 17:20:21,991 WARN org.apache.ratis.grpc.server.RaftServerProtocolService: d9654353-6240-4ac6-b561-04e0498ba522_9858: Failed appendEntries 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858->d9654353-6240-4ac6-b561-04e0498ba522_9858#1
 java.lang.IllegalStateException: Unexpected Index: previous is (t:11, i:457) but entries[0].getIndex()=0
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.server.impl.RaftServerImpl.validateEntries(RaftServerImpl.java:800)
 at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:873)
 at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:838)
 at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:247)
 at org.apache.ratis.grpc.server.RaftServerProtocolService$1.onNext(RaftServerProtocolService.java:76)
 at org.apache.ratis.grpc.server.RaftServerProtocolService$1.onNext(RaftServerProtocolService.java:66)
 at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248)
 at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263)
 at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:683)
 at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
 at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
 at java.lang.Thread.run(Thread.java:745)
 2018-09-06 17:20:22,249 WARN org.apache.ratis.grpc.server.RaftServerProtocolService: d9654353-6240-4ac6-b561-04e0498ba522_9858: appendEntries onError: org.apache.ratis.shaded.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
 2018-09-06 17:20:25,303 WARN org.apache.ratis.grpc.server.RaftServerProtocolService: d9654353-6240-4ac6-b561-04e0498ba522_9858: Failed appendEntries 071106cd-87b7-4c2b-8ae0-f1c94c3485ca_9858->d9654353-6240-4ac6-b561-04e0498ba522_9858#11
 java.lang.IllegalStateException: Unexpected Index: entries[1].getIndex()=0 but entries[0].getIndex()=0
 at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
 at org.apache.ratis.server.impl.RaftServerImpl.validateEntries(RaftServerImpl.java:812)
 at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:873)
 at org.apache.ratis.server.impl.RaftServerImpl.appendEntriesAsync(RaftServerImpl.java:838){noformat}
cc - [~shashikant] , [~ljain]",[],2018-09-07 13:32:38+00:00,2018-09-10 05:58:51+00:00,2018-09-10 05:58:51+00:00,Resolved,13183634,RATIS-312
Bug,[],zander,dongeforever,zander,dongeforever,Critical,"!image-2018-09-07-15-32-03-392.png!

 

!image-2018-09-07-15-33-05-459.png!",[],2018-09-07 07:33:19+00:00,2018-10-09 14:40:17+00:00,2019-04-26 23:12:43+00:00,Resolved,13183575,RATIS-311
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"+underlined text+Currently, ratis retries indefinitely if a client request fails. This Jira aims to add retryPolicy in Ratis which :

1) Adds a policy to retry with a fixed count and with fixed sleep interval

2) Default policy is set to RETRY_FOREVER","['acadia', 'ozone']",2018-09-03 12:28:04+00:00,2018-09-11 18:08:05+00:00,2018-10-06 09:09:18+00:00,Resolved,13182624,RATIS-310
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Even though Ratis server provides api's to add remove peers from a raft server, there are no client side api's to let us do the same.",[],2018-09-03 09:33:54+00:00,2018-11-16 19:25:27+00:00,2018-11-16 19:25:27+00:00,Resolved,13182591,RATIS-309
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira will be used an umbrella jira to track all the tasks for a native client using C++ grpc bindings. Will populate all the subtasks here soon. ,[],2018-08-31 13:25:03+00:00,,2018-08-31 13:25:03+00:00,Open,13182359,RATIS-308
Improvement,[],elek,Marton Elek,elek,Marton Elek,Minor,"During the 0.2.0 release I used a helper script which contained the smaller steps for the release process.

Compared to the existing make_rc script it could
 # create the git tag, change maven version
 # test the src release by compiling the project from the src tar
 # upload artifacts to the apache nexus
 # sign artifacts
 # upload artifacts to the dev svn staging area
 # push git tag to the git repository

 

All of the small steps are defined in bash functions and they could be executed one by one and I could check the results between the steps.

In this patch I merge my custom script with the existing make_rc to make it easier to release ratis in the future.

 ",[],2018-08-30 15:37:47+00:00,2019-10-29 19:00:11+00:00,2019-10-29 19:00:11+00:00,Resolved,13182160,RATIS-307
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In the multiple raft group use case, multiple raft logs will be written at the same time.  If there are multiple disk devices available in the server, it is better to have multiple storage directories configured in different disk devices for a better performance.

We may change the server conf {{raft.server.storage.dir}} to take a list of directories so that the server could assign them to individual group.",['ozone'],2018-08-29 17:06:12+00:00,2018-10-08 13:36:58+00:00,2018-10-08 13:36:58+00:00,Resolved,13181944,RATIS-306
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After RATIS-300, multiple RaftServerImpl objects is supported in a RaftServerProxy object.  We need some group management APIs for client to add/remove groups.","['acadia', 'ozone']",2018-08-29 16:52:50+00:00,2018-09-10 23:16:59+00:00,2018-09-11 20:39:32+00:00,Resolved,13181941,RATIS-305
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,EntryWithData#getEntry currently returns the LogEntryProto received from readStateMachineData directly. This brings the responsibility of correctly initializing the logEntryProto to StateMachine. We can change the readStateMachineData api to return SMLogEntryProto so that the logEntryProto can be correctly initialized within EntryWithData.,[],2018-08-24 09:31:02+00:00,2018-09-27 23:18:08+00:00,2018-09-27 23:18:08+00:00,Resolved,13180915,RATIS-304
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"TestRaftStateMachineException is failing with the following exception

{code}
[ERROR] testRetryOnExceptionDuringReplication[2](org.apache.ratis.statemachine.TestRaftStateMachineException)  Time elapsed: 0.001 s  <<< ERROR!
java.lang.NullPointerException
	at org.apache.ratis.statemachine.TestRaftStateMachineException.testRetryOnExceptionDuringReplication(TestRaftStateMachineException.java:139)
{code}",['ozone'],2018-08-24 07:38:55+00:00,2018-09-10 20:09:48+00:00,2018-09-10 20:09:48+00:00,Resolved,13180889,RATIS-303
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"I got multiple errors during ozone tests with ratis:

{code}
WARNING: Failed to construct URI for proxy lookup, proceeding without proxy
java.net.URISyntaxException: Illegal character in hostname at index 13: https://ozone_datanode_3.ozone_default:9858
        at java.net.URI$Parser.fail(URI.java:2848)
        at java.net.URI$Parser.parseHostname(URI.java:3387)
        at java.net.URI$Parser.parseServer(URI.java:3236)
        at java.net.URI$Parser.parseAuthority(URI.java:3155)
        at java.net.URI$Parser.parseHierarchical(URI.java:3097)
        at java.net.URI$Parser.parse(URI.java:3053)
        at java.net.URI.<init>(URI.java:673)
{code}

It came from the shaded io.grpc during the proxy detection. Unfortunately this is a limitation of the docker-compose. I use docker-compose to create clusters but compose use underscore in the dns names which are invalid. It's checked in one of the constructor of the java.net.URI/URL.

See also: https://github.com/docker/compose/issues/229

There is no real fix for that. Fortunately in the latest grpc-java the proxy detection part is improved and I can't see similar errors (even if my host names still invalid).

I propose to use the latest grpc and (just to make it easier) swtich to the same netty which is used by grpc-java.

I tested the change with ozone pseudo cluster and it worked well.
 
",[],2018-08-22 15:04:51+00:00,2018-08-24 07:43:57+00:00,2018-09-10 22:10:31+00:00,Resolved,13180493,RATIS-302
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently for a client to re-initialize a raft group, it should be in the same group as the server's current group. This jira proposes to add a force option to override this requirement.",['ozone'],2018-08-17 13:54:09+00:00,2018-08-31 14:27:03+00:00,2018-08-31 14:27:03+00:00,Resolved,13179590,RATIS-301
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, there is only one RaftServerImpl object in a RaftServerProxy object.  This JIRA is to support multiple RaftServerImpl objects in a RaftServerProxy object in order to support mult-raft.",['ozone'],2018-08-14 18:25:03+00:00,2018-09-03 09:03:45+00:00,2018-09-03 09:03:46+00:00,Resolved,13178920,RATIS-300
Bug,[],jingc,Jing Chen,jingc,Jing Chen,Minor,"An error happens when running start-all.sh in ratis-examples.

 
{noformat}
➜  bin git:(master) ./start-all.sh
/tmp/incubator-ratis/ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0-SNAPSHOT.jar
Waiting for the servers
/tmp/incubator-ratis/ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0-SNAPSHOT.jar
/tmp/incubator-ratis/ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0-SNAPSHOT.jar
/tmp/incubator-ratis/ratis-examples/src/main/bin/../../../target/ratis-examples-0.3.0-SNAPSHOT.jar

➜  bin git:(master) Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318) at java.util.jar.JarVerifier.update(JarVerifier.java:230) at java.util.jar.JarFile.initializeVerifier(JarFile.java:383) at java.util.jar.JarFile.getInputStream(JarFile.java:450) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977) at sun.misc.Resource.cachedInputStream(Resource.java:77) at sun.misc.Resource.getByteBuffer(Resource.java:160) at java.net.URLClassLoader.defineClass(URLClassLoader.java:454) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495) Error: A JNI error has occurred, please check your installation and try again Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318) at java.util.jar.JarVerifier.update(JarVerifier.java:230) at java.util.jar.JarFile.initializeVerifier(JarFile.java:383) at java.util.jar.JarFile.getInputStream(JarFile.java:450) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977) at sun.misc.Resource.cachedInputStream(Resource.java:77) at sun.misc.Resource.getByteBuffer(Resource.java:160) at java.net.URLClassLoader.defineClass(URLClassLoader.java:454) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)Error: A JNI error has occurred, please check your installation and try again Exception in thread ""main"" at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495) java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318) at java.util.jar.JarVerifier.update(JarVerifier.java:230) at java.util.jar.JarFile.initializeVerifier(JarFile.java:383) at java.util.jar.JarFile.getInputStream(JarFile.java:450) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977) at sun.misc.Resource.cachedInputStream(Resource.java:77) at sun.misc.Resource.getByteBuffer(Resource.java:160) at java.net.URLClassLoader.defineClass(URLClassLoader.java:454) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)
Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes
at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330)
at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263)
at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318)
at java.util.jar.JarVerifier.update(JarVerifier.java:230)
at java.util.jar.JarFile.initializeVerifier(JarFile.java:383)
at java.util.jar.JarFile.getInputStream(JarFile.java:450)
at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977)
at sun.misc.Resource.cachedInputStream(Resource.java:77)
at sun.misc.Resource.getByteBuffer(Resource.java:160)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:454)
at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes
at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330)
at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263)
at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318)
at java.util.jar.JarVerifier.update(JarVerifier.java:230)
at java.util.jar.JarFile.initializeVerifier(JarFile.java:383)
at java.util.jar.JarFile.getInputStream(JarFile.java:450)
at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977)
at sun.misc.Resource.cachedInputStream(Resource.java:77)
at sun.misc.Resource.getByteBuffer(Resource.java:160)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:454)
at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)Error: A JNI error has occurred, please check your installation and try again

Exception in thread ""main"" at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)
java.lang.SecurityException: Invalid signature file digest for Manifest main attributes
at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:330)
at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:263)
at java.util.jar.JarVerifier.processEntry(JarVerifier.java:318)
at java.util.jar.JarVerifier.update(JarVerifier.java:230)
at java.util.jar.JarFile.initializeVerifier(JarFile.java:383)
at java.util.jar.JarFile.getInputStream(JarFile.java:450)
at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977)
at sun.misc.Resource.cachedInputStream(Resource.java:77)
at sun.misc.Resource.getByteBuffer(Resource.java:160)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:454)
at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495){noformat}",[],2018-08-14 09:54:14+00:00,2018-08-14 17:39:38+00:00,2018-08-14 17:39:38+00:00,Resolved,13178812,RATIS-299
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Update auto-common to 0.8 and log4j to 2.11.0 versions in ratis.

As this causes compliation issues in Ozone as following

{code}
[WARNING] 
Dependency convergence error for com.google.auto:auto-common:0.10 paths to dependency are:
+-org.apache.hadoop:hadoop-hdds-common:0.2.1-SNAPSHOT
  +-org.apache.ratis:ratis-server:0.3.0-6a2c3d5-SNAPSHOT
    +-org.apache.ratis:ratis-proto-shaded:0.3.0-6a2c3d5-SNAPSHOT
      +-com.google.auto:auto-common:0.10
and
+-org.apache.hadoop:hadoop-hdds-common:0.2.1-SNAPSHOT
  +-org.apache.ratis:ratis-server:0.3.0-6a2c3d5-SNAPSHOT
    +-org.apache.ratis:ratis-proto-shaded:0.3.0-6a2c3d5-SNAPSHOT
      +-com.google.auto.service:auto-service:1.0-rc4
        +-com.google.auto:auto-common:0.8
 
[WARNING] 
Dependency convergence error for org.apache.logging.log4j:log4j-api:2.6.2 paths to dependency are:
+-org.apache.hadoop:hadoop-hdds-common:0.2.1-SNAPSHOT
  +-org.apache.ratis:ratis-server:0.3.0-6a2c3d5-SNAPSHOT
    +-org.apache.ratis:ratis-proto-shaded:0.3.0-6a2c3d5-SNAPSHOT
      +-org.apache.logging.log4j:log4j-api:2.6.2
and
+-org.apache.hadoop:hadoop-hdds-common:0.2.1-SNAPSHOT
  +-org.apache.logging.log4j:log4j-api:2.11.0
and
+-org.apache.hadoop:hadoop-hdds-common:0.2.1-SNAPSHOT
  +-org.apache.logging.log4j:log4j-core:2.11.0
    +-org.apache.logging.log4j:log4j-api:2.11.0
{code}",[],2018-08-10 18:13:49+00:00,2018-08-11 02:31:36+00:00,2018-08-11 02:31:36+00:00,Resolved,13178340,RATIS-298
Improvement,[],hanishakoneru,Hanisha Koneru,hanishakoneru,Hanisha Koneru,Major,"This Jira proposes to add support for notifying the state machine whenever the server state changes.

This would help the state machine to immediately discover whenever there is a state change on its server.

If a state machine implementation can service read requests without logging to the Server, this notification would help prevent an old leader from servicing any new requests.

Whenever there is a state change on the server, it should notify its state machine of this change.",['ozone'],2018-08-08 21:45:16+00:00,,2020-08-07 21:38:23+00:00,Open,13177802,RATIS-297
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,,['ozone'],2018-08-08 15:57:48+00:00,,2019-07-15 11:40:52+00:00,Open,13177711,RATIS-296
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Currently raft log worker only waits for the log data flush to finish. However it should also wait for state machine data write to finish as well.,['ozone'],2018-08-08 15:56:10+00:00,2018-08-17 22:49:39+00:00,2018-08-17 22:49:39+00:00,Resolved,13177710,RATIS-295
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Blocker,"There are multiple CVEs found in ratis-hadoop.
- CVE-2012-4449  |  High org.apache.ratis:ratis-hadoop:0.3.0-SNAPSHOT
- CVE-2016-5001  |  Low org.apache.ratis:ratis-hadoop:0.3.0-SNAPSHOT
- CVE-2017-3161  |  Medium org.apache.ratis:ratis-hadoop:0.3.0-SNAPSHOT
- CVE-2017-3162  |  High org.apache.ratis:ratis-hadoop:0.3.0-SNAPSHOT

It is very likely that the CVEs come from the Hadoop dependency.  We should either update the Hadoop version or temporarily remove Hadoop dependency in order to fix the CVEs.",['ozone'],2018-08-07 18:26:57+00:00,2018-09-28 17:33:29+00:00,2018-09-28 17:33:29+00:00,Resolved,13177478,RATIS-294
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,A raft server instance return its current group ID.,['ozone'],2018-08-06 07:04:49+00:00,2018-08-06 19:13:48+00:00,2018-08-06 19:35:54+00:00,Resolved,13177038,RATIS-293
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"RaftID can be constructed using a UUID. However the constructor has private access. Inorder to uniquely identify a ratis ring and also for the application to provide its own identifier for Raft*ID variables, Ratis should have an interface to create RaftID's from UUIDs.",['ozone'],2018-08-06 06:34:08+00:00,2018-08-06 19:07:38+00:00,2018-08-06 19:16:47+00:00,Resolved,13177032,RATIS-292
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"A Raft server uses a storage directory to store the write ahead log. If this log is lost because of a reason, then this node should fail itself.

For a follower, if raft log location has failed, then the follower will not be able to append any entries. This node will now be lagging behind the follower and will eventually be notified via notifySlowness.

For a leader where the raft log disk has failed, the leader will not append any new entries to its log. However with respect to the raft ring, the leader will still remain healthy. This jira proposes to add a new api to identify a leader with failed node.

Also this jira also proposes to add a new api to the statemachine, so that state machine implementation can provide methods to verify the raft log location.",['ozone'],2018-08-04 04:50:17+00:00,2018-08-23 22:44:18+00:00,2018-08-23 22:44:18+00:00,Resolved,13176871,RATIS-291
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"In ratis a raft server can be in 3 state, Candidate, Leader and Follower. Out of these state, in a cluster, one node being a leader and others being the follower is the steady system state. This jira proposes to add a new api to identify if a node is left aside because of network partition and is without a leader.

Once it is detected that a node has been in candidate for a sufficiently long time, then a callback to the state machine will be triggered to handle this partitioned node.",['ozone'],2018-08-04 04:44:09+00:00,2018-08-13 22:09:25+00:00,2018-08-13 22:09:25+00:00,Resolved,13176869,RATIS-290
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Currently the data is read from state machine using the getEntryWithData api. However this api does not let multiple reads to state machine to happen in parallel.,[],2018-08-02 07:55:14+00:00,2018-08-03 20:46:16+00:00,2018-08-03 20:46:16+00:00,Resolved,13176344,RATIS-289
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Minor,"I'm noticing quite a bit of over-complication in the build, mostly around ratis-proto-shaded. From what I can tell in the git history, this is holdover from quite some time ago (when the module itself was introduced).

Some weird things I see:
 * Everything being marked as optional
 * Explicit scope=compile being listed (this is the default)
 * Inheriting all configuration from the netty-all pom (not sure why we'd want this)
 * Recompilation of source files included in ratis-proto-shaded (shade-plugin can do this already)

My only guess is that some of this was to support the {{skipShade}} option. I think I can halve the amount of time for the ratis-proto-shaded model, and still support a workflow that will let folks skip re-compilation if they haven't changed the protobufs",[],2018-08-01 21:33:05+00:00,2018-08-07 21:37:50+00:00,2018-08-08 17:10:14+00:00,Resolved,13176248,RATIS-288
Bug,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Major," 

""URISyntaxException"" warning shown while running ozoneFS command should not throw the stack trace. 

e.g - 
{noformat}
hadoop@faf56555c4dd:~/bin$ ./ozone fs -put /etc/passwd /dir1
2018-07-31 07:43:52 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.rpc.type = GRPC (default)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.grpc.message.size.max = 33554432 (custom)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.client.rpc.retryInterval = 300 ms (default)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.client.async.outstanding-requests.max = 100 (default)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.client.async.scheduler-threads = 3 (default)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.grpc.message.size.max = 33554432 (custom)
2018-07-31 07:43:55 INFO ConfUtils:41 - raft.client.rpc.request.timeout = 3000 ms (default)
Jul 31, 2018 7:43:56 AM org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl detectProxy
WARNING: Failed to construct URI for proxy lookup, proceeding without proxy
java.net.URISyntaxException: Illegal character in hostname at index 13: https://ozone_datanode_3.ozone_default:9858
 at java.net.URI$Parser.fail(URI.java:2848)
 at java.net.URI$Parser.parseHostname(URI.java:3387)
 at java.net.URI$Parser.parseServer(URI.java:3236)
 at java.net.URI$Parser.parseAuthority(URI.java:3155)
 at java.net.URI$Parser.parseHierarchical(URI.java:3097)
 at java.net.URI$Parser.parse(URI.java:3053)
 at java.net.URI.<init>(URI.java:673)
 at org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl.detectProxy(ProxyDetectorImpl.java:128)
 at org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl.proxyFor(ProxyDetectorImpl.java:118)
 at org.apache.ratis.shaded.io.grpc.internal.InternalSubchannel.startNewTransport(InternalSubchannel.java:207)
 at org.apache.ratis.shaded.io.grpc.internal.InternalSubchannel.obtainActiveTransport(InternalSubchannel.java:188)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$SubchannelImpl.requestConnection(ManagedChannelImpl.java:1130)
 at org.apache.ratis.shaded.io.grpc.PickFirstBalancerFactory$PickFirstBalancer.handleResolvedAddressGroups(PickFirstBalancerFactory.java:79)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl$1NamesResolved.run(ManagedChannelImpl.java:1032)
 at org.apache.ratis.shaded.io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:73)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$LbHelperImpl.runSerialized(ManagedChannelImpl.java:1000)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl.onAddresses(ManagedChannelImpl.java:1044)
 at org.apache.ratis.shaded.io.grpc.internal.DnsNameResolver$1.run(DnsNameResolver.java:201)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
2018-07-31 07:43:57 INFO ConfUtils:41 - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2018-07-31 07:43:57 INFO ConfUtils:41 - raft.grpc.message.size.max = 33554432 (custom)
2018-07-31 07:43:57 INFO ConfUtils:41 - raft.client.rpc.request.timeout = 3000 ms (default)
Jul 31, 2018 7:43:57 AM org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl detectProxy
WARNING: Failed to construct URI for proxy lookup, proceeding without proxy
java.net.URISyntaxException: Illegal character in hostname at index 13: https://ozone_datanode_2.ozone_default:9858
 at java.net.URI$Parser.fail(URI.java:2848)
 at java.net.URI$Parser.parseHostname(URI.java:3387)
 at java.net.URI$Parser.parseServer(URI.java:3236)
 at java.net.URI$Parser.parseAuthority(URI.java:3155)
 at java.net.URI$Parser.parseHierarchical(URI.java:3097)
 at java.net.URI$Parser.parse(URI.java:3053)
 at java.net.URI.<init>(URI.java:673)
 at org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl.detectProxy(ProxyDetectorImpl.java:128)
 at org.apache.ratis.shaded.io.grpc.internal.ProxyDetectorImpl.proxyFor(ProxyDetectorImpl.java:118)
 at org.apache.ratis.shaded.io.grpc.internal.InternalSubchannel.startNewTransport(InternalSubchannel.java:207)
 at org.apache.ratis.shaded.io.grpc.internal.InternalSubchannel.obtainActiveTransport(InternalSubchannel.java:188)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$SubchannelImpl.requestConnection(ManagedChannelImpl.java:1130)
 at org.apache.ratis.shaded.io.grpc.PickFirstBalancerFactory$PickFirstBalancer.handleResolvedAddressGroups(PickFirstBalancerFactory.java:79)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl$1NamesResolved.run(ManagedChannelImpl.java:1032)
 at org.apache.ratis.shaded.io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:73)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$LbHelperImpl.runSerialized(ManagedChannelImpl.java:1000)
 at org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl.onAddresses(ManagedChannelImpl.java:1044)
 at org.apache.ratis.shaded.io.grpc.internal.DnsNameResolver$1.run(DnsNameResolver.java:201)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
hadoop@faf56555c4dd:~/bin$ echo $?
0
{noformat}
 ",['ozone'],2018-07-31 09:00:01+00:00,2018-09-10 22:10:31+00:00,2018-09-10 22:10:31+00:00,Resolved,13175771,RATIS-287
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,In order to detect slowness of a followere/leader node in a ratis ring. The delay in rpc communication between nodes should be tracked. This jira proposes to add new fields to ServerInformationReply to return this information.,[],2018-07-29 02:30:26+00:00,2018-08-01 02:08:55+00:00,2018-08-01 02:08:55+00:00,Resolved,13175374,RATIS-286
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"With Ozone, in order for the datanodes to handle failure of one of the followers, the statemachine should provide a mechanism to inform the StateMachine Implementation about a failure of nodes. This jira proposes to add a mechanism where the stateMachine implementation can be informed of the status of the ratis ring.",['ozone'],2018-07-27 10:54:25+00:00,2018-08-06 18:43:23+00:00,2018-08-06 18:43:23+00:00,Resolved,13175133,RATIS-285
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"FollowerInfo#toString currently prints the absolute time of last rpc, however while debugging ratis issues it will be useful to have last elapsed time from last rpc.",[],2018-07-27 04:47:57+00:00,2018-07-31 07:41:28+00:00,2018-07-31 07:41:28+00:00,Resolved,13175053,RATIS-284
Improvement,[],elserj,Josh Elser,elserj,Josh Elser,Major,"A big impediment towards using RATIS-271 within HBase is the lack of krb5 authentication.

My understanding that this limitation exists in Ratis due to gRPC's lack of such authentication.

The two obvious paths forward would be adding krb5 authn support to gRPC to pick up in Ratis as-is, or to use a different RPC system that does support it.

Maybe there are other solutions/avenues forward. Suggestions very welcome.",[],2018-07-26 20:12:09+00:00,,2018-07-26 20:12:20+00:00,Open,13174978,RATIS-283
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,Need to create some mechanism that will inject failures into a LogStream to see how the software fares.,[],2018-07-26 19:25:12+00:00,,2018-07-26 19:25:12+00:00,Open,13174963,RATIS-282
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"For requests with state Machine data, leader may loose the state Machine data when the entries are evicted from the cache. This jira proposes to read the entries from the statemachine and reconstruct log entries.",[],2018-07-26 18:50:11+00:00,2018-07-30 20:12:40+00:00,2018-07-30 20:12:40+00:00,Resolved,13174958,RATIS-281
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"LogStreams are kept on local filesystem as they are being written to; however, this is not a good solution for long-term storage.

We should provide the mechanism to invoke API that copies the log stream to a distributed filesystem (e.g. HDFS, S3, WASB), to reclaim the local FS space.",[],2018-07-26 16:27:33+00:00,2019-06-27 19:33:23+00:00,2019-06-27 19:33:33+00:00,Resolved,13174916,RATIS-280
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We need to do basic things like:
 * List all log streams
 * Delete a log stream
 * Truncate a log stream

This may overlap with functionality that actually should live in HBase. Making that distinction is part of the tasks of this issue.

 ",[],2018-07-26 16:25:48+00:00,2018-10-10 04:03:53+00:00,2018-10-11 01:10:41+00:00,Resolved,13174915,RATIS-279
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,We need to have metrics exported to tell us information about a LogStream's performance.,[],2018-07-26 16:22:29+00:00,2019-06-19 21:14:28+00:00,2019-06-19 21:14:28+00:00,Resolved,13174914,RATIS-278
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Create an interface that allows users of the LogService to define how quorums are formed among nodes.

The use case is that HBase will have many RegionServers available to use. We want to allow HBase to control which RegionServers are used to participate in one LogStream.",[],2018-07-26 16:19:50+00:00,,2018-07-26 16:29:03+00:00,Open,13174912,RATIS-277
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"We want the ability to ""subscribe"" to a log stream and automatically get pushed updates when they are appended to the log stream.

The analogy is calling the Unix ""tail"" command on a file.",[],2018-07-26 16:18:21+00:00,,2018-07-26 16:29:04+00:00,Open,13174910,RATIS-276
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Implement the ability to read from a log stream.

We want the ability to read linearly from a point in the log. Sub-linear seek into a given offset in the log.",[],2018-07-26 16:17:37+00:00,2018-10-04 03:10:21+00:00,2018-10-04 03:10:21+00:00,Resolved,13174907,RATIS-275
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,Implement the ability to read/write data to a log stream.,[],2018-07-26 16:16:35+00:00,2018-10-18 18:46:02+00:00,2018-10-18 18:46:02+00:00,Resolved,13174906,RATIS-274
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,Create a log-service maven module and wire up to the parent project.,[],2018-07-26 16:15:54+00:00,2018-09-26 16:06:06+00:00,2018-09-26 16:06:06+00:00,Resolved,13174905,RATIS-273
Sub-task,[],elserj,Josh Elser,elserj,Josh Elser,Major,"With influence from Apache DistributedLog, Kafka, and BookKeeper, design an API that balances the ideal notion of what a distribute log system should look like, but also considers the needs of HBase to replace a WAL.",[],2018-07-26 16:15:28+00:00,2018-09-07 20:26:35+00:00,2018-09-07 22:07:19+00:00,Resolved,13174904,RATIS-272
New Feature,[],elserj,Josh Elser,elserj,Josh Elser,Major,"Umbrella issue for building a distributed log using Ratis:

Doc: [https://docs.google.com/document/d/1Su5py_T5Ytfh9RoTTX2s20KbSJwBHVxbO7ge5ORqbCk/edit#|https://docs.google.com/document/d/1Su5py_T5Ytfh9RoTTX2s20KbSJwBHVxbO7ge5ORqbCk/edit]

Discuss: https://lists.apache.org/thread.html/f80dc3900f6d9f4ee4d9f9e0898cee9a232e3b1ca9a4d9a53fea1d71@%3Cdev.ratis.apache.org%3E",[],2018-07-26 16:13:41+00:00,,2018-10-31 21:42:30+00:00,Open,13174901,RATIS-271
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Retry requests are answered from the retry cache when requests have Replication_ALL semantics. This leads to a case, where the client retries for a response which is stuck in the delayed replies queue. This new retry is now answered from the retry cache even though the request has not been completed on all the nodes.",['ozone'],2018-07-26 03:11:40+00:00,2018-08-11 12:25:58+00:00,2018-08-11 12:25:59+00:00,Resolved,13174722,RATIS-270
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"With Ozone, in order to monitor the status of the pipeline, the server Information request api should return info about the current node role, and the storage directory status.",[],2018-07-22 15:55:41+00:00,2018-07-25 20:18:32+00:00,2018-07-25 20:18:32+00:00,Resolved,13173673,RATIS-269
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently when a leader shuts down all the pendingRequests in its LeaderState are rejected with NotLeaderException. This should not happen for requests which have already been committed to the log. These requests will be applied to the state machine and along with that the same request would be retried by the client because of NotLeaderException. The same request would be applied to the state machine twice which can lead to an inconsistent state.

This scenario would also occur in case the leader crashes. In such a scenario the leader will not send NotLeaderException but the client request would timeout leading to the same results.",[],2018-07-09 05:55:57+00:00,2018-07-09 09:03:31+00:00,2018-07-09 09:03:31+00:00,Resolved,13170776,RATIS-268
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis supports methods like re-initialize and addPeers to change the state of the Ratis Ring.

This jira proposes to add a new variable to uniquely identify a ratis ring. 
This id (UUID) should be changed everytime the state of ratis ring changes.",[],2018-07-08 06:46:03+00:00,2018-11-30 23:22:29+00:00,2018-11-30 23:22:29+00:00,Resolved,13170676,RATIS-267
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Minor,This jira proposes to log exceptions thrown during applyTransaction & writeStateMachineData,[],2018-07-06 18:20:01+00:00,2018-07-09 09:31:47+00:00,2018-07-20 09:15:14+00:00,Resolved,13170545,RATIS-266
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Blocker,"In scenario where there is lots of load on the Ratis leader, the leader accepts and adds all the requests as pending appends into the sliding window.

However if there are lots of pending replies in the sliding window, the leader should reply with an error/exception to the client to retry the command later.",['ozone'],2018-07-06 13:56:26+00:00,2019-07-14 15:54:50+00:00,2019-07-14 15:54:50+00:00,Resolved,13170494,RATIS-265
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"For Ozone, the chunk sizes are of size 16MB each, these chunk data is stored in the retry cache.

This jira proposes to add an api to set the capacity of the retry cache.",[],2018-07-06 13:38:24+00:00,2018-08-27 09:33:34+00:00,2018-08-27 17:29:59+00:00,Resolved,13170489,RATIS-264
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Critical,"There is a deadlock in Ratis between appendEntries and segmented raft log eviction.

{code}
""grpc-default-executor-6"":
        at org.apache.ratis.server.impl.LogAppender.notifyAppend(LogAppender.java:466)
        - waiting to lock <0x0000000083a1d398> (a org.apache.ratis.grpc.server.GRpcLogAppender)
        at org.apache.ratis.server.impl.LeaderState$$Lambda$222/1001509199.accept(Unknown Source)
        at java.util.concurrent.CopyOnWriteArrayList.forEach(CopyOnWriteArrayList.java:890)
        at org.apache.ratis.server.impl.LeaderState$SenderList.forEach(LeaderState.java:93)
        at org.apache.ratis.server.impl.LeaderState.notifySenders(LeaderState.java:192)
        at org.apache.ratis.server.impl.RaftServerImpl.appendTransaction(RaftServerImpl.java:476)
        - locked <0x000000008084fac8> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:524)
        at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:153)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.processClientRequestAsync(RaftClientProtocolService.java:125)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver$$Lambda$148/1250401784.accept(Unknown Source)
        at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:351)
        at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:343)
        - locked <0x00000000c0f7a060> (a org.apache.ratis.util.SlidingWindow$Server)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:145)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:109)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:252)
        at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:629)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}

Thread evicting Segmented Raft Log
{code}
""Thread-72"":
        at org.apache.ratis.server.impl.RaftServerImpl.getFollowerNextIndices(RaftServerImpl.java:1032)
        - waiting to lock <0x000000008084fac8> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.storage.SegmentedRaftLog.checkAndEvictCache(SegmentedRaftLog.java:199)
        at org.apache.ratis.server.storage.SegmentedRaftLog.get(SegmentedRaftLog.java:190)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:178)
        at org.apache.ratis.grpc.server.GRpcLogAppender.appendLog(GRpcLogAppender.java:153)
        - locked <0x0000000083a1d398> (a org.apache.ratis.grpc.server.GRpcLogAppender)
        at org.apache.ratis.grpc.server.GRpcLogAppender.run(GRpcLogAppender.java:93)
{code}",[],2018-07-06 07:03:15+00:00,2018-07-20 20:44:09+00:00,2018-08-13 09:30:14+00:00,Resolved,13170421,RATIS-263
Bug,[],elek,Marton Elek,elek,Marton Elek,Minor,"During the 0.2.0-rc2 vote [~khmarbaise] wrote the following comment:
{quote}

so far so good and got several messages about deprecated calls and things like this: 
 
INFO] --- maven-compiler-plugin:3.7.0:compile (default-compile) @ ratis-server --- 
[INFO] Compiling 55 source files to /Users/kama/Downloads/ratis-incubating-0.2.0/ratis-server/target/classes 
[WARNING] /Users/kama/Downloads/ratis-incubating-0.2.0/ratis-server/src/main/java/org/apache/ratis/server/storage/MemoryRaftLog.java:[48,26] [try] auto-closeable resource readLock is never referenced in body of corresponding try statement 
[WARNING] /Users/kama/Downloads/ratis-incubating-0.2.0/ratis-server/src/main/java/org/apache/ratis/server/storage/MemoryRaftLog.java:[57,26] [try] auto-closeable resource readLock is never referenced in body of corresponding try statement 
[WARNING] /Users/kama/Downloads/ratis-incubating-0.2.0/ratis-server/src/main/java/org/apache/ratis/server/storage/MemoryRaftLog.java:[67,26] [try] auto-closeable resource readLock is never referenced in body of corresponding try statement 
[WARNING] /Users/kama/Downloads/ratis-incubating-0.2.0/ratis-server/src/main/java/org/apache/ratis/server/storage/MemoryRaftLog.java:[85,26] [try] auto-closeable resource writeLock is never referenced in body of corresponding try statement 
 
which are not really a problem...can be fixed in the next release... 

{quote}

Would be great to fix them long-term.",[],2018-07-05 11:02:18+00:00,2018-11-01 23:10:59+00:00,2018-11-01 23:10:59+00:00,Resolved,13170242,RATIS-262
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"When GC gets triggered on a Ratis server, the node can go unresponsive for sometime.
When this node happens to be a follower node, the node after waking up from GC
will realize that the leader hasn't sent heartbeats to it and hence will trigger a leader election.

This jira proposes to add a mechanism inside a follower to check for its own liveliness before triggering a leader election.",['ozone'],2018-07-05 10:20:51+00:00,2019-07-14 15:55:11+00:00,2019-07-14 15:55:11+00:00,Resolved,13170231,RATIS-261
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This bug was simulated using Ozone using Ratis for Data pipeline.
In this test, one of the nodes was shut down permanently. This can result into a situation where a candidate node is never able to move out of Leader Election phase.

{code}
2018-06-15 07:44:58,246 INFO org.apache.ratis.server.impl.LeaderElection: 0f7b9cd2-4dad-46d7-acbc-57d424492d00_9858 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.shaded.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:192)
        at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:214)
        at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:146)
        at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:102)
Caused by: org.apache.ratis.shaded.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
        at org.apache.ratis.shaded.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:221)
        at org.apache.ratis.shaded.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:202)
        at org.apache.ratis.shaded.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:131)
        at org.apache.ratis.shaded.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:281)
        at org.apache.ratis.grpc.server.RaftServerProtocolClient.requestVote(RaftServerProtocolClient.java:61)
        at org.apache.ratis.grpc.RaftGRpcService.requestVote(RaftGRpcService.java:147)
        at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$0(LeaderElection.java:188)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.ratis.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: y128.l42scl.hortonworks.com/172.26.32.228:9858
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        at org.apache.ratis.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)
        at org.apache.ratis.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
        at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)
        at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
        at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
        at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
        at org.apache.ratis.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
        at org.apache.ratis.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        ... 1 more
Caused by: java.net.ConnectException: Connection refused
        ... 11 more
{code}

This happens because of the following lines of the code during requestVote.

{code}
    for (final RaftPeer peer : others) {
      final RequestVoteRequestProto r = server.createRequestVoteRequest(
          peer.getId(), electionTerm, lastEntry);
      service.submit(
          () -> server.getServerRpc().requestVote(r));
      submitted++;
    }
{code}

",['ozone'],2018-07-03 11:14:57+00:00,2018-08-13 09:30:14+00:00,2018-08-13 09:30:14+00:00,Resolved,13169772,RATIS-260
Improvement,[],nilotpalnandi,Nilotpal Nandi,nilotpalnandi,Nilotpal Nandi,Major,"In ozone, the pipeline type is Ratis with replication factor as 1.

Ran the following command ozone command , it hung and did not complete

--------------------------------------------------------------------------------------------------------
{noformat}
[root@ozone-vm bin]# ./ozone oz -getKey /nnvolume1/buckettest1/passwd ./hello1
Command Failed : {""httpCode"":0,""shortMessage"":""get key needs a file path to download to"",""resource"":null,""message"":""get key needs a file path to download to"",""requestID"":null,""hostName"":null}
[root@ozone-vm bin]# ./ozone oz -getKey /nnvolume1/buckettest1/passwd -file .
2018-06-29 05:09:46,865 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Command Failed : {""httpCode"":0,""shortMessage"":"".exists. Download will overwrite an existing file. Aborting."",""resource"":null,""message"":"".exists. Download will overwrite an existing file. Aborting."",""requestID"":null,""hostName"":null}
[root@ozone-vm bin]# ./ozone oz -getKey /nnvolume1/buckettest1/passwd -file ./hello11
2018-06-29 05:10:27,661 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-29 05:10:28,373 INFO conf.ConfUtils: raft.rpc.type = GRPC (default)
2018-06-29 05:10:28,406 INFO conf.ConfUtils: raft.grpc.message.size.max = 33554432 (custom)
2018-06-29 05:10:28,424 INFO conf.ConfUtils: raft.client.rpc.retryInterval = 300 ms (default)
2018-06-29 05:10:28,428 INFO conf.ConfUtils: raft.client.async.outstanding-requests.max = 100 (default)
2018-06-29 05:10:28,428 INFO conf.ConfUtils: raft.client.async.scheduler-threads = 3 (default)
2018-06-29 05:10:28,595 INFO conf.ConfUtils: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2018-06-29 05:10:28,595 INFO conf.ConfUtils: raft.grpc.message.size.max = 33554432 (custom)
2018-06-29 05:10:28,884 INFO conf.ConfUtils: raft.client.rpc.request.timeout = 3000 ms (default){noformat}
 

jstack :

------------

 
{noformat}
[root@ozone-vm logs]# jstack 4983
2018-06-29 05:31:00
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode):
""Attach Listener"" #19 daemon prio=9 os_prio=0 tid=0x00007fe9fc016000 nid=0x1804 waiting on condition [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE
""threadDeathWatcher-3-1"" #17 daemon prio=1 os_prio=0 tid=0x00007fea191e5800 nid=0x13af waiting on condition [0x00007fea02905000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)
 at java.lang.Thread.sleep(Native Method)
 at org.apache.ratis.shaded.io.netty.util.ThreadDeathWatcher$Watcher.run(ThreadDeathWatcher.java:152)
 at org.apache.ratis.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
 at java.lang.Thread.run(Thread.java:748)
""grpc-default-worker-ELG-1-2"" #16 daemon prio=5 os_prio=0 tid=0x00007fea191d4000 nid=0x13ac runnable [0x00007fea085fc000]
 java.lang.Thread.State: RUNNABLE
 at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
 at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
 at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
 at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
 - locked <0x00000000e0c372f0> (a org.apache.ratis.shaded.io.netty.channel.nio.SelectedSelectionKeySet)
 - locked <0x00000000e0c419c8> (a java.util.Collections$UnmodifiableSet)
 - locked <0x00000000e0c372a8> (a sun.nio.ch.EPollSelectorImpl)
 at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
 at org.apache.ratis.shaded.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
 at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753)
 at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409)
 at org.apache.ratis.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
 at org.apache.ratis.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
 at java.lang.Thread.run(Thread.java:748)
""grpc-default-executor-0"" #15 daemon prio=5 os_prio=0 tid=0x00007fea191d0800 nid=0x13ab waiting on condition [0x00007fea086fd000]
 java.lang.Thread.State: TIMED_WAITING (parking)
 at sun.misc.Unsafe.park(Native Method)
 - parking to wait for <0x00000000e0c55a00> (a java.util.concurrent.SynchronousQueue$TransferStack)
 at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
 at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
 at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
 at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
 at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
""grpc-default-worker-ELG-1-1"" #14 daemon prio=5 os_prio=0 tid=0x00007fea191cd800 nid=0x13aa runnable [0x00007fea087fe000]
 java.lang.Thread.State: RUNNABLE
 at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
 at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
 at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
 at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
 - locked <0x00000000e0c36d88> (a org.apache.ratis.shaded.io.netty.channel.nio.SelectedSelectionKeySet)
 - locked <0x00000000e0c3e868> (a java.util.Collections$UnmodifiableSet)
 - locked <0x00000000e0c36d40> (a sun.nio.ch.EPollSelectorImpl)
 at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
 at org.apache.ratis.shaded.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
 at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753)
 at org.apache.ratis.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409)
 at org.apache.ratis.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
 at org.apache.ratis.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
 at java.lang.Thread.run(Thread.java:748)
""Service Thread"" #7 daemon prio=9 os_prio=0 tid=0x00007fea180bd000 nid=0x139f runnable [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE
""C1 CompilerThread1"" #6 daemon prio=9 os_prio=0 tid=0x00007fea180b8800 nid=0x139e waiting on condition [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE
""C2 CompilerThread0"" #5 daemon prio=9 os_prio=0 tid=0x00007fea180b6000 nid=0x139d waiting on condition [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE
""Signal Dispatcher"" #4 daemon prio=9 os_prio=0 tid=0x00007fea180b4800 nid=0x139c runnable [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE
""Finalizer"" #3 daemon prio=8 os_prio=0 tid=0x00007fea18081000 nid=0x139b in Object.wait() [0x00007fea1dacf000]
 java.lang.Thread.State: WAITING (on object monitor)
 at java.lang.Object.wait(Native Method)
 - waiting on <0x00000000e075b328> (a java.lang.ref.ReferenceQueue$Lock)
 at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
 - locked <0x00000000e075b328> (a java.lang.ref.ReferenceQueue$Lock)
 at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
 at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:212)
""Reference Handler"" #2 daemon prio=10 os_prio=0 tid=0x00007fea1807c800 nid=0x139a in Object.wait() [0x00007fea1dbd0000]
 java.lang.Thread.State: WAITING (on object monitor)
 at java.lang.Object.wait(Native Method)
 - waiting on <0x00000000e075b4e0> (a java.lang.ref.Reference$Lock)
 at java.lang.Object.wait(Object.java:502)
 at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
 - locked <0x00000000e075b4e0> (a java.lang.ref.Reference$Lock)
 at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
""main"" #1 prio=5 os_prio=0 tid=0x00007fea18010000 nid=0x1398 waiting on condition [0x00007fea216e3000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)
 at java.lang.Thread.sleep(Native Method)
 at java.lang.Thread.sleep(Thread.java:340)
 at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
 at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:127)
 at org.apache.ratis.client.impl.RaftClientImpl.sendRequestWithRetry(RaftClientImpl.java:263)
 at org.apache.ratis.client.impl.RaftClientImpl.send(RaftClientImpl.java:192)
 at org.apache.ratis.client.impl.RaftClientImpl.sendReadOnly(RaftClientImpl.java:178)
 at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequest(XceiverClientRatis.java:217)
 at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommand(XceiverClientRatis.java:235)
 at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getKey(ContainerProtocolCalls.java:94)
 at org.apache.hadoop.ozone.client.io.ChunkGroupInputStream.getFromKsmKeyInfo(ChunkGroupInputStream.java:287)
 at org.apache.hadoop.ozone.client.rpc.RpcClient.getKey(RpcClient.java:495)
 at org.apache.hadoop.ozone.client.OzoneBucket.readKey(OzoneBucket.java:255)
 at org.apache.hadoop.ozone.web.ozShell.keys.GetKeyHandler.execute(GetKeyHandler.java:110)
 at org.apache.hadoop.ozone.web.ozShell.Shell.dispatch(Shell.java:395)
 at org.apache.hadoop.ozone.web.ozShell.Shell.run(Shell.java:135)
 at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
 at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
 at org.apache.hadoop.ozone.web.ozShell.Shell.main(Shell.java:114)
""VM Thread"" os_prio=0 tid=0x00007fea18074800 nid=0x1399 runnable
""VM Periodic Task Thread"" os_prio=0 tid=0x00007fea180c3000 nid=0x13a0 waiting on condition
JNI global references: 379
{noformat}
 

datanode log :

---------------------

 
{noformat}
2018-06-29 05:17:46,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9820. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-06-29 05:17:47,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9820
2018-06-29 05:17:53,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9820. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-06-29 05:17:53,563 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
 at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:213)
 at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:224)
 at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:175)
 at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:3109)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
 at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
 at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
 at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
 at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
 at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
 at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
 at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
 at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
 at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
 at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
 at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
 at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
2018-06-29 05:17:53,563 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
 
 
{noformat}
 ",['ozone'],2018-06-29 09:43:50+00:00,2018-08-31 14:28:13+00:00,2018-11-30 23:19:17+00:00,Resolved,13169124,RATIS-259
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"According to the [ASF incubator policy|https://incubator.apache.org/policy/incubation.html]:

{quote}the release archive MUST contain the word ""incubating"" in the filename{quote}

The current ratis assembly configuration use ""incubator"" instead of ""incubating"".
",[],2018-06-28 01:51:49+00:00,2018-06-28 02:04:15+00:00,2018-06-28 02:04:15+00:00,Resolved,13168750,RATIS-258
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"As we have no detailed documentation (I think) it would be extremly useful to add presentation links to the ratis web site.

[~msingh], [~szetszwo]: I think you have slides. Can you please upload it to somewhere to make it linkable?",[],2018-06-22 18:47:13+00:00,2018-11-05 12:37:39+00:00,2018-11-05 12:37:39+00:00,Resolved,13167719,RATIS-257
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,This jira proposes to add a cli script to start FileStoreExample.,[],2018-06-15 10:54:25+00:00,2018-11-15 21:49:43+00:00,2018-11-15 21:49:43+00:00,Resolved,13166319,RATIS-256
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In [~msingh]'s performance tests, we found that rolling log segment took a long time.  In this JIRA, we propose changing the FinalizeLogSegment task to async in order to improve the performance.",['ozone'],2018-06-14 10:23:07+00:00,,2018-09-27 23:22:45+00:00,Open,13166063,RATIS-255
Improvement,[],k8i6t2009,Kit Hui,k8i6t2009,Kit Hui,Minor,"We found that there was a javac error below if we ran {{mvn test}} after shade.
{code}
[*ERROR*] *An exception has occurred in the compiler (1.8.0_171). Please file a bug against the Java compiler via the Java bug reporting page (http://bugreport.java.com) after checking the Bug Database (http://bugs.java.com) for duplicates. Include your program and the following diagnostic in your report. Thank you.*

[*ERROR*] *java.lang.IllegalStateException: endPosTable already set*
{code}
It needs to run
{code}
mvn clean -DskipCleanShade
{code}
We should document it.",[],2018-06-13 06:25:25+00:00,2018-06-13 09:50:12+00:00,2018-06-13 09:50:12+00:00,Resolved,13165743,RATIS-254
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"With statemachine implementation which abstract out the state machine data from the append entries, frequent log rollovers can be observed.

Looking into the code, this seems to be because of 2 reasons.

a) LogSegment#append, updates the total size. However the size which needs to be considered should not include the statemachine data.

b) Also SegmentRaftLog#isSegmentFull also considers the total proto object. Here too, only the entry to be written to the log should be considered.",['ozone'],2018-06-12 08:01:57+00:00,2018-09-11 19:05:08+00:00,2018-10-17 07:08:40+00:00,Resolved,13165509,RATIS-253
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In some applications, the state machine may update external database/systems while applying a transaction.  When there are multiple servers in a raft group, all servers will submit the same update to the external systems.  It unnecessarily overloads the external system.  Ideally, only the leader should send the update and the followers should not.

In this JIRA, we provide an API so that the state machine can query its server role in order to determine if it should send the update.",[],2018-06-05 01:39:12+00:00,2018-07-18 20:59:25+00:00,2018-07-18 20:59:25+00:00,Resolved,13164030,RATIS-252
Improvement,[],ashar103,Ambud Sharma,ashar103,Ambud Sharma,Trivial,"Hoping to add documentation via a markdown file so that folks interested with the project can quickly start with the project from the source code itself.

 

 ",[],2018-05-30 20:16:29+00:00,,2019-01-02 16:24:40+00:00,Open,13162992,RATIS-251
Bug,[],elek,Marton Elek,elek,Marton Elek,Minor,"From [https://www.apache.org/dev/apply-license.html#license-file-name]

 
{quote}Can the LICENSE and NOTICE files be called LICENSE.txt and NOTICE.txt?[¶|https://www.apache.org/dev/apply-license.html#license-file-name]

This is permitted. However the preference is that the files be called LICENSE and NOTICE
{quote}",['newbie'],2018-05-26 20:41:36+00:00,2018-06-07 14:38:44+00:00,2018-06-07 14:38:44+00:00,Resolved,13162258,RATIS-250
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"Thanks to [~jmclean] who reported this problem during the 0.2.0 rc1 vote.

From the mail:

{quote}It likely that your convenience binary will need a different LICENSE and NOTICE{quote}

From the [licensing howto|https://www.apache.org/dev/licensing-howto.html#binary]:

{quote}As a result, the LICENSE and NOTICE files for a binary distribution may well differ from those in the source distribution it was built from.

In any case, the principle remains the same: LICENSE and NOTICE must exactly represent the contents of the distribution they reside in.
{quote}",[],2018-05-26 20:28:59+00:00,2018-06-28 01:11:47+00:00,2018-06-28 01:11:47+00:00,Resolved,13162257,RATIS-249
Bug,[],elek,Marton Elek,elek,Marton Elek,Blocker,"Thanks to [~jmclean], how reported this issue during the ratis 0.2.0 rc1 vote.


{quote}- LICENSE is missing a BSD license

LICENSE is missing BSD license for these files [2][3][4]. Note that a condition of the BSD license is to include it’s text, the text is missing form the headers and not included in LICENSE.

2. /ratis-incubator-0.2.0/ratis-common/src/main/java/org/apache/ratis/util/PureJavaCrc32C.java
3. /ratis-incubator-0.2.0/ratis-common/src/main/native/src/org/apache/ratis/util/bulk_crc32.c
4. /ratis-incubator-0.2.0/ratis-common/src/main/native/src/org/apache/ratis/util/bulk_crc32_x86.c

From what I can see for the source release LICENSE should be boiler place and include the BSD license mentioned above and nothing else, NOTICE should be boilerplate and a few lines long{quote}",[],2018-05-26 20:22:31+00:00,2018-06-20 23:33:57+00:00,2018-06-20 23:33:57+00:00,Resolved,13162256,RATIS-248
Test,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,Some unit tests fail with timeout occasionally.  It would be great if it dumps all threads when test timeout.,[],2018-05-24 23:03:15+00:00,2018-06-06 22:39:40+00:00,2018-06-06 22:39:41+00:00,Resolved,13161918,RATIS-247
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,HDDS-115 discusses making GRPC endpoint secure with mTLS. This jira will track the work needed in Ratis to make grpc communication secure.,['ozone'],2018-05-23 17:33:40+00:00,2018-12-15 07:12:56+00:00,2019-03-22 05:27:47+00:00,Resolved,13161531,RATIS-246
Task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"Currently TestVolume, TestBucket and TestKeys only includes tests for Rpc client. This Jira aims to add test for RestClient as well.",[],2018-05-23 10:36:22+00:00,2018-05-23 10:40:03+00:00,2018-05-23 10:40:03+00:00,Resolved,13161375,RATIS-245
Bug,[],andywu,Andy Wu,andywu,Andy Wu,Minor,"When we take snapshots, a copy of snapshot file and its MD5 file are persisted on disk. But they are not atomic operation. In some condition, we might have a partial snapshot file persisted on disk. While we need to SimpleStateMachineStorage#findLatestSnapshot(), we should skip the snapshot files without MD5.",[],2018-05-23 05:46:07+00:00,,2018-12-17 21:37:31+00:00,Open,13161301,RATIS-244
Improvement,[],andywu,Andy Wu,andywu,Andy Wu,Major,"After snapshotting the state machine, we can safely purge logs in the cache and disk.

Based on the lastAppliedIndex, we can find out which segment the index lands, we can purge all previous segments if leader has no pending RPC on it. We will leave the segment where index lands alone, so we do not need to deal with partial file deletion logic. 

Also if we only have snapshots, make sure we can install snapshots to the followers. 

 ",[],2018-05-23 05:03:18+00:00,2019-04-23 05:56:44+00:00,2019-05-16 08:51:25+00:00,Resolved,13161296,RATIS-243
Bug,[],andywu,Andy Wu,andywu,Andy Wu,Major,"How to produce:
 1. Assume we have three servers: s0, s1 and s2. We start s0 and s2, and let us randomly pick up a leader, say s0. Assume after leader election, s0 and s2 are in term k.
 2. Let us start server s1, assume s1 did not received a heartbeat for a while, and it becomes candidate. It proposes a leader election at term 1 since it has not received any heartbeat yet.
 3. Assume s0 or s2 received the vote request, and RaftServerImpl#requestVote will withholdVotes, so server s0 or s2 will reject the vote request from s1.
 4. In LeaderElection#waitForResults, s1 will be rejected with a new term. It will change its state as follower with a new term k. Somehow server s1 does not receive any heartbeat update from leader s0, and it will keep retrying leader election again and again.",[],2018-05-18 23:23:29+00:00,2018-07-18 21:25:35+00:00,2018-07-18 21:25:35+00:00,Resolved,13160462,RATIS-242
Improvement,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Minor,"The link `checksum` links to https://dist.apache.org/repos/dist/release/incubator/ratis/0.1.0-alpha/apache-ratis-incubating-0.1.0-alpha-src.tar.gz.asc which is the GPG signature file
and the link `signature` links to https://dist.apache.org/repos/dist/release/incubator/ratis/0.1.0-alpha/apache-ratis-incubating-0.1.0-alpha-src.tar.gz.mds which contains the checksums ...

",[],2018-05-17 15:29:59+00:00,2018-05-18 08:48:07+00:00,2018-05-18 08:48:07+00:00,Resolved,13160053,RATIS-241
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In order to support multi-raft with different state machine, each RaftServerImpl should have its own state machine.

It still allows sharing state machine since different RaftServerImpl objects can (choose to) be initialized with the same state machine.",[],2018-05-15 21:26:45+00:00,2018-06-07 13:25:23+00:00,2018-06-07 13:25:23+00:00,Resolved,13159539,RATIS-240
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-231, LogAppender in Leader should reconnect to the followers for some IOException such as SocketException, ClosedChannelException, etc.",[],2018-05-14 23:51:21+00:00,2018-05-31 15:04:49+00:00,2018-07-18 21:25:35+00:00,Resolved,13159242,RATIS-239
Bug,[],elek,Marton Elek,elek,Marton Elek,Minor,"The NOTICE.txt still contains 2017 in the copyright header. 

(Thanks the to [~jghoman] for the reporting during the rc0 vote)",[],2018-05-11 21:02:30+00:00,2018-05-14 20:48:33+00:00,2018-05-14 20:48:33+00:00,Resolved,13158806,RATIS-238
Bug,[],nanda,Nanda kumar,nanda,Nanda kumar,Major,"Two different definitions of {{io.opencensus.trace.unsafe.ContextUtils}} is resolved and added to the runtime classpath of Ratis. The reason for having two different definition of {{ContextUtils}} in classpath is due to the fact that we are shading/relocating io.grpc and not {{io.opencensus}}.

With shading, we are generating the below definition which ends up in ratis-proto-shaded jar
{code}
package io.opencensus.trace.unsafe;

import org.apache.ratis.shaded.io.grpc.Context;
import io.opencensus.trace.Span;

/**
* Util methods/functionality to interact with the {@link org.apache.ratis.shaded.io.grpc.Context}.
*
* <p>Users must interact with the current Context via the public APIs in {@link
* io.opencensus.trace.Tracer} and avoid usages of the {@link #CONTEXT_SPAN_KEY} directly.
*
* @since 0.5
*/
public final class ContextUtils {
  // No instance of this class.
  private ContextUtils() {}

  /**
   * The {@link org.apache.ratis.shaded.io.grpc.Context.Key} used to interact with {@link org.apache.ratis.shaded.io.grpc.Context}.
   *
   * @since 0.5
   */
  public static final Context.Key<Span> CONTEXT_SPAN_KEY = Context.key(""opencensus-trace-span-key"");
}
{code}
Since we have added {{io.opencensus}} as direct dependency in ratis-grpc we get the below definition in {{io.opencensus:opencensus-api:jar}}
{code}
package io.opencensus.trace.unsafe;

import io.grpc.Context;
import io.opencensus.trace.Span;

/**
* Util methods/functionality to interact with the {@link io.grpc.Context}.
*
* <p>Users must interact with the current Context via the public APIs in {@link
* io.opencensus.trace.Tracer} and avoid usages of the {@link #CONTEXT_SPAN_KEY} directly.
*
* @since 0.5
*/
public final class ContextUtils {
  // No instance of this class.
  private ContextUtils() {}

  /**
   * The {@link io.grpc.Context.Key} used to interact with {@link io.grpc.Context}.
   *
   * @since 0.5
   */
  public static final Context.Key<Span> CONTEXT_SPAN_KEY = Context.key(""opencensus-trace-span-key"");
}
{code}
Both of the jars end up in classpath and {{ContextUtils}} is getting loaded from {{io.opencensus:opencensus-api:jar}} which is causing problem.
",[],2018-05-07 19:09:39+00:00,2018-05-11 20:45:35+00:00,2018-05-11 21:54:06+00:00,Resolved,13157678,RATIS-237
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,TimeoutScheduler is thread safe and have auto-shutdown when there are no tasks.  Let's also use it in RaftClientImpl for submitting retry requests.,[],2018-05-03 21:13:46+00:00,2018-05-04 17:56:51+00:00,2018-05-04 17:56:51+00:00,Resolved,13156969,RATIS-236
Test,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In RaftTestUtil.assertLogEntries, it only asserts e.getIndex() > logIndex for non-async cases.  It should also check the async cases.
",[],2018-05-02 00:24:55+00:00,2018-05-02 18:35:22+00:00,2018-05-02 18:35:22+00:00,Resolved,13156477,RATIS-235
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a client request is specified with ALL replication, it is possible that it is committed (i.e. replicated to a majority of servers) but not yet replicated to all servers.  This feature is to let the client to watch it until it is replicated to all server.",['ozone'],2018-04-30 21:06:30+00:00,2018-10-10 08:31:28+00:00,2018-10-22 10:25:26+00:00,Resolved,13156217,RATIS-234
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a leader is stepping down, if there are delayed requests (i.e. the requests with ALL replications), the leader should throw an exception, say NotReplicatedException, to the client.   Then, the client will learn that the request is committed (i.e. replicated to a majority of the servers) but not yet replicated to all servers.",[],2018-04-30 21:02:39+00:00,2018-06-14 09:33:25+00:00,2018-06-14 09:33:25+00:00,Resolved,13156215,RATIS-233
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After the recent shading change in RATIS-168, all Hadoop unit tests fail with NoSuchMethodError.
{code}
java.lang.NoSuchMethodError: com.google.common.base.Objects.toStringHelper(Ljava/lang/Object;)Lcom/google/common/base/Objects$ToStringHelper;
	at org.apache.hadoop.metrics2.lib.MetricsRegistry.toString(MetricsRegistry.java:411)
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:74)
	...
{code}
The current Hadoop version depends on an old (incompatible) Guava version.",[],2018-04-25 01:00:13+00:00,,2018-07-20 21:13:41+00:00,Open,13154995,RATIS-232
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Blocker,"In RATIS-229, we found that the leader with Grpc does not reconnect when a follower restarts.  As a result, it will trigger a leader election.",[],2018-04-24 01:25:21+00:00,2018-04-30 17:52:24+00:00,2018-05-15 02:31:48+00:00,Resolved,13154667,RATIS-231
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In this JIRA, we propose
- Stack trace is missing in some exception logs.
- Change some info message to warn.
- Check isDebugEnabled and isWarnEnabled.",[],2018-04-21 00:12:40+00:00,2018-04-25 17:49:01+00:00,2018-04-25 17:49:01+00:00,Resolved,13154187,RATIS-230
Bug,[],k8i6t2009,Kit Hui,k8i6t2009,Kit Hui,Major,"When appendEntries timeout, GRpcLogAppender has already updated
lastRpcSendTime so that the next heartbeat may not be sent
immediately.

This problem is observed in RATIS-227.  The killed follower in
testBasicAppendEntriesWithAllReplication may start a leader election
after it has been restarted.",[],2018-04-20 03:04:24+00:00,2018-04-30 21:11:41+00:00,2018-04-30 21:11:41+00:00,Resolved,13153902,RATIS-229
Bug,[],k8i6t2009,Kit Hui,k8i6t2009,Kit Hui,Blocker,"When debugging RATIS-227, test may fail with
{code}
2018-04-19 12:39:39,527 ERROR storage.LogInputStream(LogInputStream.java:nextEntry(122)) - caught exception initializing log_inprogress_0
java.io.EOFException: EOF before reading a complete log header
at org.apache.ratis.server.storage.LogReader.readLogHeader(LogReader.java:140)
at org.apache.ratis.server.storage.LogInputStream.init(LogInputStream.java:92)
at org.apache.ratis.server.storage.LogInputStream.nextEntry(LogInputStream.java:120)
at org.apache.ratis.server.storage.LogSegment.readSegmentFile(LogSegment.java:107)
at org.apache.ratis.server.storage.LogSegment.loadSegment(LogSegment.java:129)
...
{code}
It turns out that the log_inprogress_0 file is zero size",[],2018-04-20 01:16:57+00:00,2018-04-24 18:11:50+00:00,2018-04-24 18:11:50+00:00,Resolved,13153890,RATIS-228
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Blocker,"The test fails after a few runs.

 

Running org.apache.ratis.grpc.TestRaftWithGrpc
Tests run: 7, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 38.009 sec <<< FAILURE! - in org.apache.ratis.grpc.TestRaftWithGrpc
testBasicAppendEntriesWithAllReplication(org.apache.ratis.grpc.TestRaftWithGrpc) Time elapsed: 6.347 sec <<< FAILURE!
java.lang.AssertionError: expected:<10> but was:<11>

testBasicAppendEntriesWithAllReplication(org.apache.ratis.grpc.TestRaftWithGrpc) Time elapsed: 6.347 sec <<< FAILURE!
java.lang.AssertionError: Unexpected exited.
Caused by: org.apache.ratis.util.ExitUtils$ExitException: StateMachineUpdater-s3: the StateMachineUpdater hits Throwable
Caused by: java.lang.IllegalStateException: retry cache entry should be pending: client-94C96ACF6473:5013:done


Results :

Failed tests:
org.apache.ratis.grpc.TestRaftWithGrpc.testBasicAppendEntriesWithAllReplication(org.apache.ratis.grpc.TestRaftWithGrpc)
 Run 1: TestRaftWithGrpc>RaftBasicTests.testBasicAppendEntriesWithAllReplication:100->RaftBasicTests.runTestBasicAppendEntries:161->RaftBasicTests.lambda$runTestBasicAppendEntries$3:161 expected:<10> but was:<11>
 Run 2: TestRaftWithGrpc>RaftBasicTests.tearDown:89 Unexpected exited.",[],2018-04-13 02:55:14+00:00,2018-05-01 18:08:31+00:00,2018-05-01 18:11:14+00:00,Resolved,13152160,RATIS-227
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The hadoop-rpc tests are currently unreliable since they are not well maintained.  Let's skip them for the moment.

TestRaftStream also has some known problem (see RATIS-149).  Let's ignore it.",[],2018-04-10 07:12:03+00:00,2018-04-26 19:14:59+00:00,2018-04-26 21:58:19+00:00,Resolved,13151298,RATIS-226
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Grpc LogAppender currently does not update next index in heartbeat reply. In case the previous appendEntry times out the next index may not be updated in the leader for a long time. Therefore we need to update the next index on a heartbeat success.,[],2018-04-09 10:28:49+00:00,2018-04-13 16:35:40+00:00,2018-04-13 16:35:40+00:00,Resolved,13150999,RATIS-225
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Currently, RpcTimeout tracks the number of users.  When the number of users becomes zero, it should shut down the scheduler .

Instead of tracking users, it is better to try the number of tasks.  When the number of tasks becomes zero, it should shut down the scheduler.",[],2018-04-07 13:58:16+00:00,2018-04-11 12:36:05+00:00,2018-04-11 12:36:05+00:00,Resolved,13150770,RATIS-224
New Feature,[],VinayBanakar,Vinay Banakar,VinayBanakar,Vinay Banakar,Major,"A bash script to stop all the java instances (nodes in our case) spawned by ./start-all.sh 

Today we have to explicitly kill these externally, a bash script to stop the running example would come in handy. ",['features'],2018-04-04 18:09:43+00:00,2018-04-21 20:08:10+00:00,2018-04-22 04:48:41+00:00,Resolved,13150103,RATIS-223
Bug,[],VinayBanakar,Vinay Banakar,VinayBanakar,Vinay Banakar,Major,"Today, In Arithmetic-Example 

 ./client.sh get –name “Unassigned variable” 

Exception handle and display for user. ",['easyfix'],2018-04-04 17:58:28+00:00,,2018-07-18 22:48:27+00:00,Patch Available,13150099,RATIS-222
New Feature,[],VinayBanakar,Vinay Banakar,VinayBanakar,Vinay Banakar,Major,"New operations can be supported in Arithmetic-Example to provide a more succinct demo for the future users/developers.

1. Adding ""append"" 

        *Command*: ./client.sh append --name X --value Y
         *Behavior*: This will increment the variable X by Y. 
         *Alternative*: Improve ""assign"" to do variable increments 
                              ./client.sh assign --name X --value X+Y
                              [This throws an Exception today]

2. Adding ""remove/delete"" (let's just say remove for now)

        *Command*: ./client.sh remove --name X 
         *Behavior*: This should remove variable X from the cluster. 
         *Alternative*: None",['features'],2018-04-04 17:53:43+00:00,,2018-09-19 21:41:16+00:00,Open,13150094,RATIS-221
Improvement,[],VinayBanakar,Vinay Banakar,VinayBanakar,Vinay Banakar,Major,"Although the code is well documented, the project's design is nowhere to be found. Each of the listed components can have their own documentation page delineating its purpose and dependencies. Have one master design document which portrays overall system design and interaction between components.

To begin with, let's not be scrupulous about flowcharts and UML diagrams. A simple high level diagram would do. ",['documentation'],2018-04-04 17:32:29+00:00,,2018-07-18 21:42:07+00:00,Open,13150085,RATIS-220
Improvement,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,We need to add configuration for setting timeout duration of requests at client and server side.,[],2018-03-28 08:22:15+00:00,2018-04-13 01:46:51+00:00,2018-04-13 01:46:51+00:00,Resolved,13148511,RATIS-219
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis provides a mechanism where heartbeat is done as part of append entry requests.

However in cases of ozone, the processing as part of append requests might take some time to process.

This jira proposes to add another heartbeat api, this api will be used just for heartbeating and will not carry any append entry request information.",[],2018-03-24 10:26:02+00:00,2018-05-02 03:42:58+00:00,2018-05-02 03:42:58+00:00,Resolved,13147681,RATIS-218
New Feature,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,This jira aims to add timeout for append entry requests sent by GrpcLogAppender.,[],2018-03-22 13:28:53+00:00,2018-04-07 13:52:12+00:00,2018-04-07 15:40:05+00:00,Resolved,13147151,RATIS-217
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This was observed on a 3 node ratis config with ozone, this was simulated using TestFreon unit test.

The problem is append to {{127.0.0.1_63765}} failed because the node ran out of memory.
A new leader is elected which tries to send the append requests to the same follower, but the request is out of order.

{code}
2018-03-21 22:05:01,495 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:handleWriteChunk(207)) - adding  index 185
2018-03-21 22:05:02,054 WARN  impl.LogAppender (GRpcLogAppender.java:onError(226)) - 127.0.0.1_63790 got error when appending entries to 127.0.0.1_63765, exception: {}.
java.io.IOException: org.apache.ratis.shaded.io.grpc.StatusRuntimeException: INTERNAL: Java heap space
        at org.apache.ratis.grpc.RaftGrpcUtil.unwrapException(RaftGrpcUtil.java:65)
        at org.apache.ratis.grpc.RaftGrpcUtil.unwrapThrowable(RaftGrpcUtil.java:48)
        at org.apache.ratis.grpc.server.GRpcLogAppender$AppendLogResponseHandler.onError(GRpcLogAppender.java:227)
        at org.apache.ratis.shaded.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)
        at org.apache.ratis.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)
        at org.apache.ratis.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)
        at org.apache.ratis.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.ratis.shaded.io.grpc.StatusRuntimeException: INTERNAL: Java heap space
        at org.apache.ratis.shaded.io.grpc.Status.asRuntimeException(Status.java:545)
        ... 9 more
2018-03-21 22:05:02,088 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:applyTransaction(263)) - removing index 185
^M 90.00% |███████████████████████████████████████████████████████████████████████████████████████████          |  18/20 Time: 0:01:282018-03-21 22:05:02,622 INFO  impl.FollowerState (FollowerState.java:r
un(72)) - 127.0.0.1_63776 changes to CANDIDATE, lastRpcTime:534, electionTimeout:414ms
2018-03-21 22:05:02,622 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(159)) - 127.0.0.1_63776 changes role from FOLLOWER to CANDIDATE at term 31 for changeToCandidate
2018-03-21 22:05:02,622 INFO  impl.FollowerState (FollowerState.java:run(72)) - 127.0.0.1_63765 changes to CANDIDATE, lastRpcTime:576, electionTimeout:411ms
2018-03-21 22:05:02,623 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(159)) - 127.0.0.1_63765 changes role from FOLLOWER to CANDIDATE at term 31 for changeToCandidate
2018-03-21 22:05:02,623 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63776: change Leader from 127.0.0.1_63790 to null at term 31 for initElection
2018-03-21 22:05:02,628 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63765: change Leader from 127.0.0.1_63790 to null at term 31 for initElection
2018-03-21 22:05:02,634 INFO  impl.LeaderElection (LeaderElection.java:askForVotes(127)) - 127.0.0.1_63765: begin an election in Term 32
2018-03-21 22:05:02,634 INFO  impl.LeaderElection (LeaderElection.java:askForVotes(127)) - 127.0.0.1_63776: begin an election in Term 32
2018-03-21 22:05:02,635 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63790: change Leader from 127.0.0.1_63790 to null at term 32 for updateCurrentTerm
2018-03-21 22:05:02,635 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63790: change Leader from 127.0.0.1_63790 to null at term 32 for updateCurrentTerm
2018-03-21 22:05:02,636 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(159)) - 127.0.0.1_63790 changes role from LEADER to FOLLOWER at term 32 for changeToFollower
2018-03-21 22:05:02,636 INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(147)) - 127.0.0.1_63790 sends responses before shutting down PendingRequestsHandler
2018-03-21 22:05:02,637 INFO  server.RaftServerProtocolService (RaftServerProtocolService.java:onCompleted(104)) - 127.0.0.1_63776: appendEntries completed
2018-03-21 22:05:02,640 INFO  impl.LogAppender (GRpcLogAppender.java:onCompleted(254)) - 127.0.0.1_63790 stops appending log entries to follower 127.0.0.1_63776(next=186, match=185, attendVote=true, lastR
pcSendTime=86068ms, lastRpcResponseTime=86080ms)
2018-03-21 22:05:02,646 INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(46)) - 127.0.0.1_63776: Election PASSED; received 2 response(s) [127.0.0.1_63776<-127.0.0.1_63765#0:FAIL-t32, 127.0.0.1_
63776<-127.0.0.1_63790#0:OK-t32] and 0 exception(s); 127.0.0.1_63776:t32, leader=null, voted=127.0.0.1_63776, raftlog=[(t:31, i:185)], conf=[127.0.0.1_63765:127.0.0.1:63765, 127.0.0.1_63776:127.0.0.1:6377
6, 127.0.0.1_63790:127.0.0.1:63790], old=null
2018-03-21 22:05:02,647 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(159)) - 127.0.0.1_63776 changes role from CANDIDATE to LEADER at term 32 for changeToLeader
2018-03-21 22:05:02,647 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63776: change Leader from null to 127.0.0.1_63776 at term 32 for becomeLeader
2018-03-21 22:05:02,647 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.staging.catchup.gap = 1000 (default)
2018-03-21 22:05:02,647 INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(46)) - 127.0.0.1_63765: Election REJECTED; received 2 response(s) [127.0.0.1_63765<-127.0.0.1_63776#0:FAIL-t32, 127.0.0.1_63765<-127.0.0.1_63790#0:FAIL-t32] and 0 exception(s); 127.0.0.1_63765:t32, leader=null, voted=127.0.0.1_63765, raftlog=[(t:31, i:185)], conf=[127.0.0.1_63765:127.0.0.1:63765, 127.0.0.1_63776:127.0.0.1:63776, 127.0.0.1_63790:127.0.0.1:63790], old=null
2018-03-21 22:05:02,647 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.rpc.sleep.time = 25 ms (default)
2018-03-21 22:05:02,650 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(159)) - 127.0.0.1_63765 changes role from CANDIDATE to FOLLOWER at term 32 for changeToFollower
2018-03-21 22:05:02,650 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.buffer.capacity = 134217728 (custom)
2018-03-21 22:05:02,650 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.batch.enabled = true (custom)
2018-03-21 22:05:02,652 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2018-03-21 22:05:02,653 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2018-03-21 22:05:02,653 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.buffer.capacity = 134217728 (custom)
2018-03-21 22:05:02,653 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.batch.enabled = true (custom)
2018-03-21 22:05:02,653 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2018-03-21 22:05:02,653 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2018-03-21 22:05:02,654 INFO  storage.RaftLogWorker (RaftLogWorker.java:rollLogSegment(256)) - Rolling segment:127.0.0.1_63776-RaftLogWorker index to:186
2018-03-21 22:05:02,673 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63765: change Leader from null to 127.0.0.1_63776 at term 32 for appendEntries
2018-03-21 22:05:02,673 INFO  impl.RaftServerImpl (ServerState.java:setLeader(215)) - 127.0.0.1_63790: change Leader from null to 127.0.0.1_63776 at term 32 for appendEntries
2018-03-21 22:05:02,674 INFO  storage.RaftLogWorker (RaftLogWorker.java:rollLogSegment(256)) - Rolling segment:127.0.0.1_63790-RaftLogWorker index to:186
2018-03-21 22:05:02,674 INFO  storage.RaftLogWorker (RaftLogWorker.java:rollLogSegment(256)) - Rolling segment:127.0.0.1_63765-RaftLogWorker index to:186
2018-03-21 22:05:02,712 INFO  server.RaftServerProtocolService (RaftServerProtocolService.java:onCompleted(104)) - 127.0.0.1_63765: appendEntries completed
2018-03-21 22:05:02,713 INFO  impl.LogAppender (GRpcLogAppender.java:onCompleted(254)) - 127.0.0.1_63790 stops appending log entries to follower 127.0.0.1_63765(next=186, match=184, attendVote=true, lastRpcSendTime=86081ms, lastRpcResponseTime=86157ms)
Mar 21, 2018 10:05:02 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@643d117e] Terminated
2018-03-21 22:05:03,016 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2018-03-21 22:05:03,017 INFO  conf.ConfUtils (ConfUtils.java:logGet(41)) - raft.grpc.message.size.max = 33554432 (custom)
Mar 21, 2018 10:05:03 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl <init>
INFO: [ManagedChannelImpl@4a23944d] Created with target 127.0.0.1:63776
2018-03-21 22:05:03,479 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:applyTransaction(263)) - removing index 185
2018-03-21 22:05:03,562 ERROR storage.RaftLogWorker (ExitUtils.java:terminate(86)) - Terminating with exit status 1: 127.0.0.1_63765-RaftLogWorker failed.
java.lang.IllegalStateException: lastWrittenIndex == 184, entry == term: 32
index: 186
noOp {
}
{code}",[],2018-03-22 08:20:35+00:00,2018-03-24 07:46:06+00:00,2018-03-24 07:46:06+00:00,Resolved,13147076,RATIS-216
New Feature,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,This jira aims to add timeout for grpc async requests.,[],2018-03-21 10:10:56+00:00,2018-03-23 10:24:24+00:00,2018-03-23 10:24:24+00:00,Resolved,13146794,RATIS-215
Task,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,This jira aims to add rpc request timeout for Grpc. ,[],2018-03-15 19:21:32+00:00,2018-03-21 03:39:24+00:00,2018-03-21 03:39:24+00:00,Resolved,13145466,RATIS-214
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"""Informaton"" is spelled incorrectly in ServerInformatonRequest.",[],2018-03-13 21:54:00+00:00,2018-03-22 00:49:11+00:00,2018-03-22 00:49:11+00:00,Resolved,13144865,RATIS-213
Improvement,[],jghoman,Jakob Homan,jghoman,Jakob Homan,Trivial,"{noformat}
  @Test
  public void testStaleReadAsync() throws Exception {
    final int numMesssages = 10;
    final CLUSTER cluster = getFactory().newCluster(NUM_SERVERS, properties);{noformat}
Too many s's in numMesssages.  This is a starter task for [~ganti], who is not showing up in the assignee section.  ",['newbie'],2018-03-09 01:35:05+00:00,,2018-10-16 06:54:34+00:00,Open,13143746,RATIS-212
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"Since RATIS-174 we have a binary assembly which contains the precompiled jar files and he examples.

To release it we need to add all the required copyright notices to the NOTICE file.",[],2018-02-27 22:12:28+00:00,2018-03-29 11:30:52+00:00,2018-04-05 14:52:37+00:00,Resolved,13141357,RATIS-211
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-208, we plan to add a parameter for client specifying the number of required servers in a write request.  In the current code, it is hard (or ugly) to add such parameter.

In this JIRA, we propose to replace enum Type in RaftClientRequestProto by 
{code}
  oneof Type {
    WriteRequestProto write = 3;
    ReadRequestProto read = 4;
    StaleReadRequestProto staleRead = 5;
  }
{code}
so that each proto can carry the request specific parameters.",[],2018-02-23 16:03:09+00:00,2018-03-16 16:16:29+00:00,2018-03-16 16:16:58+00:00,Resolved,13140530,RATIS-210
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This issue is happening on ozone for write chunk request.

1) currently write chunk request is processed in two phases, in the first phase the user data is written to the follower as part of {{writeStateMachineData}} and then the entry is committed to the follower as part of {{commit}}.

2) The issue which is hit right now is the case where a) {{writeStateMachineData}} didn't happen for a particular chunk however b) the commit entry is still processed. this leads to a case where a corresponding stateMachineFuture is not present in the hashmap.

{code}
2018-02-12 00:26:30,097 INFO org.apache.ratis.server.impl.FollowerState: 172.26.32.228_9858 changes to CANDIDATE, lastRpcTime:1773, electionTimeout:873ms
2018-02-12 00:26:30,098 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858 changes role from FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2018-02-12 00:26:30,100 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858: change Leader from 172.26.32.232_9858 to null at term 3 for initElection
2018-02-12 00:26:32,869 INFO org.apache.ratis.server.impl.LeaderElection: 172.26.32.228_9858: begin an election in Term 4
2018-02-12 00:26:32,901 INFO org.apache.ratis.grpc.server.RaftServerProtocolService: 172.26.32.228_9858: appendEntries completed
2018-02-12 00:26:33,217 INFO org.apache.ratis.server.impl.LeaderElection: 172.26.32.228_9858: Election REJECTED; received 2 response(s) [172.26.32.228_9858<-172.26.32.230_9858#0:FAIL-t4, 172.26.32.228_9858<-172.26.32.232_9858#0:FAIL-t4] and 0 exception(s); 172.26.32.228_9858:t4, leader=null, voted=172.26.32.228_9858, raftlog=[(t:3, i:10711)], conf=[172.26.32.228_9858:172.26.32.228:9858, 172.26.32.230_9858:172.26.32.230:9858, 172.26.32.232_9858:172.26.32.232:9858], old=null
2018-02-12 00:26:33,217 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858 changes role from CANDIDATE to FOLLOWER at term 4 for changeToFollower
2018-02-12 00:26:39,518 INFO org.apache.ratis.server.impl.FollowerState: 172.26.32.228_9858 changes to CANDIDATE, lastRpcTime:5624, electionTimeout:975ms
2018-02-12 00:26:39,518 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858 changes role from FOLLOWER to CANDIDATE at term 5 for changeToCandidate
2018-02-12 00:26:39,518 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858 changes role from CANDIDATE to FOLLOWER at term 5 for changeToFollower
2018-02-12 00:26:39,520 INFO org.apache.ratis.server.impl.RaftServerImpl: 172.26.32.228_9858: change Leader from null to 172.26.32.232_9858 at term 5 for appendEntries
{code}


{code}
2018-02-12 00:31:12,400 ERROR org.apache.ratis.server.impl.StateMachineUpdater: Terminating with exit status 2: StateMachineUpdater-172.26.32.228_9858: the StateMachineUpdater hits Throwable
java.lang.NullPointerException
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.applyTransaction(ContainerStateMachine.java:254)
        at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:1001)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:151)
        at java.lang.Thread.run(Thread.java:745)
2018-02-12 00:31:12,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at y128.l42scl.hortonworks.com/172.26.32.228
************************************************************/


*** shutting down gRPC server since JVM is shutting down
*** server shut down
***
{code}",[],2018-02-13 09:38:35+00:00,2018-03-27 07:37:01+00:00,2018-03-27 07:37:01+00:00,Resolved,13138120,RATIS-209
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In Raft protocol, the leader sends a reply to client once the request is committed and applied to its state machine.  A request is committed when the leader get a majority of responses from all the members in the raft group.

In some applications, the client may want to wait for all member responses instead of a majority.  For example, the application wants to support reading even if there is only one machine remaining in the group.",[],2018-02-07 01:52:41+00:00,2018-04-10 11:13:26+00:00,2018-04-10 14:27:58+00:00,Resolved,13136732,RATIS-208
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This JIRA is to complete the stale read implementation:
- Add stale read methods to RaftClient.
- Add another query method with a minIndex parameter to StateMachine.

Note that the stale read request is served by a particular server but not the Raft service.",[],2018-02-02 01:53:36+00:00,2018-02-18 14:17:01+00:00,2018-02-18 14:17:01+00:00,Resolved,13135665,RATIS-207
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
//StateMachine
CompletableFuture<RaftClientReply> query(RaftClientRequest request);
{code}
Currently, query passes RaftClientRequest as a parameter and returns a future of RaftClientReply.  However, the state machine only needs the Message inside.  It should not use the other metadata in RaftClientRequest and RaftClientReply.

Also, the state machine does not have enough information to create RaftClientReply after we add commit informations later.",[],2018-01-31 22:40:44+00:00,2018-02-05 16:37:56+00:00,2018-02-05 16:37:56+00:00,Resolved,13135245,RATIS-206
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The commit infos should be included in RaftClientReply so that client can get commit infos from the responses of client requests or getInfo.,[],2018-01-30 01:24:05+00:00,2018-02-15 06:50:21+00:00,2018-02-15 06:50:21+00:00,Resolved,13134625,RATIS-205
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"It turns out that the last applied TermIndex is useful for all StateMachine implementation in order to support snapshot.

RATIS-190 also needs it to check follower's last applied index before processing a stale read request.",[],2018-01-27 02:03:46+00:00,2018-02-01 05:20:23+00:00,2018-02-02 19:23:47+00:00,Resolved,13134170,RATIS-204
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"There are two scenarios which can lead to such a situation.
 # Raft leader accepts an entry and puts it in its retry cache. But it fails or changes before it can append the entries to its follower. In such a case the entry would remain in its retry cache. If this leader is chosen again by the ring, any subsequent request by the raft client would wait indefinitely for the future in retry cache entry to complete.
 # The leader receives the request but dies before replying to it.

Below are the log entries corresponding to first scenario.
{code:java}
2018-01-25 16:28:55,479 DEBUG impl.RaftServerImpl (LeaderState.java:addPendingRequest(239)) - s2: addPendingRequest at index=3255, request=RaftClientRequest(client-C496AD50C41A->s2) in group-8A72B1078A40, cid=3554, seq=293 RW, 322d323933
2018-01-25 16:28:57,457 DEBUG impl.RaftServerImpl (RaftServerImpl.java:submitClientRequestAsync(476)) - s2: receive client request(RaftClientRequest(client-C496AD50C41A->s2) in group-8A72B1078A40, cid=3554, seq=293 RW, 322d323933) future client-C496AD50C41A:3554:pending passedjava.util.concurrent.CompletableFuture@404d76c7[Not completed]
{code}",[],2018-01-25 11:44:25+00:00,2018-02-05 21:46:23+00:00,2018-02-05 21:52:49+00:00,Resolved,13133657,RATIS-203
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,It calls impl.get() in getImpl() so that it unnecessarily uses a thread to wait in the async methods.,[],2018-01-24 23:11:27+00:00,,2018-07-20 21:10:11+00:00,Open,13133523,RATIS-202
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Minor,It can be possible for more than one server to have their role set as LEADER in a ratis ring. There can be a race condition where term of a follower is updated but its role is not yet updated to FOLLOWER. In such a scenario MiniRaftCluster#getLeader would throw IllegalStateException.,[],2018-01-24 15:24:06+00:00,2018-02-06 21:31:32+00:00,2018-02-06 21:31:32+00:00,Resolved,13133404,RATIS-201
Test,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Minor,"{code}
testWriteWithOffset(org.apache.ratis.grpc.TestRaftStream)  Time elapsed: 1.253 sec  <<< FAILURE!
java.lang.AssertionError: expected:<8> but was:<9>
  at org.apache.ratis.grpc.TestRaftStream.testWriteWithOffset(TestRaftStream.java:240)
{code}",[],2018-01-23 21:46:05+00:00,,2018-07-20 21:41:49+00:00,Open,13133187,RATIS-200
Test,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Minor,"TestStateMachine times out when run as part of the test suite.

This was as of commit 0f7169db51ba15108c265b1e937e9daeaa085045",[],2018-01-23 17:36:04+00:00,,2018-07-20 21:41:58+00:00,Open,13133131,RATIS-199
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Major,"While Executing TestCorona#ratisTest3, with the attached patch hit the below exception.
{code:java}

2018-01-23 18:15:11,058 [IPC Server handler 5 on 51292] INFO scm.StorageContainerManager (StorageContainerManager.java:notifyObjectStageChange(687)) - Object type container name 2efd4054-c479-45a4-a1db-3a4ec3526d4d op create new stage complete
100.00% |█████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 Time: 0:00:05
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@7202ef94] Terminated
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@5e5452c3] Terminated
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@72d74e90] Terminated
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@3679cc6c] Terminated
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.internal.ManagedChannelImpl maybeTerminateChannel
INFO: [ManagedChannelImpl@589f60fd] Terminated
Jan 23, 2018 6:15:11 PM org.apache.ratis.shaded.io.grpc.netty.NettyServerHandler onConnectionError
WARNING: Connection Error
java.io.IOException: Connection reset by peer
at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
at sun.nio.ch.IOUtil.read(IOUtil.java:192)
at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
at org.apache.ratis.shaded.io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
{code}{code}",['ozone'],2018-01-23 12:50:24+00:00,2019-07-01 09:45:07+00:00,2019-07-01 09:45:07+00:00,Resolved,13133035,RATIS-198
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Read failing found in Ozone; see HDFS-13078 for the details.
",[],2018-01-23 12:10:58+00:00,2018-02-07 20:22:30+00:00,2018-02-07 20:22:30+00:00,Resolved,13133028,RATIS-197
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"This issue was observed while deploying Ozone with Ratis, with appendEntriesAsync {{AppendEntryRequestProto}} are sent to the followers in an asynchronous manner. It can happen that the follower is replying to the Leader even after the election is over.

{code}
         server.appendEntriesAsync(request).thenCombine(previous,
              (reply, v) -> {
              responseObserver.onNext(reply);
            current.complete(null);
{code}",[],2018-01-21 11:57:51+00:00,2018-01-22 05:20:20+00:00,2018-01-22 05:20:20+00:00,Resolved,13132502,RATIS-196
Test,[],yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,Ted Yu,Minor,"As of commit 7b3a9a6f5f8e8075727d84e3ddeae7b594eda89c, I observed the following :
{code}
testRevertConfigurationChange(org.apache.ratis.server.simulation.TestRaftReconfigurationWithSimulatedRpc)  Time elapsed: 2.119 sec  <<< FAILURE!
java.lang.AssertionError: 1 0 expected:<NOOP> but was:<CONFIGURATIONENTRY>
{code}
1 was confIndex and 0 was log.getLastCommittedIndex()

",[],2018-01-19 20:35:39+00:00,2018-09-26 23:04:18+00:00,2018-09-26 23:04:18+00:00,Resolved,13132285,RATIS-195
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The test has timeout in a few QA builds, e.g. https://builds.apache.org/job/PreCommit-RATIS-Build/100/testReport/org.apache.ratis.server.simulation/TestRaftWithSimulatedRpc/testBasicAppendEntries/

However, it can pass when I testing it in my machine.",[],2018-01-19 10:30:25+00:00,2018-07-20 21:17:29+00:00,2018-07-20 21:17:29+00:00,Resolved,13132136,RATIS-194
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"In case of errors in RaftClientProtocolService.java, on error {{responseObserver.onError(RaftGrpcUtil.wrapException(t));}} will be called which will close the stream observer. This can lead into a case where stream in closed twice in cases of errors. A check similar to RATIS-189 should be added as well.
 
{code:java}
2018-01-16 11:57:09,810 [grpc-default-executor-3] WARN  client.RaftClientProtocolService (RaftClientProtocolService.java:responseError(186)) - 127.0.0.1_54322-16: Failed processClientRequestAsync for RaftClientRequest(client-8764D94435EE->127.0.0.1_54322) in group-7347726F7570, cid=4, seq=0 RW, 08011224613033313231...(size=291)
org.apache.ratis.protocol.LeaderNotReadyException: 127.0.0.1_54322 is in LEADER state but not ready yet.
        at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:377)
        at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:454)
        at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:147)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.processClientRequestAsync(RaftClientProtocolService.java:125)
        at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:351)
        at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:343)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:145)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:109)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$2$1.onMessage(ServerCalls.java:206)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messageRead(ServerCallImpl.java:237)
        at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1.runInContext(ServerImpl.java:485)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Jan 16, 2018 11:57:09 AM org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner run
{code}

stream is closed again here
{code}
SEVERE: Exception while executing runnable org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$2@7edacaf
java.lang.IllegalStateException: call already closed
        at org.apache.ratis.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:174)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl.close(ServerCallImpl.java:178)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:304)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.close(RaftClientProtocolService.java:179)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onCompleted(RaftClientProtocolService.java:172)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$2$1.onHalfClose(ServerCalls.java:217)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:260)
        at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$2.runInContext(ServerImpl.java:503)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}",[],2018-01-16 06:41:20+00:00,2018-01-18 09:01:57+00:00,2018-01-19 09:46:22+00:00,Resolved,13131147,RATIS-193
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After RATIS-183,  TestFileStoreWithGrpc starts to fail.",[],2018-01-15 15:55:31+00:00,2018-01-19 10:22:18+00:00,2018-01-19 10:28:06+00:00,Resolved,13131060,RATIS-192
Bug,[],xyao,Xiaoyu Yao,xyao,Xiaoyu Yao,Major,The bind failure was always hit when running some Ozone tests multiple times. ,['ozone'],2018-01-11 18:58:32+00:00,2019-07-15 05:01:11+00:00,2019-07-15 05:01:11+00:00,Resolved,13130286,RATIS-191
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The RAFT protocol in general does not support read only request from followers since a follower may be few or more transactions behind the leader.  The state in a follower may be stale.

In some specific applications, we may safely support read from followers.  One case is that there is no overwrite, as a result, no stale data.",[],2018-01-11 07:56:07+00:00,2018-02-19 03:38:13+00:00,2018-02-19 03:38:13+00:00,Resolved,13130100,RATIS-190
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"AppendRequestStreamObserver can be called twice, causing the following exception.
The following sequence of events will trigger this exception :-
1) AppendRequestStreamObserver#sendReply calls close
2) close closes responseObserver with responseObserver#onCompleted();
3) This will cause the server to again call AppendRequestStreamObserver#onCompleted
4) This will again call close, causing this exception.

{code}
SEVERE: Exception while executing runnable org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$2@5036879a
java.lang.IllegalStateException: call already closed
        at org.apache.ratis.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:174)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl.close(ServerCallImpl.java:178)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:304)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.close(RaftClientProtocolService.java:175)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onCompleted(RaftClientProtocolService.java:169)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$2$1.onHalfClose(ServerCalls.java:217)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:260)
        at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$2.runInContext(ServerImpl.java:503)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}",[],2018-01-10 04:32:17+00:00,2018-01-12 01:18:19+00:00,2018-01-12 01:18:19+00:00,Resolved,13129748,RATIS-189
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Window size limit is a standard sliding window feature number so that it can limit the number of outstanding requests.

Currently, we use a separated Semaphore in RaftClientImpl in order to limit the number of client requests.  We may remove the Semaphore once we have size limit feature.",['ozone'],2018-01-09 07:53:59+00:00,,2018-07-31 18:26:00+00:00,Open,13129456,RATIS-188
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"FileStoreStateMachine should implement takeSnapshot() defined in StateMachine.  Also, it should initialize/reinitialize to the latest snapshot, if there is any.

",[],2018-01-09 07:44:55+00:00,,2020-09-19 07:35:19+00:00,Open,13129453,RATIS-187
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,HTTP flow control window size can be controlled in grpc. The following fix in grpc provided the api to control the flow control window. https://github.com/grpc/grpc-java/issues/494. This patch will add a config option to control the flow control window size in Ratis.,[],2018-01-06 17:53:16+00:00,2018-01-07 08:07:27+00:00,2018-01-07 08:07:27+00:00,Resolved,13129019,RATIS-186
Bug,[],Sandeep Nemuri,Sandeep Nemuri,Sandeep Nemuri,Sandeep Nemuri,Major,"Unable to assign more than one digit in the CLI of arithmetic example

{code:java}
bin> ./client.sh assign --name a --value 11
/Users/snemuri/git/incubator-ratis/ratis-examples/src/main/bin/../../../target/ratis-examples-0.1.1-alpha-SNAPSHOT.jar
Exception in thread ""main"" java.lang.IllegalArgumentException: Invalid expression 11 Try something like: 'a+b' or '2'
	at org.apache.ratis.examples.arithmetic.cli.Assign.createExpression(Assign.java:73)
	at org.apache.ratis.examples.arithmetic.cli.Assign.operation(Assign.java:53)
	at org.apache.ratis.examples.arithmetic.cli.Client.run(Client.java:50)
	at org.apache.ratis.examples.arithmetic.Runner.main(Runner.java:62)

{code}
",[],2018-01-05 10:39:51+00:00,2018-01-07 08:10:32+00:00,2018-01-07 08:12:08+00:00,Resolved,13128773,RATIS-185
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We should add instructions for deploy a snapshot to ""How to deploy"" in BUILDING.md.",[],2018-01-05 07:57:03+00:00,2018-01-29 18:32:57+00:00,2018-01-29 18:32:57+00:00,Resolved,13128731,RATIS-184
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently the followers in a Ratis ring append entries synchronously on raft log sync. This happens because of the following code. server.appendEntries(request) which further invokes raft log sync.

{code}
//RaftServerProtocolService.java
  @Override
  public StreamObserver<AppendEntriesRequestProto> appendEntries(
      StreamObserver<AppendEntriesReplyProto> responseObserver) {
    return new StreamObserver<AppendEntriesRequestProto>() {
      @Override
      public void onNext(AppendEntriesRequestProto request) {
        try {
          final AppendEntriesReplyProto reply = server.appendEntries(request);
          responseObserver.onNext(reply);
        } catch (Throwable e) {
    ...
  }
{code}",[],2018-01-04 12:28:41+00:00,2018-01-08 09:55:33+00:00,2018-01-15 15:53:21+00:00,Resolved,13128488,RATIS-183
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Leader currently doesn't wait for the transaction to be appended to the log. This can lead to a situation where {{applyTransaction}} can be called before {{writeStateMachineData}} finishes.

{code}
  public long append(long term, TransactionContext operation,
      ClientId clientId, long callId) throws StateMachineException {
...
...
...
      appendEntry(e) <---- This should be synced
      operation.setLogEntry(e);
      return nextIndex;
    }
  }
{code}",[],2018-01-01 07:41:31+00:00,2018-01-07 17:14:15+00:00,2018-01-07 17:14:15+00:00,Resolved,13127847,RATIS-182
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In [build #71|https://builds.apache.org/job/PreCommit-RATIS-Build/71/testReport/org.apache.ratis.hadooprpc/TestRetryCacheWithHadoopRpc/testRetryOnNewLeader/], it failed with
{code}
java.lang.AssertionError: expected:<5> but was:<6>
{code}",[],2017-12-28 07:13:10+00:00,2018-07-20 21:23:04+00:00,2018-07-20 21:23:04+00:00,Resolved,13127479,RATIS-181
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- It failed with timeout if running it alone, e.g.
{noformat}
./dev-support/run-test-repeatedly.sh TestRaftExceptionWithNetty#testNotLeaderExceptionWithReconf
{noformat}
- It failed with a NullPointerException in [the qa build #74|https://builds.apache.org/job/PreCommit-RATIS-Build/74/testReport/junit/org.apache.ratis.netty/TestRaftExceptionWithNetty/testNotLeaderExceptionWithReconf/].",[],2017-12-22 16:59:28+00:00,2018-07-20 21:24:18+00:00,2018-07-20 21:24:31+00:00,Resolved,13126848,RATIS-180
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Log message changes:
- when a server changes role, log also the term and the reason.
- when a server changes the recognized Leader, log also the term and the reason.

Test refactoring:
- Move the leader election tests from RaftBasicTests to a new class since RaftBasicTests is getting large.",[],2017-12-22 16:30:46+00:00,2018-01-02 19:09:28+00:00,2018-01-03 04:48:23+00:00,Resolved,13126843,RATIS-179
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When two servers starts in a 3-server group, they may elect a leader and then start the service.  Then, start the third server.  It somehow fails to join the group.",[],2017-12-22 06:01:22+00:00,2018-01-03 21:24:20+00:00,2018-01-03 21:24:20+00:00,Resolved,13126732,RATIS-178
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently Raft Leader returns LeaderNotReady Exception for all the requests coming to the server. We should return the reply in case the request has already been completed normally.,[],2017-12-20 13:50:32+00:00,2018-01-05 06:32:20+00:00,2018-01-05 06:32:20+00:00,Resolved,13126295,RATIS-177
Bug,[],shashikant,Shashikant Banerjee,shashikant,Shashikant Banerjee,Minor,"LogAppender while adding append entry in LogEntryBuffer, checks whether the total allocated for all entries does not exceed the maxBufferSize allocated. In case, the size exceeds the limit ,entries are not added to the buffer but no exception is thrown . This case needs to be handled.",[],2017-12-19 15:41:02+00:00,2018-03-28 05:42:46+00:00,2018-03-28 05:42:46+00:00,Resolved,13125949,RATIS-176
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,Currently RaftServerProxy does not close the server rpc in case its instance creation fails. This leads to BindException when a RaftServerProxy instance creation is reattempted in ServerImplUtils#newRaftServer.,[],2017-12-17 14:27:14+00:00,2017-12-22 17:02:41+00:00,2017-12-22 17:02:41+00:00,Resolved,13125464,RATIS-175
New Feature,[],elek,Marton Elek,elek,Marton Elek,Major,"Until now we had just one source package as a release artifact. I propose to create a binary artifact as well as usually this is what a user is looking for. The binary artifact would contain:

 * A readme to explain that it's a library
 * the compiled jars
 * licence/notice/disclaimer files as ususal
 * the scripts to execute the example servers. Currently it works with the arithmetic example but it could be extended with the filestore example.

I think to provide a binary package with a simple startup script to demonstrate the behavior of the library, could help to the users to try it out even without coding. ",[],2017-12-15 11:23:06+00:00,2017-12-22 04:20:31+00:00,2017-12-22 04:20:31+00:00,Resolved,13125185,RATIS-174
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"The current release build can't be run because of javadoc warnings:

{code}
mvn  install  -Prelease -DskipTests assembly:single
{code}

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.10.3:jar (module-javadocs) on project ratis-common: MavenReportException: Error while generating Javadoc: 
[ERROR] Exit code: 1 - /home/elek/projects/ratis/ratis-common/src/main/java/org/apache/ratis/protocol/RaftClientReply.java:92: warning: no @return
[ERROR]   public NotLeaderException getNotLeaderException() {
[ERROR]                             ^
[ERROR] /home/elek/projects/ratis/ratis-common/src/main/java/org/apache/ratis/protocol/RaftClientReply.java:97: warning: no @return
[ERROR]   public StateMachineException getStateMachineException() {
[ERROR]                                ^
[ERROR] /home/elek/projects/ratis/ratis-common/src/main/java/org/apache/ratis/protocol/RaftPeer.java:44: warning: no @param for id
[ERROR]   public RaftPeer(RaftPeerId id) {
[ERROR]          ^
[ERROR] /home/elek/projects/ratis/ratis-common/src/main/java/org/apache/ratis/protocol/RaftPeer.java:49: warning: no @param for id
[ERROR]   public RaftPeer(RaftPeerId id, InetSocketAddress address) {
[ERROR]          ^
{code}

There are two options here:
 * Fix all the occurrences
 * Ignore the warnings

I checked the errors for fixing them but I found multiple false positive issue. Usually there is a javadoc with clear description, for example:

{code}
/** If this reply has {@link NotLeaderException}, return it; otherwise return null. */
  public NotLeaderException getNotLeaderException() {
    return JavaUtils.cast(exception, NotLeaderException.class);
  }

  /** If this reply has {@link StateMachineException}, return it; otherwise return null. */
  public StateMachineException getStateMachineException() {
    return JavaUtils.cast(exception, StateMachineException.class);
  }
{code}

I can't see any value to repeat the mesage with a return tag here, so I propose to hide the warnings and check the existence of javadoc parameters with checkstyle according to more sophisticated rules.

Note: There is a setting in our pom.xml even now to ignore the errors  but it uses wrong parameter for the current javadoc plugin.",[],2017-12-15 11:14:38+00:00,2017-12-18 02:02:27+00:00,2017-12-18 02:02:28+00:00,Resolved,13125181,RATIS-173
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"After RATIS-161, TestBatchAppend fails with timeout.

Tried to reset the HEAD to before RATIS-161. TestBatchAppend could pass successfully.",[],2017-12-13 14:58:23+00:00,2017-12-18 01:59:24+00:00,2017-12-18 01:59:24+00:00,Resolved,13124696,RATIS-172
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In the RaftLogWorker.WriteLog constructor, stateMachineFuture can be null since stateMachine.writeStateMachineData(entry) may return null.  In such case, it throws NullPointerException when creating the combined future. ",[],2017-12-12 15:47:18+00:00,2017-12-18 10:59:26+00:00,2017-12-18 10:59:26+00:00,Resolved,13124388,RATIS-171
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Implements async read/write/delete operations in the FileStore example

Also add a test similar to FileStoreBaseTest except that the new test uses the async API.",[],2017-12-09 23:55:05+00:00,2018-02-12 02:08:31+00:00,2018-02-12 02:08:31+00:00,Resolved,13123943,RATIS-170
Test,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,We need a test similar to RaftBasicTests#testWithLoad for testing the async api.,[],2017-12-07 08:25:01+00:00,2018-01-24 22:00:44+00:00,2018-01-24 22:00:44+00:00,Resolved,13123391,RATIS-169
Improvement,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis is using grpc version 1.0.1, This version should be updated to a later version.
",[],2017-12-06 18:05:59+00:00,2018-03-31 19:48:09+00:00,2018-03-31 19:48:09+00:00,Resolved,13123260,RATIS-168
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"With an in-order async API, it is easy to implement a high performance OutputStream.

Also, since the async API already takes care leader change, the OutputStream implementation supports automatic failover for free.

The code is generic in the sense that it is RPC independent (as long as the RPC supports in-order async API).",['ozone'],2017-12-06 07:29:40+00:00,2019-06-03 06:51:34+00:00,2019-06-03 06:51:48+00:00,Resolved,13123111,RATIS-167
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"sun.misc.Unsafe is used in NativeIO.  However, all the methods using Unsafe are not used anywhere in Ratis.  Since the use of Unsafe generates some javac warning, let's remove those methods from NativeIO.",[],2017-12-05 07:50:31+00:00,2017-12-06 03:02:49+00:00,2017-12-06 03:02:49+00:00,Resolved,13122790,RATIS-166
Improvement,[],k8i6t2009,Kit Hui,k8i6t2009,Kit Hui,Minor,"ClientProtoUtils change from ""class"" to ""interface"". The methods included some ""public"", ""private"" so that we can remove ""public"", ""private"" from the declarations",[],2017-12-05 07:23:25+00:00,2017-12-06 02:58:51+00:00,2017-12-06 02:58:51+00:00,Resolved,13122780,RATIS-165
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"ProtoUtils is an interface.  The methods are automatically public so that we can remove ""public"" from the declarations.",[],2017-12-05 06:09:16+00:00,2017-12-05 07:21:54+00:00,2017-12-05 07:21:54+00:00,Resolved,13122767,RATIS-164
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"During the last qbt nightly build TestRaftWithHadoopRpc is failed.

The problem could be reproduced locally:

mvn test -Dtest=TestRaftWithHadoopRpc#testBasicLeaderElection

The key output is at the end of the log file:

{code}
2017-12-03 15:25:00,966 INFO  ipc.Client (Client.java:handleConnectionFailure(940)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46409. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-03 15:25:00,967 WARN  ipc.Client (Client.java:handleConnectionFailure(922)) - Failed to connect to server: 0.0.0.0/0.0.0.0:46409: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:679)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:775)
	at org.apache.hadoop.ipc.Client$Connection.access$3300(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1556)
	at org.apache.hadoop.ipc.Client.call(Client.java:1387)
	at org.apache.hadoop.ipc.Client.call(Client.java:1351)
	at org.apache.hadoop.ipc.ProtobufRpcEngineShaded$Invoker.invoke(ProtobufRpcEngineShaded.java:214)
	at com.sun.proxy.$Proxy13.requestVote(Unknown Source)
	at org.apache.ratis.hadooprpc.server.HadoopRpcService.lambda$requestVote$4(HadoopRpcService.java:176)
	at org.apache.ratis.hadooprpc.server.HadoopRpcService.processRequest(HadoopRpcService.java:188)
	at org.apache.ratis.hadooprpc.server.HadoopRpcService.requestVote(HadoopRpcService.java:175)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$0(LeaderElection.java:189)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{code}

In this test case the unit test just kills all the leaders one by one. If one leader is killed the other follower still tries to connect to them. At every voterequest the running nodes will (try to) send a message to the killed nodes.

But there is a retry logic in Hadoop RPC by default. So the LeaderElection.submitRequest/requestVote method (which is executed in a spereated executor) won't be finished even if the LeaderElection is stopped. The requestVote task should be finised quite fast by default, but in this case hadop rpc just tries to reconnect again and again, so the internal executor of the LeaderElection will work even if the LeaderElection itself is stopped.

The easiest way to solve this to disable hadoop ipc retry. I suggest this (at least for now), as the current test failure is not a real test case failure, just the junit test framework can't finish the test method as there are still ongoing hadoop rpc clients.

The tricky solution would be to try to stop existing hadoop client request in case of the LeaderElection shutdown.",[],2017-12-03 14:28:35+00:00,2017-12-03 22:26:28+00:00,2017-12-03 22:26:28+00:00,Resolved,13122430,RATIS-163
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This is to refactor the code for RATIS-140.

We also improve error/debug messages.

Another improvement is to close clientRpc connection to the old leader when a client changing leader. 
",[],2017-12-03 08:49:28+00:00,2017-12-05 00:57:21+00:00,2017-12-05 03:18:05+00:00,Resolved,13122415,RATIS-162
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,RATIS-133 add a check to the raft client to ensure that server doesn't receive messages which are greater than maxMessageSize. However GRPCLogAppender can append entries to the server and these entries can be greater than the max message size. This jira will add a check to GRPCLogAppender as well.,[],2017-11-30 08:31:34+00:00,2017-12-12 10:34:40+00:00,2017-12-13 14:59:45+00:00,Resolved,13121847,RATIS-161
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"This jira is in relation to the below exception seen in the logs. 

{code:java}
java.lang.IllegalStateException: retry cache entry should be pending: client-89341C13-2136-4EF3-BD8A-73C2526B7703:1777:done
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
        at org.apache.ratis.server.impl.RetryCache.getOrCreateEntry(RetryCache.java:169)
        at org.apache.ratis.server.impl.RaftServerImpl.replyPendingRequest(RaftServerImpl.java:915)
        at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:974)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:151)
        at java.lang.Thread.run(Thread.java:748)
Exception in thread ""StateMachineUpdater-s3"" org.apache.ratis.util.ExitUtils$ExitException: StateMachineUpdater-s3: the StateMachineUpdater hits Throwable
        at org.apache.ratis.util.ExitUtils.terminate(ExitUtils.java:94)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:175)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: retry cache entry should be pending: client-89341C13-2136-4EF3-BD8A-73C2526B7703:1777:done
        at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
        at org.apache.ratis.server.impl.RetryCache.getOrCreateEntry(RetryCache.java:169)
        at org.apache.ratis.server.impl.RaftServerImpl.replyPendingRequest(RaftServerImpl.java:915)
        at org.apache.ratis.server.impl.RaftServerImpl.applyLogToStateMachine(RaftServerImpl.java:974)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:151)
        ... 1 more
{code}

This occurs when leader commits a log entry but is not able to send a reply to the client before leader is changed. When the new leader gets the request it sends the append entry request to the followers whose cache already has the  corresponding entry leading to the above exception.",[],2017-11-30 08:18:43+00:00,2018-01-18 22:21:21+00:00,2018-01-19 10:25:28+00:00,Resolved,13121844,RATIS-160
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Found the following deadlock while testing ratis with Ozone. I have also attached the stack trace file along with the jira.


Java stack information for the threads listed above:
===================================================
{code}
""Thread-195"":
        at org.apache.ratis.server.impl.RaftServerImpl.getFollowerNextIndices(RaftServerImpl.java:946)
        - waiting to lock <0x0000000081bbca08> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.storage.SegmentedRaftLog.checkAndEvictCache(SegmentedRaftLog.java:199)
        at org.apache.ratis.server.storage.SegmentedRaftLog.get(SegmentedRaftLog.java:190)
        at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:170)
        at org.apache.ratis.grpc.server.GRpcLogAppender.appendLog(GRpcLogAppender.java:138)
        - locked <0x00000000ad0101f8> (a org.apache.ratis.grpc.server.GRpcLogAppender)
        at org.apache.ratis.grpc.server.GRpcLogAppender.run(GRpcLogAppender.java:85)
{code}

{code}
""grpc-default-executor-32"":
        at org.apache.ratis.server.impl.LogAppender.notifyAppend(LogAppender.java:456)
        - waiting to lock <0x00000000ad0101f8> (a org.apache.ratis.grpc.server.GRpcLogAppender)
        at org.apache.ratis.server.impl.LeaderState$$Lambda$124/1715853171.accept(Unknown Source)
        at java.util.concurrent.CopyOnWriteArrayList.forEach(CopyOnWriteArrayList.java:890)
        at org.apache.ratis.server.impl.LeaderState$SenderList.forEach(LeaderState.java:91)
        at org.apache.ratis.server.impl.LeaderState.notifySenders(LeaderState.java:190)
        at org.apache.ratis.server.impl.RaftServerImpl.appendTransaction(RaftServerImpl.java:438)
        - locked <0x0000000081bbca08> (a org.apache.ratis.server.impl.RaftServerImpl)
        at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:481)
        at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:137)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:113)
        at org.apache.ratis.grpc.client.RaftClientProtocolService$AppendRequestStreamObserver.onNext(RaftClientProtocolService.java:96)
        at org.apache.ratis.shaded.io.grpc.stub.ServerCalls$2$1.onMessage(ServerCalls.java:206)
        at org.apache.ratis.shaded.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messageRead(ServerCallImpl.java:237)
        at org.apache.ratis.shaded.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1.runInContext(ServerImpl.java:485)
        at org.apache.ratis.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
        at org.apache.ratis.shaded.io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}",[],2017-11-30 06:57:23+00:00,2018-07-20 18:11:44+00:00,2018-07-20 18:11:44+00:00,Resolved,13121834,RATIS-159
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"mvn clean install on centos7 fails with the following message 
{code}
[INFO] ------------------------------------------------------------------------                                                                                                                             
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------                                                                                                                             
[INFO] Total time: 01:34 min
[INFO] Finished at: 2017-11-29T06:22:06-05:00                                                                                                                                                               
[INFO] Final Memory: 167M/5136M
[INFO] ------------------------------------------------------------------------                                                                                                                             
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:3.1.0:shade (default) on project ratis-examples: Error creating shaded jar: The name ""os.detected.release.like.""centos"""" is not legal for JDOM/XML elements: XML names cannot contain the character """""". -> [Help 1]                                                                                                                         
[ERROR]
{code}",[],2017-11-30 06:38:15+00:00,2018-01-09 04:11:57+00:00,2018-01-09 04:11:57+00:00,Resolved,13121832,RATIS-158
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,"We need to add counters to measure time taken in various stages such as log append, commit and apply transaction.",['ozone'],2017-11-29 09:44:28+00:00,,2018-07-20 21:26:21+00:00,Open,13121598,RATIS-157
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,We need to implement configuration for setting the number of async request handlers and the number of outstanding requests in RaftClientImpl.,[],2017-11-24 04:35:32+00:00,2017-11-26 04:38:09+00:00,2017-11-26 04:38:09+00:00,Resolved,13120565,RATIS-156
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
2017-11-23 16:30:44, 212 ERROR storage.RaftLogWorker (ExitUtils.java:terminate(86)) - Terminating with exit status 1: s0-RaftLogWorker failed.
java.lang.NullPointerException
	at org.apache.ratis.server.storage.RaftLogWorker.lambda$new$0(RaftLogWorker.java:98)
	at org.apache.ratis.util.JavaUtils$1.get(JavaUtils.java:90)
	at org.apache.ratis.server.storage.RaftLogWorker.flushWrites(RaftLogWorker.java:219)
	at org.apache.ratis.server.storage.RaftLogWorker.access$500(RaftLogWorker.java:47)
	at org.apache.ratis.server.storage.RaftLogWorker$WriteLog.execute(RaftLogWorker.java:302)
	at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:174)
	at java.lang.Thread.run(Thread.java:748)
{code}
",[],2017-11-24 00:35:00+00:00,2017-11-25 00:25:42+00:00,2017-11-25 00:25:42+00:00,Resolved,13120556,RATIS-155
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Setter functions are not currently present for all the Raft config keys. The following keys were found to have no setter functions for config keys.

{code}
    properties.setInt(""raft.server.log.segment.cache.num.max"", 2);
    properties.setInt(""raft.grpc.message.size.max"",
        scmChunkSize + raftSegmentSize);
    properties.setInt(""raft.server.rpc.timeout.min"", 500);
    properties.setInt(""raft.server.rpc.timeout.max"", 600);
{code}",[],2017-11-23 14:46:09+00:00,2017-12-18 02:12:29+00:00,2017-12-18 02:12:29+00:00,Resolved,13120495,RATIS-154
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Currently the heartbeat monitor on the follower is updated when the last rpc is received from the leader. When this threshold crosses the *raft.server.rpc.timeout*, an election is triggered to elect a new leader.

However generally it might happen that the leader doesn't had append entries to forward to the follower. This will trigger unnecessary leader elections.

This also causes the Raft Client to find the new Leader as well which can be time consuming.

This jira proposes to add a heartbeat mechanism, where the leader will periodically (lets say, raft.server.rpc.timeout/2) will send empty heartbeats to its followers to ensure that leader stays elected as the leader.",[],2017-11-21 15:35:37+00:00,2018-01-22 07:30:47+00:00,2018-01-22 07:30:47+00:00,Resolved,13119975,RATIS-153
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Ratis server on Ozone unit test using MiniOzoneCluster throws the following error because of failure to register jmx. This happens because jmx's are registered in a static context.

{code}
2017-11-21 15:36:40,601 [Datanode State Machine Thread - 0] ERROR impl.RaftServerImpl (RaftServerImpl.java:registerMBean(182)) - RaftServer JMX bean can't be registered
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-414F5A4F-4E45-5241-5449-5347524F5550,id=127.0.0.1_61259
        at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
        at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:180)
        at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:171)
        at org.apache.ratis.util.JavaUtils.getAndConsume(JavaUtils.java:67)
        at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:123)
        at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:143)
        at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:132)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:126)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:281)
        at java.lang.Thread.run(Thread.java:745)
{code}",[],2017-11-21 14:06:51+00:00,2017-12-13 06:31:36+00:00,2017-12-13 06:31:36+00:00,Resolved,13119952,RATIS-152
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"This JIRA is to help reducing the patch size in RATIS-141.

We refactor the tests so that DEFAULT_CALLID is only used in MiniRaftCluster.",[],2017-11-20 23:26:34+00:00,2017-11-21 23:05:23+00:00,2017-11-21 23:05:23+00:00,Resolved,13119792,RATIS-151
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,All hadoop tests in ratis-example fail with NoClassDefFoundError: org/apache/ratis/shaded/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngineProtos$RequestHeaderProto,[],2017-11-20 21:26:15+00:00,2017-11-22 21:48:20+00:00,2017-11-22 21:48:20+00:00,Resolved,13119779,RATIS-150
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Two different failure cases:
- {code}
java.lang.AssertionError: expected:<500> but was:<350>
	at org.apache.ratis.grpc.TestRaftStream.checkLog(TestRaftStream.java:106)
	at org.apache.ratis.grpc.TestRaftStream.testSimpleWrite(TestRaftStream.java:100)
{code}
- {code}
org.junit.internal.ArrayComparisonFailure: arrays first differed at element [0]; expected:<63> but was:<-81>
	at org.apache.ratis.grpc.TestRaftStream.checkLog(TestRaftStream.java:114)
	at org.apache.ratis.grpc.TestRaftStream.testSimpleWrite(TestRaftStream.java:100)
{code}
Note that TestRaftStream was rename to TestGrpcOutputStream",[],2017-11-20 02:06:24+00:00,,2019-06-03 06:53:37+00:00,Open,13119543,RATIS-149
Sub-task,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,,[],2017-11-20 01:26:05+00:00,2017-11-22 01:21:05+00:00,2017-11-24 00:37:35+00:00,Resolved,13119538,RATIS-148
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"It is useful to run a single test repeatedly to reproduce intermittent failed test.

It seems that there is no mvn command to do so.  Please correct me if I am wrong.  :)",[],2017-11-20 01:12:39+00:00,2017-11-20 22:50:52+00:00,2017-11-21 23:06:25+00:00,Resolved,13119537,RATIS-147
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,Currently maven install does not install the proto files. This is not useful when we need to make changes to proto files and use it in other projects.,[],2017-11-19 17:27:07+00:00,2017-11-29 20:13:21+00:00,2017-11-29 20:13:47+00:00,Resolved,13119505,RATIS-146
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"Latest nighliy build is failed with asflicense check:

https://builds.apache.org/job/ratis-qbt-master-java8-linux-x86/18/artifact/out/patch-asflicense-problems.txt

{code}
Lines that start with ????? in the ASF License  report indicate files that do not have an Apache license header:
 !????? /testptch/ratis/ratis-examples/dependency-reduced-pom.xml
{code}

The trivial fix is to add dependency-reduced-pom.xml to the .gitignore file.",[],2017-11-18 19:42:56+00:00,2017-11-25 00:28:53+00:00,2017-11-25 00:28:53+00:00,Resolved,13119437,RATIS-145
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"Currently the ratis precommit builds are failing because yetus calculates the changed modules and only the changed modules are built, even if we need a new shading/protoc generation  every clean. 

In this patch I suggest to build all the modules as the whole ratis build is quite fast (at least compared to a full hadoop build...). Later we can change to more sophisticated module selection (for example to build changed modules + ratis-proto-shaded)",[],2017-11-18 19:37:21+00:00,2017-11-24 18:55:21+00:00,2017-11-24 18:55:22+00:00,Resolved,13119436,RATIS-144
Bug,[],ljain,Lokesh Jain,ljain,Lokesh Jain,Major,RaftClientImpl should have a upper bound on active async requests. Further request should be blocked until the active one is handled. Idea is to use semaphore so that a request is blocked until a permit is released by one of the active ones.,[],2017-11-15 18:12:11+00:00,2017-11-24 01:08:44+00:00,2017-11-24 01:08:44+00:00,Resolved,13118616,RATIS-143
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"The Gauss–Legendre algorithm, a.k.a. the arithmetic–geometric mean method, is a fast algorithm to compute pi; see https://en.wikipedia.org/wiki/Gauss%E2%80%93Legendre_algorithm

We use it to test the ArithmeticStateMachine example.",[],2017-11-15 02:13:16+00:00,2017-11-17 20:20:57+00:00,2017-11-17 21:28:46+00:00,Resolved,13118420,RATIS-142
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
//RaftClientProtocolService.AppendRequestStreamObserver.onNext(..)

              // we assume the callId is consecutive for a stream RPC call
              final PendingAppend pendingForReply = pendingList.get(
                  (int) (replySeq - headSeqNum));
{code}
Call id is used for different kinds of calls (e.g. getInfo) so that it may not be consecutive.",[],2017-11-11 01:34:39+00:00,2017-11-28 23:29:20+00:00,2017-11-28 23:29:21+00:00,Resolved,13117709,RATIS-141
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Async client is being added in RATIS-113.  However, we found that the server side (RaftClientProtocolService) may see out-of-order grpc messages even if all messages are sent by the same client.",[],2017-11-09 22:53:50+00:00,2017-12-28 06:45:12+00:00,2018-01-21 18:35:46+00:00,Resolved,13117426,RATIS-140
Improvement,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,"{code}
  private boolean shouldFlush() {
    return pendingFlushNum >= forceSyncNum ||
        (pendingFlushNum > 0 && queue.isEmpty());
  }
{code}

It is possible that queue is often non-empty, but not full to trigger force sync. We could use two queues similar to two buffer approach in HDFS edit logs.",['ozone'],2017-11-08 22:57:59+00:00,,2018-07-31 18:17:26+00:00,Open,13117121,RATIS-139
Bug,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,"mvn clean and mvn install work when performed in two different commands.
However, mvn clean install doesn't work.",[],2017-11-08 17:20:26+00:00,2017-11-08 22:37:00+00:00,2017-11-08 22:37:00+00:00,Resolved,13117037,RATIS-138
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"[~atrivedi] reported in RATIS-72 that the test may fail.
{code}
TestRaftWithHadoopRpc>RaftBasicTests.testBasicAppendEntries:127->RaftBasicTests.lambda$testBasicAppendEntries$1:127 expected:<10> but was:<11>
{code}",[],2017-11-08 02:00:17+00:00,2017-11-11 21:48:45+00:00,2017-11-11 21:48:45+00:00,Resolved,13116855,RATIS-137
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"ratis logs every segment rollover, this does generate lots of log entries in the log file for Ozone. This patch will reduce the log entries for some of the log entries.",[],2017-11-06 13:41:12+00:00,2017-11-08 02:11:36+00:00,2017-11-08 02:11:36+00:00,Resolved,13116389,RATIS-136
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Closed segments leak memory as eviction does not remove these segments from closed segments list.

{code}
 void evictCache(long[] followerIndices, long flushedIndex,
      long lastAppliedIndex) {
    List<LogSegment> toEvict = evictionPolicy.evict(followerIndices,
        flushedIndex, lastAppliedIndex, closedSegments, maxCachedSegments);
    for (LogSegment s : toEvict) {
      s.evictCache();
    }
{code}

After the segments have been marked for eviction, they should be removed from queue as well.",[],2017-11-06 04:53:01+00:00,2017-11-09 00:28:00+00:00,2017-11-09 00:28:00+00:00,Resolved,13116307,RATIS-135
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"{{PeerProxyMap#addPeers}} currently adds peers to the proxyMap without checkint the current state. This should be optimized to allow addition only if the peer is not present in the proxyMap.


{code}
  public void addPeers(Iterable<RaftPeer> newPeers) {
    for(RaftPeer p : newPeers) {
      peers.put(p.getId(), new PeerAndProxy(p));
    }
  }
{code}",[],2017-11-05 07:08:13+00:00,2017-11-15 21:32:01+00:00,2017-11-15 21:32:02+00:00,Resolved,13116234,RATIS-134
Bug,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Critical,"Raft client should check the entry size before the command is send, This can otherwise lead to StatusRuntimeException. Checking the size on the client will help avoiding error handling on the RaftServer.",[],2017-11-04 17:55:58+00:00,2017-11-11 22:21:19+00:00,2017-11-11 22:21:19+00:00,Resolved,13116187,RATIS-133
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"The current situation is described in the BUILDING.md:

{code}
When building Ratis the first time, shaded files need to be generated by the following command:
```
$ mvn package -DskipTests
```
After that, `mvn compile` or `mvn test` can be used as normal.
For example, we may run the basic tests by
```
{code}

In short: the shading phase is bound to the 'package' maven phase, therefore we can't use 'mvn clean install' just 'mvn clean package' because the package phase should be done before the compilation of ratis-proto-shaded.

This blocks the nightly build as yetus uses one 'mvn clean compile' or 'mvn clean test-compile' without invoking the package phase.",[],2017-11-04 12:18:00+00:00,2017-11-08 01:52:07+00:00,2017-11-08 02:11:09+00:00,Resolved,13116147,RATIS-132
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,This JIRA is to setup our checkstyle coding conventions.  We probably should start with [Sun coding conventions|https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/sun_checks.xml] or [Google coding conventions|https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml].,[],2017-11-04 00:14:24+00:00,2018-11-14 21:26:14+00:00,2019-02-13 15:07:55+00:00,Resolved,13116096,RATIS-131
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,It seems that the Jerkins build is not using the correct command to build Ratis so that all the builds fail with compilation errors.  It probably has not generated the shaded source when build Ratis the first time.,[],2017-11-04 00:07:47+00:00,2018-01-24 20:28:22+00:00,2018-01-24 20:28:22+00:00,Resolved,13116095,RATIS-130
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, we uses skipShade to activate protobuf compilation and shading.  It is better to check if the corresponding shaded source directory is missing.",[],2017-11-03 22:35:49+00:00,2017-11-08 22:35:06+00:00,2017-11-10 18:50:12+00:00,Resolved,13116081,RATIS-129
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-shade-plugin is missing. @ org.apache.ratis:ratis-hadoop-shaded:[unknown-version], /Users/szetszwo/hadoop/incubator-ratis/ratis-hadoop-shaded/pom.xml, line 184, column 19
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for org.apache.ratis:ratis-proto-shaded:jar:0.1.1-alpha-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.xolstice.maven.plugins:protobuf-maven-plugin is missing. @ org.apache.ratis:ratis-proto-shaded:[unknown-version], /Users/szetszwo/hadoop/incubator-ratis/ratis-proto-shaded/pom.xml, line 491, column 19
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-shade-plugin is missing. @ org.apache.ratis:ratis-proto-shaded:[unknown-version], /Users/szetszwo/hadoop/incubator-ratis/ratis-proto-shaded/pom.xml, line 524, column 19
{code}
",[],2017-11-02 21:28:27+00:00,2017-11-03 21:55:05+00:00,2017-11-03 21:55:06+00:00,Resolved,13115755,RATIS-128
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"BaseStateMachine, SingleFileSnapshotInfo, FileListSnapshotInfo and SimpleStateMachineStorage are implementations.  They should be moved to a new package, say statemachine.impl.

For TransactionContext, it should be separated out the API and move the implementation to a new class.",[],2017-11-02 19:42:23+00:00,2018-01-27 01:23:06+00:00,2018-01-27 01:23:06+00:00,Resolved,13115725,RATIS-127
Bug,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,It may be a good idea to support HTrace for Ratis. It will help in debugging and performance profiling.,[],2017-11-01 23:16:41+00:00,,2018-07-20 21:27:35+00:00,Open,13115500,RATIS-126
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"StateMachineExceptionProto only has class name, message and stack trace but not the cause.

In the client side, it cannot see the real cause of the exception.",['ozone'],2017-11-01 22:46:38+00:00,,2019-08-22 17:16:58+00:00,Patch Available,13115494,RATIS-125
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RaftServerImpl.appendEntries, it first appends entries to RaftLog and then calls logSync().  It sync the last entry but not all the entries appended by this call.

This is a problem if data are written to state machine asynchronously.
",[],2017-11-01 22:35:18+00:00,2017-12-12 10:09:31+00:00,2017-12-12 15:49:53+00:00,Resolved,13115491,RATIS-124
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-122, we adds a File Store example which support the following operations
-	Write(path, data)
-	Read(path)
-	Delete(path)

In this JIRA, we add some CLIs so that servers and the clients can be run in command line.",[],2017-10-27 00:35:05+00:00,,2018-07-20 21:21:21+00:00,Open,13112444,RATIS-123
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"I propose to add a new FileStore example.  Below are the ideas:
- It uses Ratis to store files so that the files are replicated in a Raft group.
- It is not a file system -- it only supports basic operations such as read, write and delete but not ls, rename, etc.
- Its state machine stores the file data separated from the log in order to reduce the log size.
- It can be served as a Ratis performance test.",[],2017-10-17 18:23:17+00:00,2017-11-08 23:03:47+00:00,2017-11-08 23:03:47+00:00,Resolved,13110076,RATIS-122
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When the serverId is missing, it can be initialized automatically using the given properties such as host and port.

Also, the group should be automatically initialized to an empty group since group may not be known when starting a server.",[],2017-10-13 22:51:25+00:00,2017-11-02 20:38:33+00:00,2017-11-02 20:38:33+00:00,Resolved,13109397,RATIS-121
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,Current RaftClient.Builder requires user to initial clientRpc explicitly.  It is cleaner if clientRpc can be initialized automatically.,[],2017-10-13 22:10:40+00:00,2017-10-24 19:42:47+00:00,2017-10-24 19:42:47+00:00,Resolved,13109384,RATIS-120
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"[~linyiqun] has reported that RaftServerImpl.registerMBean may throw MalformedObjectNameException in HDFS-12593.
{code}
2017-10-10 14:50:01,163 [Datanode State Machine Thread - 0] ERROR impl.RaftServerImpl (RaftServerImpl.java:registerMBean(182)) - RaftServer JMX bean can't be registered
javax.management.MalformedObjectNameException: Invalid character ':' in value part of property
	at javax.management.ObjectName.construct(ObjectName.java:618)
	at javax.management.ObjectName.<init>(ObjectName.java:1382)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:179)
	...
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:126)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$0(DatanodeStateMachine.java:280)
	at java.lang.Thread.run(Thread.java:745)
{code}
This is probably due to HDFS using host:port as raft server id.",[],2017-10-10 15:21:12+00:00,2017-10-24 21:10:55+00:00,2017-12-13 06:31:36+00:00,Resolved,13108319,RATIS-119
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- A few ServerInformation related files does not have a license header.

- The shaded sources in ratis-hadoop-shaded should be excluded from rat, i.e. license header check.",[],2017-09-28 07:36:15+00:00,2017-09-28 08:01:33+00:00,2017-09-28 08:01:33+00:00,Resolved,13105679,RATIS-118
Test,[],yubox,Yubo Xu,yubox,Yubo Xu,Minor,"As described in Question 7 of the quiz at [https://ramcloud.stanford.edu/~ongaro/userstudy/quizzes.html], an old leader can complete the commitment of an old log entry satisfying certain requirements. We need tests to confirm Ratis behaves correctly under such cases.",[],2017-09-25 07:08:25+00:00,2017-11-09 21:16:09+00:00,2017-11-09 22:01:28+00:00,Resolved,13104670,RATIS-117
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"xmtsui has reported that there is a memory leak problem in PendingRequests.java
The field pendingRequests, can only be added, but no remove logic.

See https://github.com/hortonworks/ratis/issues/7",[],2017-09-19 05:05:58+00:00,2017-10-11 03:10:04+00:00,2017-10-11 03:10:04+00:00,Resolved,13103144,RATIS-116
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-111, we saw this problem but could not reproduce it.  I could reproduce this now -- just keep changing leader many many times.",[],2017-09-11 05:05:28+00:00,2017-09-28 03:28:55+00:00,2017-09-28 03:28:55+00:00,Resolved,13101151,RATIS-115
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"It may stop having any progress at some index until timeout.  For example, see [this log|https://issues.apache.org/jira/secure/attachment/12885286/org.apache.ratis.hadooprpc.TestRaftWithHadoopRpc-output.txt].",[],2017-09-06 08:27:57+00:00,2017-09-15 18:59:00+00:00,2017-09-16 02:44:49+00:00,Resolved,13100067,RATIS-114
New Feature,[],msingh,Mukul Kumar Singh,msingh,Mukul Kumar Singh,Major,"Raft Client currently only has a sync interface, an sync interface is needed for ozone",[],2017-08-25 07:52:30+00:00,2017-11-14 21:32:37+00:00,2017-11-14 21:32:37+00:00,Resolved,13097515,RATIS-113
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"RaftReconfigurationBaseTest.testRevertConfigurationChange may fail once a while.  It usually happens with TestRaftReconfigurationWithHadoopRpc although it also happens with other RPCs.

When it happens, it fails with AssertionError at line 577, i.e. newState remains false.",[],2017-08-24 19:04:25+00:00,2017-08-28 21:06:54+00:00,2017-08-28 21:06:54+00:00,Resolved,13097393,RATIS-112
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
Exception in thread ""RaftLogWorker for Storage Directory /Users/szetszwo/hadoop/incubator-ratis/ratis-server/target/test/data/e19600c7a0228b58/MiniRaftClusterWithSimulatedRpc/s3/group-E1192218-3981-4FC5-90BF-4CFB0D270F6B"" 2017-08-22 15:52:47,983 INFO  impl.RaftServerImpl (RaftLogWorker.java:execute(278)) - RaftLogWorker-s4 finalizing log segment /Users/szetszwo/hadoop/incubator-ratis/ratis-server/target/test/data/e19600c7a0228b58/MiniRaftClusterWithSimulatedRpc/s4/group-E1192218-3981-4FC5-90BF-4CFB0D270F6B/current/log_inprogress_0
org.apache.ratis.util.ExitUtils$ExitException: RaftLogWorker for Storage Directory /Users/szetszwo/hadoop/incubator-ratis/ratis-server/target/test/data/e19600c7a0228b58/MiniRaftClusterWithSimulatedRpc/s3/group-E1192218-3981-4FC5-90BF-4CFB0D270F6B failed.
	at org.apache.ratis.util.ExitUtils.terminate(ExitUtils.java:88)
	at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:185)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: File /Users/szetszwo/hadoop/incubator-ratis/ratis-server/target/test/data/e19600c7a0228b58/MiniRaftClusterWithSimulatedRpc/s3/group-E1192218-3981-4FC5-90BF-4CFB0D270F6B/current/log_inprogress_0 does not exist.
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:60)
	at org.apache.ratis.server.storage.RaftLogWorker$FinalizeLogSegment.execute(RaftLogWorker.java:280)
	at org.apache.ratis.server.storage.RaftLogWorker.run(RaftLogWorker.java:155)
	... 1 more
{code}",[],2017-08-22 23:18:45+00:00,2017-09-07 06:19:01+00:00,2017-09-07 06:19:01+00:00,Resolved,13096871,RATIS-111
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Currently, we directly use a constructor to create ClientId / RaftGroupId.  It is better to use valueOf instead of a constructor since the return value can possibly be cached in the future.",[],2017-08-22 22:39:48+00:00,2017-09-02 02:29:25+00:00,2017-09-02 02:29:25+00:00,Resolved,13096862,RATIS-110
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In RATIS-100, a large part of the patch is just code refactoring and improving log messages. We separate them to this JIRA.",[],2017-08-21 21:04:03+00:00,2017-08-23 18:53:22+00:00,2017-08-23 18:53:22+00:00,Resolved,13096567,RATIS-109
Test,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"As the title suggested, all tests should have a timeout.",[],2017-08-17 23:45:45+00:00,2017-08-21 22:20:27+00:00,2017-08-21 22:20:28+00:00,Resolved,13095491,RATIS-108
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In order to avoid servers being accidentally reinitialized incorrectly, we propose that reinitialize must be applied from an empty group to a non-empty group, or from a non-empty group to an empty group.
",[],2017-08-16 22:34:44+00:00,2018-09-25 22:52:53+00:00,2018-09-25 22:52:53+00:00,Resolved,13095174,RATIS-107
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"The server storageDir is converted from/to String, File and URI in different code locations and tests.  Let's consistently use File for it (except for writing it as String to RaftProperties).",[],2017-08-16 21:28:02+00:00,2017-08-17 21:33:26+00:00,2017-08-17 21:33:26+00:00,Resolved,13095152,RATIS-106
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-100, we found a bug that a server may response to another server with different group so that a cluster with multiple groups may not work correctly.  The solution is to check the group id for each server request before responding to it.

In this JIRA, we add a similar group id check for the client requests.",[],2017-08-14 23:23:16+00:00,2017-09-04 21:56:03+00:00,2017-09-05 06:14:02+00:00,Closed,13094638,RATIS-105
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We propose to add a getServerInfo RPC to get server information from a server.,[],2017-08-14 21:28:14+00:00,2017-09-12 04:32:23+00:00,2017-09-28 07:36:57+00:00,Resolved,13094604,RATIS-104
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"The CopyOnWriteArrayList may not work well in LeaderState since it does not support remove.

RaftReconfigurationBaseTest.testRemovePeers() fails with UnsupportedOperationException.
{code}
Exception in thread ""Thread-102"" java.lang.UnsupportedOperationException
        at java.util.concurrent.CopyOnWriteArrayList$COWIterator.remove(CopyOnWriteArrayList.java:1176)
        at org.apache.ratis.server.impl.LeaderState.updateSenders(LeaderState.java:254)
        ...
{code}",[],2017-08-11 19:06:17+00:00,2017-08-12 22:30:24+00:00,2017-08-12 22:30:24+00:00,Resolved,13094175,RATIS-103
Bug,[],elek,Marton Elek,elek,Marton Elek,Major,"RATIS-49 introduced new profiles to cleanup the generated sources/proto files in the shaded artifacts.

I suggest to make it more easier by binding the additional {clean:clean} plugin calls to the clean phase of the default clean lifecycle instead of trigger them from a separated profile.  

In RATIS-4 I experimenting  with build scripts and yetus test-patch script. As the simple {{mvn clean}} command is more common, it would be easier to switch to the simple clean without the profile.

The cleanup could be done with triggering additional clean plugin execution.

To test:
{code}
git checkout 52c4b64
mvn clean package -DskipTests
git checkout master
mvn clean package -DskipTests
{code}

Without the patch the second only works with -Pclean-shade, with the proposed patch it works without activating any additional profile",['build'],2017-08-11 13:27:04+00:00,2017-11-02 21:45:59+00:00,2017-11-04 12:22:13+00:00,Resolved,13094097,RATIS-102
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- We can avoid copying bytes by using ByteString.
- ByteString is immutable.",[],2017-08-04 20:42:51+00:00,2017-08-07 22:27:36+00:00,2017-08-07 22:27:36+00:00,Resolved,13092600,RATIS-101
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We found the following bugs when trying to add a test similar to ReinitializationBaseTest.runTestReinitializeMultiGroups(..) with a state machine.
- In PendingRequests, the {{last}} PendingRequest is not updated in addConfRequest(..).
- In RaftServerImpl, it should check if the group in the request is the same as the group in the server.
- In StateMachineUpdater, it should join the updater thread in stop().",[],2017-08-02 21:14:15+00:00,2017-09-04 21:19:16+00:00,2017-09-05 05:53:00+00:00,Resolved,13092006,RATIS-100
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"The current checkstyle report is too noisy as all of the copied sources are also checked. 

I propose to exclude all the shaded files from proto-shaded/hadoop-shaded.",[],2017-07-28 14:23:51+00:00,2017-07-28 20:38:51+00:00,2017-07-28 20:38:51+00:00,Resolved,13090790,RATIS-99
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,RaftId may convert the same UUID to byte[] and String multiple times.  It is better to cache it.,[],2017-07-28 00:23:26+00:00,2017-08-02 22:13:01+00:00,2017-08-02 22:13:01+00:00,Resolved,13090655,RATIS-98
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Here is an example: Suppose a group has 3 servers and one of them is the leader.  Use setConfiguration to add 6 more servers.  The leader is still running as a leader although it does not has majority anymore.  The 6 new servers may elect a new leader among them.  Finally, there are two leaders in the group.",[],2017-07-25 21:28:40+00:00,2017-08-11 05:43:51+00:00,2017-08-11 05:43:51+00:00,Resolved,13090051,RATIS-97
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{code}
java.lang.ArrayIndexOutOfBoundsException: 0
	at org.apache.ratis.server.impl.LeaderState.computeLastCommitted(LeaderState.java:490)
	at org.apache.ratis.server.impl.LeaderState.updateLastCommitted(LeaderState.java:400)
	at org.apache.ratis.server.impl.LeaderState.handleEvent(LeaderState.java:329)
	at org.apache.ratis.server.impl.LeaderState.access$500(LeaderState.java:48)
{code}
This happens when followers is empty and not includeSelf == false.
",[],2017-07-20 21:22:30+00:00,2017-08-01 06:33:33+00:00,2017-08-01 17:59:10+00:00,Resolved,13088900,RATIS-96
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"The current example project shows an example implementation of the base interfaces. I suggest to create simple CLI application for the test (just an additional class with main and argument parsing) to make it easier to demonstrate how a ratis cluster could be run.

For example:

{code}
java -jar ratis-examples-uber.jar --port 2323 --id node2 --peers node3:localhost:4566,node1:localhost:3456  
{code}",[],2017-07-20 16:06:46+00:00,2017-11-17 21:54:35+00:00,2017-11-17 22:04:20+00:00,Resolved,13088808,RATIS-95
Improvement,[],elek,Marton Elek,elek,Marton Elek,Major,"To make it easier to debug the current state of the nodes the basic RatisServer information should be exposed over the JMX interface. Such as: role (leader,follower), latest term, index, follower peers (in case of LEADER)",[],2017-07-20 16:02:41+00:00,2017-08-11 05:31:29+00:00,2017-08-11 19:08:40+00:00,Resolved,13088807,RATIS-94
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"When randomly selecting a peer, we first copy the peer list and then select a peer in a loop indefinitely until a new peer is found.

We could first filter the peers when copying the list.  Then, we can eliminate the loop.",[],2017-07-11 00:08:01+00:00,2017-07-11 20:39:50+00:00,2017-07-11 21:02:13+00:00,Resolved,13086114,RATIS-93
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"getClassByName and getClassByNameOrNull can be changed to static.  Then, they become independent of RaftProperties.  It is better to move them to ReflectionUtils.",[],2017-06-22 14:48:02+00:00,2017-06-23 03:33:56+00:00,2017-06-23 03:33:56+00:00,Resolved,13081809,RATIS-92
New Feature,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"In some of the use cases, each node can belong to multiple raft groups at the same time. We will use this jira as an umbrella jira to support the feature.",['ozone'],2017-05-30 17:44:42+00:00,2018-11-30 23:27:10+00:00,2019-03-22 05:27:49+00:00,Resolved,13075900,RATIS-91
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"This is an issue found by Nicholas: currently after the client hit an IOException when submitting request to a server (say s0 dies), it always pick the ""next"" raft server (say s1) in its local server list. If s1 returns a NotLeaderException and suggests s0 as the new leader, then the client may go into the same process again. We should let the client randomly pick a server from the list when it hits an exception and does not know which server is the new leader.",[],2017-05-24 21:25:30+00:00,2017-05-29 17:27:27+00:00,2017-05-29 17:27:27+00:00,Resolved,13074653,RATIS-90
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"To support the scenario where a raft server belongs to multiple raft groups, we need to add globally unique ID for each raft group.",[],2017-05-19 21:58:23+00:00,2017-06-14 02:45:17+00:00,2017-06-14 02:45:17+00:00,Resolved,13073582,RATIS-89
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"In any Ratis application, the number of distinct RaftPeerId objects are very small.  We enforce using valueOf methods to get RaftPeerId so that the RaftPeerId objects can be cached.  Then, we don't have to create new RaftPeerId objects for each rpc request.",[],2017-05-12 20:57:42+00:00,2017-05-15 18:25:09+00:00,2017-05-15 18:25:09+00:00,Resolved,13071673,RATIS-88
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Separate RaftServerImpl into proxy and impl
- Proxy: reads rpc requests and propagates them to impl.  It also can start/stop  Impl.
- Impl: captures the server state and handles rpc request.",[],2017-05-05 23:36:47+00:00,2017-05-10 20:58:43+00:00,2017-05-30 18:20:12+00:00,Resolved,13069618,RATIS-87
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"When a RaftServer is built, it creates a RaftServerImpl object and starts running a RaftServerRpc service.  The RaftServerImpl captures ServerState including RaftLog and RaftConfiguration.

We want to support server re-initialization so that a server can support multiple raft clusters sequentially.  This is our first step to support multi-raft.",[],2017-05-05 23:31:57+00:00,2017-05-19 18:24:06+00:00,2017-05-30 18:21:25+00:00,Resolved,13069615,RATIS-86
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,,[],2017-05-03 19:39:55+00:00,2017-05-12 23:42:38+00:00,2017-05-12 23:42:38+00:00,Resolved,13068900,RATIS-85
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"- Exclude dependency-reduced-pom.xml.
- Use a better mvn command to get project.name and project.artifactId.
- Show the mvn commands being executed.
- Improve the echo messages.",[],2017-04-29 01:31:02+00:00,2017-05-02 00:06:14+00:00,2017-05-02 00:06:14+00:00,Resolved,13067865,RATIS-84
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We also need a DISCLAIMER file according to http://incubator.apache.org/guides/branding.html#disclaimers,[],2017-04-28 21:43:24+00:00,2017-05-01 20:38:18+00:00,2017-05-01 20:38:18+00:00,Resolved,13067822,RATIS-83
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,,[],2017-04-28 20:52:06+00:00,2017-05-10 17:58:07+00:00,2017-05-10 17:58:07+00:00,Resolved,13067807,RATIS-82
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The license header is missing.,[],2017-04-27 22:57:31+00:00,2017-04-28 01:18:52+00:00,2017-04-28 01:18:52+00:00,Resolved,13067551,RATIS-81
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, all the project names start with ""Ratis"".  We should change the name prefix to ""Apache Ratis"".",[],2017-04-27 19:33:00+00:00,2017-04-27 20:09:10+00:00,2017-04-28 01:19:15+00:00,Resolved,13067482,RATIS-80
Wish,[],nielsbasjes,Niels Basjes,nielsbasjes,Niels Basjes,Major,"A few weeks ago I attended the presentation in Munich about Ratis.
I had an idea on how the adoption of Ratis can be improved.

Apache Curator makes using zookeeper easy.
So if a development team only has to change a dependency (so instead of curator use raftcurator) and with as few code changes as possible they can experiment with raft. Then the switching cost of a project will go down a lot and the probability of switching increases.

So my proposal is: Make a wrapper/library that is a 100% drop in replacement for Apache Curator. All externally facing package names, classnames and methods are 'the same' and behave 'the same'.

P.S. Perhaps this ticket should be implemented at the curator end instead of here. I let you decide.

",[],2017-04-25 07:02:59+00:00,,2017-04-25 07:02:59+00:00,Open,13066594,RATIS-79
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,Currently the ratis code base cannot get compiled in Intellij because the Forked Tomcat Native cannot get located.,[],2017-04-21 23:22:50+00:00,2017-04-25 15:44:22+00:00,2017-04-25 15:44:37+00:00,Resolved,13066032,RATIS-78
Bug,[],kaiyangzhang,kaiyangzhang,kaiyangzhang,kaiyangzhang,Major,"*Maybe a bug, look at the comments in the code and GRpc.proto*



{code:title=GRpc.proto|borderStyle=solid}
   ......
   ......
   //Executes a client-streaming call , return only one response.
   rpc installSnapshot(stream ratis.common.InstallSnapshotRequestProto)
      returns(ratis.common.InstallSnapshotReplyProto) {}
   .......
   .......
{code}
{code:title=RaftServerProtocolService.java |borderStyle=solid}
    ........
    ........
    @Override
  public StreamObserver<InstallSnapshotRequestProto> installSnapshot(
      StreamObserver<InstallSnapshotReplyProto> responseObserver) {
    return new StreamObserver<InstallSnapshotRequestProto>() {
      @Override
      public void onNext(InstallSnapshotRequestProto request) {
        try {
          //receive a client-streaming call, return a response stream
          //code and GRpc.proto inconsistent
          final InstallSnapshotReplyProto reply = server.installSnapshot(request);
          responseObserver.onNext(reply);
        } catch (Throwable e) {
          LOG.info(""{} got exception when handling installSnapshot {}: {}"",
              id, request.getServerRequest(), e);
          responseObserver.onError(RaftGrpcUtil.wrapException(e));
        }
      }
   ..........
   ..........
{code}



",[],2017-04-21 09:33:31+00:00,,2018-07-20 21:25:09+00:00,Open,13065819,RATIS-77
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"RATIS-70 separates term/index/offset and entry content in {{LogSegment}}. Now {{LogSegment}} can always holds term/index/offset part in memory as index, and load log entry into a cache only when necessary. In this jira we will add a cache loading policy in {{LogSegment}}.",[],2017-04-13 20:43:04+00:00,2017-04-26 17:57:07+00:00,2017-04-26 17:57:07+00:00,Resolved,13063921,RATIS-76
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Critical,"We need to provide document about how to use Ratis library. Things to cover:
# How to run ratis on top of your current RPC engine
# How to integrate your state machine",[],2017-04-13 19:54:17+00:00,,2018-07-18 21:42:53+00:00,Open,13063914,RATIS-75
Bug,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Critical,If you using the profile {{release}} you will get a failure based on the missing dependency for the {{enforceBytecodeVersion}.,[],2017-04-13 14:37:53+00:00,2017-04-25 15:57:07+00:00,2017-04-25 15:57:08+00:00,Resolved,13063809,RATIS-74
Improvement,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Trivial,Upgrading the apache-rat-plugin to 0.12 and remove the rest of the configuration cause it's the default.,[],2017-04-13 14:32:59+00:00,2017-04-13 18:21:15+00:00,2017-04-25 15:59:40+00:00,Resolved,13063807,RATIS-73
New Feature,[],atrivedi,Animesh Trivedi,atrivedi,Animesh Trivedi,Minor,"We want to enable Ratis to run on high-performance RDMA networks. There has already been quite a bit of activity in leveraging RDMA networks in modern data processing stacks. Distributed consensus is one of the problems that can be accelerated using high-performance/RDMA messaging. 

We start by implementing a Ratis RPC implementation using DiSNI and DaPRC modules (https://github.com/zrlio/) for RDMA networks. ",[],2017-04-12 14:22:00+00:00,,2017-11-08 02:27:43+00:00,Open,13063502,RATIS-72
Improvement,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Trivial,"Currently there several plugins usages which look like this:
{code:xml}
             <groupId>org.apache.maven.plugins</groupId>
             <artifactId>maven-shade-plugin</artifactId>
             <version>${maven-shade-plugin.version}</version>
{code}
which is superfluous cause the versions are already defined via the pluginManagement in parent.",[],2017-04-06 19:41:47+00:00,2017-04-10 07:52:23+00:00,2017-04-10 07:52:23+00:00,Resolved,13062225,RATIS-71
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"The current RaftLogCache consists of LogSegment, and logSegment consists of log entries. Instead of directly storing all the log entries, we should separate the term/index/offset information and the entry content information. The former part is more like the index information and can be always kept in the memory. The entry content part can later be evicted from the memory based on eviction policies.",[],2017-04-06 18:07:54+00:00,2017-04-17 17:53:25+00:00,2017-04-17 17:53:25+00:00,Resolved,13062191,RATIS-70
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"This is actually a TODO in RaftLogCache: in the current simple implementation of segmented log, we cache all the segments in memory. We will use this jira to provide a more usable log and cache implementation.",[],2017-04-06 18:04:19+00:00,2018-02-02 22:49:57+00:00,2018-02-02 22:49:57+00:00,Resolved,13062186,RATIS-69
Improvement,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Trivial,"Every child pom has in it's parent:

{code:xml}
  <modelVersion>4.0.0</modelVersion>
  <parent>
    <artifactId>ratis</artifactId>
    <groupId>org.apache.ratis</groupId>
    <version>0.1-SNAPSHOT</version>
    <relativePath>..</relativePath>
  </parent>
  ..
  <version>0.1-SNAPSHOT</version>
{code} where the entry for {{relativePath}} is simply not needed, cause it the default in Maven.
Furthermore each child defines the version which is also not needed cause it's inherited from the parent. This can be simplified.

I have attached an appropriate patch to fix the issue.",[],2017-04-05 23:00:13+00:00,2017-04-06 18:21:29+00:00,2017-04-06 18:21:29+00:00,Resolved,13061898,RATIS-68
Bug,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Critical,"The {{BUILDING.md}} file claims to build RATIS for the first time via:
{code}
mvn package -DskipTests
{code}
which simply fails with the following output:
{code}
[ERROR] Failed to execute goal on project ratis-hadoop-shaded: Could not resolve dependencies for project org.apache.ratis:ratis-hadoop-shaded:jar:0.1-SNAPSHOT: Failure to find org.apache.hadoop:hadoop-common:jar:3.0.0-alpha1 in http://localhost:8081/nexus/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced -> [Help 1]
{code}
This looks like those dependencies are used instead of being dependencies defined by {{<optional>true</optional}}...",[],2017-04-05 22:56:46+00:00,2017-04-13 10:43:14+00:00,2017-04-13 15:22:33+00:00,Closed,13061896,RATIS-67
Improvement,[],khmarbaise,Karl Heinz Marbaise,khmarbaise,Karl Heinz Marbaise,Trivial,I have taken a look into your pom file and seen that you have defined {{make-maven-plugin}} which is a plugin from 2009 ? Are you really have need for this? Furthermore I have taken a look at MojoHaus (former codehaus) there does not exist any references of this plugin which means it is not supported nor developer in any kind?,[],2017-04-05 22:35:13+00:00,2017-04-06 18:16:45+00:00,2017-04-06 18:16:45+00:00,Resolved,13061890,RATIS-66
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As suggested by [~enis] below, we should add a script to automate the release process.
{quote}
On an unrelated note, what can help us for driving frequent releases is to have a script to drive the release process. I think we should do something like this: https://github.com/apache/hbase/blob/master/dev-support/make_rc.sh. 
{quote}",[],2017-04-02 13:55:41+00:00,2017-04-28 21:24:43+00:00,2017-04-28 21:24:43+00:00,Resolved,13060971,RATIS-65
Bug,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"Hugo and I were discussing a case were the shading should happen at the last step, rather than what we do today. 

I think there are 3 possible strategies of shading that one can do: 
 (1) pre-shade some of your dependencies, so that your other dependencies can work. This what we do today, we shade PB+ GRPC, etc so that Hadoop can work. 
 (2) pre-shade some of your dependencies' transitive dependencies so that you depend on already-shaded artifacts. This will be like having maven artifacts of shaded-hadoop so that hadoop itself does not bring in any more dependency. If hadoop has shaded artifacts, or we do shading of hadoop's dependencies in another repository, we won't need to pre-shade PB, etc. 
 (3) post-shade. This means that in the code itself we do not depend on shaded packages anymore, but do the shading as a different module so that we publish shaded artifacts. This allows the downstreamers to be able to consume ratis, while allowing ratis source code to be saner. 

Obviously for doing (3), we need to kick out ratis-hadoop module to the hadoop project. Thinking about it, I think ratis-hadoop does not belong in Ratis itself anyway. What do you guys think about moving the code over to Hadoop, and getting rid of the hadoop dependency to end this shading madness? ",[],2017-04-01 20:24:01+00:00,2018-11-15 18:36:28+00:00,2018-11-15 18:36:28+00:00,Resolved,13060931,RATIS-64
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"According to [Licensing Documentation|http://www.apache.org/legal/release-policy.html#licensing-documentation], we need a NOTICE file.",[],2017-04-01 13:02:36+00:00,2017-04-28 21:20:01+00:00,2017-04-28 21:20:01+00:00,Resolved,13060898,RATIS-63
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,This is a TODO in RaftServerImpl#appendTransaction. The IOException thrown by {{applyLog}} is actually from the {{StateMachine#preAppendTransaction}}. This exception should be return to RaftClient as a {{StateMachineException}}.,[],2017-03-31 21:12:04+00:00,2017-03-31 22:17:59+00:00,2017-03-31 22:17:59+00:00,Resolved,13060804,RATIS-62
Sub-task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"Replicated map is like zookeper, where there is a fixed set of known-hosts in the quorum. No reconfiguration yet. 

{code}
QuorumSupplier::List<RaftPeer> getQuorum()
{code}",[],2017-03-30 21:13:51+00:00,,2018-07-20 21:14:21+00:00,Open,13060499,RATIS-61
Sub-task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"Right now, for flexibility, both Message and SMLogEntry are ByteStrings. This allows using custom serialization formats other than PB (or maybe use a different  version of PB). 

However, this is very inefficient for the common case where both the messages and SM Log Entries are themselves PB objects. We unnecessarily serialize twice. ",[],2017-03-30 21:02:54+00:00,,2018-07-20 21:14:43+00:00,Open,13060493,RATIS-60
Sub-task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,Changes to bin/ scripts for the Rmap server and CLI. ,[],2017-03-30 20:44:01+00:00,,2018-07-20 21:14:32+00:00,Open,13060489,RATIS-59
Sub-task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,The PB file for the replicated map RPC. ,[],2017-03-30 20:39:29+00:00,2017-04-10 07:57:30+00:00,2017-04-10 07:57:30+00:00,Resolved,13060486,RATIS-58
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"According to [Prepare your POMs for release|http://www.apache.org/dev/publishing-maven-artifacts.html#prepare-poms], the following command can test the pom.
{code}
mvn release:prepare -DdryRun=true -DautoVersionSubmodules=true
{code}
The JIRA is to fix the unexpected diff between pom.xml and pom.xml.tag.",[],2017-03-30 10:06:55+00:00,2017-03-31 00:04:56+00:00,2017-03-31 00:04:56+00:00,Resolved,13060321,RATIS-57
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"We may use the following command to update the project version from 0.1-SNAPSHOT to 0.1.0-alpha.
{code}
find . -name pom.xml | xargs sed -i.old ""s/0.1-SNAPSHOT/0.1.0-alpha/g"" 
{code}",[],2017-03-30 06:59:59+00:00,2017-05-03 01:35:25+00:00,2017-05-03 05:44:32+00:00,Resolved,13060267,RATIS-56
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"{{mvn apache-rat:check}} reports that a few files do not have the license header. 
",[],2017-03-30 06:29:59+00:00,2017-03-30 20:38:38+00:00,2017-03-30 20:38:38+00:00,Resolved,13060259,RATIS-55
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"[~enis] found that some earlier Maven 3.x version does not work well; see [this comment|https://issues.apache.org/jira/browse/RATIS-47?focusedCommentId=15935648&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15935648].

Maven 3.3.9 is the latest stable release, released on 2015-11-14; see https://maven.apache.org/docs/history.html

It seems reasonable to require Maven 3.3.9.",[],2017-03-30 06:07:21+00:00,2017-04-04 06:15:27+00:00,2017-04-04 06:15:27+00:00,Resolved,13060254,RATIS-54
Task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As [discussed in the dev mail list|https://lists.apache.org/thread.html/13c7d789db991ca26a23c4851fd0478b324ebf79430051da2abcffd2@%3Cdev.ratis.apache.org%3E], we have decided to roll our first Alpha release.  The JIRA is to track the tasks required to roll the release.",[],2017-03-30 05:06:24+00:00,2017-07-11 00:11:05+00:00,2017-07-11 00:11:06+00:00,Resolved,13060245,RATIS-53
Improvement,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"Ideally we should not have a generic {{RaftUtils}} class. The code should be broken up into at least: 
{code}
ReflectionUtils -> All reflection, construction, initialization logic 
IOUtils -> Add buffer and IO logic 
SystemUtils or PlatformUtils -> OS type detection, etc 
Preconditions (or something like that) -> assertTrue, etc 
{code}",[],2017-03-29 18:30:46+00:00,2017-04-10 07:43:24+00:00,2017-04-10 07:43:24+00:00,Resolved,13060107,RATIS-52
Sub-task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,,[],2017-03-29 02:42:33+00:00,2017-03-30 20:42:26+00:00,2017-03-30 20:42:27+00:00,Resolved,13059909,RATIS-51
Wish,[],kaiyangzhang,kaiyangzhang,kaiyangzhang,kaiyangzhang,Minor,"*current:*  
  *one* ""RaftClientProtocolService, RaftServerProtocolService"" to *one* ""RaftPeerId , RaftServerProtocol "".

*wish:*
  *one* ""RaftClientProtocolService, RaftServerProtocolService"" to *many* ""RaftPeerId , RaftServerProtocol "".

",[],2017-03-22 05:31:28+00:00,2018-01-24 20:35:14+00:00,2018-01-24 20:35:14+00:00,Resolved,13058101,RATIS-50
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"There is no way to remove the shaded source using mvn.  We have to remove them manually by
- rm -rf ratis-proto-shaded/src/main/java
- rm -rf ratis-hadoop-shaded/src/main/java
",[],2017-03-21 19:38:32+00:00,2017-03-29 02:40:42+00:00,2017-03-29 02:40:42+00:00,Resolved,13057987,RATIS-49
Test,[],kaiyangzhang,kaiyangzhang,kaiyangzhang,kaiyangzhang,Minor,"1.Environment
||IP||Network card||Disk||Software||
| 192.168.3.166|10 Gigabit|SSD|RaftPeer0, benchmark|
| 192.168.3.167|10 Gigabit|SSD|RaftPeer1|
| 192.168.3.168|10 Gigabit|SSD|RaftPeer2|

2.JVM 
|Xms = 16GB|
|Xmx =  16GB|

3.RaftProperties

|RAFT_SERVER_LOG_APPENDER_FACTORY_CLASS_KEY|pipelineLogAppenderFactory.class|
|RAFT_OUTPUTSTREAM_BUFFER_SIZE_KEY|1024*1024 byte|
|RAFT_LOG_SEGMENT_MAX_SIZE_KEY|1024*1024*128 byte|

4.Speed
(1) TPS: avg speed of the lastest 5 seconds
      Min = 1024 byte * 20000
      Max = 1024 btye * 50000
(2) AVG: avg speed
     AVG = 1024 byte * 40000 = 40MB/s

",[],2017-03-21 02:39:35+00:00,2018-02-02 22:53:59+00:00,2018-02-02 22:53:59+00:00,Resolved,13057763,RATIS-48
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Even we do not use google guava internally, gRPC still depends on it.  Therefore, we need to shade it.",[],2017-03-17 23:03:28+00:00,2017-03-20 22:44:24+00:00,2017-03-23 21:02:14+00:00,Resolved,13057187,RATIS-47
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We should remove the dependencies on commons-io and commons-lang since we don't really need them. ,[],2017-03-17 20:59:03+00:00,2017-03-20 21:42:42+00:00,2017-03-20 21:42:42+00:00,Resolved,13057157,RATIS-46
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-44, all the modules have a transitive dependency on gRPC.  We should move gRPC out.",[],2017-03-16 23:51:34+00:00,2017-03-21 00:05:36+00:00,2017-03-21 00:05:36+00:00,Resolved,13056852,RATIS-45
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,The dependency tree shows that all the ratis modules have a transitive dependency to hadoop since everything depends on ratis-proto-shaded and ratis-proto-shaded depends on hadoop (in order to shade it).,[],2017-03-16 23:39:52+00:00,2017-03-17 22:01:18+00:00,2017-03-17 22:01:18+00:00,Resolved,13056846,RATIS-44
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Minor,"RaftClientProtocolService#client is actually not a client, but a service implementation. We should rename it to {{impl}} maybe.",[],2017-03-16 23:27:47+00:00,2017-03-17 18:08:42+00:00,2017-03-17 18:08:42+00:00,Resolved,13056842,RATIS-43
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,We need to shade netty so that the user application can use a different version of netty.,[],2017-03-15 21:53:05+00:00,2017-03-17 21:58:20+00:00,2017-03-17 21:58:20+00:00,Resolved,13056455,RATIS-42
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to RATIS-39, we remove the use of google guava in the ratis-common module.",[],2017-03-14 00:39:12+00:00,2017-03-20 21:46:58+00:00,2017-03-20 21:46:58+00:00,Resolved,13055783,RATIS-41
New Feature,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"Ratis replicated map is an implementation of a sorted map (think TreeMap) as a replicated state machine. This is not under examples because it is intended to be used in production where a simple in-memory map is sufficient to hold the data. The data is fully cached in memory, but it is still durable since raft log is used as a replicated log, and data is snapshotted periodically.

The replicated map (RMap) is not only the state machine implementation, but all of the remaining code, including the client and querying capabilities which is built on top of the other modules. In that sense, it is dog-fooding the ratis library to implement an end-to-end solution for a replicated in-memory data store.

Replicated maps are conceptually similar to ZooKeeper/Etcd/LogCabin where the data is hosted in a known cluster configuration and is not sharded. All the servers in the cluster participate in a single RAFT ring.

The data model is that users can create independent RMap instances in the cluster and read / write or scan the data as key value pairs in those replicated maps. A replicated map named the meta map contains information about all of the other maps in the cluster.",[],2017-03-11 04:13:46+00:00,,2020-03-06 20:00:00+00:00,Open,13050219,RATIS-40
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In order to allow user application using google guava, we should either not using it or shade it.

Except for ratis-common, we can replace google guava by:
- Preconditions: add similar methods in our util.  
- VisibleForTesting: remove it.
- ThreadFactoryBuilder: use Daemon::new
- Charsets: use StandardCharsets
- Lists, ImmutableList: use java collections
- Throwables; just throw IOException
",[],2017-03-10 02:40:42+00:00,2017-03-14 19:25:10+00:00,2017-03-14 22:42:50+00:00,Resolved,13049848,RATIS-39
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,RaftClient should only retry for exceptions happening during the raft replication. Exception coming from the StateMachine should be handled by the higher level client (the client that uses RaftClient for replication).,[],2017-03-09 19:25:19+00:00,2017-03-16 20:10:39+00:00,2017-03-16 20:10:40+00:00,Resolved,13049721,RATIS-38
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"With SizeInBytes and TimeDuration, the size and time properties can be specified with human readable format such as 16MB, 300ms, etc.",[],2017-03-09 00:57:42+00:00,2017-03-10 00:33:27+00:00,2017-03-10 00:33:27+00:00,Resolved,13049458,RATIS-37
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In RATIS-34, we change RaftServerConfigKeys to use ConfUtils.  We do similar changes here for RaftClientConfigKeys, RaftConfigKeys, RaftGrpcConfigKeys, HadoopConfigKeys and NettyConfigKeys.
",[],2017-03-07 01:00:00+00:00,2017-03-08 23:18:43+00:00,2017-03-08 23:18:43+00:00,Resolved,13048716,RATIS-36
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Minor,"After RATIS-34, there are a couple of methods in ConfUtils with ""Possible heap pollution from parameterized vararg type"" warning. We can add SafeVarargs annotations to suppress the warning.",[],2017-03-07 00:10:02+00:00,2017-03-10 00:07:08+00:00,2017-03-10 00:07:08+00:00,Resolved,13048704,RATIS-35
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"The methods in ConfUtils make the code shorter, easier to read and less error prone.  We should use them to get and set RaftServerConfigKeys",[],2017-03-02 23:40:47+00:00,2017-03-06 23:42:52+00:00,2017-03-06 23:42:52+00:00,Resolved,13047848,RATIS-34
Bug,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"In RATIS-26 we specify the following activation conditions for compiling protobuf files:
{code}
      <activation>
        <!-- Activate this if the generated source directory is missing. It will automatically
         kick the protoc compilation if you are doing a mvn install for the first time. Otherwise
         it will only compile the resources under src/main/java as usual.  If you want to
         force-compile the proto files (for example after changing them), you should run with
         mvn install -Dcompile-protobuf -->
        <file>
          <missing>${sources.dir}</missing>
        </file>
        <property>
          <name>compile-protobuf</name>
        </property>
      </activation>
{code}

This does not work after maven version 3.2.2, due to MNG-4565 that changes the activation condition relationships from OR to AND. Thus we have to do both 1) delete ratis-proto-shaded/src/main/java, and 2) include -Dcompile-protobuf in the command to trigger the protobuf compilation.",[],2017-03-01 00:28:13+00:00,2017-03-02 22:40:51+00:00,2017-03-02 22:40:51+00:00,Resolved,13047139,RATIS-33
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"As suggest by [~jingzhao] in RATIS-22, let's do the rename.",[],2017-02-28 22:58:59+00:00,2017-02-28 23:57:17+00:00,2017-03-01 00:21:29+00:00,Resolved,13047128,RATIS-32
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"This JIRA is to address [~jingzhao] comment in RATIS-28
{quote}
Maybe we should consider using RpcType as an internal util stuff instead of exposing it in public interfaces, considering most library users will have to integrate the Ratis library with their own RPC engine.
{quote}",[],2017-02-27 21:56:18+00:00,2017-02-28 01:44:04+00:00,2017-02-28 01:44:04+00:00,Resolved,13046772,RATIS-31
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In this JIRA, we address the following comment from [~jingzhao] in RATIS-28.
{quote}
We can consider use some other way for library users to pass extra configuration objects for their RPC engine (e.g., Hadoop Configuration) into the RPC factory. In this way we can get a neater API for RPC creation and avoid using an lazy initialization supplier in RaftServerImpl.
{quote}",[],2017-02-25 00:31:22+00:00,2017-03-04 01:31:09+00:00,2017-03-04 01:31:09+00:00,Resolved,13046211,RATIS-30
Bug,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"We need {{bin/}} scripts. I will model those from HBase (and not Hadoop). I am not very fond of Hadoop's layout, and it is unnecessarily complex for ratis for now. ",[],2017-02-24 18:49:40+00:00,,2018-07-20 21:38:17+00:00,Open,13046114,RATIS-29
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"In order to support pluggable rpc, user is supposed to first choose an rpc implementation to create a RaftServerRpc rpc.  Then create a RaftServer server.  Finally, call server.setServerRpc(rpc) to connect these two objects.

In this JIRA, we add a RpcType property and use it to initialize RaftServer and then automatically create RaftServerRpc from the RpcType.",[],2017-02-23 02:33:13+00:00,2017-02-25 00:17:59+00:00,2017-02-25 00:17:59+00:00,Resolved,13045481,RATIS-28
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,"Enforce all the tests to use the factory methods to create MiniRaftCluster so that we may setup RaftProperties in centralized locations.

We also change the HadoopRpcService to not throwing IOException.  Then, MiniRaftCluster creation also no longer needs to throw IOException.


",[],2017-02-23 00:19:37+00:00,2017-02-23 02:24:04+00:00,2017-02-23 02:24:04+00:00,Resolved,13045453,RATIS-27
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"Currently developers need to enter the ratis-proto-shaded directory and run ""mvn package -Dcompile-protobuf"" to compile shaded sources. This is not convenient when updating protobuf definitions. We can make this step a default step.",[],2017-02-22 23:25:23+00:00,2017-02-25 01:50:08+00:00,2017-02-25 01:50:09+00:00,Resolved,13045435,RATIS-26
Bug,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Minor,RATIS-24 missed some changes in a few Hadoop Rpc tests so that they no longer compiled.,[],2017-02-21 21:58:05+00:00,2017-02-21 22:17:59+00:00,2017-02-21 22:17:59+00:00,Resolved,13044978,RATIS-25
Improvement,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,There are a few Hadoop Rpc specific config keys in RaftServerConfigKeys.  We should move them to the ratis-hadoop module.,[],2017-02-17 23:56:15+00:00,2017-02-18 23:35:47+00:00,2017-02-18 23:35:47+00:00,Resolved,13044153,RATIS-24
Bug,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,"A distributionManagement section should be added to the pom, for releases as well as snapshots.",[],2017-02-17 18:57:21+00:00,2017-03-09 01:22:50+00:00,2017-03-09 01:22:58+00:00,Resolved,13044065,RATIS-23
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Similar to ServerFactory, we should provide a ClientFactory to create RaftClientRequestSender objects.  The ClientFactory implementation can be automatically deduced from the RpcType.",[],2017-02-17 00:58:23+00:00,2017-02-28 22:43:16+00:00,2017-02-28 22:43:16+00:00,Resolved,13043815,RATIS-22
Sub-task,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Add an RpcType enum so that it can identify rpc implementations such as NETTY, GRPC, etc.",[],2017-02-15 22:55:25+00:00,2017-02-17 01:06:15+00:00,2017-02-17 01:06:15+00:00,Resolved,13043415,RATIS-21
New Feature,[],szetszwo,Tsz-wo Sze,szetszwo,Tsz-wo Sze,Major,"Currently, user has to know some RPC implementation details in order to use it correctly.  For example, for grpc, users has to set the following RaftProperties.
{code}
properties.setClass(RaftServerConfigKeys.RAFT_SERVER_LOG_APPENDER_FACTORY_CLASS_KEY,
          PipelinedLogAppenderFactory.class, LogAppenderFactory.class);
{code}
Also, users need to know the actual implementations of various interfaces.  such as RaftServerRpc and RaftClientRequestSender.  For grpc, the implementations are RaftGRpcService and RaftClientSenderWithGrpc.

We should provide a simple API to configure the RPC and hide the implementation details.",[],2017-02-15 22:53:18+00:00,2017-03-23 23:14:09+00:00,2017-03-23 23:14:09+00:00,Resolved,13043414,RATIS-20
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,We should include clientId and callId (which are used as key for retry cache) in raft log entries and use them for retry cache reconstruction in raft peers.,[],2017-02-09 19:32:54+00:00,2017-02-28 23:14:58+00:00,2017-02-28 23:14:58+00:00,Resolved,13041817,RATIS-19
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"When a raft peer becomes the new leader, it can commit entries belonging to the previous term only along with the entry with the new term. Before that commit happens, the new leader cannot determine exactly what entries should be applied to the state machine and the retry cache. The retry cache is complete only after the leader commits the first leader-placeholder entry.",[],2017-02-09 19:30:16+00:00,2017-02-18 02:18:03+00:00,2017-02-18 02:18:03+00:00,Resolved,13041814,RATIS-18
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,This jira will add the basic data structure definition for the retry cache.,[],2017-02-09 19:18:10+00:00,2017-03-31 07:18:14+00:00,2017-03-31 07:18:14+00:00,Resolved,13041809,RATIS-17
New Feature,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Critical,We do not have any metrics now. We need to add it everywhere...,[],2017-02-07 21:26:41+00:00,,2018-07-20 20:50:50+00:00,Open,13041132,RATIS-16
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"Add call ID in raft client. A client's request and its retry will share the same call ID. Remote Raft peers then can use ""Client ID + Call ID"" to identify the retry requests.",[],2017-02-07 19:38:45+00:00,2017-03-04 03:02:33+00:00,2017-03-04 03:02:33+00:00,Resolved,13041101,RATIS-15
Bug,[],jnp,Jitendra Nath Pandey,jnp,Jitendra Nath Pandey,Major,Ensure ip-clearance documents are provided for Ratis.,[],2017-02-07 00:20:26+00:00,2017-02-22 01:48:32+00:00,2017-02-22 01:48:32+00:00,Resolved,13040808,RATIS-14
Sub-task,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"Similar idea as HADOOP-9688. But since we need to support various RPC engines, the client id is not added in the RPC layer but in the raft protocol layer.",[],2017-02-03 21:44:04+00:00,2017-02-16 23:26:52+00:00,2017-02-16 23:26:52+00:00,Closed,13040252,RATIS-13
Bug,[],sebb,Sebb,sebb,Sebb,Major,"The entry in asf-authorization-template for ratis is:

ratis=jing9,szetetszwo,enis,aengineer,arp,cnauroth,jghoman,mayank_bansal,xyao,liuml07,umamahesh,jitendra,devaraj,gtCarrera9,hanishakoneru,xiaobingo,cliang

The following uids don't exist and need to be corrected to correctly grant karma:

gtCarrera9
szetetszwo
mayank_bansal

[1] https://git1-us-west.apache.org/repos/asf?p=infrastructure-puppet.git;a=blob;f=modules/subversion_server/files/authorization/asf-authorization-template;h=32252dc37991287817c4cf5bf549f8a029396ff9;hb=5c2268c8",[],2017-02-02 19:23:30+00:00,2017-02-02 22:06:00+00:00,2017-02-02 22:06:00+00:00,Resolved,13039918,RATIS-12
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,"We should have better retry policy support on the raft client side, such as different retry policies, more flexible retry parameter settings, etc.",[],2017-02-02 00:39:43+00:00,2018-11-30 23:19:17+00:00,2018-11-30 23:19:17+00:00,Resolved,13039654,RATIS-11
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Critical,"We need retry cache support on Raft servers to correctly handle client's retry requests. During leader re-election, a client may hit a {{NotLeaderException}} while the request has been committed by the old leader. The new leader should be able to correctly recognize the retry request from the client.",[],2017-02-01 23:34:47+00:00,2017-03-31 07:19:18+00:00,2017-03-31 07:19:18+00:00,Resolved,13039639,RATIS-10
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,We need more test cases for InstallSnapshot RPC. Currently we only have a basic test case in {{RaftSnapshotBaseTest}}. More test cases should be added to cover scenarios such as the snapshot is transferred in chunks.,[],2017-02-01 23:21:50+00:00,,2018-07-20 21:38:25+00:00,Open,13039638,RATIS-9
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Major,It's usually not recommended to use {{Optional}} as class fields. Let's use this jira to revisit the {{Optional}} usage in {{TransactionContext}}.,[],2017-02-01 23:18:37+00:00,2017-07-09 04:03:15+00:00,2020-04-29 15:02:13+00:00,Resolved,13039637,RATIS-8
Improvement,[],jingzhao,Jing Zhao,jingzhao,Jing Zhao,Minor,"The current SimpleStateMachine4Testing code can be further cleaned. E.g.,
# There is an unused import
# some member fields' access can be private

We can use this jira to cleanup it code.",[],2017-02-01 23:15:06+00:00,2017-02-22 22:27:24+00:00,2017-02-22 22:27:24+00:00,Resolved,13039635,RATIS-7
Task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,,[],2017-02-01 22:56:53+00:00,2017-11-30 18:47:48+00:00,2017-12-07 00:01:35+00:00,Resolved,13039629,RATIS-6
Task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"A project website is needed. Possibly, we can use bootstrap and fork already existing syles. 

https://phoenix.apache.org/
https://hbase.apache.org/
https://cassandra.apache.org/

Since Ratis is a podling it will be
  https://ratis.incubator.apache.org/
",[],2017-02-01 22:56:30+00:00,2018-01-21 21:44:01+00:00,2018-01-21 21:44:01+00:00,Resolved,13039628,RATIS-5
Task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,Jenkins unit test builds should be set up. ,[],2017-02-01 22:51:34+00:00,2017-11-02 21:48:23+00:00,2017-11-03 00:18:09+00:00,Resolved,13039626,RATIS-4
Task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,"A precommit checker would be pretty useful. We can use yetus for this, or do the old way via cloning the hadoopqa script. Our mvn structure is very similar, so should not be a hard issue. ",[],2017-02-01 22:49:46+00:00,2017-11-02 05:32:11+00:00,2017-11-02 05:32:11+00:00,Resolved,13039625,RATIS-3
Task,[],enis,Enis Soztutar,enis,Enis Soztutar,Major,I think we should change the version to 0.1-SNAPSHOT rather than 1.0-SNAPSHOT. We can do a couple of 0.x releases before 1.0. ,[],2017-02-01 21:05:45+00:00,2017-02-15 22:22:58+00:00,2017-02-15 22:22:58+00:00,Resolved,13039598,RATIS-2
Bug,[],sebb,Sebb,sebb,Sebb,Major,"The summary page includes the following committers:

szetetszwo 	Tsz Wo Nicholas Sze
mayank_bansal 	Mayank Bansal
hkoneru 	Hanisha Koneru

However the ids don't exist as ASF committer ids; looks like they are misspelt

Also the following looks wrong:

llu 	Li Lu

There is an ASF id 'llu' but that belongs to Luke Lu.
I suspect the name should be gtcarrera9

Please check the ids carefully and correct any mistakes.
Thanks.
",[],2017-02-01 13:50:56+00:00,2017-02-03 18:23:53+00:00,2017-02-03 18:23:53+00:00,Resolved,13039468,RATIS-1
